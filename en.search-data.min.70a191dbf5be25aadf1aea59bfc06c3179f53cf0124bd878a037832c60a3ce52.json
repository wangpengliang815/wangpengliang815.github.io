[{"id":0,"href":"/docs/acp/pmi-acpdown/","title":"Pmi Acpdown","section":"所有文章","content":"\n"},{"id":1,"href":"/docs/acp/pmi-acp%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/","title":"Pmi Acp基础了解","section":"所有文章","content":"PMI 认证体系# PMI（Project Management Institute）认证计划以适应全球化的发展和应用而著名，这一特点使PMI认证得到了跨行业、跨地域的认可。同时，PMI认证不受限于任何一种方法、标准或组织来应用，这一通用性使得持证人士在不同职业发展阶段和各种项目场景上都更具职业发展优势。\nPMI-ACP# 熟练运用敏捷、善于协作、积极应对复杂的环境、快速响应，都是现今商业环境亟需的技能。\nPMI敏捷管理专业人士（PMI-ACP）认证表明持证人士掌握敏捷原则、知识、技能和方法。如果具备敏捷技能，通过PMI-ACP认证将使你的能力进一步被雇主、相关方、同事所认可。\nPMI-ACP涵盖了多种敏捷方法，如Scrum、看板、精益、极限编程（XP）和测试驱动开发（TDD），因此可根据项目需求灵活多样地运用敏捷方法。\n申请对象# 在敏捷团队中工作，或者所在组织正在采用敏捷实践，可以考虑申请 PMI-ACP 认证。与其他仅基于培训和考试的敏捷认证相比，PMI-ACP表明持证人士具备实际的敏捷经验和技能。\n拿证和续证# PMI-ACP认证考试形式为120道选择题，考试时间为3小时 为维持PMI-ACP认证的有效性，必须每3年积累30个与敏捷相关的专业发展单位（PDU） 报考条件# 教育背景：中等学历(高中文凭，大专学历，全球同等学历及以上) 普通项目经验：需在申请之日起前五年内在项目团队工作2000小时(12个月) 敏捷项目经验：需在申请之日起前三年内在项目团队运用敏捷方法工作1500小时(8个月)，这些工作时长是在普通项目经验要求的2000小时以外的 PMI-ACP 与PMI-PMP# ACP 和 PMP 都是PMI体系下的，PMP全称 Project Management Professional (项目管理专业人士认证)。PMP证书作为项目管理专业人士的重要标志，在众多企业尤其是跨国企业中被认为是项目经理岗位的必备条件，同时也是许多重大项目招标中项目经理人员必备的资质证明。目前全球有100多万PMP，中国也已经有20多万人通过PMP认证考试，PMP证书正获得越来越多的职业人士的青睐，被誉为与MBA、MPA齐名的全球三大管理证书。\nPMI-ACP 考试是由美国项目管理协会(PMI)于2011年推出一门敏捷项目管理的考试，全称 Agile Certified Practitioner。PMI经过多年调查发现许多项目需求不断地变更，成员小于10人的团队 ，套用以往“先做计划再做事”的思维，项目根本推不动。因此，PMI提倡采用敏捷(Agile)的方法管理充满变动的项目，并从2011年开始正式推出 PMI Agile Certified Practitioner(PMI-ACP) 认证，使项目经理能够具备快速应变的能力\nPMP是传统项目管理模式，它的雏形是建筑工程项目，然后将其理论化、标准化、抽象化，形成一个 universal 的项目管理框架，但将PMP应用到软件工程中在实践层面时会觉得比较别扭，主要问题是软件工程的不确定性远高于其他行业。ACP是起始于软件工程，同时在向其他行业领域推广，所以ACP更适合软件行业，但有PMP的知识作为支撑是更强的组合。\nPMP 学的是标准的项目管理知识体系，侧重理论知识。ACP主要学习敏捷方法和策略，侧重敏捷开发管理\n参考# https://pmichina.org/certification/index.jhtml\n"},{"id":2,"href":"/docs/acp/pmi-acp%E5%A4%87%E8%80%83%E7%AC%94%E8%AE%B001/","title":"Pmi Acp备考笔记01","section":"所有文章","content":"为什么选择敏捷？# 传统项目管理特点# 预测性性生命周期 通过文档驱动（每个人对于文档理解力不一样可能会导致执行过程中有偏差） 过程控制（需要项目经理在过程中跟踪整个执行过程） 带来的问题：\n交付周期长 软件质量无法保证 团队士气弱（长期做同一个产品但一直得不到反馈） 按时发布率低（技术债务导致无法按时发布） 沟通效果差（文档的变化带来沟通不及时） 进度延期久 三边四没六拍# 三边# 边计划 边实施 边修改 四没# 开始时，没问题\n过程中，没关系\n失败时，没办法\n总结时，没资源\n六拍# 拍脑袋（领导拍脑袋提出想法） 拍肩膀（领导拍项目经理肩膀好好干） 拍胸脯（项目经理拍胸脯保证完成任务） 拍桌子（项目执行各种扯皮拍桌子） 拍屁股（干不下去拍屁股走人） 拍大腿（领导承担最终结果拍大腿后悔不该做） 敏捷管理特点# 透明（所有事项都会通过 US、Backlog 等形式开放给团队所有成员看到） 检查（每日站会、迭代回顾） 适应变化 带来的好处：\n快速交付 降低风险（短周期迭代持续反馈提高预见性） 适应变化（小步快跑快速验证产品需求及调整方向） 更好的质量（通过持续集成及频繁测试保证代码质量更高） 持续完善（迭代结束进行回顾检视团队动向） 更高的满意度（高优先级的需求快速交付便于快速实现商业价值） 快鱼法则# 当今市场竞争不是大鱼吃小鱼，而是快鱼吃慢鱼，这就是快鱼法则\nMVP思想# MVP（最小可行化产品，Minimum Viable Product）思想：先在市场投入极简的原型产品，通过不断试错，学习和有价值的用户反馈，对产品进行快速迭代以适应市场\n迭代和增量# Scrum基于迭代开发和增量开发。\n迭代开发# 迭代开发承认我们在把事情做对之前有可能做错，在把事情做好之前有可能做坏。迭代开发本身是一种有计划的修改策略。通过多次开发来改善正在构建的特性，逐步得出一个完善的解决方案。不过产品迭代开发的最大缺点是在遇到不确定因素的时候，很难事先确定需要改进多少次。\n此图非常经典，用于阐述很多敏捷方面的概念和理念。最开始是解释 MVP 的概念，但是正好借助MVP也可以更好的理解迭代开发。\n需求：客户需要一种工具，希望可以从A地快速的到达B地。于是研发团队开始开会研究，假设他们严格的执行了迭代开发的原则（因为他们也不确定最后造出来的到底是什么）。因为用户的需求很迫切，研发团队要快速的占领市场。所以首批推向市场的工具：滑板。\n交到用户手里时，用户很高兴。这个小东西可比走路快多了。但是随着使用的时间增加，会很累。研发团队在得到用户的反馈之后，又快速迭代。在原有滑板的基础上，增加了扶手装置。有了扶手装置，明显没有那么累了。但是长距离使用时，还是需要一只脚登地发力，还是很累。\n好，又得到了用户的反馈。针对反馈优化产品放入下一轮迭代。这次交付到客户手中的产品，被设计成了一个具有两个大大轮子的东西。用户骑起来，果然又快又省力。可是用户又问，还能更快吗？\n还能更快吗？对于研发团队没有什么做不到的，发挥集体智慧。在第四个迭代完成后，交付到客户手中的是具备发动机提供动力取代人力的东西。根本不需要人出力，用户非常的高兴。\n这个时候用户已经可以很快的从A地到达B地了。但是用户的需求永远的不会满足，“我需要带着我的家人去海边度假”，“我需要拉些重物到XX”。最后交付到用户手中，是一辆崭新的骑车。\n从一开始用户提出需求后，任何人都没有想到最后交付的尽然是一辆汽车。但是这些都是在一次一次不断的迭代中，逐步形成的。但是这其中有一个环节是不能被忽视的，发布、反馈和调整。这是一个正向的闭环。发布完版本之后，听取使用者的反馈再根据反馈进行调整。反馈可能或者一定与研发团队预想的不一致，所以需要先接纳变化，内化后再输出。\n增量开发# 增量开发基于一个古老的原则：先构建部分，在构建整体。避免到最后才冒出一个大的、爆发式的活动，集成所有组件和交付所有产品。相反把产品分解成更小的特性，先构建一部分，再来做出调整，构建更多的特性。\n增量开发展示了一个重要的信息，使我们能够适应开发工作并改变工作方式。增量开发中最大的缺点是逐步构建的过程中，有迷失全局的风险。\n哪些项目适用于敏捷# 需求、技术明确。采用传统项目管理足以成功 需求、技术都不确定，适合使用敏捷 三角倒置# 传统项目管理（计划驱动） 敏捷项目管理（价值驱动） 敏捷思维# 价值驱动、优先排序 尽早交付、及时反馈 转变思维、三角倒置 敏捷宣言# 个体和交互胜过流程和工具 重视个体和团队的力量 坚持以人为本、倡导共同参与 一种流程不一定适用于所有团队，不同的人具有不同的工作方式 可工作的软件胜过面面俱到的文档 文档够用就好 just enough just in time just because 5-why 法获取需要该文档的根本原因 避免镀金 客户合作胜过合同谈判 提倡跟客户合作，聚焦于谈判阻碍客户价值的输入势必造成对立关系 响应变化胜过遵循计划 变更是创造伟大产品的有价值的工具 去除低优先级的需求 敏捷12条准则# 没有什么方法可以保证团队一定能开发出完美的软件，敏捷的团队也是同样的，所以有一系列的原则来帮助敏捷团队\n尽早、持续地交付有价值的软件，让客户满意\n欣然面对需求变化，即使在开发后期。敏捷过程利用变化为客户维持竞争的优势\n频繁地交付可工作的软件，从数周到数月，交付周期越短越好\n在团队内外，面对面交谈是最有效，也是最高效的沟通方式\n在整个项目过程中，业务人员必须和开发人员每天都在一起工作\n以受激励的个体为核心构建项目。为他们提供所需的环境和支持，相信他们可以把工作做好\n可工作的软件是衡量进度的首要标准\n敏捷过程倡导可持续开发\n坚持不懈的追求技术卓越和良好的设计，以此增强敏捷的能力\n简单是尽最大可能减少不必要工作的艺术，是敏捷的根本\n最好的架构、需求和设计来自自组织的团队\n团队定期反思如何提升效率，并依此调整自己的行为\n客户总是对的吗？\n一个好的开发团队要交付给客户真正需要的东西，而不是提供给他们要的东西。亨利.福特曾经说过一句话“如果我问人们想要什么，他们肯定会说想要更快地马（而不是汽车）”。这个事情说明客户无法在一开始就告诉你他想要的是一辆汽车而不是一匹更快地马。\n敏捷所说的12条原则的初衷就是让团队构建用户真正需要的产品，有价值的软件。但是每个人都会看到软件中不同的价值，那么就要求每个人都想想其他利益相关人，想他们各自关心的事情，想想软件会给他们带来的价值。任何新产品在第一次面市的时候都是功能不全面的，尤其市面上没有同类产品的时候，随着时间以及版本的更替，产品会解决越来越多的问题，以及会变的越来越好用，我们现在去看当初的产品肯定很容易就看出来其中的问题，但是在项目刚刚开始的时候是很难思考全面的。\n按我现在说的做，而不是按我之前说的做\n很多公司做一个项目或者产品的时候会在一开始组织专门的人员找齐全部利益相关人开会讨论，然后将所有的信息整合到一起形成一份说明书，然后再发送到各利益相关人那里进行评审，然后再开会讨论，再出一份更好的说明书，一次一次的可能要耗费好几天，最终形成一份各方面都满意的说明书。拿给开发团队评估工期，综合各方面可能要1、2个月之久，但是各利益人都觉得很不错，因为一年之后就可以拿到一个非常棒的产品。经过一年的奋斗，开发团队终于交付了产品，产品与说明书相差无几，准确地展现了各利益人所要的功能。但是结果呢，往往一年的时间市场已经变化，一年前很被市场需要的软件并不被当前的市场所需要。\n市场存在着变数，一些变数在项目初期是可以被发现的，但是更多的变数都是在项目开始的时候无法被发现的。但是说明书已经制定了，而开发团队又不喜欢自己做的东西不停的变化。所以团队要快速地响应市场以及各利益相关人的变化，敏捷的几项原则就是帮助团队应对这种变化的。\n原则1：尽早、持续地交付有价值的软件，让客户满意\n敏捷团队最重要的事情就是给客户交付可工作的软件。而这条原则就包含三点，尽早发布软件、持续交付价值、让客户满意。\n没有什么事情的完美的。尽管在项目一开始每个人都想一次性的提出全部的需求，但是问题在于客户在真正拿到可工作的软件之前，都不清楚应该提什么样的需求。所以就要求开发团队尽早的交付，尽早的给客户一个可工作的软件，即便是仅交付了一个可工作的特性，也是一种突破。这对整个团队都是有益的，因为客户可以给出有价值的反馈，这样开发团队才能朝着正确地方向推进项目。\n尽早交付也有一个缺点，就是最初交付给客户的软件完成度非常的低。很多客户很难忍受一个仅有部分功能，还有可能存在大量BUG的软件，这些客户往往认为既然交付就要交付完整地产品。\n敏捷的核心价值观里有一句，客户协作高于合同谈判。这就要去客户也要能够和开发团队一起成长，一起协作，共同逐步完善产品。如果客户非常官僚，那么团队就必须全新的变更管理流程，这要去与客户重新进行一轮合同谈判。真正与客户协作的团队可以在开发过程中任意进行任何有必要地改变，这也是持续交付的意义所在。而团队确定哪些特性能交付价值的唯一方法就是与客户协作，并利用前一次迭代收到的反馈。从短期看，团队可以通过尽早交付价值让客户满意，从长期看，交付最终产品的时候可以使得价值最大化。\n原则2：欣然面对需求变化，即使是在开发后期。敏捷过程利用变化为客户维持竞争优势\n如果做项目就会面临着大量的变化，尤其是老板不会顾及工作量，也不会改变截止时间，当这种情况下存在大量的变化时，开发人员就一定会有情绪，从而形成恶性循环。\n为什么会使得开发人员抱怨不止，因为在需求变更之前，开发人员会认为项目进展的很好，而且可能做了很多决策：如何规划产品结构，要开发什么产品，向客户承诺交付什么。结果一个项目外的人突然告诉你这个计划里有错误，而且是你的锅。给开发人员说它错了，是很难接收的。尤其说的人还享受着他的服务，就好比，你做了一盘菜给别人吃，那个人一边津津乐道的吃，还一边骂你做的菜难吃如屎。开发人员对自己所做的工作都是有一种自豪感的：我们交付的产品我们能负责，而且能满足用户的需求。而变化就是在质疑这种自豪感。瞬间就会感觉自己的努力没有得到尊重。\n而开发人员如何才能够接收变化。简单地说就是站在客户的角度去看待问题。其实客户也不愿意给开发人员提出变化，因为这就是要求他们承认自己在一开始犯了错误，让开发人员白做了很多事情。正因如此，往往客户都是很晚才来告诉开发人员变化，因为他们知道自己带来的是坏消息，这是让人很难堪的行为，客户还要为整个变化买单。所以，将心比心，开发和客户都要做一些不可能的事情，开发人员被要求读懂客户的心，客户被要求能预测未来。\n要做到能够欣然接收变化，就要意识到以下几点：\n不要认为有变化就要有人要倒霉。每个人都要求知道犯错了以后就立即改正而不是期待一开始就做到完美\n我们是一条绳上的蚂蚱。每个人包括客户都要对全部需求以及变化负责，争论谁对谁错是没有意义的，抱怨变化是没有意义的\n我们不把变化拖到最后。谁都不愿意犯错误，但是这是难免的，那么就要尽早修复，将损失降到最低\n我们不要再把变化当做犯错。在当时的信息环境下，能做到那个程度已经很好了，出了错事才会让路变得更加明朗\n我们通过变化学到东西。变化才是团队成长最有效的方式\n原则3：频繁交付可工作的软件，从数周到数月，交付周期越短越好\n对于敏捷实践者来说，传统的实践方法被称作“命令-控制”。这种方式与军事的命令-控制的方式是一致的。“命令”指的是项目经理给团队分配任务的方式。尽管并不是所有成员都向项目经理汇报，但是项目经理仍然可以控制所有人的任务分配。“控制”指的是项目经理管理变化的方式。无论是项目内的变化还是员工休假、机器故障，亦或是其他一些无关的变化，都在项目经理的监控之内。当变化时对其进行评估，更新项目计划，在进度安排和文档中引入变化带来的改变，给团队分配新的任务，管理利益干系人的期待，不要让人感到意外。使用敏捷的传统项目负责人不愿意欣然接受变化的原因就是害怕变化引起的混乱。\n那么，如何才能又能欣然的接受变化，又能不引入混乱？关键在于频繁发布可工作的软件。团队将迭代的周期缩短，在每一轮迭代结束的时候，都可以交付一个可以使用或者演示的软件，然后计划下一个迭代要干什么，这样一个可预测的进度安排和持续检查可以帮助团队尽早掌握变化，同时也创建了一个没有责备的氛围。传统项目经理最大的困难就是监视变化，每日审查和迭代回顾相当于让整个团队帮助项目经理尽早的发现变化，避免将变化放在项目的晚期，从而防止这些变化对项目造成更严重的影响。\n传统的瀑布式流程一旦定义好需求就把开发团队和客户完全隔离开，而敏捷团队采取的则完全不同，后者始终与客户交互。这样就可以及时响应变化，开发出更好地产品。但是每当发现项目确实需要修改的时候，都有一半人返回去更新规格说明书，以保证计划保持最新的状态。越来越多的人觉得文档太多，但是每当想砍掉一些内容的时候，就会有人说如果不写某项功能、需求、设计或测试用例，那么就会有人产生误解。如果最终的实现不正确，他们就会因此遭到谴责。于是，文档中的任何一部分看上去都是必要地，因为少了任何一部分团队都有可能开发出错误的软件。\n一直以来各个团队都对文档写多少而感到困惑，一直都在努力找到一种平衡。那么对于敏捷团队来说，文档写的够项目开发用就可以了，具体要参看团队要解决的问题以及沟通的情况。一个原则就是如果某种文档不能给团队开发软件带来帮助，而且也没有必须写的原因，那么敏捷团队就不写这种文档。\n原则4：在团队内外，面对面交谈是最有效、也是最高效的沟通方式\n为什么要写文档，并不是因为要写出来一份东西，而是要把我的想法告诉你，使我脑子里地想法和你脑子里地想法仅可能的接近。为什么面对面的交谈是最有效的，而且大于文档。因为我们都知道，一份完整地文档是很难实现的，而且是非常耗时的，到最后完成的文档又不一定在项目中有用。然而面对面去交谈，就很容易形成头脑的风暴，很容易让大家的思想达到统一，这正是交谈的良好方式，一有什么变化就可以立即进行讨论。\n团队沟通的终极目标是形成一种集体意识，在成员之间建立不必直说也能领悟的共同知识。一个团队能够形成集体意识，越能共享同样地视角，就越容易对同样地问题形成一致的答案。这为团队构筑了处理变化的坚实基础，可以跳过冲突，立即编写代码，而且不会因为维护文档而分心。\n原则5：在整个项目中，业务人员和开发人员必须每天在一起工作\n为了完成出色的软件，开发团队需要与业务人员进行大量面对面的讨论，业务人员了解需要什么软件，因为他们在没有软件的情况下开展了同样地工作，有了业务人员的陪伴，研发人员可以及时更改自己的开发方向，但是业务人员往往希望开上一两次会就解决剩下的问题，因为他们同样也有自己的工作。\n如何解决这个问题，首先双方要都认识到，团队要给公司开发带来价值的软件。完成后的软件应该值得公司的投入。如果软件带来的价值超过了开发软件的成本，那么公司就值得在这项开发上面投入资金。一个好的项目应该有足够的价值让业务人员赶到值得投入精力。所以业务人员应该与开发人员坐在一起工作，尽早的处理变化，因为后期修改的成本会很高。而业务人员应该很喜欢跟敏捷的团队一起合作，因为传统的开发团队把业务人员看做谈判的客户，而敏捷团队则是与客户合作的，在项目进行过程中客户具有平等的发言权。\n原则6：以受激励的个体为核心构建项目，为他们提供环境和支持，相信他们可以把工作做好\n如果团队里地每一个人都认为自己开发的软件是很有价值的，是能够给公司带来利益的，那么这个团队就会越来越好。相反，如果团队成员看不到软件的价值，或者他们没有因为开发优秀软件而得到奖励，那么在这种情况下，项目就会失败，因为项目中最重要的是人。现在大多数公司的考核与绩效往往不利于员工开展高效的敏捷方法。\n大多数公司的问题为：\n在代码审查中，如果不断发现bug，那么这个程序员就会得到糟糕的评价，如果没有发现bug，那么这个程序员就会得到奖励。（这会导致程序员在代码审查中不愿意去寻找bug。）\n根据发现bug的数量去奖励测试人员。（这会导致测试人员挑刺并且奖励报告的质量。这种方式还会使得程序员和测试人员之间产生敌对情绪，会阻碍程序员和测试员之间的合作。）\n根据业务分析员产出的文档量去判定其绩效评级（而不是根据他们与团队分享的知识量评评级）\n所以以这种绩效去考核程序员，最终出来的内容肯定不会好，一个很好的团队应该根据成员对团队的贡献去进行考核，鼓励贡献多的人员。比如认识到软件并没有解决的某个业务问题并将其修复的程序员，以及能够发现代码或架构中的问题并提交给团队的测试人员。\n不好的氛围容易引发一种一心自保（Cover Your Ass，CYA）的态度，在这种态度下，测试人员会努力确保每一项需求都有测试覆盖，而不去考虑测试到底能不能对软件的质量有所帮助。程序员会严格遵循需求文档中的每一个字，而不去认真想一想自己开发的功能是不是真正给用户带来价值。在这样的公司经理自然想找一个“始作俑者”为那些因变化而产生的额外工作量而负责。当这种趋势不可避免的时候，团队里的成员会逐渐转向编写“防御性文档”以保护自己。为了避免糟糕的考核或惩罚，他们可以把责任撇向他们所遵循的那部分文档。\n过于详尽的文档会增加需求含糊以及团队成员之间误解和沟通的风险。敏捷团队最有效的沟通方式就是面对面的沟通，并且输出最少的文档，让开发人员和业务人员每天工作在一起，尽快的交付最大价值的产品，并且在团队中每一位成员都会有项目的责任感，因为他们都要对项目负责，并且他们都可以为项目做出正确地决定。\n原则7：可工作的软件是衡量进的的首要标准\n好的团队合作会确保所有人在任何时刻都了解项目的进展。\n在传统的“命令-控制”项目经理眼中，要想掌控项目的进展就要让成员经常更新项目的状态。但是状态汇报是很难获得项目的真正状态。汇报本身就不是一种完美的沟通工具，而且还带有很浓重的政治色彩，而且所有的项目经理到知道有时候需要在状态汇报中略去一些会让经理和团队主管难堪的东西，而别人常常需要用这些信息进行决策。\n所以，最好的汇报方式就是一个可工作的软件，只要真切的看到了软件在眼前工作，那么你就“得到了”项目的进展。当看到软件中缺少或者不满意的部分，相关人员就会主动去沟通下一步的计划了。敏捷团队在每一轮迭代结束的时候交付可工作的软件，通过真实地产品向大家展示具体成果，团队可以让大家掌握项目进展的最新情况，而且这种方式几乎不可能让人产生误解。\n原则8：敏捷过程倡导可持续开发。赞助商、开发人员和用户要能够共同、长期维持其步调，稳定向前\n很多团队就会出现一种现象，每当截止日期临近的时候，就会出现拼命的加班，尤其是在晚上和周末。这种做法是不可靠的，一个团队可以拼命工作几个星期干更多地活，但是团队的工作效率一般都会再这段时间过后一落千丈。人们会感到疲劳，而且由于加班而耽误的事情，最终都会找上门来，然后就会付出更多的时间和精力去处理。因此敏捷团队要做的就是可持续的开发节奏。会预留时间，并且制定一个切实可靠的计划，通过迭代。因为每次预估的都是接下来一周、两周的公布工作内容，而且承诺的仅是可以交付的内容，所以就不会动不动的加班，从而形成一种良性循环。\n可持续的开发节奏就是给予团队足够的开发时间，让成员不需要工作到深夜，也不需要周末加班的节奏。\n原则9：坚持不懈的追求技术卓越和设计优越，以此增强敏捷的能力\n计划做的太夸张并不是老加班的唯一原因，有的时候看起来是一个很简单地功能，当做起来就觉得有点难度，而随着越做越深入，就觉得这是一个坑。然后发布了以后本来可以轻松的转向其他的事情，但是却要不停的修复这个功能的bug以及打补丁。所以从长久来看设计良好的代码会大量减少后续的维护工作。但是这并不是意味着在软件一开始就进行完整地设计。而一个良好的程序员会再编写的时候不停的寻找设计和代码的问题，一旦发现问题，就会立即进行修复。在项目的开发过程中，只需要在当下多花一点点时间编写可靠的代码并及时修复问题，那么留下来的这份代码库在未来就会非常好的维护。\n原则10：简单是尽最大可能减少不必要工作的艺术，是敏捷的根本\n在开发软件的时候，要尽量的简单，解除耦合性，因为如果项目比较复杂，那么在向项目中添加新的代码的时候就会让项目变得越来越复杂，因为有了依赖关系，变化导致系统另一部分发生变化的可能性会提升，后面还有可能导致第三个变化，到最后就会形成多米诺效应。而产出好的代码的方式就是以最少计划启动项目，但是人们往往认为没有良好的计划，那么将来面对变化的时候就会很头疼，因为如果现在就开始编码的花，那么以后遇到变化的话，就有可能删除现在的代码。\n避免这种现象的方法就是迭代式的编程，每轮迭代都开发没有太多依赖或者不必要依赖的代码系统。编码的时候如果团队仅基于一些智能实现单一功能的小型自包含单元进行设计，那么就可以很好地避免多米诺效应。那么哪些单元是很有必要的，就要去业务人员与开发人员经常的进行沟通，确保只开发有价值的特性，因为后期维护一些没有价值的特性往往比这些特性给公司带来的价值要高。\n原则11：最好的架构、需求和设计来自自组织的团队\n有大量事前设计的团队非常容易做出过于复杂的设计。因为在设计和架构的阶段就要尽全力就必定意味着要构建可以做到的最棒的架构。如果提出的需求比较少而且设计太简单，那么从直觉上就会给人一种偷工减料的感觉。只有他们拿出一份巨大的需求文档和一个复杂的设计才不会让人质疑。过于复杂的设计又会舍得后期做变化的时候陷入恶性循环。\n那么一个比较好的方式就是组织自组织的团队（self-organizing team），没有明确地需求和设计环节。这个团队会一起对项目进行规划，并且会作为一个团队进行改进计划，没有明确地领导，也就没有很多的干预项，他们会把项目分解成多个部分，从能给公司带来最大价值的部分着手，然后再考虑详细的需求、设计和架构。这样的团队所有人都会对架构进行设计，每个人都有责任，每个人都说的算。这样的团队就很容易循序渐进，从而设计出一个增量式的方案。\n原则12：团队定期反思如何提升效率，并依此调整\n一个敏捷团队如果不能持续地改进构建软件的方式，那么团队就不算敏捷。敏捷的团队会不断的对项目进行检查，不断的进行优化，他们会从项目中学习，通过检查的结果对未来进行改造。而且他们并不只是在项目结束的时候这么做，他们会每天都在寻找需要改进的地方。增强团队实力的唯一方式就是经常回顾自己已经做的事情，然后评估作为一个团队这些事情做得怎么样，最后提出改进的计划。要经常回顾过去，看看哪些事情做对了，哪些事情做错了。这需要揪出具体的问题和错误，而很少有人会对公然指出其他的错误而感到自在。随着时间的推移，团队中的成员会对这件事情感到越来越自然。最终，大家会认为这是提意见而不是挑刺。\n很多团队认为他们并没有时间去进行这件事情，他们在一个项目结束了以后就会立即投入下一个项目中，认为与其花时间在这个上面还不如投入到下一个项目中。那么就要求团队在制定计划的时候就给项目结束后预留一些时间来进行回顾，因为这件事情很重要，团队成员可以从这其中吸取教训，提高效率。\n整合所有的原则\n一个好的敏捷团队是要整合所有的原则，而不是从中寻找几个实践，整合这些实践的关键在于团队的思维方式，敏捷的价值观和原则是思维背后的动力。敏捷团队不仅要诚实的回顾开发软件的方式，还要回顾成员交流的方式，以及与公司其他同事交流的方式。首先要理解原则，然后要理解其中的原理，还要在工作中不断的评估和改进。\n并且敏捷团队的沟通方式可以让开发人员真正的进步，因为他们的团队很可能是自组织团队，每个人都会去进行自主的学习，因为团队的知识决定了项目的宽度，并且团队成员自己会决定让团队正常运转的沟通内容，这不仅可以开发出更好地产品，而且你还可以向坐在身边的开发人员取长补短。\n"},{"id":3,"href":"/docs/acp/pmi-acp%E5%A4%87%E8%80%83%E7%AC%94%E8%AE%B002/","title":"Pmi Acp备考笔记02","section":"所有文章","content":"Scrum 简介# Scrum 是一个用于开发和维持复杂产品的框架，是一个增量的、迭代的开发过程。在这个框架中，整个开发过程由若干个短的迭代周期组成，一个短的迭代周期称为一个 Sprint ,每个 Sprint 建议长度是2到4周，在Scrum中使用产品 Backlog 来管理产品的需求。\nBacklog 简介# Backlog 是一个按照商业价值排序的需求列表，列表条目的体现方式通常为用户故事。\nScrum的334(5)5原则# 3-Roles（角色）# Product Owner (产品负责人) Scrum Master（团队负责人） Dev-Team（开发团队） 3-Artifacts（工件）# Product Backlog（产品功能列表） Sprint Backlog（迭代冲刺列表） Burn-Down Chat（燃尽图） 4-Ceremonies（仪式）# Sprint Planning Meeting（迭代计划会议） Daily Scrum Meeting（每日站会） Sprint Review Meeting（迭代评审会议） Sprint Retrospective Meeting（迭代回顾会议） Sprint（最新的Scrum会把Sprint也当做一个仪式） 5-Values（价值观）# 开放 勇气 尊重 专注 承诺 Scrum 相关会议# Scrum 项目阶段# 敏捷角色与职责# PO# PO是有授权的产品领导力核心，是Scrum团队的三大角色之一。\n产品负责人需要面对2个方向：\nPO必须很好地理解组中利益干系人、客户和用户的需求和优先级。从这个角度而言，PO担任产品经理的角色，确保能开发出正确的解决方案。 PO必须保证已经有明确的接收标准，标准满足后续测试验证的标准。从这个角度而言，PO做的是业务分析师和测试人员的工作。 职责\n管理经济效益\nPO要负责确保在版本、Sprint和产品列表层面都能够持续做出良好的经济决策。\n参与规划活动\nPO是组合规划、产品规划、版本规划、冲刺规划的重要参与者。\n组合规划时，PO负责人与内部利益干系人一起把产品放到组合列表中正确的位置并确定产品开发工作的起止日期\n产品规划时，PO与利益干系人一起制定产品愿景\n版本规划时，PO与利益干系人以及Team一起确定下一个版本的内容\n冲刺规划时，PO与Dev Team一起确定Sprint目标\n梳理产品列表\nPO负责管理产品列表的梳理活动，包括US的建立、细化、估算和排列优先级顺序。并不是所有的梳理工作都需要PO自己执行，但是在执行期间，PO负责解答问题，澄清疑问\n定义接收标准并验证这些标准是否满足\nPO负责为每一个US定义接收标准。还可能会写对应接收标准的测试用例，可以找他人协助完成 PO最终负责确认US是否满足接收标准，做产品验收测试 PO要在Sprint执行的过程中验证接收标准，而不是Sprint Review时，这一点很重要 与开发团队合作\nPO必须与Dev Team紧密合作，每天参与Team活动。若是参与不足，不能及时给出必要的反馈，而等到最后反馈时，他产生的价值已经大大降低。参与不足，会给Team带来产品返工的人力资源等损失，项目被迫延期等风险。\n与利益干系人合作\nPO是内外部利益干系人团队的唯一代言人。\n日常工作内容\nPO参与组合规划 PO参与产品规划，与利益干系人一起构思新产品 Sprint前，PO负责制定Sprint计划 Sprint内，PO要参加Daily Meeting。例会上听取情况，了解进展，提供协助 PO必须每天能够解答问题，并进行验收测试 Sprint内，PO还要确定下个Sprint的计划及优先级顺序 PO参与Sprint Plan，对产品列表进行梳理 Sprint结束时，PO要参与show case 和 Sprint RetroSpect Scrum Master# 作为 Scrum 流程的捍卫者和布道者，ScrumMaster在Scrum团队中起到至关重要的作用，他们确保团队使用正确的流程，确保团队正确地召开各种会议，帮助每个人理解Scrum 理论、实践、规则和价值。\nScrum Master 对 Scrum 团队而言，他/她是一位服务型领导。Scrum Master 帮助Scrum 团队之外的人了解他/她如何与Scrum 团队交互是有益的，通过改变他/她们与Scrum 团队的互动方式来最大化Scrum 团队所创造的价值。\nScrum Master服务于产品负责人\nScrum Master以各种方式服务于产品负责人，包括：\n尽可能确保Scrum 团队中的每个人都能理解目标、范围和产品域 找到有效管理产品待办列表的技巧 帮助Scrum 团队理解为何需要清晰且简明的产品待办列表项 理解在经验主义的环境中的产品规划 确保产品负责人懂得如何来安排产品待办列表使其达到最大化价值 理解并实践敏捷性 按要求或需要引导Scrum 事件 Scrum Master服务于开发团队\nScrum Master以各种方式服务于开发团队，包括：\n在自组织和跨职能方面给予开发团队指导 帮助开发团队创造高价值的产品 移除开发团队工作进展中的障碍 按要求或需要引导Scrum 事件 在Scrum 还未完全采纳和理解的组织环境中指导开发团队 Scrum Master服务于组织\nScrum Master以各种方式服务于组织，包括：\n带领并指导组织采纳Scrum 在组织范围内规划Scrum 的实施 帮助员工和利益攸关者理解并实施Scrum 和经验产品开发 引发能够提升Scrum 团队生产率的改变 与其他Scrum Master 一起工作，增加组织中Scrum 应用的有效性 用户故事# 简介# 角色：谁要使用\n功能：需要完成什么样的功能\n价值：为什么要完成这个功能，这个功能有什么价值\n格式# 作为 \u0026lt;用户角色 who\u0026gt;，我需要 \u0026lt;功能 how\u0026gt;，以实现 \u0026lt;业务价值 why\u0026gt;\n注意：用户故事不能使用技术语言描述，要使用用户可以理解的业务语言描述\n3C 法则# Card（卡片）\nConversation（会话）\nConfirmation（确认）\nIVNEST 原则# Independent（独立性）# 要尽可能让一个用户故事独立于其他的用户故事 依赖太强会导致制定计划、确定优先级、工作量估算都变得很困难 Valuable 有价值# 每个故事必须要对客户具有价值 Negotiable（可协商性）# 内容要是可以协商的，用户故事不是合同 对用户故事的一个简短描述，不包括太多细节 Estimable 可估算性# 开发团队需要估计一个用户故事以便确定优先级，工作量，安排计划 Small 短小# 要确保在一个迭代或Sprint 中能够完成 Testable 可测试性# 一个用户故事要是可以测试的，要有验收标准 如何写好用户故事# 聚焦用户 功能≠价值 使用场景 从Epic开始 明确验收标准 验收标准 AC（Acceptance Criteria）# 敏捷测试中 user story 的重要组成部分 Ac是根据 user story 的阐述制定的验收标准 Ac初稿由BA根据客户的需求来编写，需User、BA（业务分析师）、QA、和Dev共同Review 每条Ac都应体现业务价值，是story的功能集，是story 交付时必须满足的一组条件 测试用例 Tc（Test Cases）# TC主要由测试人员根据AC编写，BA、QA、和测试一起Review 从开发流程讲，TC应该是story交付前必须执行的测试 从内容上讲，TC是AC的具体实现，应该比AC更详细 TC还应包括很多异常测试永猎 Product Backlog# PB是条目化/量化的用户需求，将需求文档中需要实际开发的需求（包括功能性和非功能性）条目化的表达出来。\n用户故事拆分方法# 基于业务流程步骤拆分# 基于用户流程。将整个故事拆分多个环节，将每个环节还原成具体的用户场景\n推迟性能实现# 先让用户基本故事跑起来，再满足性能要求\n化繁为简# 先完成最核心的版本，再通过其他用户故事完善功能\n主要投入# 根据主要投入或工作量来拆分\n界面入口多样性# 是否考虑先试用简单界面入口获取同样数据\n业务规则多样性# 先满足一种规则，后续完善其他规则\n# "},{"id":4,"href":"/docs/acp/pmi-acp%E5%A4%87%E8%80%83%E7%AC%94%E8%AE%B003/","title":"Pmi Acp备考笔记03","section":"所有文章","content":"用户故事地图# 敏捷估算与估算方法# 什么时候估算# 在第一个Sprint开始前 Sprint Planning 每个Sprint中做Backlog梳理的时候估算 故事点 （story point）\n故事点是敏捷估算时用来计量工作量规模的单位 故事点通常用于产品Backlog中的PBI或 完成标准DOD# Spike 探刺# WIP (Work in Progress)# "},{"id":5,"href":"/docs/devops/gitlab%E5%AE%89%E8%A3%85/","title":"Gitlab安装","section":"所有文章","content":"操作系统：Linux version 3.10.0-862.el7.x86_64 Gitlab：gitlab-ce14.10.0-ce.0.el7 安装必要依赖# 安装所需的依赖：ssh、postfix(用于邮件通知) 、wget，已安装的可略过。\nssh# 安装ssh，root 用户可不加 sudo\nsudo yum install -y curl policycoreutils-pythonopenssh-server设置开机自启动\nsudo systemctl enable sshd 启动ssh服务\nsudo systemctl start sshdpostfix# 安装 Postfix 用于发送通知邮件\nsudo yum install postfix设置开机自启动\nsudo systemctl enable postfix启动postfix\nsudo systemctl start postfix wget# wget 用于从外网下载插件，检查系统中是否已经安装：\n[root@centos-01 ~]# wget -V GNU Wget 1.14 在 linux-gnu 上编译。 +digest +https +ipv6 +iri +large-file +nls +ntlm +opie +ssl/openssl Wgetrc: /etc/wgetrc (系统) 字符集: /usr/share/locale 编译: gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC=\u0026#34;/etc/wgetrc\u0026#34; -DLOCALEDIR=\u0026#34;/usr/share/locale\u0026#34; -I. -I../lib -I../lib -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic 链接程序: gcc -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -lssl -lcrypto /usr/lib64/libssl.so /usr/lib64/libcrypto.so /usr/lib64/libz.so -ldl -lz -lz -lidn -luuid -lpcre ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a Copyright (C) 2011 Free Software Foundation, Inc. 授权 GPLv3+: GNU GPL 第三版或更高版本 \u0026lt;http://www.gnu.org/licenses/gpl.html\u0026gt;。 这是自由软件：您可以自由地更改并重新分发它。 在法律所允许的范围内，没有任何担保。 最初由 Hrvoje Nikšić \u0026lt;hniksic@xemacs.org\u0026gt; 编写。 请将错误报告或建议寄给 \u0026lt;bug-wget@gnu.org\u0026gt;。如果未安装则进行安装，安装命令如下：\nyum install wget -yvim# yum install vim -yGitLab 安装# yum 方式安装# 注意： gitlab-ce 镜像仅支持 x86-64 架构\nCentos 可以通过配置 yum 源然后使用 yum 一键安装，国内可以使用清华大学镜像源安装GitLab速度会快不少。【相关配置安装参考这里】。\n将以下内容写入 yum 源配置文件：/etc/yum.repos.d/gitlab-ce.repo\n# vim /etc/yum.repos.d/gitlab-ce.repo [gitlab-ce] name=Gitlab CE Repository baseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/ gpgcheck=0 enabled=1yum makecache #将服务器包信息下载到本地缓存 yum install gitlab-ce #自动安装最新版安装指定版本\n# yum install gitlab-ce-x.x.x #安装指定版本rpm 方式安装# wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el8/gitlab-ce-14.0.0-ce.0.el8.x86_64.rpmrpm -i gitlab-ce-14.0.0-ce.0.el8.x86_64.rpm详细操作请自行查找相关资料。无论使用哪种方式，看到类似如下输出表示安装成功：\nRunning transaction check\rRunning transaction test\rTransaction test succeeded\rRunning transaction\r正在安装 : setools-libs-3.3.8-4.el7.x86_64 1/8\r正在安装 : libcgroup-0.41-21.el7.x86_64 2/8\r正在安装 : audit-libs-python-2.8.5-4.el7.x86_64 3/8\r正在安装 : python-IPy-0.75-6.el7.noarch 4/8\r正在安装 : libsemanage-python-2.5-14.el7.x86_64 5/8\r正在安装 : checkpolicy-2.5-8.el7.x86_64 6/8\r正在安装 : policycoreutils-python-2.5-34.el7.x86_64 7/8\r正在安装 : gitlab-ce-14.10.0-ce.0.el7.x86_64 8/8\rIt looks like GitLab has not been configured yet; skipping the upgrade script.\r*. *.\r*** ***\r***** *****\r.****** *******\r******** ********\r,,,,,,,,,***********,,,,,,,,,\r,,,,,,,,,,,*********,,,,,,,,,,,\r.,,,,,,,,,,,*******,,,,,,,,,,,,\r,,,,,,,,,*****,,,,,,,,,.\r,,,,,,,****,,,,,,\r.,,,***,,,,\r,*,.\r_______ __ __ __\r/ ____(_) /_/ / ____ _/ /_\r/ / __/ / __/ / / __ `/ __ \\\r/ /_/ / / /_/ /___/ /_/ / /_/ /\r\\____/_/\\__/_____/\\__,_/_.___/\rThank you for installing GitLab!\rGitLab was unable to detect a valid hostname for your instance.\rPlease configure a URL for your GitLab instance by setting `external_url`\rconfiguration in /etc/gitlab/gitlab.rb file.\rThen, you can start your GitLab instance by running the following command:\rsudo gitlab-ctl reconfigure\rFor a comprehensive list of configuration options please see the Omnibus GitLab readme\rhttps://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\rHelp us improve the installation experience, let us know how we did with a 1 minute survey:\rhttps://gitlab.fra1.qualtrics.com/jfe/form/SV_6kVqZANThUQ1bZb?installation=omnibus\u0026amp;release=14-10\r验证中 : checkpolicy-2.5-8.el7.x86_64 1/8\r验证中 : libsemanage-python-2.5-14.el7.x86_64 2/8\r验证中 : python-IPy-0.75-6.el7.noarch 3/8\r验证中 : policycoreutils-python-2.5-34.el7.x86_64 4/8\r验证中 : audit-libs-python-2.8.5-4.el7.x86_64 5/8\r验证中 : libcgroup-0.41-21.el7.x86_64 6/8\r验证中 : gitlab-ce-14.10.0-ce.0.el7.x86_64 7/8\r验证中 : setools-libs-3.3.8-4.el7.x86_64 8/8\r已安装:\rgitlab-ce.x86_64 0:14.10.0-ce.0.el7\r作为依赖被安装:\raudit-libs-python.x86_64 0:2.8.5-4.el7 checkpolicy.x86_64 0:2.5-8.el7 libcgroup.x86_64 0:0.41-21.el7\rlibsemanage-python.x86_64 0:2.5-14.el7 policycoreutils-python.x86_64 0:2.5-34.el7 python-IPy.noarch 0:0.75-6.el7\rsetools-libs.x86_64 0:3.3.8-4.el7\r完毕！默认路径# 安装完成后可以利用 rpm -ql gitlab-ce 查看其文件安装路径及相关文件路径：\n默认安装路径：/opt/gitlab/ 程序数据及配置文件保存路径： /var/opt/gitlab 代码仓库保存位置：/var/opt/gitlab/git-data/repositories/ 代码仓库备份位置：/var/opt/gitlab/backups/ postgresql数据及配置目录：/var/opt/gitlab/postgresql/data/ redis默认配置目录：/var/opt/gitlab/redis gitlab主要配置文件：/etc/gitlab/gitlab.rb GitLab 配置修改# 修改配置文件指定服务器ip和自定义端口：\nvim /etc/gitlab/gitlab.rb external_url \u0026#39;http://localhost:8888\u0026#39; 注意：这里设置的端口不能被占用，默认是8080端口，如果8080已经使用，请自定义其它端口，并在防火墙设置开放相对应端口，我这里直接使用 8888\n重置并启动 GitLab\ngitlab-ctl reconfigure gitlab-ctl restart[root@localhost ~]# gitlab-ctl restart ok: run: alertmanager: (pid 88474) 1s ok: run: gitaly: (pid 88487) 0s ok: run: gitlab-exporter: (pid 88502) 0s ok: run: gitlab-kas: (pid 88504) 1s ok: run: gitlab-workhorse: (pid 88516) 0s ok: run: grafana: (pid 88529) 1s ok: run: logrotate: (pid 88541) 0s ok: run: nginx: (pid 88547) 1s ok: run: node-exporter: (pid 88556) 0s ok: run: postgres-exporter: (pid 88563) 0s ok: run: postgresql: (pid 88572) 0s ok: run: prometheus: (pid 88584) 0s ok: run: puma: (pid 88601) 0s ok: run: redis: (pid 88606) 0s ok: run: redis-exporter: (pid 88612) 1s ok: run: sidekiq: (pid 88696) 0s提示 \u0026ldquo;ok: run:\u0026ldquo;表示启动成功\nGitLab 访问# 如果没有域名，直接输入服务器ip和指定端口进行访问。\n注意：gitlab-ce-14初装后，将密码放在 /etc/gitlab/initial_root_password 临时文件中 ，这个文件将在首次执行 reconfigure 后24小时自动删除，所以拿到密码后尽快登陆Web界面进行密码修改\n[root@localhost ~]# cat /etc/gitlab/initial_root_password # WARNING: This value is valid only in the following conditions # 1. If provided manually (either via `GITLAB_ROOT_PASSWORD` environment variable or via `gitlab_rails[\u0026#39;initial_root_password\u0026#39;]` setting in `gitlab.rb`, it was provided before database was seeded for the first time (usually, the first reconfigure run). # 2. Password hasn\u0026#39;t been changed manually, either via UI or via command line. # # If the password shown here doesn\u0026#39;t work, you must reset the admin password following https://docs.gitlab.com/ee/security/reset_user_password.html#reset-your-root-password. Password: HjGOs7XePmSXYSbncxu7UDujhh+SWxyjVkxTvVPpbf8= # NOTE: This file will be automatically deleted in the first reconfigure run after 24 hours.\nGitLab 常用命令# gitlab-ctl start # 启动所有 gitlab 组件 gitlab-ctl stop # 停止所有 gitlab 组件 gitlab-ctl restart # 重启所有 gitlab 组件 gitlab-ctl status # 查看服务状态 gitlab-ctl reconfigure # 启动服务 vim /etc/gitlab/gitlab.rb # 修改默认的配置文件 gitlab-rake gitlab:check SANITIZE=true --trace # 检查gitlab sudo gitlab-ctl tail # 查看日志 gitlab-ctl --help # 查看更多命令"},{"id":6,"href":"/docs/devops/jenkins%E5%AE%89%E8%A3%85/","title":"Jenkins安装","section":"所有文章","content":"安装 jdk/git# yum -y install java-1.8.0-openjdk* #安装jdk yum install git #安装git安装 ca-certificates# yum install epel-release yum install -y ca-certificates导入公钥# sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key安装 Jenkins# wget https://mirrors.bfsu.edu.cn/jenkins/redhat-stable/jenkins-2.319.3-1.1.noarch.rpm rpm -ivh jenkins-2.319.3-1.1.noarch.rpm配置修改# 主要修改两个地方：\n账户：因为 Jenkins 默认账户是 jenkins，这个账户我们没有，而且为了不因为权限出现各种问题，这里直接使用 root，也可以创建一个名叫 jenkins 的账户\n端口：Jenkins的默认端口是 8080，为了避免端口冲突，可以修改为其他端口\n配置文件地址：vi /etc/sysconfig/jenkins\n防火墙添加端口# 查看开放端口：\nfirewall-cmd --zone=public --list-ports添加 Jenkins 端口\nfirewall-cmd --zone=public --add-port=8080/tcp --permanent 防火墙配置立即生效\nfirewall-cmd --reload目录权限修改# chown -R root:root /var/lib/jenkins chown -R root:root /var/cache/jenkins chown -R root:root /var/log/jenkins启动 Jenkins# systemctl start jenkins如果报错：\nJob for jenkins.service failed because the control process exited with error code. See \u0026#34;systemctl status jenkins.service\u0026#34; and \u0026#34;journalctl -xe\u0026#34; for details.解决方案：\n查看当前Java的环境变量 echo $JAVA_HOME 复制Java的环境变量地址, 编辑 /etc/init.d/jenkins 文件, 指定位置添加该地址, 后缀附上 /bin/java vim /etc/init.d/jenkins candidates=\u0026#34; /etc/alternatives/java /usr/lib/jvm/java-1.8.0/bin/java /usr/lib/jvm/jre-1.8.0/bin/java /usr/lib/jvm/java-11.0/bin/java /usr/lib/jvm/jre-11.0/bin/java /usr/lib/jvm/java-11-openjdk-amd64 /usr/bin/java /usr/jdk/jdk-18.0.1.1/bin/java # 新增jdk地址 \u0026#34;修改完重新加载一下配置文件，使其生效：\nsystemctl daemon-reload然后启动，将刚才修改的端口放开或者直接关闭防火墙，这里直接关闭防火墙：\nsystemctl stop firewalld重启 Jenkins\nsystemctl restart jenkinsJenkins 插件安装# 步骤：添加插件 =\u0026gt; 系统管理 =\u0026gt; 插件管理\n需要添加的插件：\nGitlab Hook Build Authorization Token Root Publish Over SSH Gitlab Authentication Gitlab Git Parameter 在centos7中 ssh 服务默认是已经被安装了的。通过命令 rpm -qa | grep openssh 查看是否安装了ssh服务\nrpm -qa | grep openssh"},{"id":7,"href":"/docs/devops/jenkins%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/","title":"Jenkins常见操作","section":"所有文章","content":"通过 ssh 连接目标服务器# 插件安装# Manage Jenkins =\u0026gt; Manage Plugins\n下载 Publish over SSH 插件\n下载后的本地路径：$JENKINS_HOME/plugins/\n全局配置# 系统管理 =\u0026gt; 系统设置 =\u0026gt; 拉到底部找到 Publish over SSH\nPassphrase 和 Key 二选一即可\nPassphrase 密码方式登录服务器\nKey 免密方式登录服务器。具体步骤：（将 Jenkins 所在主机的 public_key 添加到目标服务器的 ~/.ssh/authorized_keys 即可）：\ncat id_rsa.pub \u0026gt;\u0026gt; authorized_keys # 生成authorized_keys scp authorized_keys root@10.80.188.130:/root/.ssh # 将authorized_keys拷贝到目标服务器 root/.ssh Remote Directory： 填写当前用户有权限操作并且必须是已经存在的路径\nSSH 服务器默认端口号是22，点击高级即可自定义端口号\n配置完成后，点击 Test Configuration 返回 Success 证明 Jenkins 所在宿主机可以正常连接到目标服务器。\n视图权限管理# 目标：jenkins 配置不同用户显示不同视图。\n添加用户# Manage Jenkins =\u0026gt; Manage Users =\u0026gt; 新建用户\n插件安装# Manage Jenkins =\u0026gt; Manage Plugins\n下载 Role-based Authorization Strategy 插件\nManage Jenkins =\u0026gt; Configure Global Security =\u0026gt; 授权策略 =\u0026gt; 选择启用 Role-Based Strategy\n权限配置# Manage Jenkins =\u0026gt; Manage And Assign Roles\nManage Roles：编辑权限 Assign Roles： 把编辑好的权限分配给不同用户 Role Strategy Macros： 角色策略宏，没有用到 Manage Roles# 编辑全局用户权限 Global roles：添加角色 normal 并分配相关权限\n编辑项目权限 Item roles：添加项目组，根据需要自己调整权限范围\n使用通配符配置之后，添加 Job 时按照设定的前缀作为名称，则可以实现按照设定权限显示给不同用户。\npattern 为正则表达式，语法为 java 正则表达式语法\n比如：group_dev 组对应的项目以 dev 开头，用户创建 Job 时必须以 dev 开头，否则对应的授权用户无法看到此Job。\n注意： 这里的模糊匹配时不能写成 * 要写成 .*\nAssign Roles# Global roles：指定用户有哪个用户组权限\nItem roles ：指定用户有哪个项目组权限\n添加视图# 管理账户中点击标签栏“+”号添加新视图。需要注意：视图名大小写要与通配符一致，根据之前添加项目角色时通配符配置的前缀创建视图。一定要选择列表视图。\n视图复制# import hudson.model.* //源view def str_view = \u0026#34;CeriOS.Core.DataDir\u0026#34; //目标view def str_new_view = \u0026#34;CeriOS.Core.Gateway\u0026#34; //源job名称(模糊匹配) def str_search = \u0026#34;CeriOS.Core.Datadir\u0026#34; //目标job名称(模糊匹配后替换) def str_replace = \u0026#34;CeriOS.Core.Gateway\u0026#34; def view = Hudson.instance.getView(str_view) //copy all projects of a view for(item in view.getItems()) { //create the new project name newName = item.getName().replace(str_search, str_replace) // copy the job, disable and save it def job try { //因为第一次导入后报错，所以添加了try-catch 跳过已存在的job job = Hudson.instance.copy(item, newName) } catch(IllegalArgumentException e) { println(e.toString()) println(\u0026#34;$newName job is exists\u0026#34;) continue } catch(Exception e) { println(e.toString()) continue } //是否禁用任务，false不禁用，true禁用 job.disabled = false job.save() Hudson.instance.getView(str_new_view).add(job) println(\u0026#34; $item.name copied as $newName\u0026#34;) }"},{"id":8,"href":"/docs/devops/nugetserver%E6%90%AD%E5%BB%BA/","title":"Nuget Server搭建","section":"所有文章","content":"背景介绍# NuGet 是用于微软.NET（包括 .NET Core）开发平台的软件包管理器。NuGet 能够使得在项目中添加、移除和更新引用的工作变得更加快捷方便\n通常使用 NuGet 都是官方的服务，也可以搭建针对自己公司或部门的私有 NuGet 托管一些自己的类库，公司内部的类库等。搭建私有 NuGet 的方法有很多，比如：NuGet.Server、ProGet 等。这里使用 BaGet。\nGitHub地址：https://loic-sharma.github.io/BaGet/， 安装方式选择 Docker。\nConfigure BaGet# 在服务器上自定义创建目录，目录结构如下：\nprojects ├─baget ├───baget.env ├───baget-databaget.env 文件用于存储BaGet的配置，内容如下：\n# The following config is the API Key used to publish packages. # You should change this to a secret value to secure your server. ApiKey=ApiKey # 推送包是需要提供这个ApiKey Storage__Type=FileSystem Storage__Path=/var/baget/packages Database__Type=Sqlite Database__ConnectionString=Data Source=/var/baget/baget.db Search__Type=Database配置指南介绍\nRun BaGet# Pull BaGet\u0026rsquo;s latest docker image docker pull loicsharma/baget run BaGet docker run -d --restart always --name nuget-server -p 80:80 --env-file /projects/baget/baget.env -v /projects/baget/baget-data:/var/baget loicsharma/baget:latestBrowse packages# You can browse packages by opening the URL http://localhost:80 in your browser.\nPublish packages# 项目中右键打包生成 you project.1.0.0.nupkg 文件，包的具体描述和版本号可在项目属性中更改，在控制台中通过命令将包推送到 Baget，命令如下：\ndotnet nuget push -s http://localhost:80/v3/index.json -k NUGET-SERVER-API-KEY you project.1.0.0.nupkg -k NUGET-SERVER-API-KEY ：baget.env 中配置的ApiKey you project.1.0.0.nupkg：要上传的包路径 -s http://localhost:80/v3/index.json：baget 地址 Restore packages# 现在可以在 Visual Studio 使用以下包源还原包：\nhttp://localhost:80/v3/index.jsonImport packages# 将本地包源推送到 Baget，需要确保已安装 nuget.exe。在 PowerShell 中，运行：\n$source = \u0026#34;C:\\Users\\Administrator\\.nuget\\packages\u0026#34; $destination = \u0026#34;http://localhost:80/v3/index.json\u0026#34; \u0026amp;D:\\Nuget\\nuget\\nuget.exe setapikey \u0026#34;NUGET-SERVER-API-KEY\u0026#34; -Source $destination $packages = D:\\Nuget\\nuget\\nuget.exe list -AllVersions -Source $source $packages | % { $id, $version = $_ -Split \u0026#34; \u0026#34; $nupkg = $id + \u0026#34;.\u0026#34; + $version + \u0026#34;.nupkg\u0026#34; $path = [IO.Path]::Combine($source, $id, $version, $nupkg) Write-Host \u0026#34;D:\\Nuget\\nuget\\nuget.exe push -Source $destination \u0026#34;\u0026#34;$path\u0026#34;\u0026#34;\u0026#34; \u0026amp; D:\\Nuget\\nuget\\nuget.exe push -Source $destination $path }"},{"id":9,"href":"/docs/docker/1.1docker%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%AE%89%E8%A3%85/","title":"1.1 Docker概念及安装","section":"所有文章","content":"软件开发最大的麻烦事之一就是环境配置。计算机的环境都不相同，为了保证软件能在不同的机器上正常运行必须保证两件事：\n操作系统的设置 各种库和组件的安装 比如安装一个dotnet core 应用，计算机必须有dotnet SDK，还必须有各种依赖，可能还要配置环境变量。而且换一台机器就要重新配置一遍。能不能做到软件可以带环境安装？也就是说安装的时候，把原始环境一模一样地复制过来。\n虚拟机# 虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件不需要了就删掉，对其他部分毫无影响。\n虽然可以通过虚拟机还原软件的原始环境。但是这个方案有几个缺点：\n资源占用多：虚拟机会独占一部分内存和硬盘空间。它运行的时候其他程序就不能使用这些资源了。哪怕虚拟机里面的应用程序，真正使用的内存只有1MB，虚拟机依然需要几百MB的内存才能运行 冗余步骤多：虚拟机是完整的操作系统，一些系统级别的操作步骤，往往无法跳过，比如用户登录 启动慢：启动操作系统需要多久，启动虚拟机就需要多久。可能要等几分钟，应用程序才能真正运行 Linux 容器# 由于虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（ Linux Containers 缩写为 LXC ）Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。\n由于容器是进程级别的，相比虚拟机有很多优势：\n启动快：容器里面的应用，直接就是底层系统的一个进程而不是虚拟机内部的进程。所以启动容器相当于启动本机的一个进程，而不是启动一个操作系统，速度就快很多 资源占用少：容器只占用需要的资源，不占用没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源 体积小：容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多 总之，容器有点像轻量级的虚拟机，能够提供虚拟化的环境，但是成本开销小得多\n下图比较了Docker和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程。\n容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。\nDocker概念# Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案\nDocker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker就不用再担心环境问题。\nDocker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 版本开始，则进一步演进为用 runC 和 containerd 。\nDocker优点# 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势：\n更高效的利用系统资源：由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用 更快速的启动：传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间 一致的运行环境：开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题」 这类问题 持续交付和部署：对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像 更轻松的迁移：由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云其运行结果是一致的。因此可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况 更轻松的维护和扩展：Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本 Docker对比传统虚拟机总结\n特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 Docker组成# Docker 使用客户端-服务器 (C/S) 架构模式 使用远程API来管理和创建Docker容器。Docker 容器（Container）通过 Docker 镜像（Image）来创建，二者之间的关系类似于面向对象中的对象与类。\nDocker由三个基本概念组成\n仓库（Repository）：Docker用于存放镜像文件的仓库 镜像（Image）：Image是构建容器的源代码，是一个只读的模板。由一层一层的文件系统组成的类似于虚拟机的镜像 容器(Container）：Container是由Docker镜像创建的运行实例，类似于虚拟机。容器之间是相互隔离的，包含特定的应用及其所需的依赖文件 ✨ Docker Hub是Docker公司提供的一个注册服务器（Register）来保存多个仓库，每个仓库又可以包含多个具备不同tag的镜像\nDocker安装# Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。企业版包含了一些收费服务，个人开发者一般用不到。\n环境准备# 官方建议 Centos7 Linux 内核需要3.10以上\n注意：使用 root 用户登录执行命令前无需加sudo，非 root 的所有命令前面要加 sudo\n查看内核版本# [root@wangpengliang ~]# uname -r 3.10.0-1160.25.1.el7.x86_64Yum安装# 更新 yum 包。可选项：如之后出现不兼容的情况的话就必须执行 yum -y update ​\t安装必要系统工具。yum-util 提供 yum-config-manager 功能，另外两个是 devicemapper 驱动依赖的 yum install -y yum-utils device-mapper-persistent-data lvm2 设置 yum 源。下面两个都可用 yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 查看可用版本 [root@wangpengliang ~]# yum list docker-ce --showduplicates | sort -r 已加载插件：fastestmirror 可安装的软件包 * updates: mirrors.163.com Loading mirror speeds from cached hostfile * extras: mirrors.163.com docker-ce.x86_64 3:20.10.6-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.5-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.4-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.3-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.2-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.1-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.0-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.9-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.8-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.7-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.6-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.5-3.el7 docker-ce-stable * centos-sclo-sclo: mirrors.163.com * centos-sclo-rh: mirrors.163.com * base: mirrors.163.com 选择版本并安装 格式：yum install docker-ce-版本号 yum -y install docker-ce-20.10.6 6. 启动并设置开机自启\nsystemctl start docker \u0026amp;\u0026amp; systemctl enable docker查看安装版本\n[root@wangpengliang ~]# docker version Client: Docker Engine - Community Version: 20.10.6 API version: 1.41 Go version: go1.13.15 Git commit: 370c289 Built: Fri Apr 9 22:45:33 2021 OS/Arch: linux/amd64 Context: default Experimental: true Server: Docker Engine - Community Engine: Version: 20.10.6 API version: 1.41 (minimum version 1.12) Go version: go1.13.15 Git commit: 8728dd2 Built: Fri Apr 9 22:43:57 2021 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.4.4 GitCommit: 05f951a3781f4f2c1911b05e61c160e9c30eaa8e runc: Version: 1.0.0-rc93 GitCommit: 12644e614e25b05da6fd08a38ffa0cfe1903fdec docker-init: Version: 0.19.0 GitCommit: de40ad0 测试运行 由于本地没有 hello-world 这个镜像，正常情况下会下载一个 hello-world 的镜像并在容器内运行\ndocker run hello-world脚本安装# 必备条件\n使用 sudo 或 root 权限登录 Centos\n确保 yum 包更新到最新\n执行安装脚本 执行脚本会添加 docker.repo 源并安装 Docker\ncurl -fsSL https://get.docker.com -o get-docker.sh sh get-docker.sh 启动进程 systemctl start docker 测试运行 sudo docker run hello-worldDocker 卸载# 1)：查看当前docker状态，如果是运行状态则停掉\nsystemctl status docker systemctl stop docker2)：查看yum安装的docker文件包\nyum list installed |grep docker3)：查看docker相关的rpm源文件\nrpm -qa |grep docker4)：删除所有安装的docker文件包\nyum -y remove docker.x86_64其他docker相关的安装包同样删除，删完之后再查看下docker rpm源\nrpm -qa |grep docker5)：删除docker的镜像文件，默认在**/var/lib/docker**目录下\nrm -rf /var/lib/docker"},{"id":10,"href":"/docs/docker/1.2docker%E9%95%9C%E5%83%8F/","title":"1.2 Docker镜像","section":"所有文章","content":"镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，包含运行软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件，Docker 运行容器前需要本地存在对应的镜像，如果本地不存在会从镜像仓库下载该镜像。\n操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像就相当于是一个 root 文件系统。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统\n镜像来源# 远程仓库下载 拷贝 自己制作镜像( Dockerfile ) 获取镜像# Docker Hub 上有大量高质量的镜像可以用，获取镜像的命令是 docker pull，格式为：\ndocker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]具体选项可以通过 docker pull --help 命令看到，镜像名称格式如下：\nDocker 镜像仓库地址：地址格式一般是 \u0026lt;域名/IP\u0026gt;[:端口号]。默认地址是 Docker Hub 仓库名：这里的仓库名是两段式名称，即 \u0026lt;用户名\u0026gt;/\u0026lt;软件名\u0026gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像 比如：\n[root@wangpengliang ~]# docker pull redis:6.2.4 6.2.4: Pulling from library/redis 69692152171a: Pull complete a4a46f2fd7e0: Pull complete bcdf6fddc3bd: Pull complete 2902e41faefa: Pull complete df3e1d63cdb1: Pull complete fa57f005a60d: Pull complete Digest: sha256:7e2c6181ad5c425443b56c7c73a9cd6df24a122345847d1ea9bb86a5afc76325 Status: Downloaded newer image for redis:6.2.4 docker.io/library/redis:6.2.4上面的命令中没有给出 Docker 镜像仓库地址，因此将会从 Docker Hub 获取镜像。而镜像名称是 redis:6.2.4，因此将会获取官方镜像 library/redis仓库中标签为 6.2.4 的镜像。\n从下载过程中可以看到分层存储的概念，镜像是由多层存储所构成。下载也是一层层的去下载，并非单一文件下载。过程中给出了每一层的 ID 的前 12 位。下载结束后，给出该镜像完整的 sha256 的摘要以确保下载一致性。\n镜像列表# 镜像下载完成后可以使用 docker image ls 查看本地镜像列表\n[root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE redis 6.2.4 fad0ee7e917a 2 days ago 105MB redis latest fad0ee7e917a 2 days ago 105MB hello-world latest d1165f221234 3 months ago 13.3kB列表包含了 仓库名、标签、镜像 ID、创建时间以及所占用的空间，镜像 ID 是镜像的唯一标识，一个镜像可以对应多个标签。\n镜像体积# 仔细观察会注意到上面标识的所占用空间和在 Docker Hub 上看到的镜像大小不同。比如，redis:6.2.4 镜像大小，在这里是 105 MB，但是在 Docker Hub 显示的却是 37 MB。这是因为 Docker Hub 中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的，因此 Docker Hub 所显示的大小是网络传输中更关心的流量大小。而 docker image ls 显示的是镜像下载到本地后，展开的大小。准确说，是展开后的各层所占空间的总和，因为镜像到本地查看空间的时候，更关心的是本地磁盘空间占用的大小。\n另外一个需要注意的问题是，docker image ls 列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 UNION FS，相同的层只需要保存一份即可。因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小。\n通过以下命令可以查看镜像、容器、数据卷所占用的空间：\n[root@wangpengliang ~]# docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 2 1 105.4MB 13.34kB (0%) Containers 1 1 26B 0B (0%) Local Volumes 1 1 0B 0B Build Cache 0 0 0B 0B虚悬镜像# 有时候可以看到这种特殊的镜像，仓库名和标签均为 \u0026lt;none\u0026gt;\n\u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 00285df0df87 5 days ago 342 MB这个镜像原本是有镜像名和标签的，比如原来为 mongo:3.2，随着官方镜像维护，发布了新版本后，重新 docker pull mongo:3.2 时，mongo:3.2 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 \u0026lt;none\u0026gt;。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 \u0026lt;none\u0026gt; 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) 。\n通过以下命令可以查看这类镜像：\ndocker image ls -f dangling=true REPOSITORY TAG IMAGE ID CREATED SIZE \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 00285df0df87 5 days ago 342 MB一般来说虚悬镜像已经失去了存在的价值，是可以随意删除的。可以通过以下命令删除：\ndocker image prune中间层镜像# 为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。\ndocker image ls -a这样会看到很多无标签的镜像，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，只要删除依赖它们的镜像后，这些被依赖的中间层镜像也会被连带删除。\n列出部分镜像# 不加任何参数的情况下，docker image ls 会列出所有顶层镜像，但有时候只希望列出部分镜像。docker image ls 有几个参数可以帮助做到\n根据仓库名列出镜像：\n[root@wangpengliang ~]# docker image ls redis REPOSITORY TAG IMAGE ID CREATED SIZE redis 6.2.4 fad0ee7e917a 2 days ago 105MB redis latest fad0ee7e917a 2 days ago 105MB指定仓库名和标签：\n[root@wangpengliang ~]# docker image ls redis:6.2.4 REPOSITORY TAG IMAGE ID CREATED SIZE redis 6.2.4 fad0ee7e917a 2 days ago 105MB除此以外，docker image ls 还支持过滤器参数 --filter或者简写 -f。\n只显示镜像ID -q：\n[root@wangpengliang ~]# docker image ls -q fad0ee7e917a fad0ee7e917a d1165f221234格式化显示镜像结果，只包含镜像ID和仓库名：\n[root@wangpengliang ~]# docker image ls --format \u0026#34;{{.ID}}: {{.Repository}}\u0026#34; fad0ee7e917a: redis fad0ee7e917a: redis d1165f221234: hello-world # 以表格等距显示（需要自己定义列） [root@wangpengliang ~]# docker image ls --format \u0026#34;table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\u0026#34; IMAGE ID REPOSITORY TAG fad0ee7e917a redis 6.2.4 fad0ee7e917a redis latest d1165f221234 hello-world latest删除镜像# 如果要删除本地镜像，可以使用 docker image rm 命令，格式为：\n$ docker image rm [选项] \u0026lt;镜像1\u0026gt; [\u0026lt;镜像2\u0026gt; ...] #\u0026lt;镜像\u0026gt; 可以是 镜像短 ID、镜像长 ID、镜像名 或者 镜像摘要或者使用：\ndcoker rmi \u0026lt;镜像\u0026gt;[root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE redis 6.2.4 fad0ee7e917a 2 days ago 105MB redis latest fad0ee7e917a 2 days ago 105MB hello-world latest d1165f221234 3 months ago 13.3kB [root@wangpengliang ~]# docker rmi redis:latest Untagged: redis:latest [root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE redis 6.2.4 fad0ee7e917a 2 days ago 105MB hello-world latest d1165f221234 3 months ago 13.3kB运行容器# 上面了解了关于镜像的一些基础知识，有了镜像就能够以这个镜像为基础启动并运行一个容器。以 redis 为例\n[root@wangpengliang ~]# docker run -it --name redis -d redis:6.2.4 68b9ad2b60fc7fd2a546e764448798195c86f5f22bfce200cd7e583d60df8096 [root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 68b9ad2b60fc redis:6.2.4 \u0026#34;docker-entrypoint.s…\u0026#34; 4 seconds ago Up 3 seconds 6379/tcp redis [root@wangpengliang ~]# docker exec -it redis /bin/bash root@68b9ad2b60fc:/data# cat /etc/os-release PRETTY_NAME=\u0026#34;Debian GNU/Linux 10 (buster)\u0026#34; NAME=\u0026#34;Debian GNU/Linux\u0026#34; VERSION_ID=\u0026#34;10\u0026#34; VERSION=\u0026#34;10 (buster)\u0026#34; VERSION_CODENAME=buster ID=debian HOME_URL=\u0026#34;https://www.debian.org/\u0026#34; SUPPORT_URL=\u0026#34;https://www.debian.org/support\u0026#34; BUG_REPORT_URL=\u0026#34;https://bugs.debian.org/\u0026#34;UnionFS# 联合文件系统是一种分层、轻量级并且高性能的文件系统，支持对文件系统的修改，作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下（unite directories into a single virtual filesystem） UnionFS是Docker镜像的基础，镜像可以通过分层来继承，基于基础镜像（没有父镜像的镜像），可以制作各种具体的应用镜像 特性一次同时加载多个文件系统，但从外面看起来只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 Docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统叫 UnionFS BootFS（Boot file system）主要包含 bootloader 和 kernel，bootloader 主要是引导加载 kernel，Linux 刚启动时会加载 BootFS文件系统，在 Docker 镜像的最底层是 BootFS。这一层与典型的 Linux/Unix 系统是一样的，包含 boot 加载器和内核。当 boot 加载完成之后整个内核就都在内存中了，此时内存的使用权已由 BootFS 转交给内核，此时系统也会卸载 BootFS RootFS（Root File System），在 BootFS 之上，包含的就是典型 Linux 系统中的 /dev，/proc，/bin，/etc 等标准目录和文件。RootFS就是各种不同的操作系统发行版，比如 Ubuntu CentOS 等 比如：mysql 和 tomcat 都需要 centos 环境，先安装 mysql 就有了 centos 的环境，再安装 tomcat 时就可以共用这一层 centos ，不需要再下载 centos\nCommit镜像# 镜像是容器的基础，每次执行 docker run 的时候都会指定哪个镜像作为容器运行的基础。之前例子中一直使用来自于 Docker Hub 的镜像。直接使用这些镜像是可以满足一定的需求，而当这些镜像无法直接满足需求时，就需要定制镜像。\n镜像是多层存储，每一层是在前一层的基础上进行的修改。容器同样也是多层存储，以镜像为基础层，在其基础上加一层作为容器运行时的存储层。\n以定制一个 Web 服务器为例，来了解镜像是如何构建的：\ndocker run --name webserver -d -p 80:80 nginx使用 nginx 镜像启动一个容器，命名为 webserver 并且映射 80 端口，然后浏览器去访问这个服务器会看到默认的 nginx 欢迎页面。\n现在将\u0026quot;Welcome to nginx!\u0026quot; 改成 \u0026ldquo;Welcome to Docker!\u0026quot;，通过 docker cp 将容器内文件拷贝出来修改后再放回去。\n[root@wangpengliang home]# docker cp 470e01aed950:/usr/share/nginx/html/index.html /home/ 这里也可以使用 docker exec 进入到容器内进行修改，不过因为容器内并没安装 vi ，还需额外安装就懒得折腾了\n现在刷新浏览器的话，会发现内容改变了。 上面修改了容器的文件，也就是改动了容器的存储层。可以通过 docker diff 命令看到具体的改动\n[root@wangpengliang home]# docker diff webserver C /etc C /etc/nginx C /etc/nginx/conf.d C /etc/nginx/conf.d/default.conf C /run A /run/nginx.pid C /usr C /usr/share C /usr/share/nginx C /usr/share/nginx/html C /usr/share/nginx/html/index.html C /var C /var/cache C /var/cache/nginx A /var/cache/nginx/fastcgi_temp A /var/cache/nginx/proxy_temp A /var/cache/nginx/scgi_temp A /var/cache/nginx/uwsgi_temp A /var/cache/nginx/client_temp C /root A /root/.bash_history当运行一个容器时（如果不使用卷），做的任何文件修改都会被记录于容器存储层里。而 Docker 提供了一个 docker commit 命令，可以将容器的存储层保存下来成为镜像。换句话说就是在原有镜像的基础上再叠加上容器的存储层，并构成新的镜像。以后运行这个新镜像时，就会拥有原有容器最后的文件变化。\ndocker commit [选项] \u0026lt;容器ID或容器名\u0026gt; [\u0026lt;仓库名\u0026gt;[:\u0026lt;标签\u0026gt;]]docker commit -m=\u0026#34;提交的描述信息\u0026#34; -a=\u0026#34;作者\u0026#34; 容器id 目标镜像名[tag][root@wangpengliang ~]# docker commit -m=\u0026#39;nginx2.0\u0026#39; -a=\u0026#39;wangpengliang\u0026#39; 470e01aed950 nginx:2.0 sha256:546ad28bcf61aeedd04de8c255efa508ee65eeff0b2a4529d17d3df835aa6bb2 [root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx 2.0 546ad28bcf61 5 seconds ago 133MB redis 6.2.4 fad0ee7e917a 2 days ago 105MB nginx latest d1a364dc548d 9 days ago 133MB hello-world latest d1165f221234 3 months ago 13.3kB使用 docker history 可以具体查看镜像内的历史记录，如果比较 nginx:latest 的历史记录，会发现新增了刚刚提交的这一层：\n[root@wangpengliang ~]# docker history nginx:2.0 IMAGE CREATED CREATED BY SIZE COMMENT 546ad28bcf61 About a minute ago nginx -g daemon off; 2.03kB nginx2.0 d1a364dc548d 9 days ago /bin/sh -c #(nop) CMD [\u0026#34;nginx\u0026#34; \u0026#34;-g\u0026#34; \u0026#34;daemon… 0B \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) STOPSIGNAL SIGQUIT 0B \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) EXPOSE 80 0B \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) ENTRYPOINT [\u0026#34;/docker-entr… 0B \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) COPY file:09a214a3e07c919a… 4.61kB \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) COPY file:0fd5fca330dcd6a7… 1.04kB \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) COPY file:0b866ff3fc1ef5b0… 1.96kB \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) COPY file:65504f71f5855ca0… 1.2kB \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c set -x \u0026amp;\u0026amp; addgroup --system -… 63.9MB \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) ENV PKG_RELEASE=1~buster 0B \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) ENV NJS_VERSION=0.5.3 0B \u0026lt;missing\u0026gt; 9 days ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.21.0 0B \u0026lt;missing\u0026gt; 3 weeks ago /bin/sh -c #(nop) LABEL maintainer=NGINX Do… 0B \u0026lt;missing\u0026gt; 3 weeks ago /bin/sh -c #(nop) CMD [\u0026#34;bash\u0026#34;] 0B \u0026lt;missing\u0026gt; 3 weeks ago /bin/sh -c #(nop) ADD file:7362e0e50f30ff454… 69.3MB新的镜像定制好后，运行这个镜像。\ndocker run --name webserver2 -d -p 81:80 nginx:2.0这里命名为新的服务为 webserver2 ，并且映射到 81 端口。看到结果内容和之前修改后的 webserver 一样\n慎用Commit镜像# docker commit 命令虽然可以比较直观的帮助理解镜像分层存储的概念，但是实际环境中并不推荐这么用，原因有如下几点：\n问题一：\n仔细观察之前的 docker diff webserver 的结果，会发现除了真正想要修改的 /usr/share/nginx/html/index.html 文件外，由于命令的执行还有很多文件被改动或添加了。这还仅仅是最简单的操作，如果是安装软件包、编译构建那会有大量的无关内容被添加进来。如果不清理干净，将导致镜像极为臃肿。\n问题二：\n使用 docker commit 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为黑箱镜像，除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。而且，即使是这个制作镜像的人，过一段时间后也无法记清具体操作。虽然 docker diff 或许可以得到一些线索，但是远远不到可以确保生成一致镜像的地步。这种黑箱镜像将导致维护工作非常痛苦。\n问题三：\n镜像所使用的分层存储的概念是除当前层外，之前的每一层都是不会发生改变的，换句话说，任何修改的结果仅仅是在当前层进行标记、添加、修改，而不会改动上一层。如果使用 docker commit 制作镜像以及后期修改的话，每一次修改都会让镜像更加臃肿一次，所删除的上一层的东西并不会丢失，会一直如影随形的跟着这个镜像，即使根本无法访问到。这也会让镜像更加臃肿。\nDockerFile示例# 根据之前的 docker commit 了解到镜像的定制实际上就是定制每一层所添加的配置、文件。如果可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是Dockerfile 。\nDockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。了解了 Dockerfile 如何构建镜像后，以 nginx 举例来构建这个镜像。\n在空白目录中建立文件命名为 Dockerfile：\n$ mkdir mynginx $ cd mynginx $ touch Dockerfile编写内容：\nFROM nginx RUN echo \u0026#39;\u0026lt;h1\u0026gt;Hello, Docker!\u0026lt;/h1\u0026gt;\u0026#39; \u0026gt; /usr/share/nginx/html/index.html使用 docker build 命令依赖 Dockerfile文件生成镜像：（注意：最后有个. 这是必须的）\n[root@wangpengliang ~]# docker build -t nginx:3.0 .查看构建好的镜像：\n[root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx 3.0 f89693105193 7 minutes ago 133MB nginx 2.0 546ad28bcf61 3 days ago 133MB redis 6.2.4 fad0ee7e917a 5 days ago 105MB nginx latest d1a364dc548d 12 days ago 133MB hello-world latest d1165f221234 3 months ago 13.3kB运行 nginx:3.0 镜像测试：\ndocker run --name webserver3 -d -p 82:80 nginx:3.0\n其他 Docker Build 用法# Git repo 构建# docker build 支持从 URL 构建，比如可以直接从 Git repo 中构建：\n$ docker build https://github.com/twang2218/gitlab-ce-zh.git#:11.1 Sending build context to Docker daemon 2.048 kB Step1: FROM gitlab/gitlab-ce:11.1.0-ce.0 11.1.0-ce.0:Pulling from gitlab/gitlab-ce aed15891ba52:Already exists 773ae8583d14:Already exists这里指定了构建所需的 git repo ，并且指定默认的 master 分支，构建目录为 /11.1/，然后 Docker 就会去 git clone 这个项目、切换到指定分支、并进入到指定目录后开始构建。\ntar 压缩包构建# $ docker build http://server/context.tar.gz如果给出的 URL 不是个 Git repo ，而是个 tar 压缩包，那么 Docker 引擎会下载这个包，并自动解压缩，以其作为上下文，开始构建。\n读取 Dockerfile 构建# docker build -\u0026lt;Dockerfile 或 cat Dockerfile| docker build -如果标准输入传入的是文本文件，则将其视为 Dockerfile，并开始构建。这种形式由于直接从标准输入中读取 Dockerfile 的内容，它没有上下文，因此不可以像其他方法那样可以将本地文件 COPY 到镜像之类的事情。\n读取上下文压缩包构建# $ docker build -\u0026lt; context.tar.gz如果发现标准输入的文件格式是 gzip、bzip2 以及 xz 的话，将会使其为上下文压缩包，直接将其展开，将里面视为上下文，并开始构建。\n"},{"id":11,"href":"/docs/docker/1.3docker%E5%AE%B9%E5%99%A8/","title":"1.3 Docker容器","section":"所有文章","content":"容器是依赖于镜像生成，独立运行的一个或一组应用以及它们的运行环境。\n启动容器# 启动容器有两种方式\n基于镜像新建容器并启动 将在终止状态（stopped）的容器重新启动 新建并启动容器# 比如下面的命令输出“hello world!”，之后终止容器：\n[root@wangpengliang ~]# docker run ubuntu /bin/echo \u0026#39;hello world!\u0026#39; hello world!下面的命令则启动一个 bash 终端，允许用户进行交互：\n[root@wangpengliang ~]# docker run -it ubuntu /bin/bash root@ef8fa7a1ffd6:/# -t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上 -i 让容器的标准输入保持打开 -it 是简写，在交互模式下可以通过所创建的终端来输入命令，比如：\n[root@wangpengliang ~]# docker run -it ubuntu /bin/bash root@ef8fa7a1ffd6:/# pwd / root@ef8fa7a1ffd6:/# ls bin boot dev etc home lib lib32 lib64 libx32 media mnt opt proc root run sbin srv sys tmp usr var root@ef8fa7a1ffd6:/# 使用 docker run 创建容器时，Docker 在后台运行的标准操作包括：\n检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动已终止容器# 可以利用 docker container start 命令，直接将一个已经终止的容器启动运行。可以在伪终端中利用 ps 或 top 来查看进程信息：\nroot@ef8fa7a1ffd6:/# ps PID TTY TIME CMD 1 pts/0 00:00:00 bash 12 pts/0 00:00:00 ps后台运行# 更多的时候，需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。可以通过添加 -d 参数来实现。\n不使用 -d 参数：\n[root@wangpengliang ~]# docker run ubuntu /bin/sh -c \u0026#39;while true;do echo hello docker; sleep 1;done\u0026#39; hello docker hello docker hello docker hello docker容器会把输出的结果 (STDOUT) 打印到宿主机上1s打印一次\u0026quot;hello docker\u0026quot;。\n使用 -d 参数：\n[root@wangpengliang ~]# docker run -d ubuntu /bin/sh -c \u0026#39;while true;do echo hello docker; sleep 1;done\u0026#39; 3c443074634c5edd6272c62fd08d8439ac2b5f3b9677233aae06deb2724c917c此时容器会在后台运行并不会把输出结果 (STDOUT) 打印到宿主机上。\n可以使用 docker logs 查看输出结果\n[root@wangpengliang ~]# docker logs 3c443074634c hello docker hello docker hello docker使用 -d 参数启动后会返回一个唯一的 id，也可以通过 docker container ls 命令来查看容器信息：\n[root@wangpengliang ~]# docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3c443074634c ubuntu \u0026#34;/bin/sh -c \u0026#39;while t…\u0026#34; 2 minutes ago Up 2 minutes affectionate_agnesi a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 17 hours ago Up 17 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3要获取容器的输出信息，可以按上面说的使用 docker container logs 命令，格式 docker container logs [container ID or NAMES] [root@wangpengliang ~]# docker container logs 3c443074634c hello docker hello docker hello docker终止容器# 使用 docker container stop 来终止一个运行中的容器，此外当 Docker 容器中指定的应用终结时，容器也自动终止。比如对于上面只启动了一个终端的容器，通过 exit 命令或 ctrl+d 退出终端时，创建的容器立刻终止。\n终止状态的容器可以用 docker container ls -a 命令看到：\n[root@wangpengliang ~]# docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 18 hours ago Up 18 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 bab7ffb6e2e9 nginx:2.0 \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Exited (255) 18 hours ago 0.0.0.0:81-\u0026gt;80/tcp, :::81-\u0026gt;80/tcp webserver2 470e01aed950 nginx 处于终止状态的容器，可以通过 docker container start 命令来重新启动：\n[root@wangpengliang ~]# docker container start webserver webserver [root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 18 hours ago Up 18 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 bab7ffb6e2e9 nginx:2.0 \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Exited (255) 18 hours ago 0.0.0.0:81-\u0026gt;80/tcp, :::81-\u0026gt;80/tcp webserver2 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 5 seconds 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserverdocker container restart 命令会将一个运行状态的容器终止，然后再重新启动：\n[root@wangpengliang ~]# docker container restart webserver webserver进入容器# 使用 -d 参数时，容器启动后会进入后台，某些时候需要进入容器进行操作，包括使用 docker attach 或 docker exec 命令，推荐使用 docker exec 。\nattach# [root@wangpengliang ~]# docker run -dit ubuntu 21498e13f12425718093684e74f342e30e7b9665e57b9b919f0a718d888f7b50 [root@wangpengliang ~]# docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 21498e13f124 ubuntu \u0026#34;/bin/bash\u0026#34; 9 seconds ago Up 8 seconds elated_chatelet a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 18 hours ago Up 18 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 minutes 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver [root@wangpengliang ~]# docker attach 21498e13f124 root@21498e13f124:/# ls bin boot dev etc home lib lib32 lib64 libx32 media mnt opt proc root run sbin srv sys tmp usr var root@21498e13f124:/# exit exit [root@wangpengliang ~]# docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 18 hours ago Up 18 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 minutes 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver 注意：如果从这个 stdin 中 exit，会导致容器的停止\nexec# docker exec 后边可以跟多个参数，这里主要说明 -i -t 参数\n只用 -i 参数时由于没有分配伪终端，界面没有熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回 当 -i -t 参数一起使用时，则可以看到熟悉的 Linux 命令提示符 [root@wangpengliang ~]# docker exec -it 2687f43c0e42 bash root@2687f43c0e42:/# ls bin boot dev etc home lib lib32 lib64 libx32 media mnt opt proc root run sbin srv sys tmp usr var如果从这个 stdin 中 exit，不会导致容器的停止。这就是为什么推荐使用 docker exec 的原因，更多参数说明使用 docker exec --help 查看。\n导出容器# 如果要导出本地某个容器，可以使用 docker export 命令，这将导出容器快照到本地文件：\n[root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2687f43c0e42 ubuntu \u0026#34;/bin/bash\u0026#34; 2 hours ago Up 2 minutes romantic_greider a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 20 hours ago Up 20 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 bab7ffb6e2e9 nginx:2.0 \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Exited (255) 20 hours ago 0.0.0.0:81-\u0026gt;80/tcp, :::81-\u0026gt;80/tcp webserver2 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 hours 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver [root@wangpengliang ~]# docker export 2687f43c0e42 \u0026gt; ubuntu.tar导入容器# 可以使用 docker import 从容器快照文件中再导入为镜像。比如：\n[root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2687f43c0e42 ubuntu \u0026#34;/bin/bash\u0026#34; 2 hours ago Up 2 minutes romantic_greider a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 20 hours ago Up 20 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 bab7ffb6e2e9 nginx:2.0 \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Exited (255) 20 hours ago 0.0.0.0:81-\u0026gt;80/tcp, :::81-\u0026gt;80/tcp webserver2 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 hours 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver [root@wangpengliang ~]# docker export 2687f43c0e42 \u0026gt;ubuntu.tar [root@wangpengliang ~]# cat ubuntu.tar|docker import - test/ubuntu:v1.0 sha256:557b6b4bfca63802c6b89bb4c8f1800a2af7954fdff345bd94adba2c770ad4d4 [root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE test/ubuntu v1.0 557b6b4bfca6 9 seconds ago 72.7MB nginx 3.0 f89693105193 20 hours ago 133MB nginx 2.0 546ad28bcf61 3 days ago 133MB redis 6.2.4 fad0ee7e917a 5 days ago 105MB redis latest fad0ee7e917a 5 days ago 105MB nginx latest d1a364dc548d 13 days ago 133MB ubuntu latest 7e0aa2d69a15 6 weeks ago 72.7MB hello-world latest d1165f221234 3 months ago 13.3kB此外，也可以通过指定 URL 或者某个目录来导入，比如：\ndocker import http://example.com/exampleimage.tgz example/imagerepo 注意：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息\n删除容器# 可以使用 docker container rm 来删除一个处于终止状态的容器\n[root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2687f43c0e42 ubuntu \u0026#34;/bin/bash\u0026#34; 2 hours ago Up 6 minutes romantic_greider a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 20 hours ago Up 20 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 bab7ffb6e2e9 nginx:2.0 \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Exited (255) 20 hours ago 0.0.0.0:81-\u0026gt;80/tcp, :::81-\u0026gt;80/tcp webserver2 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 hours 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver [root@wangpengliang ~]# docker container rm bab7ffb6e2e9 bab7ffb6e2e9 [root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2687f43c0e42 ubuntu \u0026#34;/bin/bash\u0026#34; 2 hours ago Up 7 minutes romantic_greider a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 20 hours ago Up 20 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 hours 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver如果要删除一个运行中的容器，可以添加 -f 参数。Docker 会发送 SIGKILL 信号给容器\n[root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2687f43c0e42 ubuntu \u0026#34;/bin/bash\u0026#34; 2 hours ago Up 8 minutes romantic_greider a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 20 hours ago Up 20 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 hours 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver [root@wangpengliang ~]# docker container rm -f 2687f43c0e42 2687f43c0e42 [root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a1ea64a6c039 nginx:3.0 \u0026#34;/docker-entrypoint.…\u0026#34; 20 hours ago Up 20 hours 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp webserver3 470e01aed950 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 days ago Up 2 hours 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp webserver用 docker container ls -a 命令可以查看所有已经创建的包括终止状态的容器，如果数量太多一个个删除可能会很麻烦，用下面的命令可以清理掉所有处于终止状态的容器：\ndocker container prune"},{"id":12,"href":"/docs/docker/1.4docker%E4%BB%93%E5%BA%93/","title":"1.4 Docker仓库","section":"所有文章","content":"仓库是集中存放镜像的地方。注册服务器是管理仓库的具体服务器，每个服务器上可以有多个仓库，每个仓库下面有多个镜像。\nDocker Hub# Docker 官方维护了一个公共仓库 Docker Hub，其中已经包括了数量超过 15,000 的镜像。大部分需求都可以通过在 Docker Hub 中直接下载镜像来实现。\n注册# 在 Docker Hub 免费注册一个 Docker 账号。\n登录# 通过执行 docker login 命令交互式的输入用户名及密码来完成在命令行界面登录 Docker Hub，通过 docker logout 退出登录。\n拉取镜像# 通过 docker search 命令查找官方仓库中的镜像，并利用 docker pull 命令来下载到本地，以 centos 为关键词为例\n[root@wangpengliang ~]# docker search centos NAME DESCRIPTION STARS OFFICIAL AUTOMATED centos The official build of CentOS. 6582 [OK] ansible/centos7-ansible Ansible on Centos7 134 [OK] consol/centos-xfce-vnc Centos container with \u0026#34;headless\u0026#34; VNC session… 129 [OK] jdeathe/centos-ssh OpenSSH / Supervisor / EPEL/IUS/SCL Repos - … 118 [OK] centos/systemd systemd enabled base container. 99 [OK] imagine10255/centos6-lnmp-php56 centos6-lnmp-php56 58 [OK] tutum/centos Simple CentOS docker image with SSH access 48 kinogmt/centos-ssh CentOS with SSH 29 [OK] pivotaldata/centos-gpdb-dev CentOS image for GPDB development. Tag names… 13 guyton/centos6 From official centos6 container with full up… 10 [OK] centos/tools Docker image that has systems administration… 7 [OK] drecom/centos-ruby centos ruby 6 [OK] pivotaldata/centos Base centos, freshened up a little with a Do… 5 mamohr/centos-java Oracle Java 8 Docker image based on Centos 7 3 [OK] pivotaldata/centos-gcc-toolchain CentOS with a toolchain, but unaffiliated wi… 3 darksheer/centos Base Centos Image -- Updated hourly 3 [OK] pivotaldata/centos-mingw Using the mingw toolchain to cross-compile t… 3 dokken/centos-7 CentOS 7 image for kitchen-dokken 2 indigo/centos-maven Vanilla CentOS 7 with Oracle Java Developmen… 2 [OK] amd64/centos The official build of CentOS. 2 pivotaldata/centos6.8-dev CentosOS 6.8 image for GPDB development 1 mcnaughton/centos-base centos base image 1 [OK] blacklabelops/centos CentOS Base Image! Built and Updates Daily! 1 [OK] pivotaldata/centos7-dev CentosOS 7 image for GPDB development 0 smartentry/centos centos with smartentry 0 [OK]看到返回了很多包含关键字的镜像，其中包括镜像名字、描述、收藏数（表示该镜像的受关注程度）、是否官方创建（OFFICIAL）、是否自动构建。\n根据是否是官方提供，可将镜像分为两类：\n类似 centos 这样的镜像，被称为基础镜像或根镜像。这些基础镜像由 Docker 公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。 还有一种类型，比如 tianon/centos 镜像，它是由 Docker Hub 的注册用户创建并维护的，往往带有用户名称前缀。可以通过前缀 username/ 来指定使用某个用户提供的镜像，比如 tianon 用户 在查找的时候通过 --filter=stars=N 参数可以指定仅显示收藏数量为 N 以上的镜像\n下载镜像# [root@wangpengliang ~]# docker pull centos Using default tag: latest latest: Pulling from library/centos 7a0437f04f83: Pull complete Digest: sha256:5528e8b1b1719d34604c87e11dcd1c0a20bedf46e83b5632cdeac91b8c04efc1 Status: Downloaded newer image for centos:latest docker.io/library/centos:latest推送镜像# 可以在登录后通过 docker push 命令来将自己的镜像推送到 Docker Hub 以下命令中的 username 替换为你的 Docker 账号用户名\n[root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx 2.0 546ad28bcf61 3 days ago 133MB redis 6.2.4 fad0ee7e917a 6 days ago 105MB redis latest fad0ee7e917a 6 days ago 105MB ubuntu latest 7e0aa2d69a15 6 weeks ago 72.7MB hello-world latest d1165f221234 3 months ago 13.3kB centos latest 300e315adb2f 6 months ago 209MB [root@wangpengliang ~]# docker login Login with your Docker ID to push and pull images from Docker Hub. If you dont have a Docker ID, head over to https://hub.docker.com to create one Username: wangpengliang Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded [root@wangpengliang ~]# docker tag nginx:2.0 wangpengliang/nginx:mytest [root@wangpengliang ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx 2.0 546ad28bcf61 3 days ago 133MB wangpengliang/nginx mytest 546ad28bcf61 3 days ago 133MB redis 6.2.4 fad0ee7e917a 6 days ago 105MB redis latest fad0ee7e917a 6 days ago 105MB ubuntu latest 7e0aa2d69a15 6 weeks ago 72.7MB hello-world latest d1165f221234 3 months ago 13.3kB centos latest 300e315adb2f 6 months ago 209MB [root@wangpengliang ~]# docker push wangpengliang/nginx:mytest The push refers to repository [docker.io/wangpengliang/nginx] 8be9905423d3: Pushed 075508cf8f04: Mounted from library/nginx 5c865c78bc96: Mounted from library/nginx 134e19b2fac5: Mounted from library/nginx 83634f76e732: Mounted from library/nginx 766fe2c3fc08: Mounted from library/nginx 02c055ef67f5: Mounted from library/nginx mytest: digest: sha256:05cb206e7659009b6cfe41d4891078aecf1656e527c5a075af609b9cfcad74df size: 1778\n自动构建# 有时候构建了镜像，安装了某个软件，当软件发布新版本则需要手动更新镜像。而自动构建允许通过 Docker Hub 指定跟踪一个目标网站（支持 GitHub 或 BitBucket）上的项目，一旦项目发生新的提交 （commit）或者创建了新的标签（tag），Docker Hub 会自动构建镜像并推送到 Docker Hub 中。自动构建（Automated Builds）功能对于需要经常升级镜像内程序来说十分方便。\n要配置自动构建，包括如下步骤\n登录 Docker Hub 在 Docker Hub 点击右上角头像，在账号设置（Account Settings）中关联（Linked Accounts）目标网站 在 Docker Hub 中新建或选择已有的仓库，在 Builds 选项卡中选择 Configure Automated Builds 选取一个目标网站中的项目（需要含 Dockerfile）和分支 指定 Dockerfile 的位置并保存之后，可以在 Docker Hub 的仓库页面的 Timeline 选项卡中查看每次构建的状态 私有仓库# 创建Docker私有仓库的目的在于私密性，适用于团体内部，如公司部门，企业内部等需要在团体成员中共享Docker相关资源的场景。docker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。\n下载镜像# [root@centos-01 ~]# docker pull registry Using default tag: latest latest: Pulling from library/registry ddad3d7c1e96: Pull complete 6eda6749503f: Pull complete 363ab70c2143: Pull complete 5b94580856e6: Pull complete 12008541203a: Pull complete Digest: sha256:bac2d7050dc4826516650267fe7dc6627e9e11ad653daca0641437abdf18df27 Status: Downloaded newer image for registry:latest docker.io/library/registry:latest启动容器并开放端口# [root@centos-01 ~]# docker run -d -p 5000:5000 --restart=always --name registry registry 63411fb8a1475200da83a72aed4c584d329f2d02a6d473a09a00be06cce189a2这里使用官方的 registry 镜像来启动私有仓库。默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下：\n[root@centos-01 ~]# docker run -d -p 5000:5000 --restart=always --name registry registry 63411fb8a1475200da83a72aed4c584d329f2d02a6d473a09a00be06cce189a2 [root@centos-01 ~]# ls anaconda-ks.cfg [root@centos-01 ~]# cd / [root@centos-01 /]# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var [root@centos-01 /]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 63411fb8a147 registry \u0026#34;/entrypoint.sh /etc…\u0026#34; About a minute ago Up About a minute 0.0.0.0:5000-\u0026gt;5000/tcp, :::5000-\u0026gt;5000/tcp registry [root@centos-01 /]# docker exec -it 63411fb8a147 /bin/sh / # ls bin entrypoint.sh home media opt root sbin sys usr dev etc lib mnt proc run srv tmp var / # cd /var/lib/registry/ /var/lib/registry # ls可以通过 -v 参数将镜像文件存储在本地的指定路径。例如下面的例子将上传的镜像放到本地的 /opt/data/registry 目录：\n$ docker run -d \\ -p 5000:5000 \\ -v /opt/data/registry:/var/lib/registry \\ registry上传/搜索/下载镜像# 创建好私有仓库后，就可以使用 docker tag 来标记一个镜像，然后推送到仓库。这里私有仓库地址为 192.168.31.32:5000 ，查看本机已有镜像：\n[root@centos-01 /]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest d1a364dc548d 2 weeks ago 133MB registry latest 1fd8e1b0bb7e 8 weeks ago 26.2MB使用 docker tag 将 nginx:latest 这个镜像标记为 192.168.31.32:5000/nginx:latest，格式为 :\ndocker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG][root@centos-01 /]# docker tag nginx:latest 192.168.31.32:5000/nginx:latest [root@centos-01 /]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE 192.168.31.32:5000/nginx latest d1a364dc548d 2 weeks ago 133MB nginx latest d1a364dc548d 2 weeks ago 133MB registry latest 1fd8e1b0bb7e 8 weeks ago 26.2MB使用 docker push 上传标记的镜像：\n[root@centos-01 /]# docker push 192.168.31.32:5000/nginx Using default tag: latest The push refers to repository [192.168.31.32:5000/nginx] Get https://192.168.31.32:5000/v2/: http: server gave HTTP response to HTTPS client这里发现无法成功推送镜像，原因是因为：Docker 默认不允许以非 HTTPS 方式推送镜像。可以通过 Docker 的配置选项来取消这个限制。对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在需要手动创建该文件）\ndaemon.json# { \u0026#34;registry-mirror\u0026#34;: [ \u0026#34;https://registry.docker-cn.com\u0026#34; ], \u0026#34;insecure-registries\u0026#34;: [ \u0026#34;192.168.31.32:5000\u0026#34; ] } 注意：该文件必须符合 json 规范，否则 Docker 将不能启动\n增加配置文件后，重启docker服务：\nsystemctl daemon-reload service docker restart再次测试 docker push :\n[root@centos-01 docker]# docker push 192.168.31.32:5000/nginx Using default tag: latest The push refers to repository [192.168.31.32:5000/nginx] 075508cf8f04: Pushed 5c865c78bc96: Pushed 134e19b2fac5: Pushed 83634f76e732: Pushed 766fe2c3fc08: Pushed 02c055ef67f5: Pushed latest: digest: sha256:61191087790c31e43eb37caa10de1135b002f10c09fdda7fa8a5989db74033aa size: 1570curl查看仓库中的镜像：\n[root@centos-01 docker]# curl 192.168.31.32:5000/v2/_catalog {\u0026#34;repositories\u0026#34;:[\u0026#34;nginx\u0026#34;]}看到 {\u0026quot;repositories\u0026quot;:[\u0026quot;nginx\u0026quot;]}，说明镜像成功上传。\n下面演示先删除已有镜像，再尝试从私有仓库中下载这个镜像：\n[root@centos-01 docker]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest d1a364dc548d 2 weeks ago 133MB 192.168.31.32:5000/nginx latest d1a364dc548d 2 weeks ago 133MB registry latest 1fd8e1b0bb7e 8 weeks ago 26.2MB [root@centos-01 docker]# docker rmi nginx:latest Untagged: nginx:latest Untagged: nginx@sha256:6d75c99af15565a301e48297fa2d121e15d80ad526f8369c526324f0f7ccb750 [root@centos-01 docker]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE 192.168.31.32:5000/nginx latest d1a364dc548d 2 weeks ago 133MB registry latest 1fd8e1b0bb7e 8 weeks ago 26.2MB [root@centos-01 docker]# docker rmi 192.168.31.32:5000/nginx:latest Untagged: 192.168.31.32:5000/nginx:latest Untagged: 192.168.31.32:5000/nginx@sha256:61191087790c31e43eb37caa10de1135b002f10c09fdda7fa8a5989db74033aa Deleted: sha256:d1a364dc548d5357f0da3268c888e1971bbdb957ee3f028fe7194f1d61c6fdee Deleted: sha256:fcc8faba78fe8a1f75025781c8fa1841079b75b54fce8408d039f73a48b7a81b Deleted: sha256:a476b265974ace4c857e3d88b358e848f126297a8249840c72d5f5ea1954a4bf Deleted: sha256:56722ee1ee7e73a5c6f96ea2959fa442fb4db9f044399bcd939bb0a6eb7919dc Deleted: sha256:c657df997c75f6c1a9c5cc683e8e34c6f29e5b4c1dee60b632d3477fd5fdd644 Deleted: sha256:e9e1f772d2a8dbbeb6a4a4dcb4f0d07ff1c432bf94fac7a2db2216837bf9ec5b Deleted: sha256:02c055ef67f5904019f43a41ea5f099996d8e7633749b6e606c400526b2c4b33 [root@centos-01 docker]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE registry latest 1fd8e1b0bb7e 8 weeks ago 26.2MB [root@centos-01 docker]# docker pull 192.168.31.32:5000/nginx:latest latest: Pulling from nginx 69692152171a: Pull complete 30afc0b18f67: Pull complete 596b1d696923: Pull complete febe5bd23e98: Pull complete 8283eee92e2f: Pull complete 351ad75a6cfa: Pull complete Digest: sha256:61191087790c31e43eb37caa10de1135b002f10c09fdda7fa8a5989db74033aa Status: Downloaded newer image for 192.168.31.32:5000/nginx:latest 192.168.31.32:5000/nginx:latest [root@centos-01 docker]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE 192.168.31.32:5000/nginx latest d1a364dc548d 2 weeks ago 133MB registry latest 1fd8e1b0bb7e 8 weeks ago 26.2MB私有仓库高级配置# 参考：https://www.bookstack.cn/read/docker_practice-v1.1.0/repository-registry_auth.md\nNexus 3# 参考：https://www.bookstack.cn/read/docker_practice-v1.1.0/repository-nexus3_registry.md\n"},{"id":13,"href":"/docs/docker/1.5docker%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/","title":"1.5 Docker数据管理","section":"所有文章","content":"在容器中管理数据主要有两种方式：\n数据卷（ Volumes ） 挂载主机目录 ( Bind Mounts ) 关于使用：-v or --mount，新手推荐选择 --mount 参数，经验丰富的自由发挥。\n容器数据卷# 数据卷（Volumes）是一个可供一个或多个容器使用的特殊目录它可以绕过 UFS，可以提供很多有用的特性：\n数据卷可以在容器之间共享和重用 对数据卷的修改会立马生效 对数据卷的更新不会影响镜像 数据卷默认会一直存在，即使容器被删除 数据卷的使用，类似 Linux 下对目录或文件进行 mount，镜像中被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）\n创建数据卷# [root@wangpengliang ~]# docker volume create myredis myredis查看所有数据卷# [root@wangpengliang ~]# docker volume ls DRIVER VOLUME NAME local myredis查看指定数据卷# [root@wangpengliang ~]# docker volume inspect myredis [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2021-05-26T13:35:05+08:00\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: {}, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/myredis/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;myredis\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ]启动容器# 使用 docker run 命令时，使用 --mount 标记来将数据卷挂载到容器里。在一次docker run中可以挂载多个数据卷。\ndocker run -d --name redis -v myredis:/data redis redis-server --appendonly yes # or docker run -d --name redis --mount source=myredis,target=/data redis redis-server --appendonly yes查看数据卷具体信息# $ docker inspect redis数据卷信息在 Mounts Key 下面\n删除数据卷\n$ docker volume rm myredis数据卷是用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 命令。\n无主的数据卷可能会占据很多空间，要清理使用以下命令：\n$ docker volume prune挂载主机目录# 挂载主机目录指挂载一个主机目录作为数据卷（Bind Mounts）。\n使用 --mount 标记可以指定挂载一个本地主机的目录到容器中：\ndocker run -d --name redis -v /data/docker/redis/data:/data redis redis-server --appendonly yes # or docker run -d --name redis --mount type=bind,source=/data/docker/redis/data,target=/data redis redis-server --appendonly yes上面命令加载宿主机的/data/docker/redis/data 目录到容器的 /data目录。\n注意：本地目录路径必须是绝对路径，使用 -v 参数时如果本地目录不存在 Docker 会自动创建一个目录，使用--mount参数时如果本地目录不存在，Docker 会报错\nDocker 挂载主机目录的默认权限是读写，也可以通过增加 readonly 指定为只读：\ndocker run -d --name redis -v /data/docker/redis/data:/data:ro redis redis-server --appendonly yes # or docker run -d --name redis6 --mount type=bind,source=/data/docker/redis/data,target=/data,ro redis redis-server --appendonly yes加了readonly之后，就挂载为只读了。如果在容器内 /bin 目录新建文件，会显示如下错误\n加了 readonly 之后，就挂载为只读了。如果在容器内 /bin 目录新建文件，会显示如下错误：\nRead-only file system简拼\nro ：ReadOnly rw ：ReadAndWrite 挂载方式判定# -v 容器内路径 匿名挂载 -v 卷名:容器内路径 具名挂载 -v /宿主机路径:容器内路径 指定路径挂载 指定路径挂载# docker run -it -v [本地路径]:[容器内路径] docker run -d --name redis -v /data/docker/redis/data:/data redis redis-server /etc/redis/redis.conf --appendonly yes # 查看容器详细信息 docker inspect redis\n匿名挂载# docker run -d --name redis -v /data redis redis-server --appendonly yes # 查看容器详细信息 docker inspect redis\n具名挂载# docker run -d --name redis -v redis:/data redis redis-server --appendonly yes 推荐使用具名挂载因为方便后期查找或其他操作\n数据卷容器 # 定义一个容器（挂载了数据卷的），其他容器通过挂载这个容器(父容器)实现数据共享，挂载数据卷的容器，称为数据卷容器（ --volumes-from）。通过数据卷容器可以实现容器间的数据共享。\ndocker run -it/ -d -p 主机端口:容器端口 --name=容器名称 --volumes-from 数据卷容器ID/数据卷容器名称 生成数据卷容器的镜像ID/镜像名称[:版本号] 注：这里数据共享的方式：是拷贝不是共享，这就意味着哪怕父数据卷容器被停止，子容器数据还是存在的\n"},{"id":14,"href":"/docs/docker/1.6docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/","title":"1.6 Docker容器网络模式","section":"所有文章","content":"安装Docker时会自动创建三个网络。可以使用 docker network ls 命令列出网络：\n[root@centos-01 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE cdda3ae8795a bridge bridge local ed7ffc7437dd host host local fa66bc1a17f4 none null local四种网络模式# 在使用 docker run 创建容器时，可以用 --network 指定容器的网络模式，Docker有以下四种网络模式：\n--net=host ：容器和宿主机共享 Network namespace --net=none ：容器有独立的 Network namespace，但并没有对其进行任何网络设置，如分配 veth pair 和网桥连接、配置IP等 --net=bridge：默认设置 --net=container:name_Or_id ：容器和另外一个容器共享 Network namespace Bridge# 简介# 该模式是在启动docker服务后默认的网络模式，Docker 启动时，Docker使用Linux桥接（参考《Linux虚拟网络技术》），在宿主机虚拟一个Docker容器网桥 docker0，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为 Container-IP ，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的 Container-IP 互相通信。\n当创建一个 Docker 容器时，同时会创建一个 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以接收相同的数据包）。这对接口一端在容器内，即 eth0 ；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头。通过这种方式主机可以跟容器通信，容器之间也可以相互通信。Docker就创建了在主机和所有容器之间的一个虚拟共享网络。\n在安装和启动docker服务之后即可查看到这个 docker0 的虚拟网桥设备：\n[root@centos-01 ~]# ip addr 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:50:75:ae brd ff:ff:ff:ff:ff:ff inet 192.168.126.143/24 brd 192.168.126.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 2409:8900:2b86:13cc:a958:4c6e:c162:309d/64 scope global noprefixroute dynamic valid_lft 3569sec preferred_lft 3569sec inet6 fe80::1f3a:afc1:82f6:3f66/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:cb:f1:35:ea brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever docker0 网桥是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络是无法通过ip地址直接寻址的，需要通过其他方式来使外部网络可以访问容器，一般会通过 访问宿主机ip结合容器的端口（端口映射）进行容器的访问\n实现步骤\nDocker Daemon 利用 veth pair 技术，在宿主机上创建两个虚拟网络接口设备，假设为 veth0 和 veth1 。 veth pair 技术的特性可以保证无论哪一个 veth 接收到网络报文，都会将报文传输给另一方 Docker Daemon 将 veth0 附加到 Docker Daemon 创建的 docker0 网桥上。保证宿主机的网络报文可以发往 veth0 Docker Daemon 将 veth1 添加到 Docker Container 所属的 namespace 下，并被改名为 eth0 。保证宿主机的网络报文若发往 veth0 则立即会被 eth0 接收，实现宿主机到Docker Container网络的联通，同时也保证容器单独使用 eth0，实现容器网络环境的隔离 缺陷\n该模式下容器不具有公有IP ，就是说和宿主机的 eth0 不处于同一个网段。导致的结果是：在宿主机以外不能直接和容器进行通信 虽然经过中间处理（NAT模式） 可以解决公有IP的问题，但是NAT模式仍然存在问题与不便，比如：容器都需要在宿主机上竞争端口，容器内部服务的访问者需要使用服务发现获知服务的外部端口等 另外由于NAT模式是在三层网络上的实现手段，会影响网络传输效率 测试# 1)：查看本机网络\n[root@centos-01 ~]# ip addr 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:50:75:ae brd ff:ff:ff:ff:ff:ff inet 192.168.126.143/24 brd 192.168.126.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 2409:8900:2b86:13cc:a958:4c6e:c162:309d/64 scope global noprefixroute dynamic valid_lft 3569sec preferred_lft 3569sec inet6 fe80::1f3a:afc1:82f6:3f66/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: docker0: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP\u0026gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:cb:f1:35:ea brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever2)：创建容器并查看IP\n[root@centos-01 ~]# docker run -d --name nginx nginx 8afe1080ba992614f96b6868dbbcab463e37c98f8d3fa729245d48c2e6a1e3fe [root@centos-01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8afe1080ba99 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 seconds ago Up 2 seconds 80/tcp nginx [root@centos-01 ~]# docker inspect nginx\n发现其ip为 172.17.0.2 ,当容器桥接 docker0 后，会自动分配 ip 地址，之后的IP地址递增。\n3)：查看网桥和端口连接\n[root@centos-01 ~]# brctl show bridge name\tbridge id\tSTP enabled\tinterfaces docker0\t8000.0242cbf135ea\tno\tveth3a98010一个新的网络接口 veth3a98010 被挂到了 docker0 上， veth3a98010 就是新创建容器的虚拟网卡。\n4)：查看veth pair 配置\n[root@centos-01 ~]# ip addr 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:50:75:ae brd ff:ff:ff:ff:ff:ff inet 192.168.126.143/24 brd 192.168.126.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 2409:8900:2b86:13cc:a958:4c6e:c162:309d/64 scope global noprefixroute dynamic valid_lft 3520sec preferred_lft 3520sec inet6 fe80::1f3a:afc1:82f6:3f66/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: docker0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:cb:f1:35:ea brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:cbff:fef1:35ea/64 scope link valid_lft forever preferred_lft forever 21: veth3a98010@if20: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 16:ea:7d:ca:a3:07 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::14ea:7dff:feca:a307/64 scope link valid_lft forever preferred_lft forever [root@centos-01 ~]# brctl show bridge name\tbridge id\tSTP enabled\tinterfaces docker0\t8000.0242cbf135ea\tno\tveth3a98010 [root@centos-01 ~]# docker exec -it nginx /bin/bash root@8afe1080ba99:/# cat /sys/class/net/eth0/iflink 21注意：veth 设备是成双成对出现的，一端在容器内部名为 eth0，一端加入到网桥名为 vethxxx （通常命名为veth），它们组成一个数据传输通道，一端进一端出，veth设备连接了两个网络设备并实现了数据通信；在bridge模式下，连在同一网桥上的容器可以相互通信。若出于安全考虑，也可以禁止它们之间通信，方法是在 DOCKER_OPTS 变量中设置 –icc=false，这样只有使用 –link 才能使两个容器通信。\nHost# 简介# 如果启动容器时使用的是host模式，那么容器将不会获得一个独立的 Network Namespace（网络命名空间） ，而是和宿主机系统共用一个。这意味着：容器不会虚拟出自己的网卡以及配置自己的ip等，而是使用宿主机的ip以及端口。不过在其他方面例如文件系统、进程列表等还是与之隔离的。使用host模式的容器可以直接使用宿主机的IP地址与外界通信，容器内部的服务端口也可以使用宿主机的端口，不需要进行 NAT ，Host最大的优势就是网络性能比较好，但是已经被使用的端口就不能再用了。\n介绍\nhost 网络模式需要在容器创建时指定 --network=host host 模式可以直接使用宿主机的IP地址与外界进行通信，若宿主机的 eth0 是一个公有 IP，那么容器也拥有这个公有IP。同时容器内服务的端口也可以使用宿主机的端口，无需额外进行 NAT 转换 host模式可以让容器共享宿主机网络栈，这样的好处是外部主机与容器直接通信，但是容器的网络缺少隔离性 缺陷\n容器网络环境隔离性的弱化。即容器不再拥有隔离、独立的网络栈 使用 host 模式的容器虽然可以让容器内部的服务和传统情况无差别、无改造的使用，但是由于网络隔离性的弱化，该容器会与宿主机竞争网络栈的使用 容器内部将不再拥有所有的端口资源，原因是部分端口资源已经被宿主机本身的服务占用，还有部分端口已经用以 bridge 网络模式容器的端口映射 测试# [root@centos-01 ~]# docker run -d --network=host --name nginx nginx ba0eb1c89ab6b505619db9b6789074db397a9f729ce18aeb82543986971b83d1 [root@centos-01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ba0eb1c89ab6 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 seconds ago Up 2 seconds nginx注意\n不需要添加 -p 参数，因为它使用的就是主机的IP和端口，添加 -p 参数后，反而会出现警告： WARNING: Published ports are discarded when using host network mode 宿主机的ip路由转发功能一定要打开，否则所创建的容器无法联网。echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward host端口占用模式是容器占用主机上当前所监听的端口(官网描述为publish)。比如这里nginx占用80端口，那么用host模式启动的时候，主机上的80端口会被nginx占用，这时其他的容器就不能再指定80端口，但可以指定其他端口，所以说一台主机上可以运行多个host模式的容器，只要彼此监听的端口不一样即可\n[root@centos-01 ~]# curl 192.168.126.143:80 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;Container# Container模式 与 Host模式 类似，指定新创建的容器和已经存在的一个容器共享一个 Network Namespace 。这意味着：新建的容器不会创建自己的网卡等相关操作，而是和与指定的容器共享这些资源。除了网络方面，其文件系统、进程列表等都是隔离的。\n注：它并没有改善容器与宿主机以外世界通信的情况（和桥接模式一样，不能连接宿主机以外的其他设备）\n[root@centos-01 ~]# docker run -d --name nginx --network=container:ba0eb1c89ab6b50 nginxNone# Docker容器拥有自己的 Network Namespace ，但不会对容器进行任何的网络配置。这意味着：这个容器没有网卡、IP、路由等信息。需要自己为Docker容器添加网卡、配置IP等。这种方式网络的隔离性最为彻底，即表明关闭了容器的网络功能，也无法访问这个容器。\n[root@centos-01 ~]# docker run -d --name nginx --network=none nginx参考# https://www.w3cschool.cn/docker/docker-command-manual.html https://docs.docker.com/reference/ https://www.runoob.com/docker/docker-command-manual.html https://blog.csdn.net/qq_43791724/article/details/109758108 https://zhuanlan.zhihu.com/p/83041422 "},{"id":15,"href":"/docs/docker/1.7docker%E9%AB%98%E7%BA%A7%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/","title":"1.7 Docker高级网络配置","section":"所有文章","content":"除了自动创建的网络，还可以创建自定义网络。Docker提供三种自定义网络驱动： bridge /overlay / macvlan ，其中 overlay 和 macvlan 用于创建跨主机的网络。\n注意：建议使用自定义的网络来控制哪些容器可以相互通信，可以自动DNS解析容器名称到IP地址\n除了自动创建的网络还可以创建自定义网络。Docker提供三种自定义网络驱动：\nbridge overlay macvlan 其中 overlay 和 macvlan 用于创建跨主机的网络。\n注意：建议使用自定义的网络来控制哪些容器可以相互通信，可以自动DNS解析容器名称到IP地址\n自定义创建bridge网络# 通过 bridge 驱动创建类似于默认的 bridge 网络（自定义网桥中会自己分配ip地址和网关地址）。\n创建自定义网桥\n[root@centos-01 ~]# docker network create --driver bridge my-net c62a2e3d6ad5dece71a470cde488ad9c41c24fac9380689f43905ffbd70d4389 [root@centos-01 ~]# brctl show bridge name\tbridge id\tSTP enabled\tinterfaces br-c62a2e3d6ad5\t8000.0242ae4b8680\tno\tdocker0\t8000.0242cbf135ea\tno\t[root@centos-01 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE f6524186651f bridge bridge local ed7ffc7437dd host host local c62a2e3d6ad5 my-net bridge local fa66bc1a17f4 none null local看到新增网桥 br-c62a2e3d6ad5， c62a2e3d6ad5 是新建网桥 my-net 的短id，docker network inspect 看下 my-net 的配置信息：\n[root@centos-01 ~]# docker network inspect my-net [ { \u0026#34;Name\u0026#34;: \u0026#34;my-net\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;c62a2e3d6ad5dece71a470cde488ad9c41c24fac9380689f43905ffbd70d4389\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2021-06-18T11:16:55.17530733+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.19.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.19.0.1\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: {}, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ]这里 172.19.0.0/16 是 Docker 自动分配的IP网段，网关为 172.19.0.1 ,在 my-net 对应的网桥br-c62a2e3d6ad5上\n如果想要指定IP网段。只需在创建网段时指定 --subnet 和 -gateway 参数即可，命令如下：\ndocker network create --driver bridge --subnet 172.22.16.0/24 --gateway 172.22.16.1 my-net容器要使用新的网络，需要在启动时通过 --network 指定：\n[root@centos-01 ~]# docker run -d --network=my-net --name nginx nginx 2104ba150f62d9ea552d09b05ccb0b376db10ce054b50908d16361a639826b84查看容器配置：\n容器分配到的IP为 172.19.0.2 到目前为止，这里的IP是docker自动从 subnet 中分配的，如果想要指定一个静态IP可以通过 --ip 指定。\n这里有个问题需要注意：\n[root@centos-01 ~]# docker run -d --network=my-net --ip 172.19.0.110 --name nginx nginx 5506e7ca82c8252727d8e7e4ae2c25ae1e3e5276fcf031112a17702ac4194e77 docker: Error response from daemon: user specified IP address is supported only when connecting to networks with user configured subnets.Docker中只有使用 --subnet 创建的网络才能指定静态IP。因此在使用 docker-compose 或者 docker run 命令创建容器时，如果需要指定可以使用 ：\n–subnet 指定 IP 段 –gateway 指定网关 my-net 指定网桥名称 同网桥下容器通信# nginx1：\n[root@centos-01 ~]# docker run -d --name nginx1 --network=my-net nginx 96a448f4c29fef3038abdd91410d7f9264ef3620cb1a80974bcb63694e61953c\n[root@centos-01 ~]# docker exec -it nginx1 /bin/bash root@96a448f4c29f:/# ping 172.19.0.3 PING 172.19.0.3 (172.19.0.3) 56(84) bytes of data. 64 bytes from 172.19.0.3: icmp_seq=1 ttl=64 time=0.175 ms 64 bytes from 172.19.0.3: icmp_seq=2 ttl=64 time=0.052 ms 64 bytes from 172.19.0.3: icmp_seq=3 ttl=64 time=0.044 msnginx2:\n[root@centos-01 ~]# docker run -d --name nginx2 --network=my-net nginx 8d47f51c8138e0ef935f3e8a7447c16a655ce21f18e87a0af0bc6e5ea2daaa21\n[root@centos-01 ~]# docker exec -it nginx2 /bin/bash root@8d47f51c8138:/# ping 172.19.0.2 PING 172.19.0.2 (172.19.0.2) 56(84) bytes of data. 64 bytes from 172.19.0.2: icmp_seq=1 ttl=64 time=0.043 ms 64 bytes from 172.19.0.2: icmp_seq=2 ttl=64 time=0.064 ms 64 bytes from 172.19.0.2: icmp_seq=3 ttl=64 time=0.049 ms结果可知：同一网络中的容器、网关之间都是可以通信的。\n容器跨网桥通信# 这里有个问题是 my-net 与默认的 bridge 网络是否可以通信，正常来说两个网络属于不同的网桥应该不能通信，测试一下：\n[root@centos-01 ~]# docker ps -a 1CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8d47f51c8138 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 32 minutes ago Up 32 minutes 80/tcp nginx2 96a448f4c29f nginx \u0026#34;/docker-entrypoint.…\u0026#34; 32 minutes ago Up 32 minutes 80/tcp nginx1 [root@centos-01 ~]# docker run -d --name nginx3 nginx 220cc3010771f7a3b0c778d4d5668baa860e969e8d5a6cde830290b31dad89fd [root@centos-01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 220cc3010771 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 seconds ago Up 2 seconds 80/tcp nginx3 8d47f51c8138 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 32 minutes ago Up 32 minutes 80/tcp nginx2 96a448f4c29f nginx \u0026#34;/docker-entrypoint.…\u0026#34; 32 minutes ago Up 32 minutes 80/tcp nginx1 [root@centos-01 ~]# brctl show bridge name\tbridge id\tSTP enabled\tinterfaces br-c62a2e3d6ad5\t8000.0242ae4b8680\tno\tveth0a1e1ba veth1069d0c docker0\t8000.0242cbf135ea\tno\tveth3147348 [root@centos-01 ~]# docker inspect nginx3\n新建容器 nginx3 但不指定网桥所以会使用默认的 bridge 网络，结果显示 br-c62a2e3d6ad5 上绑定了两个虚拟网卡 veth0a1e1ba 和 veth1069d0c 对应 nginx1 和 nginx2 , docker0 上绑定了 veth3147348 ，对应 ngnix3 ，分配的IP地址是 172.17.0.2 也可以看出来不在一个网段。\n[root@centos-01 ~]# docker exec -it nginx1 /bin/bash root@96a448f4c29f:/# ping 172.17.0.2 PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.结果可知：不同网段的确是 ping 不通的。\n思考：“不同的网络如果加上路由是否可以通信”，如果host上对每个网络都有一条路由，同时操作系统上打开了 ip forwarding ，host就成了一个路由器，挂接在不同网桥上的网络就能够相互通信。试试看。\n查看路由表：\n[root@centos-01 ~]# ip r default via 192.168.126.67 dev ens33 proto static metric 100 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.19.0.0/16 dev br-c62a2e3d6ad5 proto kernel scope link src 172.19.0.1 192.168.126.0/24 dev ens33 proto kernel scope link src 192.168.126.143 metric 100 172.17.0.0/16 和 172..16.0/24 两个网络的路由都定义好了。再看看 ip forwarding ：\n[root@centos-01 ~]# sysctl net.ipv4.ip_forward net.ipv4.ip_forward = 1这里看到路由转发也是开启的，条件都满足的情况下为什么还不行呢，再看看 iptables 这里看到原因是因为： iptables DROP掉了网桥 dockero 与 br-c62a2e3d6ad5 之间双向的流量。从规则命名 DOCKER-ISOLATION 可知 docker 在设计上就是要隔离不同的 netwrok, 这里可以通过使用 docker network connect 命令添加一块网卡来实现不同网桥容器通信：\n[root@centos-01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 220cc3010771 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 34 hours ago Up 34 hours 80/tcp nginx3 8d47f51c8138 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 34 hours ago Up 34 hours 80/tcp nginx2 96a448f4c29f nginx \u0026#34;/docker-entrypoint.…\u0026#34; 34 hours ago Up 34 hours 80/tcp nginx1 [root@centos-01 ~]# docker network connect my-net 220cc3010771 #将nginx3连接到my-net中[root@centos-01 ~]# docker exec -it nginx1 /bin/bash root@96a448f4c29f:/# ping 172.19.0.4 PING 172.19.0.4 (172.19.0.4) 56(84) bytes of data. 64 bytes from 172.19.0.4: icmp_seq=1 ttl=64 time=0.130 ms 64 bytes from 172.19.0.4: icmp_seq=2 ttl=64 time=0.046 ms 64 bytes from 172.19.0.4: icmp_seq=3 ttl=64 time=0.060 ms此时发现 nginx1 已经可以访问到 nginx3 了。\n端口映射# 容器访问外网是通过 iptables 的 SNAT 实现的，docker容器在启动的时候，如果不指定端口映射参数，容器外部无法通过网络访问容器内的网络应用和服务。需要设置端口映射，也可以使用 Dockerfile 文件中的 EXPOSE 指令来配置。\n端口映射使用 -p 、 -P 来实现\n-p 容器内部端口绑定到指定的主机端口 -P 容器内部端口随机映射到主机的高端口 格式：指定ip:指定宿主机端口:指定容器端口/IP:HOSTPORT:CONTAINERPORT\n这适用于将容器端口映射到指定地址的指定端口：\n[root@wangpengliang ~]# docker run -it -d -p 127.0.0.1:5000:5000 --name redis redis #将容器的5000端口映射到指定地址127.0.0.1的5000端口上 c2179a906b05e210c42eb6561cf76285f3391e703d5db249a154e06d4d025f28 [root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4927cb5dfe67 redis \u0026#34;docker-entrypoint.s…\u0026#34; 49 seconds ago Up 48 seconds 127.0.0.1:5000-\u0026gt;5000/tcp, 6379/tcp redis格式：指定ip、宿主机随机端口、指定容器端口 /IP::CONTAINERPORT\n这适用于将容器端口映射到指定地址的任意端口：\n[root@wangpengliang ~]# docker run -it -d -p 127.0.0.1::5000 --name redis redis #将容器的5000端口映射到指定地址127.0.0.1的任意端口上 c19e6b8f249db67b2f50455d35159f718a1d68e6efd02c106f0148bae14ba496 [root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c19e6b8f249d redis \u0026#34;docker-entrypoint.s…\u0026#34; 2 seconds ago Up 2 seconds 6379/tcp, 127.0.0.1:49153-\u0026gt;5000/tcp redis格式：不指定ip、指定宿主机端口、指定容器端口/HOSTPORT:CONTAINERPORT\n这适用于将容器指定端口映射到宿主机的指定端口：\n[root@wangpengliang ~]# docker run -it -d -p 80:8000 --name redis redis #将容器的8000端口映射到宿主机的80端口上 3ad63ffd90665413e644cd16f2eb7d404fcb14bb509eee05f67e0db8f1c067a4 [root@wangpengliang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3ad63ffd9066 redis \u0026#34;docker-entrypoint.s…\u0026#34; 5 seconds ago Up 4 seconds 6379/tcp, 0.0.0.0:80-\u0026gt;8000/tcp, :::80-\u0026gt;8000/tcp redis绑定 UDP 端口# 默认情况下 -p 和 -P 绑定的都是 tcp 协议端口，如果要绑定 udp 协议端口，只能使用 -p 参数，且在最后添加 /udp 字符串。\n[root@wangpengliang ~]# docker run -d -p 127.0.0.1:5553:5000/udp jcdemo/flaskapp 6aa30aa070a6e77f0d3f8653df69c654edf6e8bb68cea475aefbc68f6f7f9572绑定多个端口# 多次使用 -p 参数可以映射多个端口。\n[root@wangpengliang ~]# docker run -d -p 5552:5000 -p 5551:5001 jcdemo/flaskapp fa116ae4f5c19d82d9d4f40560c3219c85540a21d88f7fa999b60382ab57524a查看映射端口# docker port container_ID #容器ID #结果输出 80/tcp -\u0026gt; 0.0.0.0:800跨主机网络解决方案# TODO\n"},{"id":16,"href":"/docs/docker/1.8dockerfile/","title":"1.8 Dockerfile","section":"所有文章","content":"之前已经了解到镜像的定制实际上就是定制每一层所添加的配置、文件。如果可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，这就是 Dockerfile。\n格式描述# Dockerfile 整体由两类语句组成\nComment 注释信息 Instruction arguments 指令参数，一行一个指令 注意\nDockerfile 文件名首字母必须大写 Dockerfile 指令不区分大小写，但为方便和参数做区分，通常指令使用大写字母 Dockerfile 指令按顺序从上至下依次执行 Dockerfile 第一个非注释行必须是 FROM 指令，用来指定制作当前镜像依据的是哪个基础镜像 Dockerfile 需要调用的文件必须跟 Dockerfile 文件在同一目录下，或者在其子目录下。父目录或者其它路径无效 FROM# 功能为指定基础镜像，并且必须是第一条指令 如果不以任何镜像为基础写法为： FROM scratch ，意味着接下来所写的指令将作为镜像的第一层开始 注意：如果没有指定仓库，docker build 会先从本机查找是否有此基础镜像，如果没有默认去 Docker Hub Registry 上拉取，再找不到就会报错\nFROM \u0026lt;image\u0026gt; FROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; FROM \u0026lt;image\u0026gt;:\u0026lt;digest\u0026gt; # 三种写法，其中\u0026lt;tag\u0026gt;和\u0026lt;digest\u0026gt; 是可选项，如果没有选择，那么默认值为latestMAINTAINER（新版本过时）# Dockerfile 作者信息，一般格式是：姓名+邮箱地址 并不限制 MAINTAINER 指令的位置，但建议放在 FROM 指令之后 在较新的 docker 版本中，MAINTAINER 已经被 LABEL 替代 MAINTAINER \u0026#34;merle@example.com\u0026#34;LABEL# 为镜像指定各种元数据（键值对格式）: LABEL 会继承基础镜像中的 LABEL ，如遇 key 相同值将会被覆盖\nLABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt;COPY# 复制宿主机上的文件到目标镜像中，格式：\nCOPY [--chown=:] \u0026lt;源路径\u0026gt;... \u0026lt;目标路径\u0026gt; COPY [--chown=:] [\u0026#34;\u0026lt;源路径1\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;目标路径\u0026gt;\u0026#34;]和 RUN 指令一样，COPY 也有两种格式，一种类似于命令行，一种类似于函数调用。COPY 指令将从构建上下文目录中 \u0026lt;源路径\u0026gt; 的文件/目录复制到新的一层的镜像内的 \u0026lt;目标路径\u0026gt; 位置。比如：\nCOPY package.json /usr/src/app/\u0026lt;源路径\u0026gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，比如：\nCOPY hom* /mydir/ COPY hom?.txt /mydir/\u0026lt;目标路径\u0026gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先创建缺失目录。\n注意：使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候\n在使用该指令的时候还可以加上 --chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt; 选项来改变文件的所属用户及所属组\nCOPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ COPY --chown=1 files* /mydir/ COPY --chown=10:11 files* /mydir/ADD# ADD 指令跟 COPY 类似，不过它支持使用 tar 文件和 URL 路径 当拷贝的源文件是 tar 文件时，会自动展开为一个目录并拷贝进新的镜像中。通过 URL 获取到的 tar 文件不会自动展开 主机可以联网的情况下， docker build 可以将网络上的某文件引用下载并打包到新的镜像中 ADD \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; ADD [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 注意：ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。在 Docker 官方的 Dockerfile 最佳实践文档 中要求，尽可能的使用 COPY，因为 COPY 的语义很明确，就是复制文件，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。因此在 COPY 和 ADD 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD\n在使用该指令的时候也可以加上 --chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt; 选项来改变文件的所属用户及所属组\nADD --chown=55:mygroup files* /mydir/ ADD --chown=bin files* /mydir/ ADD --chown=1 files* /mydir/ ADD --chown=10:11 files* /mydir/WORKDIR# 同 docker run -w 指定工作目录，可以指定多个，每个 WORKDIR 只影响它下面的指令，直到遇见下一个 WORKDIR 为止 WORKDIR 可以调用由 ENV 指令定义的变量 WORKDIR 相对路径或者绝对路径：相对路径是相对于上一个 WORKDIR 指令的路径，如果上面没有 WORKDIR 指令，那就是当前 Dockerfile 文件的目录 VOLUME# 同 docker run -v 用于在镜像中创建一个挂载点目录。之前提到 Volume 有两种类型：挂载主机目录和数据卷。在Dockerfile中只支持docker数据卷，也就是说只能指定容器内的路径，不能指定宿主机的路径 VOLUME \u0026lt;mountpoint\u0026gt; VOLUME [\u0026#34;\u0026lt;mountpoint\u0026gt;\u0026#34;]EXPOSE# 同 docker run -expose 指定容器中待暴露的端口。比如容器提供的是一个https服务且需要对外提供访问，那就需要指定待暴露443端口，然后在使用此镜像启动容器时搭配 -P 参数才能将待暴露的状态转换为真正暴露的状态，转换的同时443也会转换成一个随机端口，跟 -p:443一个意思 EXPOSE 指令可以一次指定多个端口，例如： EXPOSE 11111/udp 11112/tcp EXPOSE \u0026lt;port\u0026gt;[/\u0026lt;protocol\u0026gt;] [\u0026lt;port\u0026gt;[/\u0026lt;protocol\u0026gt;] ...] \u0026lt;protocol\u0026gt;用于指定协议类型，如果不指定，默认TCP协议ENV# 同 docker run -e 为镜像定义所需的环境变量，并可被 ENV 指令后面的其它指令所调用。调用格式为 $variable_name 或者 ${variable_name} 使用 docker run 启动容器的时候加上 -e 的参数为 variable_name 赋值，可以覆盖 Dockerfile 中 ENV 指令指定的环境变量值。但不会影响到 Dockerfile 中已经引用过此变量的文件 ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... # 第一种格式一次只能定义一个变量，\u0026lt;key\u0026gt;之后所有内容都会被视为\u0026lt;value\u0026gt;的组成部分 # 第二种格式一次可以定义多个变量，每个变量为一个\u0026#34;=\u0026#34;的键值对，如果\u0026lt;value\u0026gt;中包含空格，可以用反斜线 \\ 进行转义，也可以为\u0026lt;value\u0026gt;加引号，另外参数过长时可用反斜线做续行。 # 定义多个变量时，建议使用第二种方式，因为Dockerfile中每一行都是一个镜像层，构建起来比较吃资源RUN# 用于指定 docker build 过程中运行的程序，可以是任何命令 RUN 指令后所执行的命令必须在 FROM 指令后的基础镜像中存在才行 RUN \u0026lt;command\u0026gt; RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;]第一种后边直接跟 shell 命令\nlinux 上默认 /bin/sh -c windows 上默认 cmd /S /C 第二种类似于函数调用，可将 executable 理解成为可执行文件，后面就是两个参数。\nRUN /bin/bash -c 'source $HOME/.bashrc; echo $HOME RUN [\u0026quot;/bin/bash\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;echo hello\u0026quot;] 注意：多行命令不要写多个RUN，原因是Dockerfile中每一个指令都会建立一层，多少个RUN就构建了多少层镜像，会造成镜像的臃肿、多层，不仅仅增加了构件部署的时间，还容易出错。RUN书写时的换行符是 \\\nCMD# 指定启动容器的默认要运行的程序，也就是 PID 为1的进程命令，且其运行结束后容器也会终止。如果不指定，默认是 bash CMD 指令指定的默认程序会被 docker run 命令行指定的参数所覆盖 Dockerfile 中可以存在多个 CMD 指令，但仅最后一个生效。因为一个 docker 容器只能运行一个 PID 为1的进程。 CMD 类似于 RUN 指令，也可以运行任意命令或程序，但是两者的运行时间点不同（ RUN 指令运行在 docker build 的过程中，而 CMD 指令运行在基于新镜像启动容器也就是 docker run 时） CMD command param1 param2 CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] CMD [\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;]前两种语法格式同 RUN 指令。第一种用法对于CMD指令基本没有意义，因为它运行的程序PID不为1。 第三种则需要结合 ENTRYPOINT 指令使用，CMD指令后面的命令作为 ENTRYPOINT 指令的默认参数。如果 docker run 命令行结尾有参数指定，那 CMD 后面的参数不生效。\nENTRYPOINT# 类似 CMD 指令的功能，用于为容器指定默认运行程序 Dockerfile 中可以存在多个 ENTRYPOINT 指令，但仅最后一个生效 与CMD区别在于：由 ENTRYPOINT 启动的程序不会被 docker run 命令行指定的参数所覆盖，而且这些命令行参数会被当做参数传递给 ENTRYPOINT 指令指定的程序 docker run 的 --entrypoint 选项的参数可覆盖 ENTRYPOINT 指定的默认程序 ENTRYPOINT command param1 param2 ENTRYPOINT [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;]USER# 用于指定 docker build 过程中任何 RUN 、 CMD 等指令的用户名或者 UID 默认情况下容器的运行用户为 root USER \u0026lt;user\u0026gt;[:\u0026lt;group\u0026gt;] USER \u0026lt;UID\u0026gt;[:\u0026lt;GID\u0026gt;] 实践中UID需要是 /etc/passwd 中某用户的有效UID，否则docker run命令将运行失败\nHEALTHCHECK# 顾名思义，健康检查。此指令的就是告诉 docker 检查容器是否正常工作\nHEALTHCHECK [OPTIONS] CMD command HEALTHCHECK NONEHEALTHCHECK 指令定义一个 CMD ，在CMD后面编写一条命令去判断服务运行是否正常。检查肯定不是一次性的，所以 OPTIONS 就是指定检查的频率等\n--interval=DURATION （默认值：30s）：每隔多久检查一次，默认30s --timeout=DURATION （默认值：30s）：超时时长，默认30s --start-period=DURATION （默认值：0s）：启动健康检查的等待时间。因为容器启动成功时，进程不一定立马就启动成功，过早开始检查就会返回不健康 --retries=N （默认值：3）：如果检查一次失败就返回不健康未免太武断，所以默认三次机会 CMD 健康检测命令发出时，返回值有三种情况：\n0：成功 1：不健康 2：保留，无实际意义。 HEALTHCHECK NONE 就是不做健康检查\nHEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1SHELL# 用来指定运行程序默认要使用的 shell 类型，因为 windows 环境默认是 powershell 。此指令一般不会使用。\nSHELL [\u0026#34;executable\u0026#34;, \u0026#34;parameters\u0026#34;]STOPSIGNAL# 指定发送使容器退出的系统调用信号。 docker stop 之所以能停止容器，就是发送了15的信号给容器内PID为1的进程。此指令一般不会使用。\nSTOPSIGNAL signalARG# ARG 命令同 EVN 类似，也是指定一个变量，但不同的是， ENV 指令配合 -e 参数可以在 docker run 过程中传参，而使用 ARG 指令配合 --build-arg 参数可以在 docker build 过程中传参，方便为不同场景构建不同镜像。\nARG \u0026lt;name\u0026gt;[=\u0026lt;default value\u0026gt;]ONBUILD# 用于在 Dockerfile 中定义一个触发器 ONBUILD 后面指定的指令在 docker build 时是不会执行，构建完的镜像在被另一个 Dockerfile 文件中 FROM 指令所引用的时才会触发执行 ONBUILD [INSTRUCTION] 几乎任何指令都可以成为触发器指令，但 ONBUILD 不能自我嵌套，且不会触发 FROM 和 MAINTAINER 指令，多数情况是使用 RUN 或者 ADD 在使用 COPY 指令时，应该注意后续引用该镜像的 Dockerfile 的同级目录下是否有被拷贝的文件 "},{"id":17,"href":"/docs/docker/1.9dockercompose/","title":"1.9 Docker Compose","section":"所有文章","content":" Docker Compose 是 Docker 官方编排（Orchestration）项目之一，负责实现对 Docker 容器集群的快速编排，快速的部署分布式应用。\n通过之前学习已经了解到使用一个 Dockerfile 模板文件，可以很方便的定义一个单独的应用容器。然而在日常工作中，经常碰到的情况是需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器、负载均衡容器等等。Compose 就是用来处理这些事情的。它通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目project。\nCompose 中有两个重要的概念：\n服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理，Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此只要所操作的平台支持 Docker API 就可以在其上利用 Compose 来进行编排管理。\n安装# Compose 支持 Linux、macOS、Windows 10 三大平台，安装方式：\n通过 Python 的包管理工具 pip 进行安装 直接下载编译好的二进制文件使用 直接在 Docker 容器中运行 前两种方式是传统方式，适合本地环境下安装使用；最后一种方式则不破坏系统环境，更适合云计算场景，Docker for Mac 、 Docker for Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。\n查看本机是否安装\n[root@wangpengliang ~]# docker-compose --version -bash: docker-compose: 未找到命令Linux下安装 Compose\n在 Linux 上安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。\n例如，在 Linux 64 位系统上直接下载对应的二进制包\n$ sudo curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-uname -s-uname -m \u0026gt; /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose查看本机架构\n[root@wangpengliang ~]# uname -m x86_64这里选择使用二进制包下载安装\n[root@wangpengliang ~]# curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 633 100 633 0 0 63 0 0:00:10 0:00:09 0:00:01 155 100 8649k 100 8649k 0 0 292k 0 0:00:29 0:00:29 --:--:-- 1989k [root@wangpengliang ~]# curl -L https://raw.githubusercontent.com/docker/compose/1.8.0/contrib/completion/bash/docker-compose \u0026gt; /etc/bash_completion.d/docker-compose % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 10554 100 10554 0 0 1435 0 0:00:07 0:00:07 --:--:-- 2753 [root@wangpengliang ~]# chmod +x /usr/local/bin/docker-compose [root@wangpengliang ~]# docker-compose --version docker-compose version 1.17.1, build 6d101fbPIP 安装\n注意： x86_64 架构的 Linux 建议按照上边的方法下载二进制包进行安装，如果计算机的架构是 ARM (例如，树莓派)，再使用 pip 安装\n这种方式是将 Compose 当作一个 Python 应用来从 pip 源中安装\n执行安装命令：\nsudo pip install -U docker-compose看到类似如下输出，说明安装成功\nCollecting docker-compose Downloading docker-compose-1.17.1.tar.gz (149kB): 149kB downloaded ... Successfully installed docker-compose cached-property requests texttable websocket-client docker-py dockerpty six enum34 backports.ssl-match-hostname ipaddressbash 补全命令\n$ curl -L https://raw.githubusercontent.com/docker/compose/1.8.0/contrib/completion/bash/docker-compose \u0026gt; /etc/bash_completion.d/docker-compose容器中执行 Compose 既然是一个 Python 应用，自然也可以直接用容器来执行\n$ curl -L https://github.com/docker/compose/releases/download/1.8.0/run.sh \u0026gt; /usr/local/bin/docker-compose $ chmod +x /usr/local/bin/docker-compose查看下载的 run.sh 脚本内容\nset -e VERSION=\u0026#34;1.8.0\u0026#34; IMAGE=\u0026#34;docker/compose:$VERSION\u0026#34; # Setup options for connecting to docker host if [ -z \u0026#34;$DOCKER_HOST\u0026#34; ]; then DOCKER_HOST=\u0026#34;/var/run/docker.sock\u0026#34; fi if [ -S \u0026#34;$DOCKER_HOST\u0026#34; ]; then DOCKER_ADDR=\u0026#34;-v $DOCKER_HOST:$DOCKER_HOST -e DOCKER_HOST\u0026#34; else DOCKER_ADDR=\u0026#34;-e DOCKER_HOST -e DOCKER_TLS_VERIFY -e DOCKER_CERT_PATH\u0026#34; fi # Setup volume mounts for compose config and context if [ \u0026#34;$(pwd)\u0026#34; != \u0026#39;/\u0026#39; ]; then VOLUMES=\u0026#34;-v $(pwd):$(pwd)\u0026#34; fi if [ -n \u0026#34;$COMPOSE_FILE\u0026#34; ]; then compose_dir=$(dirname $COMPOSE_FILE) fi # TODO: also check --file argument if [ -n \u0026#34;$compose_dir\u0026#34; ]; then VOLUMES=\u0026#34;$VOLUMES -v $compose_dir:$compose_dir\u0026#34; fi if [ -n \u0026#34;$HOME\u0026#34; ]; then VOLUMES=\u0026#34;$VOLUMES -v $HOME:$HOME -v $HOME:/root\u0026#34; # mount $HOME in /root to share docker.config fi # Only allocate tty if we detect one if [ -t 1 ]; then DOCKER_RUN_OPTIONS=\u0026#34;-t\u0026#34; fi if [ -t 0 ]; then DOCKER_RUN_OPTIONS=\u0026#34;$DOCKER_RUN_OPTIONS -i\u0026#34; fi exec docker run --rm $DOCKER_RUN_OPTIONS $DOCKER_ADDR $COMPOSE_OPTIONS $VOLUMES -w \u0026#34;$(pwd)\u0026#34; $IMAGE \u0026#34;$@\u0026#34;可以看到，其实是下载了 docker/compose 镜像并运行\n卸载# 如果是二进制包方式安装的，删除二进制文件即可\n$ sudo rm /usr/local/bin/docker-compose如果是通过 pip 安装的，则执行如下命令即可\n$ sudo pip uninstall docker-compose使用# 之前说到Compose 中有两个重要的概念：\n服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例 项目 (project)：由一组关联的应用容器组成的一个完整业务单元 可见，一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。\n创建Web应用\n示例用 Python 创建一个能够记录页面访问次数的 web 网站。新建文件夹，在该目录中编写 app.py 文件\nfrom flask import Flask from redis import Redis app = Flask(__name__) redis = Redis(host=\u0026#39;redis\u0026#39;, port=6379) @app.route(\u0026#39;/\u0026#39;) def hello(): count = redis.incr(\u0026#39;hits\u0026#39;) return \u0026#39;Hello World! 该页面已被访问 {} 次。\\n\u0026#39;.format(count) if __name__ == \u0026#34;__main__\u0026#34;: app.run(host=\u0026#34;0.0.0.0\u0026#34;, debug=True)Dockerfile\n编写 Dockerfile 文件内容为：\nFROM python:3.6-alpine ADD . /code WORKDIR /code RUN pip install redis flask CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;]docker-compose.yml\n编写 docker-compose.yml 文件，这个是 Compose 使用的主模板文件\nversion: \u0026#39;3\u0026#39; services: web: build: . ports: - \u0026#34;5000:5000\u0026#34; redis: image: \u0026#34;redis:alpine\u0026#34;运行 compose\ndocker-compose up创建 pythontests 目录，创建 app.py Dockerfile docker-compose.yml 文件\n[root@wangpengliang pythontests]# ls app.py docker-compose.yml Dockerfile运行 docker-compose\n[root@wangpengliang pythontests]# docker-compose up Building web Step 1/5 : FROM python:3.6-alpine # 下载基础镜像python:3.6-alpine 3.6-alpine: Pulling from library/python 540db60ca938: Pull complete a7ad1a75a999: Pull complete 5545670c3922: Pull complete c89910f38943: Pull complete b6a40d090e87: Pull complete Digest: sha256:492bb540e9c9bc9f586d5d69467c66bc32072d9af48463b1f0054d4ff9b93709 Status: Downloaded newer image for python:3.6-alpine ---\u0026gt; ac438c122d19 Step 2/5 : ADD . /code # 拷贝文件到/code目录 ---\u0026gt; 68cbe5b2f598 Step 3/5 : WORKDIR /code # 设置/code目录为工作目录 ---\u0026gt; Running in 4fd09a1580a8 Removing intermediate container 4fd09a1580a8 # 拆卸中间容器：4fd09a1580a8 ---\u0026gt; 2e4bbd31555d Step 4/5 : RUN pip install redis flask # 运行pip安装redis、flask ---\u0026gt; Running in c12f4ece64f1 Collecting redis Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB) Collecting flask Downloading Flask-2.0.1-py3-none-any.whl (94 kB) Collecting click\u0026gt;=7.1.2 Downloading click-8.0.1-py3-none-any.whl (97 kB) Collecting Werkzeug\u0026gt;=2.0 Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB) Collecting itsdangerous\u0026gt;=2.0 Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB) Collecting Jinja2\u0026gt;=3.0 Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB) Collecting importlib-metadata Downloading importlib_metadata-4.5.0-py3-none-any.whl (17 kB) Collecting MarkupSafe\u0026gt;=2.0 Downloading MarkupSafe-2.0.1.tar.gz (18 kB) Collecting dataclasses Downloading dataclasses-0.8-py3-none-any.whl (19 kB) Collecting typing-extensions\u0026gt;=3.6.4 Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB) Collecting zipp\u0026gt;=0.5 Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB) Building wheels for collected packages: MarkupSafe Building wheel for MarkupSafe (setup.py): started Building wheel for MarkupSafe (setup.py): finished with status \u0026#39;done\u0026#39; Created wheel for MarkupSafe: filename=MarkupSafe-2.0.1-py3-none-any.whl size=9761 sha256=e2a25263f4c7babbdd0cdda87cad139e54eb972cf742f2f7b7893003e0ecfe97 Stored in directory: /root/.cache/pip/wheels/05/46/9b/189d9acb1f643857fb8ad990ca04c02509c35d3ad6fac81794 Successfully built MarkupSafe Installing collected packages: zipp, typing-extensions, MarkupSafe, importlib-metadata, dataclasses, Werkzeug, Jinja2, itsdangerous, click, redis, flask Successfully installed Jinja2-3.0.1 MarkupSafe-2.0.1 Werkzeug-2.0.1 click-8.0.1 dataclasses-0.8 flask-2.0.1 importlib-metadata-4.5.0 itsdangerous-2.0.1 redis-3.5.3 typing-extensions-3.10.0.0 zipp-3.4.1 WARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv Removing intermediate container c12f4ece64f1 ---\u0026gt; 061f502fa95e Step 5/5 : CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] ---\u0026gt; Running in c6ac95ba9659 Removing intermediate container c6ac95ba9659 ---\u0026gt; aabe65a53ffd Successfully built aabe65a53ffd Successfully tagged pythontests_web:latest WARNING: Image for service web was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Pulling redis (redis:alpine)... alpine: Pulling from library/redis 29712d301e8c: Pull complete 8173c12df40f: Pull complete 8cc52074f78e: Pull complete aa7854465cce: Pull complete 6ab1d05b4973: Pull complete Digest: sha256:eaaa58f8757d6f04b2e34ace57a71d79f8468053c198f5758fd2068ac235f303 Status: Downloaded newer image for redis:alpine Creating pythontests_web_1 Creating pythontests_redis_1 Attaching to pythontests_redis_1, pythontests_web_1 redis_1 | 1:C 09 Jun 2021 03:16:24.588 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo redis_1 | 1:C 09 Jun 2021 03:16:24.588 # Redis version=6.2.4, bits=64, commit=00000000, modified=0, pid=1, just started redis_1 | 1:C 09 Jun 2021 03:16:24.588 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf redis_1 | 1:M 09 Jun 2021 03:16:24.588 * monotonic clock: POSIX clock_gettime redis_1 | 1:M 09 Jun 2021 03:16:24.590 * Running mode=standalone, port=6379. redis_1 | 1:M 09 Jun 2021 03:16:24.590 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. redis_1 | 1:M 09 Jun 2021 03:16:24.590 # Server initialized redis_1 | 1:M 09 Jun 2021 03:16:24.590 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. redis_1 | 1:M 09 Jun 2021 03:16:24.590 * Ready to accept connections web_1 | * Serving Flask app \u0026#39;app\u0026#39; (lazy loading) web_1 | * Environment: production web_1 | WARNING: This is a development server. Do not use it in a production deployment. web_1 | Use a production WSGI server instead. web_1 | * Debug mode: on web_1 | * Running on all addresses. web_1 | WARNING: This is a development server. Do not use it in a production deployment. web_1 | * Running on http://172.19.0.2:5000/ (Press CTRL+C to quit) web_1 | * Restarting with stat web_1 | * Debugger is active! web_1 | * Debugger PIN: 103-300-970 web_1 | 172.19.0.1 - - [09/Jun/2021 03:17:00] \u0026#34;GET / HTTP/1.1\u0026#34; 200 -测试结果\n[root@wangpengliang pythontests]# curl 172.18.0.2:5000 Hello World! 该页面已被访问 1 次。 [root@wangpengliang pythontests]# curl 172.18.0.2:5000 Hello World! 该页面已被访问 2 次。 [root@wangpengliang pythontests]# curl 172.18.0.2:5000 Hello World! 该页面已被访问 3 次。 [root@wangpengliang pythontests]# curl 172.18.0.2:5000 Hello World! 该页面已被访问 4 次。 [root@wangpengliang pythontests]# curl 172.18.0.2:5000 Hello World! 该页面已被访问 5 次。命令对象与格式# 对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目。这意味着项目中所有的服务都会受到命令影响。\n查看具体某个命令的使用格式：\ndocker-compose [COMMAND] --help 或 docker-compose help [COMMAND]docker-compose 命令的基本使用格式：\ndocker-compose [-f=\u0026lt;arg\u0026gt;...] [options] [COMMAND] [ARGS...]命令选项# -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息 -v, --version 打印版本并退出 命令使用说明# build# 格式： docker-compose build [options] [SERVICE...]\n构建（重新构建）项目中的服务容器。服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。可以随时在项目目录下运行 docker-compose build 来重新构建服务\n选项：\n--force-rm 删除构建过程中的临时容器 --no-cache 构建镜像过程中不使用 cache（这将加长构建过程） --pull 始终尝试通过 pull 来获取更新版本的镜像 config# 验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。\ndown# 此命令将会停止 up 命令所启动的容器，并移除网络。\nexec# 进入指定容器。\nhelp# 获得一个命令的帮助。\nimages# 列出 Compose 文件中包含的镜像。\nkill# 格式： docker-compose kill [options] [SERVICE...]\n通过发送 SIGKILL 信号来强制停止服务容器。支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号\n$ docker-compose kill -s SIGINTlogs# 格式： docker-compose logs [options] [SERVICE...]\n查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。该命令在调试问题的时候经常使用\npause# 格式：docker-compose pause [SERVICE...]\n暂停一个服务容器\nport# 格式： docker-compose port [options] SERVICE PRIVATE_PORT\n打印某个容器端口所映射的公共端口\n选项：\n--protocol=proto 指定端口协议，tcp（默认值）或者 udp --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1） ps# 格式： docker-compose ps [options] [SERVICE...]\n列出项目中目前的所有容器。\n选项：\n-q 只打印容器的 ID 信息 pull# 格式： docker-compose pull [options] [SERVICE...]\n拉取服务依赖的镜像\n选项：\n--ignore-pull-failures 忽略拉取镜像过程中的错误 push# 推送服务依赖的镜像到 Docker 镜像仓库\nrestart# 格式：docker-compose restart [options] [SERVICE...]\n重启项目中的服务\n选项：\n-t, --timeout TIMEOUT 指定重启前停止容器的超时（默认10 秒） rm# 格式：docker-compose rm [options] [SERVICE...]\n删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器\n选项：\n-f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项 -v 删除容器所挂载的数据卷 run# 格式： docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]\n在指定服务上执行一个命令\n例如：\n$ docker-compose run ubuntu ping docker.com这将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。\n两个不同点：\n给定命令将会覆盖原有的自动运行命令 不会自动创建端口，以避免冲突 如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如：\n$ docker-compose run --no-deps web python manage.py shell将不会启动 web 容器所关联的其它容器。\n选项：\n-d 后台运行容器 --name NAME 为容器指定一个名字 --entrypoint CMD 覆盖默认的容器启动指令 -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量 -u, --user=\u0026quot;\u0026quot; 指定运行容器的用户名或者 uid --no-deps 不自动启动关联的服务容器 --rm 运行命令后自动删除容器，d 模式下将忽略 -p, --publish=[] 映射容器端口到本地主机 --service-ports 配置服务端口并映射到本地主机 -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行 scale# 格式： docker-compose scale [options] [SERVICE=NUM...]\n设置指定服务运行的容器个数。\n通过 service=num 的参数来设置数量。例如：\n$ docker-compose scale web=3 db=2这将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。\n一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。\n选项：\n-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 start# 格式： docker-compose start [SERVICE...]\n启动已经存在的服务容器\nstop# 格式： docker-compose stop [options] [SERVICE...]\n停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器\n选项：\n-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top# 查看各个服务容器内运行的进程\nunpause# 格式： docker-compose unpause [SERVICE...]\n恢复处于暂停状态中的服务\nup# 格式： docker-compose up [options] [SERVICE...]\n该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。链接的服务都将会被自动启动，除非已经处于运行状态。大部分时候都可以直接通过该命令来启动一个项目。默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。\n当通过 Ctrl-C 停止命令时，所有容器将会停止。\n如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。\n默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果只想重新部署某个服务，可以使用 docker-compose up --no-deps -d \u0026lt;SERVICE_NAME\u0026gt; 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 选项：\n-d 在后台运行服务容器。 --no-color 不使用颜色来区分不同的服务的控制台输出。 --no-deps 不启动服务所链接的容器。 --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build 不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 version# 格式： docker-compose version\n打印版本信息\nCompose 模板文件# 模板文件是使用 Compose 的核心，涉及到的指令关键字也大部分指令跟 docker run 相关参数的含义都是类似的。默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。\nversion: \u0026#34;3\u0026#34; services: webapp: image: examples/web ports: - \u0026#34;80:80\u0026#34; volumes: - \u0026#34;/data\u0026#34; 注意：每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像\n如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。\nbuild# 指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。\nversion: \u0026#39;3\u0026#39; services: webapp: build: ./dir也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。\nversion: \u0026#39;3\u0026#39; services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1使用 cache_from 指定构建镜像的缓存\nbuild: context: . cache_from: - alpine:latest - corp/web_app:3.14cap_add, cap_drop# 指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力：\ncap_add: - ALL去掉 NET_ADMIN 能力：\ncap_drop: - NET_ADMINcommand# 覆盖容器启动后默认执行的命令。\ncommand: echo \u0026#34;hello world\u0026#34;cgroup_parent# 指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。\ncgroup_parent: cgroups_1container_name# 指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。\ncontainer_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称\ndevices# 指定设备映射关系。\ndevices: - \u0026#34;/dev/ttyUSB1:/dev/ttyUSB0\u0026#34;depends_on# 解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web。\nversion: \u0026#39;3\u0026#39; services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动\ndns# 自定义 DNS 服务器。可以是一个值，也可以是一个列表。\ndns: 8.8.8.8 dns: - 8.8.8.8 - 114.114.114.114dns_search# 配置 DNS 搜索域。可以是一个值，也可以是一个列表。\ndns_search: example.com dns_search: - domain1.example.com - domain2.example.comtmpfs# 挂载一个 tmpfs 文件系统到容器。\ntmpfs: /run tmpfs: - /run - /tmpenv_file# 从文件中获取环境变量，可以为单独的文件路径或列表。如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。\nenv_file: .env env_file: - ./common.env - ./apps/web.env - /opt/secrets.env环境变量文件中每一行必须符合格式，支持 # 开头的注释行。\n# common.env: Set development environment PROG_ENV=developmentenvironment# 设置环境变量。可以使用数组或字典两种格式。只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。\nenvironment: RACK_ENV: development SESSION_SECRET: environment: - RACK_ENV=development - SESSION_SECRET如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括\ny|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFFexpose# 暴露端口，但不映射到宿主机，只被连接的服务访问。仅可以指定内部端口为参数。\nexpose: - \u0026#34;3000\u0026#34; - \u0026#34;8000\u0026#34;external_links# 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。\n注意：不建议使用该指令\nexternal_links: - redis_1 - project_db_1:mysql - project_db_1:postgresqlextra_hosts# 类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。\nextra_hosts: - \u0026#34;googledns:8.8.8.8\u0026#34; - \u0026#34;dockerhub:52.1.157.61\u0026#34;会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目\n8.8.8.8 googledns 52.1.157.61 dockerhubhealthcheck# 通过命令检查容器是否健康运行。\nhealthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;curl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;http://localhost\u0026#34;] interval: 1m30s timeout: 10s retries: 3image# 指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。\nimage: ubuntu image: orchardup/postgresql image: a4bc65fdlabels# 为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。\nlabels: com.startupteam.description: \u0026#34;webapp for a startup team\u0026#34; com.startupteam.department: \u0026#34;devops department\u0026#34; com.startupteam.release: \u0026#34;rc3 for v1.0\u0026#34;links# 注意：不推荐使用该指令\nlogging# 配置日志选项。\nlogging: driver: syslog options: syslog-address: \u0026#34;tcp://192.168.0.42:123\u0026#34;目前支持三种日志驱动类型\ndriver: \u0026quot;json-file\u0026quot; driver: \u0026quot;syslog\u0026quot; driver: \u0026quot;none\u0026quot; options 配置日志驱动的相关参数\noptions: max-size: \u0026#34;200k\u0026#34; max-file: \u0026#34;10\u0026#34;network_mode# 设置网络模式。使用和 docker run 的 --network 参数一样的值。\nnetwork_mode: \u0026#34;bridge\u0026#34; network_mode: \u0026#34;host\u0026#34; network_mode: \u0026#34;none\u0026#34; network_mode: \u0026#34;service:[service name]\u0026#34; network_mode: \u0026#34;container:[container name/id]\u0026#34;networks# 配置容器连接的网络。\nversion: \u0026#34;3\u0026#34; services: some-service: networks: - some-network - other-network networks: some-network: other-network:pid# 跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。pid: \u0026quot;host\u0026quot;\nports# 暴露端口信息。使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。\nports: - \u0026#34;3000\u0026#34; - \u0026#34;8000:8000\u0026#34; - \u0026#34;49100:22\u0026#34; - \u0026#34;127.0.0.1:8001:8001\u0026#34; 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式\nsecrets# 存储敏感数据，例如 mysql 服务密码。\nversion: \u0026#34;3.1\u0026#34; services: mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secret secrets: my_secret: file: ./my_secret.txt my_other_secret: external: truesecurity_opt# 指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。\nsecurity_opt: - label:user:USER - label:role:ROLEstop_signal# 设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。stop_signal: SIGUSR1\nsysctls# 配置容器内核参数。\nsysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0 sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0ulimits# 指定容器的 ulimits 限制值。例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。\nulimits: nproc: 65535 nofile: soft: 20000 hard: 40000volumes# 数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。该指令中路径支持相对路径。\nvolumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro其它指令# 此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir 等指令，基本跟 docker run 中对应参数的功能一致。\n指定服务容器启动后执行的入口文件\nentrypoint: /code/entrypoint.sh\n指定容器中运行应用的用户名 user: nginx\n指定容器中工作目录 working_dir: /code\n指定容器中搜索域名、主机名、mac 地址等\ndomainname: your_website.com hostname: test mac_address: 08-00-27-00-0C-0A允许容器中运行一些特权命令 privileged: true\n指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped restart: always\n以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改 read_only: true\n打开标准输入，可以接受外部输入 stdin_open: true\n模拟一个伪终端 tty: true\n读取变量# Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。\nversion: \u0026#34;3\u0026#34; services: db: image: \u0026#34;mongo:${MONGO_VERSION}\u0026#34;如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。\n# 支持 # 号注释 MONGO_VERSION=3.6执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。\n"},{"id":18,"href":"/docs/docker/2.0dockermachine/","title":"2.0 Docker Machine","section":"所有文章","content":"概念# Docker Machine 是 Docker 官方编排（Orchestration）项目之一，负责在多种平台上快速安装 Docker 环境，基于 Go 语言实现。\n安装# Docker Machine 可以在多种操作系统平台上安装，包括 Linux、MacOS，以及 Windows。\nMacOS、Windows# Docker for Mac、Docker for Windows 自带 docker-machine 二进制包，安装之后即可使用。 查看版本信息\ndocker-machine -v docker-machine version 0.13.0, build 9ba6da9Linux# 在 Linux 上的安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。 在 Linux 64 位系统上直接下载对应的二进制包\ncurl -L https://github.com/docker/machine/releases/download/v0.16.2/docker-machine-`uname -s`-`uname -m` \u0026gt;/tmp/docker-machine \u0026amp;\u0026amp; chmod +x /tmp/docker-machine \u0026amp;\u0026amp; sudo cp /tmp/docker-machine /usr/local/bin/docker-machine这里因为下载太慢选择翻墙直接下载 releases 版本后copy到主机 /usr/local/bin/ 目录中。然后执行\nchmod +x /usr/local/bin/docker-machine完成后，查看版本信息\n[root@wangpengliang bin]# docker-machine -v docker-machine version 0.16.2, build bd45ab13使用# Docker Machine 支持多种后端驱动，包括虚拟机、本地主机和云平台等。\nVirtualbox 驱动# 使用 virtualbox 类型的驱动，创建一台 Docker 主机，命名为 test。\ndocker-machine create -d virtualbox test也可以在创建时加上如下参数，来配置主机或者主机上的 Docker\n--engine-opt dns=114.114.114.114 配置 Docker 的默认 DNS --engine-registry-mirror https://registry.docker-cn.com 配置 Docker 的仓库镜像 --virtualbox-memory 2048 配置主机内存 --virtualbox-cpu-count 2 配置主机 CPU更多参数使用 docker-machine create --driver virtualbox --help 命令查看\nmacOS xhyve 驱动# xhyve 驱动 GitHub: https://github.com/zchee/docker-machine-driver-xhyve，xhyve 是 macOS 上轻量化的虚拟引擎，使用其创建的 Docker Machine 较 VirtualBox 驱动创建的运行效率要高。\nbrew install docker-machine-driver-xhyve docker-machine create \\ -d xhyve \\ # --xhyve-boot2docker-url ~/.docker/machine/cache/boot2docker.iso \\ --engine-opt dns=114.114.114.114 \\ --engine-registry-mirror https://registry.docker-cn.com \\ --xhyve-memory-size 2048 \\ --xhyve-rawdisk \\ --xhyve-cpu-count 2 \\ xhyve 注意：非首次创建时建议加上 --xhyve-boot2docker-url ~/.docker/machine/cache/boot2docker.iso 参数，避免每次创建时都从 GitHub 下载 ISO 镜像。\n更多参数请使用 docker-machine create --driver xhyve --help 命令查看。\nWindows 10# Windows 10 安装 Docker for Windows 之后不能再安装 VirtualBox，也就不能使用 virtualbox 驱动来创建 Docker Machine，可以选择使用 hyperv 驱动。\n注意，必须事先在 Hyper-V 管理器中新建一个 外部虚拟交换机 执行下面的命令时，使用 --hyperv-virtual-switch=MY_SWITCH 指定虚拟交换机名称\ndocker-machine create --driver hyperv --hyperv-virtual-switch=MY_SWITCH vm更多参数使用 docker-machine create --driver hyperv --help 命令查看。\n使用介绍# 创建好主机之后，查看主机\ndocker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS test - virtualbox Running tcp://192.168.99.187:2376 v17.10.0-ce创建主机成功后，可以通过 env 命令来让后续操作对象都是目标主机\ndocker-machine env test后续根据提示在命令行输入命令之后就可以操作 test 主机。也可以通过 SSH 登录到主机\ndocker-machine ssh test docker@test:~$ docker --version Docker version 17.10.0-ce, build f4ffd25连接到主机之后就可以在其上使用 Docker 了\n官方支持驱动# 通过 -d 选项可以选择支持的驱动类型。\namazonec2 azure digitalocean exoscale generic google hyperv none openstack rackspace softlayer virtualbox vmwarevcloudair vmwarefusion vmwarevsphere 第三方驱动# 参考：第三方驱动列表\n操作命令# active 查看活跃的 Docker 主机 config 输出连接的配置信息 create 创建一个 Docker 主机 env 显示连接到某个主机需要的环境变量 inspect 输出主机更多信息 ip 获取主机地址 kill 停止某个主机 ls 列出所有管理的主机 provision 重新设置一个已存在的主机 regenerate-certs 为某个主机重新生成 TLS 认证信息 restart 重启主机 rm 删除某台主机 ssh SSH 到主机上执行命令 scp 在主机之间复制文件 mount 挂载主机目录到本地 start 启动一个主机 status 查看主机状态 stop 停止一个主机 upgrade 更新主机 Docker 版本为最新 url 获取主机的 URL version 输出 docker-machine 版本信息 help 输出帮助信息 每个命令，又带有不同的参数，可以通过$ docker-machine COMMAND --help查看具体用法\n"},{"id":19,"href":"/docs/docker/2.1dockerswarm/","title":"2.1 Docker Swarm","section":"所有文章","content":"背景介绍# 借助一个Redis实例来学习 Docker Swarm，背景：standalone 部署模式故障转移机制：独立部署 Redis ，借助 docker swarm 故障转移机制做到基本HA，多节点的Redis通过 NFS 实现容器数据共享。\n环境准备# 独立的 NFS 服务器\n192.168.158.143 部署NFS服务 Swarm 集群由 管理节点 和 工作节点 组成。这里创建一个包含一个管理节点和两个工作节点的最小 Swarm 集群\nIP IsManager 192.168.158.144 Yes 192.168.158.145 ​ 192.168.158.146 Docker Swarm# Docker Swarm 是 Docker 官方三剑客项目之一，提供 Docker 容器集群服务，是 Docker 官方对容器云生态进行支持的核心方案。使用它可以将多个 Docker 主机封装为单个大型的虚拟 Docker 主机，快速打造一套容器云平台。\n注意：Docker 1.12.0+ Swarm mode 已经内嵌入 Docker 引擎，成为了 docker 子命令 docker swarm，Docker 引擎 API 已经删除 Docker Swarm\nSwarm mode 内置 kv 存储功能，提供了众多新特性，比如：具有容错能力的去中心化设计、内置服务发现、负载均衡、路由网格、动态伸缩、滚动更新、安全传输等。\nSwarm 是使用 [SwarmKit](https://github.com/docker/swarmkit/) 构建的 Docker 引擎内置（原生）的集群管理和编排工具。使用 Swarm 集群之前需要了解以下几个概念。\n节点# 运行 Docker 的主机可以主动初始化一个 Swarm 集群或者加入一个已存在的 Swarm 集群，这样这个运行 Docker 的主机就成为一个 Swarm 集群的节点 (node) 。节点分为管理 (manager) 节点和工作 (worker) 节点。管理节点用于 Swarm 集群的管理，docker swarm 命令基本只能在管理节点执行（节点退出集群命令 docker swarm leave 可以在工作节点执行）。一个 Swarm 集群可以有多个管理节点，但只有一个管理节点可以成为 leader，leader 通过 raft 协议实现。工作节点是任务执行节点，管理节点将服务 (service) 下发至工作节点执行。管理节点默认也作为工作节点。也可以通过配置让服务只运行在管理节点。\n集群中管理节点与工作节点的关系\n服务和任务# 任务 （Task）是 Swarm 中的最小的调度单位，目前来说就是一个单一的容器。服务 （Services） 是指一组任务的集合，服务定义了任务的属性。服务有两种模式：\nreplicated services 按照一定规则在各个工作节点上运行指定个数的任务 global services 每个工作节点上运行一个任务 两种模式通过 docker service create 的 --mode 参数指定。\n容器/任务/服务的关系\nNFS 服务搭建# 服务端： 192.168.158.143安装 nfs-server\nyum -y install rpcbind nfs-utils systemctl start rpcbind systemctl enable rpcbind systemctl start nfs-server　//NFS依赖rpcbind进行通讯，所以要先启动rpcbind systemctl enable nfs-server客户端 ：192.168.158.145/192.168.158.146 安装 nfs-utils，这里管理节点 192.168.158.144 并不打算部署服务故不需要安装nfs-utils\nyum -y install nfs-utils创建共享目录\n//服务端 [root@centos-01 /]# mkdir -p /mnt/nfs_file/redis //客户端 [root@centos-01 /]# mkdir -p /mnt/nfs_file/redis 服务端NFS配置# vim /etc/exports/mnt/nfs_file/ 192.168.158.143/24(rw,sync,no_root_squash) //ro只读权限 //rw读写权限 //sync同步写入内存与磁盘当中 //no_all_squash保留共享文件的UID和GID（默认） //no_root_squash使得root用户具有根目录的完全访问权限[root@centos-01 ~]# vi /etc/exports [root@centos-01 ~]# cat /etc/exports /mnt/nfs_file/ 192.168.57.0/24(rw,sync,no_root_squash)配置生效\n[root@centos-01 ~]# exportfs -rv exporting 192.168.158.143/24:/mnt/nfs_file客户端NFS配置# 关联服务器\nmount -t nfs 192.168.158.143:/mnt/nfs_file /mnt/nfs_file//挂载测试 [root@centos-01 ~]# showmount -e 192.168.158.143 Export list for 192.168.158.143: /mnt/nfs_file 192.168.158.143/24备注：出现 clnt_create:RPC:Port mapper failure - Unable to receive:error 113(NO route to host) 报错时，需要关闭服务端与客户端之间的防火墙，或者开放NFS使用的2049端口。\nsystemctl stop firewalld //添加规则(指定端口，--permanent永久生效，没有此参数重启后失效） //firewall-cmd --zone=public --add-port=2049/tcp --permanentDocker 集群搭建# 创建集群# 管理节点：192.168.158.144 [root@centos-01 ~]# docker swarm init Swarm initialized: current node (khtc8jboe8dy7wm73x1cacnqf) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4fixdycxiue0273gkral83cn9bgqvkct13r9fo1k01iy6oaadm-e3rd668t3ww1b2w3e0xfxi8yo 192.168.158.144:2377 To add a manager to this swarm, run \u0026#39;docker swarm join-token manager\u0026#39; and follow the instructions.工作节点1：192.168.158.145\n[root@centos-01 ~]# docker swarm join --token SWMTKN-1-4fixdycxiue0273gkral83cn9bgqvkct13r9fo1k01iy6oaadm-e3rd668t3ww1b2w3e0xfxi8yo 192.168.158.144:2377 This node joined a swarm as a worker.工作节点2：192.168.158.146\n[root@centos-01 ~]# docker swarm join --token SWMTKN-1-4fixdycxiue0273gkral83cn9bgqvkct13r9fo1k01iy6oaadm-e3rd668t3ww1b2w3e0xfxi8yo 192.168.158.144:2377 This node joined a swarm as a worker.更改节点可用性# [root@centos-01 ~]# docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION 0aw4rk8kwos84yi0ca57q5pcq centos-01 Ready Active 20.10.6 579nqzz3p512aobe6mp4g93ep centos-01 Ready Active 20.10.6 khtc8jboe8dy7wm73x1cacnqf * centos-01 Ready Active Leader 20.10.6 [root@centos-01 ~]# docker node update --availability drain khtc8jboe8dy7wm73x1cacnqf khtc8jboe8dy7wm73x1cacnqf [root@centos-01 ~]# docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION 0aw4rk8kwos84yi0ca57q5pcq centos-01 Ready Active 20.10.6 579nqzz3p512aobe6mp4g93ep centos-01 Ready Active 20.10.6 khtc8jboe8dy7wm73x1cacnqf * centos-01 Ready Drain Leader 20.10.6查看集群状态# 192.168.158.144\n[root@centos-01 ~]# docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION 0aw4rk8kwos84yi0ca57q5pcq centos-01 Ready Active 20.10.6 579nqzz3p512aobe6mp4g93ep centos-01 Ready Active 20.10.6 khtc8jboe8dy7wm73x1cacnqf * centos-01 Ready Active Leader 20.10.6解散集群# docker swarm leave # 工作节点：主动离开集群，让节点处于down状态，才能删除 docker node rm g36lvv23ypjd8v7ovlst2n3yt # 管理节点：删除指定节点 docker swarm leave --force # 管理节点：解散集群Redis部署# standalone 部署模式区别于传统 Redis Cluster 部署，首先需要借助 NFS 实现多主机 Redis配置和持久化数据共享 借助 Docker Swarm 的故障转移机制来达到 基本的HA。\nRedis配置共享# [root@centos-01 ~]# cd /mnt/nfs_file/redis/ [root@centos-01 redis]# ls redis.conf 备注：redis.conf 需要关闭 Cluster-Enable Redis服务部署# [root@centos-01 ~]# docker service create -p 6379:6379 --name redis --mount type=bind,src=/mnt/nfs_file/redis/redis.conf,dst=/etc/redis/redis.conf --mount type=bind,src=/mnt/nfs_file/redis,dst=/data redis redis-server /etc/redis/redis.conf --appendonly yes gc4q2nrqwp6qbimjwy3un0lmn overall progress: 1 out of 1 tasks 1/1: running [==================================================\u0026gt;] verify: Service converged Docker Swarm 会随机选择一个工作节点（这里是 192.168.158.145 ）部署 一个Redis容器。\n查看运行服务# [root@centos-01 ~]# docker service ls ID NAME MODE REPLICAS IMAGE PORTS gc4q2nrqwp6q redis replicated 1/1 redis:latest *:6379-\u0026gt;6379/tcp 查看服务详情# [root@centos-01 ~]# docker service ps redis ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS zf137g379xj6 redis.1 redis:latest centos-01 Running Running 3 minutes ago 查看服务日志# [root@centos-01 ~]# docker service logs redis redis.1.zf137g379xj6@centos-01 | 1:C 16 Jul 2021 05:46:38.388 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo redis.1.zf137g379xj6@centos-01 | 1:C 16 Jul 2021 05:46:38.388 # Redis version=6.2.4, bits=64, commit=00000000, modified=0, pid=1, just started redis.1.zf137g379xj6@centos-01 | 1:C 16 Jul 2021 05:46:38.389 # Configuration loaded redis.1.zf137g379xj6@centos-01 | 1:M 16 Jul 2021 05:46:38.389 * monotonic clock: POSIX clock_gettime redis.1.zf137g379xj6@centos-01 | 1:M 16 Jul 2021 05:46:38.391 # Warning: Could not create server TCP listening socket ::1:6379: bind: Cannot assign requested address redis.1.zf137g379xj6@centos-01 | 1:M 16 Jul 2021 05:46:38.393 * Running mode=standalone, port=6379. redis.1.zf137g379xj6@centos-01 | 1:M 16 Jul 2021 05:46:38.394 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. redis.1.zf137g379xj6@centos-01 | 1:M 16 Jul 2021 05:46:38.394 # Server initialized redis.1.zf137g379xj6@centos-01 | 1:M 16 Jul 2021 05:46:38.394 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. redis.1.zf137g379xj6@centos-01 | 1:M 16 Jul 2021 05:46:38.396 * Ready to accept connections这里保证只有一个 Redis 容器运行（standalone 部署）,所以不需要使用 --replicas number 。 关于服务动态伸缩/服务更新与回滚/滚动更新等相关知识参考：https://www.bookstack.cn/read/docker_practice-v1.1.0/swarm_mode-README.md。\n删除服务# docker service rm redis测试# 基本功能测试# 使用 RedisClient 连接Redis 192.168.158.146 故障转移测试# 这里手动将 192.168.158.146 Redis容器停止，查看Swarm会怎么处理\n[root@centos-01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9855ebf35829 redis:latest \u0026#34;docker-entrypoint.s…\u0026#34; 4 minutes ago Up 4 minutes 6379/tcp redis.1.vys54q07u7egrmc64rnn2frj4 [root@centos-01 ~]# docker stop redis.1.vys54q07u7egrmc64rnn2frj4 redis.1.vys54q07u7egrmc64rnn2frj4 [root@centos-01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9855ebf35829 redis:latest \u0026#34;docker-entrypoint.s…\u0026#34; 4 minutes ago Exited (0) 4 seconds ago redis.1.vys54q07u7egrmc64rnn2frj4发现 192.168.158.145 上启动了一个新的Redis容器\n[root@centos-01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ef95253a0d79 redis:latest \u0026#34;docker-entrypoint.s…\u0026#34; 16 seconds ago Up 9 seconds 6379/tcp redis.1.jb9b26y4ikj8vc1k04j2gj35w管理节点中查看服务运行情况\n[root@centos-01 ~]# docker service ps redis ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS jb9b26y4ikj8 redis.1 redis:latest centos-01 Running Running 2 minutes ago vys54q07u7eg \\_ redis.1 redis:latest centos-01 Shutdown Complete 2 minutes ago 发现 Redis 已经被转移到了192.168.158.145 使用 RedisClient 连接192.168.158.145 使用 get name 发现可以找到数据，说明Redis容器的数据共享是没问题的。一旦某个节点挂掉，Swarm会自动转移到其他可用的工作节点，结合NFS的文件共享就可以实现Redis独立部署但拥有基本的HA。\nPortainer可视化# 在 192.168.158.1434 管理节点上运行 Portainer 容器。\n"},{"id":20,"href":"/docs/docker/2.2docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"2.2 Docker常用命令","section":"所有文章","content":"docker version# 显示docker版本信息。\ndocker info# 显示docker的系统信息，包括镜像和容器数量。\ndocker 命令 \u0026ndash;help# 帮助文档。\ndocker images# 查看所有本地主机上的镜像。\n[root@wangpengliang ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest bf756fb1ae65 10 months ago 13.3kB 标签 描述 TAG 镜像标签 IMAGE ID 镜像ID CREATED 镜像创建时间 SIZE 镜像大小 REPOSITORY 镜像仓库源 可选项 -a, --all：列出所有镜像 -q, --quiet：只显示镜像ID\ndocker search# 镜像搜索。\n[root@wangpengliang ~]# docker search mysql NAME DESCRIPTION STARS OFFICIAL AUTOMATED mysql MySQL is a widely used, open-source relation… 10910 [OK] mariadb MariaDB Server is a high performing open sou… 4119 [OK]可选项\n--filter STARS=3000： 搜索Stars数大于3000镜像\n[root@192 ~]# docker search mysql --filter STARS=3000docker pull# 下载镜像，默认下载最新版。\n[root@wangpengliang ~]# docker pull mysql Using default tag: latest # 如果不写tage，默认就是latest latest: Pulling from library/mysql bb79b6b2107f: Pull complete # 分层下载 docker iamge的核心 联合文件系统 49e22f6fb9f7: Pull complete 842b1255668c: Pull complete 9f48d1f43000: Pull complete c693f0615bce: Pull complete 8a621b9dbed2: Pull complete 0807d32aef13: Pull complete a56aca0feb17: Pull complete de9d45fd0f07: Pull complete 1d68a49161cc: Pull complete d16d318b774e: Pull complete 49e112c55976: Pull complete Digest: sha256:8c17271df53ee3b843d6e16d46cff13f22c9c04d6982eb15a9a47bd5c9ac7e2d # 签名 唯一表示 Status: Downloaded newer image for mysql:latest docker.io/library/mysql:latest # 真实地址等价于\ndocker pull mysql docker pull docker.io/library/mysql:latestdocker pull version# 指定版本下载。\n[root@192 ~]# docker pull mysql:5.7docker rmi# 删除镜像。\n[root@wangpengliang ~]# docker rmi -f 根据镜像ID删除指定镜像 [root@wangpengliang ~]# docker rmi -f 根据镜像ID删除多个镜像 [root@wangpengliang ~]# docker rmi -f $(docker images -qa) 删除所有镜像docker run [可选参数] image# 参数说明\n--name： 容器名 用来区分容器 -d ：后台方式运行 -it ：使用交互方式运行，进入容器查看内容 -p：指定容器的端口 -p 8080:8080 -P ：随机指定端口（大写-P） 测试启动容器\n[root@wangpengliang ~]# docker run -it centos /bin/bash [root@c1afa7ccf7d6 /]# ls bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var #退回容器到主机 [root@c1afa7ccf7d6 /]# exitdocker -ps# 查看Docker当前运行的容器。\n参数说明\n-a ：列出当前在运行的容器+历史容器 -q ：只显示容器编号 [root@192 ~]# docker ps -aexit# 退出容器。\ndocker rm cId/cName# docker rm 容器Id # 删除指定容器，不能删除在运行中的容器，如果要强制删除加-f docker rm -f $( docker ps -aq) # 删除所有容器 docker ps -a -q | xargs docker rm # 删除所有容器docker star cId/cName# 启动容器。\ndocker restart cId/cName# 重启容器。\ndocker stop cId/cName# 停止当前正在运行的容器。\ndocker kill cId/cName# 强制停止当前容器。\ndocker run -d cId/cName# 后台运行容器。\ndocerk logs cId/cName# 查看日志。\ndocker top cId/cName# 查看容器进程信息。\ndocker inspect cId/cName# 查看镜像的元数据新信息。\ndocker exec# [root@wangpengliang ~]# docker exec -it 88c647580c /bin/bashh [root@88c647580c32 /]# ls bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@88c647580c32 /]# ps -ef [root@88c647580c32 /]# exitdocker attach # [root@wangpengliang ~]# docker attach 88c647580cattach 与 exec 区别\ndocker exec： 进容器后开启一个新的后端，可以直接操作 docker attach：进入容器正在执行终端，不会启动新的进程 docker cp# 文件拷贝，从docker内拷贝文件到宿主机。\n#进入容器 [root@88c647580c32 /]# docker exec -it 88c647580c /bin/bash [root@88c647580c32 /]# cd home/ #创建文件 [root@88c647580c32 home]# touch test.txt [root@88c647580c32 home]# exit exit #拷贝文件 [root@88c647580c32 /]# docker cp 88c647580c:/home/test.txt /home/ [root@88c647580c32 /]# ls /home/ test.txt [root@88c647580c32 /]#apt-get update \u0026amp;\u0026amp; apt-get install iputils-ping # 在容器内安装 ping 工具。\n"},{"id":21,"href":"/docs/docker/2.3portainer%E5%8F%AF%E8%A7%86%E5%8C%96%E9%9D%A2%E6%9D%BF/","title":"2.3 Portainer可视化面板","section":"所有文章","content":"Docker的可视化管理工具有DockerUI、Shipyard、Rancher、Portainer等，具体的功能差异查看 Docker的可视化管理工具对比，Portainer是一个轻量级的docker环境管理UI，可以用来管理docker宿主机和docker swarm集群。\nPortainer主要功能\n提供状态显示面板：显示主机或者swarm集群上有多少镜像，容器、网络、数据卷等 应用模板快速部署：可以使用预存的模板或者自己定制的模板快速部署 镜像网络数据卷管理：通过页面进行管理和操作，例如构建镜像，增删数据卷等 事件日志显示：对任何操作有记录，并且有页面可以显示审计日志 容器控制台操作：查看容器，启停容器，查看容器占用的性能(内存，cpu等) Swarm集群管理：可以管理swarm集群，是最大的优点 登录用户管理：有完备的用户系统，权限控制（高级功能需付费） 部署Portiner容器\ndocker run -d -p 9000:9000 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer -v /var/run/docker.sock:/var/run/docker.sock：挂载本地 /var/run/docker.socker 与容器的 /var/run/docker.socker 连接 -v portainer_data:/data：数据持久化 参考： https://www.cnblogs.com/Yogile/p/12624404.html https://www.cnblogs.com/hellxz/p/install_portainer.html\n"},{"id":22,"href":"/docs/dotnet/1.1dataprotection%E7%AE%80%E4%BB%8B/","title":"1.1 Data Protection简介","section":"所有文章","content":"为什么需要数据保护# Web应用程序中经常需要存储一些敏感数据（如用户密码），Windows系统为桌面程序提供了 DPAPI用来使用，但是并不适用于Web系统。ASP.NET Core提供了一套简单易用的API用来保护数据。\n简单示例# public class MyClass { readonly IDataProtector protector; public MyClass(IDataProtectionProvider provider) { protector = provider.CreateProtector(nameof(MyClass)); } public void RunSample() { string testStr = \u0026#34;Hello World\u0026#34;; // 加密 string protectedPayload = protector.Protect(testStr); Console.WriteLine($\u0026#34;Protect returned: {protectedPayload}\u0026#34;); Console.WriteLine(\u0026#34;=========================================\u0026#34;); // 解密 string unprotectedPayload = protector.Unprotect(protectedPayload); Console.WriteLine($\u0026#34;Unprotect returned: {unprotectedPayload}\u0026#34;); } }[TestMethod()] public void Sample_01() { // 添加数据保护到服务中 var serviceCollection = new ServiceCollection(); serviceCollection.AddDataProtection(); var services = serviceCollection.BuildServiceProvider(); // 从DI中创建一个MyClass的实例 var instance = ActivatorUtilities.CreateInstance\u0026lt;MyClass\u0026gt;(services); instance.RunSample(); Assert.IsTrue(true); }\n在CreateProtector(nameof(MyClass))中，参数 nameof(MyClass) 可以理解为一个公钥或一个标识，表示当前Protector的用途。Data Protection 采用的是非对称加密，所以系统中应该还有一个私钥，此处的密钥由 ASP.NET Core 在系统内部维护，每一台机器都有一个自有的私钥。\n私钥存储# 如果程序寄宿在Microsoft Azure下，存储在%HOME%\\ASP.NET\\DataProtection-Keys文件夹 如果程序寄宿在IIS下，它被保存在HKLM注册表的ACLed特殊注册表键，并且只有工作进程可以访问，使用windows的DPAPI加密 如果当前用户可用，即win10或者win7中，它存储在%LOCALAPPDATA%\\ASP.NET\\DataProtection-Keys文件夹，同样使用windows的DPAPI加密 如果这些都不符合，那么也就是私钥是没有被持久化的，也就是说当进程关闭的时候，生成的私钥就丢失了 私钥文件# \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;key id=\u0026#34;bf2f4417-10fa-4d4d-ba61-b91c041029e0\u0026#34; version=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;creationDate\u0026gt;2021-03-08T02:18:08.641323Z\u0026lt;/creationDate\u0026gt; \u0026lt;activationDate\u0026gt;2021-03-09T09:07:57.9935838Z\u0026lt;/activationDate\u0026gt; \u0026lt;expirationDate\u0026gt;2021-06-06T02:18:08.5176468Z\u0026lt;/expirationDate\u0026gt; \u0026lt;descriptor deserializerType=\u0026#34;Microsoft.AspNetCore.DataProtection.AuthenticatedEncryption.ConfigurationModel.AuthenticatedEncryptorDescriptorDeserializer, Microsoft.AspNetCore.DataProtection, Version=2.1.1.0, Culture=neutral, PublicKeyToken=adb9793829ddae60\u0026#34;\u0026gt; \u0026lt;descriptor\u0026gt; \u0026lt;encryption algorithm=\u0026#34;AES_256_CBC\u0026#34; /\u0026gt; \u0026lt;validation algorithm=\u0026#34;HMACSHA256\u0026#34; /\u0026gt; \u0026lt;encryptedSecret decryptorType=\u0026#34;Microsoft.AspNetCore.DataProtection.XmlEncryption.DpapiXmlDecryptor, Microsoft.AspNetCore.DataProtection, Version=2.1.1.0, Culture=neutral, PublicKeyToken=adb9793829ddae60\u0026#34; xmlns=\u0026#34;http://schemas.asp.net/2015/03/dataProtection\u0026#34;\u0026gt; \u0026lt;encryptedKey xmlns=\u0026#34;\u0026#34;\u0026gt; \u0026lt;!-- This key is encrypted with Windows DPAPI. --\u0026gt; \u0026lt;value\u0026gt;AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAAdzyZbq38yUupe39PhMdBEAAAAAACAAAAAAAQZgAAAAEAACAAAACYrALB9ricGU/5Y6iOanIlQjSCb548eBxAWafTbwxtLAAAAAAOgAAAAAIAACAAAADd6x5zXIP/VC6r1Y5ZAf74uL/+lc68ilrliN7T8dGhYVABAAD0qlvH4LDPjhr3R9WTjP+mOJZrrtt8clI91ULbNPDN2bgwM7ibkICFOLVr9AkwMpRzP+etArhuXbIhH6jzdv9aoAjAcQsQtg37LSlWBI3TFmTtz53nHzIxmfgUuPS23sLjHc7KTBo9+DPHy5BT3qm21y8EDoQ8ehj6WqqwvaEkThRXcG5Kst5HzBbIgeRXSrSprjIeja0uhJpFJOAzOr5ngeoRG4tKfs6VMZMIU9IMbukbuGSC/JoUMR5yzavT/Yi+Cr9x9eeIewDOKzRIaq3wIkYIybhOJxZm5MMgV3A4j4nKSSN0jcW6hXee5ksdywsPKquK5E5fz/jY6bVc9Sj1DV+A6IN6MAjstQzYpZ6CIjFJwgwD7OpD9G/JmlwRNhB/TnNWKAW+4duXYEgKADWA4ZVg2riaYYphPbEmz5RXnphN+C6OEDozguAsW60Z2DJAAAAAPxkE7aqhWgiAk2Fxf8w1yZ6ZMkBSXe/b655jsvfLl6asBUStynk08vPaw5YsD61VyRNp/s8lRjrfwyHpTGrxOw==\u0026lt;/value\u0026gt; \u0026lt;/encryptedKey\u0026gt; \u0026lt;/encryptedSecret\u0026gt; \u0026lt;/descriptor\u0026gt; \u0026lt;/descriptor\u0026gt; \u0026lt;/key\u0026gt;文件包含一个创建日期，一个过期日期。间隔为90天，90天之后密钥就会失效，系统将自动生成一个新的密钥并设置新的密钥作为活动的密钥。只要已过期的密钥还存在于系统上，仍然可以解密任何受保护的数据。\nData Protection# ASP.NET Core Data Protection 主要对开发人员提供了两个接口，IDataProtectionProvider 和 IDataProtector：\nnamespace Microsoft.AspNetCore.DataProtection { // // 摘要: // An interface that can provide data protection services. public interface IDataProtector : IDataProtectionProvider { byte[] Protect(byte[] plaintext); byte[] Unprotect(byte[] protectedData); } }IDataProtector 继承自 IDataProtectionProvider ，并且提供了两个方法 Protect(加密) 和 Unprotect(解密) 。\nIDataProtectionProvider：\nnamespace Microsoft.AspNetCore.DataProtection { public interface IDataProtectionProvider { IDataProtector CreateProtector(string purpose); } }IDataProtectionProvider 提供了一个方法，通过传入一个 purpose字符串生成一个 IDataProtector 接口对象，方法签名中的 purpose 这个字符串，可以理解为一个标识，表示当前 Protector 的用途。\n使用 IDataProtector 的时候，会发现它还有一些扩展方法位于Microsoft.AspNetCore.DataProtection命名空间下：\npublic static class DataProtectionCommonExtensions { public static IDataProtector CreateProtector(this IDataProtectionProvider provider, IEnumerable\u0026lt;string\u0026gt; purposes); public static IDataProtector CreateProtector(this IDataProtectionProvider provider, string purpose, params string[] subPurposes); public static IDataProtector GetDataProtector(this IServiceProvider services, IEnumerable\u0026lt;string\u0026gt; purposes); public static IDataProtector GetDataProtector(this IServiceProvider services, string purpose, params string[] subPurposes); public static string Protect(this IDataProtector protector, string plaintext); public static string Unprotect(this IDataProtector protector, string protectedData); }可以看到，CreateProtector还提供了可以传多个purpose 的方法（IEnumerable，params string[]），因为 DataProtector 是有层次结构的，再看一下IDataProtector接口，它自身也实现了IDataProtectionProvider接口，就是说IDataProtector自身也可以再创建IDataProtector。\n用户密码哈希# 在 Microsoft.AspNetCore.Cryptography.KeyDerivation 命名空间下提供了一个 KeyDerivation.Pbkdf2 方法用来对用户密码进行哈希。\n生命周期限制# 有些时候，需要一些具有过期或者到期时间的加密字符串，比如用户在找回密码的时候，向用户的邮箱发送一封带有重置命令的一封邮件，这个重置命令就需要有一个过期时间了，超过这个过期时间后就失效，在以前可能需要向数据库存储一个时间来标记发送时间，然后再解密对比和数据库的时间差来验证。现在不用了，ASP.NET Core 默认提供了一个接口叫 ITimeLimitedDataProtector：\nCreateProtector(string purpose) : ITimeLimitedDataProtector This API is similar to the existing IDataProtectionProvider.CreateProtector in that it can be used to create purpose chains from a root time-limited protector. Protect(byte[] plaintext, DateTimeOffset expiration) : byte[] Protect(byte[] plaintext, TimeSpan lifetime) : byte[] Protect(byte[] plaintext) : byte[] Protect(string plaintext, DateTimeOffset expiration) : string Protect(string plaintext, TimeSpan lifetime) : string Protect(string plaintext) : stringITimeLimitedDataProtector 提供了数个重载方法用来设定带有生命周期的加密方法，可以通过Date TimeOffset，TimeSpan等参数来设置时间。有对应的加密，就有相对应的解密方法，在这里就不详细介绍了。有兴趣的可以去看一下官方文档。\n配置数据保护# ASP.NET Core 运行时，系统会基于当前机器的运行环境默认配置一些关于 Data Protection 的东西，但是有时可能需要对这些配置做一些改变。\n注册服务# 通过以下方式来把 Data Protection 注册到服务中：\npublic void ConfigureServices(IServiceCollection services) { services.AddDataProtection(); }指定私钥存储位置# AddDataProtection 返回的是一个 IDataProtectionBuilder 接口，这个接口提供了一个扩展方法 PersistKeysToFileSystem() 来存储私钥。可以通过它传入一个路径来指定私钥存储的位置，比如：\npublic void ConfigureServices(IServiceCollection services) { services.AddDataProtection() .PersistKeysToFileSystem(new DirectoryInfo(@\u0026#34;\\\\server\\share\\directory\\\u0026#34;)); }使用证书加密# 可以传入一个共享文件夹，来存储私钥。这样在不同机器的私钥就可以保存到一个位置了。可以通过此种方式在分布式部署的时候，隔离开机器的差异化。如果觉得不安全，还可以配置一个X.509证书来进行加密，比如：\npublic void ConfigureServices(IServiceCollection services) { services.AddDataProtection() .PersistKeysToFileSystem(new DirectoryInfo(@\u0026#34;\\\\server\\share\\directory\\\u0026#34;)) .ProtectKeysWithCertificate(\u0026#34;thumbprint\u0026#34;); }调整默认保存时间# Data Protection 默认保存时间是90天，可以通过以下方式来修改默认的保存时间：\npublic void ConfigureServices(IServiceCollection services) { services.AddDataProtection() .SetDefaultKeyLifetime(TimeSpan.FromDays(14)); }应用程序隔离# 默认情况下，即使使用相同的物理密钥库，Data Protection 也会把不同的应用程序隔离开，因为这样可以防止从一个应用程序获取另外一个应用程序的密钥。所以如果是相同的应用程序，可以设置相同的应用程序名称，比如：\npublic void ConfigureServices(IServiceCollection services) { services.AddDataProtection() .SetApplicationName(\u0026#34;my application\u0026#34;); }禁止自动生成秘钥# 有时候需要禁用应用程序生成密钥，或者是说只有一个程序用来生成或者管理密钥，其他程序只是负责读的话，那么可以这样：\npublic void ConfigureServices(IServiceCollection services) { services.AddDataProtection() .DisableAutomaticKeyGeneration(); }修改加密算法# 可以使用 UseCryptographicAlgorithms 方法来修改 ASP.NET Core Data Protection 的默认加密算法，比如：\nservices.AddDataProtection() .UseCryptographicAlgorithms(new AuthenticatedEncryptionSettings() { EncryptionAlgorithm = EncryptionAlgorithm.AES_256_CBC, ValidationAlgorithm = ValidationAlgorithm.HMACSHA256 });"},{"id":23,"href":"/docs/dotnet/1.2%E5%AE%9E%E8%B7%B5%E5%8F%8A%E5%A4%9A%E7%8E%AF%E5%A2%83%E8%B0%83%E8%AF%95/","title":"1.2实践及多环境调试","section":"所有文章","content":"新建 Web应用程序# Configuration 加载顺序# namespace Microsoft.Extensions.Hosting { // // 摘要: // Provides convenience methods for creating instances of Microsoft.Extensions.Hosting.IHostBuilder // with pre-configured defaults. public static class Host { // // 摘要: // Initializes a new instance of the Microsoft.Extensions.Hosting.HostBuilder class // with pre-configured defaults. // // 返回结果: // The initialized Microsoft.Extensions.Hosting.IHostBuilder. // // 言论： // The following defaults are applied to the returned Microsoft.Extensions.Hosting.HostBuilder: // • set the Microsoft.Extensions.Hosting.IHostEnvironment.ContentRootPath to the // result of System.IO.Directory.GetCurrentDirectory // • load host Microsoft.Extensions.Configuration.IConfiguration from \u0026#34;DOTNET_\u0026#34; // prefixed environment variables // • load app Microsoft.Extensions.Configuration.IConfiguration from \u0026#39;appsettings.json\u0026#39; // and \u0026#39;appsettings.[Microsoft.Extensions.Hosting.IHostEnvironment.EnvironmentName].json\u0026#39; // • load app Microsoft.Extensions.Configuration.IConfiguration from User Secrets // when Microsoft.Extensions.Hosting.IHostEnvironment.EnvironmentName is \u0026#39;Development\u0026#39; // using the entry assembly // • load app Microsoft.Extensions.Configuration.IConfiguration from environment // variables // • configure the Microsoft.Extensions.Logging.ILoggerFactory to log to the console, // debug, and event source output // • enables scope validation on the dependency injection container when Microsoft.Extensions.Hosting.IHostEnvironment.EnvironmentName // is \u0026#39;Development\u0026#39; public static IHostBuilder CreateDefaultBuilder(); // // 摘要: // Initializes a new instance of the Microsoft.Extensions.Hosting.HostBuilder class // with pre-configured defaults. // // 参数: // args: // The command line args. // // 返回结果: // The initialized Microsoft.Extensions.Hosting.IHostBuilder. // // 言论： // The following defaults are applied to the returned Microsoft.Extensions.Hosting.HostBuilder: // • set the Microsoft.Extensions.Hosting.IHostEnvironment.ContentRootPath to the // result of System.IO.Directory.GetCurrentDirectory // • load host Microsoft.Extensions.Configuration.IConfiguration from \u0026#34;DOTNET_\u0026#34; // prefixed environment variables // • load host Microsoft.Extensions.Configuration.IConfiguration from supplied command // line args // • load app Microsoft.Extensions.Configuration.IConfiguration from \u0026#39;appsettings.json\u0026#39; // and \u0026#39;appsettings.[Microsoft.Extensions.Hosting.IHostEnvironment.EnvironmentName].json\u0026#39; // • load app Microsoft.Extensions.Configuration.IConfiguration from User Secrets // when Microsoft.Extensions.Hosting.IHostEnvironment.EnvironmentName is \u0026#39;Development\u0026#39; // using the entry assembly // • load app Microsoft.Extensions.Configuration.IConfiguration from environment // variables // • load app Microsoft.Extensions.Configuration.IConfiguration from supplied command // line args // • configure the Microsoft.Extensions.Logging.ILoggerFactory to log to the console, // debug, and event source output // • enables scope validation on the dependency injection container when Microsoft.Extensions.Hosting.IHostEnvironment.EnvironmentName // is \u0026#39;Development\u0026#39; public static IHostBuilder CreateDefaultBuilder(string[] args); } }注意这段注释：\n// • load app Microsoft.Extensions.Configuration.IConfiguration from \u0026#39;appsettings.json\u0026#39; // and \u0026#39;appsettings.[Microsoft.Extensions.Hosting.IHostEnvironment.EnvironmentName].json\u0026#39; // • load app Microsoft.Extensions.Configuration.IConfiguration from User Secretspublic static class Program { public static void Main(string[] args) { CreateHostBuilder(args).Build().Run(); } public static IHostBuilder CreateHostBuilder(string[] args) =\u0026gt; Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =\u0026gt; { webBuilder.UseStartup\u0026lt;Startup\u0026gt;(); }); }这里意思是说：Host.CreateDefaultBuilder() 加载 Configuration 的顺序是：\nappsettings.json appsettings.{envName}.json usesecrets(secrets.json) 同一个节点信息如果在三个.json文件中都有定义，会依赖加载顺序，最后的会覆盖之前的\n多环境配置# 这里的设计思路是将全局通用配置放在 appsettings.json 中，不同环境根据需求配置自己的节点，也可以使用相同名称来覆盖 appsettings.json。\nappsettings.json\n{ \u0026#34;Logging\u0026#34;: { \u0026#34;LogLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Information\u0026#34; } }, \u0026#34;AllowedHosts\u0026#34;: \u0026#34;*\u0026#34; }appsettings.Development.json\n{ \u0026#34;ConnectString\u0026#34;: \u0026#34;Server=.;Database=WebApp01.Db.Dev;uid=sa;pwd=wpl19950815;\u0026#34; }appsettings.Sit.json\n{ \u0026#34;ConnectString\u0026#34;: \u0026#34;Server=.;Database=WebApp01.Db.Sit;uid=sa;pwd=wpl19950815;\u0026#34; }调试不同环境：\n通过设置 environmentVariables:ASPNETCORE_ENVIRONMENT 环境名称来切换使用不同环境的配置文件，这里环境变量名称需要和 appsetting.{envName}.json 中 {envName} 保持一致。\n在应用程序开发的过程中，有的时候需要在代码中保存一些机密的信息，比如加密密钥，字符串，或者是用户名密码等。通常的做法是保存到一个配置文件中，以前会保存到 web.config 中，但是 ASP.NET Core中，有更多多元化的方法可以更加优雅的的设置或者保存这些机密资料。\n用户机密简介# 使用场景：\n需要保存一些和第三方网站对接的密钥，比如和 微信，微博站点使用的 appkey 给每个开发人员配置不用的用户名密码来访问一些资源 开发人员在开发过程中使用各自本机的数据库，如何配置数据库地址、账号和密码 ASP.NET Core 提供了一种很优雅简洁的方式 User Secrets 用来解决这个事情。\n新建 Web 应用程序，在 Web 项目上右键,可以看到一个 管理用户机密 的菜单：\nsecrets.json secrets.json 文件存储位置：\n在非Windows系统中，它存储在\n~/.microsoft/usersecrets/\u0026lt;userSecretsId\u0026gt;/secrets.json在Windows系统中，它存储在\nC:\\Users\\用户名\\AppData\\Roaming\\Microsoft\\UserSecrets\\aspnet-WebAppCore-e278c40f-15bd-4c19-9662-541514f02f3e可以看到，存储的上层文件夹就是 project.json 文件中的 userSecretsId 设定的值。\n应用程序中使用# 要在应用程序中访问配置的用户机密，需要保证 project.json 文件中存在依赖项：Microsoft.Extensions.Configuration.UserSecrets 并且builder.AddUserSecrets()。\n"},{"id":24,"href":"/docs/dotnet/1.3%E5%9F%BA%E4%BA%8Edataprotection%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BF%9D%E6%8A%A4%E6%96%B9%E6%A1%88/","title":"1.3基于 Data Protection的数据保护方案","section":"所有文章","content":"准备工作# DataProtectionOption# 将使用数据保护需要的参数做成 Option ，方便配置调用。\npublic class ProtectionOption { /// \u0026lt;summary\u0026gt;应用程序名称\u0026lt;/summary\u0026gt; /// \u0026lt;value\u0026gt;The name of the application.\u0026lt;/value\u0026gt; public string ApplicationName { get; set; } /// \u0026lt;summary\u0026gt;证书指纹\u0026lt;/summary\u0026gt; /// \u0026lt;value\u0026gt;The thumbprint.\u0026lt;/value\u0026gt; public string Thumbprint { get; set; } /// \u0026lt;summary\u0026gt;私钥存储路径\u0026lt;/summary\u0026gt; /// \u0026lt;value\u0026gt;The secret key path.\u0026lt;/value\u0026gt; public string SecretKeyPath { get; set; } /// \u0026lt;summary\u0026gt;保护器名称\u0026lt;/summary\u0026gt; /// \u0026lt;value\u0026gt;The purpose.\u0026lt;/value\u0026gt; public string Purpose { get; set; } }ProtectionOptionBase# 真实项目中，不可能只对单个字符串进行加解密，大多数时候是对某个 Option 配置进行加解密，定义需要解密的 Option 需要继承的基类，Option上带有 EncryptedAttribute 标记的属性将会被解密。\n/// \u0026lt;summary\u0026gt;使用数据保护的Option要继承的基类,带有EncryptedAttribute标记的将会被解密\u0026lt;/summary\u0026gt; public abstract class ProtectionOptionBase { private bool Decrypted { get; set; } = false; public void Decrypt(IDataProtector protector) { if (Decrypted) return; foreach (PropertyInfo property in GetType().GetProperties()) { if (property.GetCustomAttribute\u0026lt;EncryptedAttribute\u0026gt;() != null) { string text = property.GetValue(this).ToString(); property.SetValue(this, protector.Unprotect(text)); } } Decrypted = true; } public void CopyTo(ProtectionOptionBase option) { foreach (PropertyInfo property in GetType().GetProperties()) { property.SetValue(option, property.GetValue(this)); } } }EncryptedAttribute# 定义特性，用于标识属性是否需要被解密。\npublic class EncryptedAttribute : Attribute { }DataProtectionExtensions# 基于数据保护服务添加扩展方法，提供注入服务并使用指定证书进行解密的能力。\npublic static class DataProtectionExtensions { /// \u0026lt;summary\u0026gt;注册数据保护服务,使用x509证书加密\u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;services\u0026#34;\u0026gt;The services.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; /// \u0026lt;exception cref=\u0026#34;Exception\u0026#34;\u0026gt;not found X509Certificate\u0026lt;/exception\u0026gt; public static IDataProtector AddDataProtectionWithX509(this IServiceCollection services) { ServiceProvider provider = services.BuildServiceProvider(); // 获取用户配置数据保护的Option ProtectionOption protectionOption = provider .GetRequiredService\u0026lt;IOptions\u0026lt;ProtectionOption\u0026gt;\u0026gt;().Value; // 获取证书 X509Certificate2 cert = GetCertificateFromStore(protectionOption.Thumbprint); // 注册服务 services.AddDataProtection() // 设置应用程序名称 .SetApplicationName(protectionOption.ApplicationName) // 设置秘钥存储路径 .PersistKeysToFileSystem(new DirectoryInfo(protectionOption.SecretKeyPath)) // 设置用于加密的证书 .UnprotectKeysWithAnyCertificate(cert); provider = services.BuildServiceProvider(); IDataProtectionProvider protectionProvider = provider.GetRequiredService\u0026lt;IDataProtectionProvider\u0026gt;(); // 创建数据保护器 IDataProtector protector = protectionProvider.CreateProtector(protectionOption.Purpose); // 注册单例的数据保护器 services.AddSingleton\u0026lt;IDataProtector\u0026gt;(serviceProvider =\u0026gt; protector); return protector; } public static IServiceCollection ProtectedConfigure\u0026lt;TOptions\u0026gt;(this IServiceCollection services , IConfigurationSection section) where TOptions : ProtectionOptionBase, new() { ServiceProvider provider = services.BuildServiceProvider(); IDataProtector protector = provider.GetRequiredService\u0026lt;IDataProtector\u0026gt;(); services.Configure\u0026lt;TOptions\u0026gt;(option =\u0026gt; { var config = section.Get\u0026lt;TOptions\u0026gt;(); config.Decrypt(protector); config.CopyTo(option); }); return services; } /// \u0026lt;summary\u0026gt; /// Get the certifcate to use to encrypt the key /// CertSearchArea：StoreLocation.CurrentUser/StoreLocation.LocalMachine /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;thumbprint\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public static X509Certificate2 GetCertificateFromStore(string thumbprint) { X509Certificate2 signingCert = GetCertificateFromStore(thumbprint, StoreLocation.CurrentUser); if (signingCert != null) { return signingCert; } else { signingCert = GetCertificateFromStore(thumbprint, StoreLocation.LocalMachine); if (signingCert != null) { return signingCert; } } throw new X509Certificate2Exception(\u0026#34;本机和当前用户证书存储区都未找到对应证书\u0026#34;); } /// \u0026lt;summary\u0026gt;Gets the certificate from store.\u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;thumbprint\u0026#34;\u0026gt;The thumbprint.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;storeLocation\u0026#34;\u0026gt;The store location.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public static X509Certificate2 GetCertificateFromStore(string thumbprint, StoreLocation storeLocation) { // 获取本地机器证书存储 X509Store localMachineStore = new X509Store(storeLocation); try { localMachineStore.Open(OpenFlags.ReadOnly); X509Certificate2Collection certCollection = localMachineStore.Certificates; X509Certificate2Collection localMachineCerts = certCollection.Find(X509FindType.FindByTimeValid, DateTime.Now, false); X509Certificate2Collection signingCert = localMachineCerts.Find(X509FindType.FindByThumbprint, thumbprint, false); if (signingCert.Count == 0) { return null; } return signingCert[0]; } finally { localMachineStore.Close(); } } }GeneratingCiphertext.Console# 依赖指定证书生成加密文件 secret.xml 以及对应 {key}.xml文件。\n{key}.xml是生成的秘钥文件 secret.xml在之后的管道集成中会使用到 注意：在启动时必须提供必需的参数才可生成 secret.xml 及 {key}.xml 文件；在管道中使用命令行操作，在Visual Studio中可以使用如下方式设置：\n示例：\n--cpath=\u0026#34;C:\\\\Users\\\\WangPengLiang\\\\Desktop\\\\DataProtection\\\\dev.pfx\u0026#34; --cpass=\u0026#34;wpl19950815\u0026#34; --purpose=\u0026#34;RedPI.Todo\u0026#34; --spath=\u0026#34;C:\\\\Users\\\\WangPengLiang\\\\Desktop\\\\DataProtection\\\\app-keys\u0026#34; --appname=\u0026#34;RedPI.Todo\u0026#34; --snodes=\u0026#34;a:1, b:2\u0026#34; --soutputpath=\u0026#34;C:\\Users\\WangPengLiang\\Desktop\\DataProtection\u0026#34;项目应用# appsettings.json# appsettings.json中包含了通用的Option的配置。\n{ // 数据保护相关配置;SecretKeyPath:固定目录 \u0026#34;ProtectionOption\u0026#34;: { \u0026#34;Thumbprint\u0026#34;: \u0026#34;CD Replace\u0026#34;, \u0026#34;ApplicationName\u0026#34;: \u0026#34;CD Replace\u0026#34;, \u0026#34;SecretKeyPath\u0026#34;: \u0026#34;DataProtection\\\\app-keys\u0026#34;, \u0026#34;Purpose\u0026#34;: \u0026#34;CD Replace\u0026#34; } }appsettings.Development.json# appsettings.Development.json 只包含针对当前环境的配置，直接明文存储。\n{ // 开发环境：明文存储 \u0026#34;TestOption\u0026#34;: { \u0026#34;Test1\u0026#34;: \u0026#34;dev-test1\u0026#34;, \u0026#34;Test2\u0026#34;: \u0026#34;dev-test2\u0026#34; }, \u0026#34;DataBase\u0026#34;: { \u0026#34;DbConnection\u0026#34;: \u0026#34;Server=.;Database=WebApp01.Database;uid=sa;pwd=wpl19950815;\u0026#34; } }appsettings.Sit.json# appsettings.Sit.json 只包含针对当前环境的配置；TestOption.Test2 添加了 Encrypted 标记用于测试解密Option；DataBase.DbConnection 用于测试解密字符串。\nnamespace WebApp01.Options { using WebApp01.CustomDataProtection; public class TestOption : ProtectionOptionBase { public string Test1 { get; set; } [Encrypted] public string Test2 { get; set; } } }{ // 数据保护相关配置;SecretKeyPath:固定目录 \u0026#34;ProtectionOption\u0026#34;: { \u0026#34;Thumbprint\u0026#34;: \u0026#34;CD Replace\u0026#34;, \u0026#34;ApplicationName\u0026#34;: \u0026#34;CD Replace\u0026#34;, \u0026#34;SecretKeyPath\u0026#34;: \u0026#34;DataProtection\\\\app-keys\u0026#34;, \u0026#34;Purpose\u0026#34;: \u0026#34;CD Replace\u0026#34; }, // 测试Option解密 \u0026#34;TestOption\u0026#34;: { \u0026#34;Test1\u0026#34;: \u0026#34;sit-test1\u0026#34;, \u0026#34;Test2\u0026#34;: \u0026#34;CD Replace\u0026#34; }, // Sit环境：需要加密的配置在CD时进行替换 \u0026#34;DataBase\u0026#34;: { \u0026#34;DbConnection\u0026#34;: \u0026#34;CD Replace\u0026#34; } }Startup# public void ConfigureServices(IServiceCollection services) { if (Environment.IsDevelopment()) { services.Configure\u0026lt;TestOption\u0026gt;(Configuration.GetSection(\u0026#34;TestOption\u0026#34;)); } else { // 注入数据保护需要的Option services.Configure\u0026lt;ProtectionOption\u0026gt;(Configuration.GetSection(\u0026#34;ProtectionOption\u0026#34;)); // 注入数据保护服务（依赖指定证书） IDataProtector dataProtector = services.AddDataProtectionWithX509(); // 解密字符串 string connStr = dataProtector.Unprotect(Configuration.GetSection(\u0026#34;Database:ConnectString\u0026#34;).Value); Console.WriteLine(connStr); // 解密Option;Option上带有EncryptedAttribute标记的属性将会被解密 services.ProtectedConfigure\u0026lt;TestOption\u0026gt;(Configuration.GetSection(\u0026#34;TestOption\u0026#34;)); } services.AddControllers(); }EnvironmentController# [ApiController] [Route(\u0026#34;[controller]\u0026#34;)] public class EnvironmentController : ControllerBase { private readonly IOptions\u0026lt;TestOption\u0026gt; testOption; public EnvironmentController(IOptions\u0026lt;TestOption\u0026gt; testOption) { this.testOption = testOption; } [HttpGet] public IActionResult GetEnvironmentVariables() { Dictionary\u0026lt;string, string\u0026gt; dicts = new Dictionary\u0026lt;string, string\u0026gt;(); ConfigurationBuilder builder = new ConfigurationBuilder(); builder.AddJsonFile(\u0026#34;appsettings.json\u0026#34;); IConfigurationRoot configuration = builder.Build(); dicts.Add(\u0026#34;ProtectionOption.Thumbprint\u0026#34;, configuration.GetSection(\u0026#34;ProtectionOption:Thumbprint\u0026#34;).Value); dicts.Add(\u0026#34;ProtectionOption.ApplicationName\u0026#34;, configuration.GetSection(\u0026#34;ProtectionOption:ApplicationName\u0026#34;).Value); dicts.Add(\u0026#34;ProtectionOption.SecretKeyPath\u0026#34;, configuration.GetSection(\u0026#34;ProtectionOption:SecretKeyPath\u0026#34;).Value); dicts.Add(\u0026#34;ProtectionOption.Purpose\u0026#34;, configuration.GetSection(\u0026#34;ProtectionOption:Purpose\u0026#34;).Value); dicts.Add(\u0026#34;TestOption.Test1\u0026#34;, testOption.Value.Test1); dicts.Add(\u0026#34;TestOption.Test2\u0026#34;, testOption.Value.Test2); dicts.Add(\u0026#34;DataBase.DbConnection\u0026#34;, configuration.GetSection(\u0026#34;DataBase:DbConnection\u0026#34;).Value); return Ok(JsonConvert.SerializeObject(dicts)); } }"},{"id":25,"href":"/docs/dotnet/1.4%E6%96%B9%E6%A1%88%E5%AE%9E%E8%B7%B5%E5%8F%8A%E9%9B%86%E6%88%90azuredevops%E7%AE%A1%E9%81%93/","title":"1.4方案实践及集成 Azure Devops管道","section":"所有文章","content":"CI Pipeline# CI Pipeline 设计并没有特别之处，重点在于 CD Pipeline设计。\nCD Pipeline# 除了自身的CI源之前，添加生成密文控制台应用程序也作为源，以便于在CD过程中使用加密功能。\nDevelopment# Development 开发环境是明文存储的，所以CD管道不做特殊处理。\nSit# SIT 环境的配置不同，在CD过程中会替换环境变量的值。\n环境变量设置# Step1：下载安全文件# 下载证书，证书存储在Devops中的库中，需要手动上传，如何生成证书自行查找资料。\nStep2：生成加密文件# 依赖生成密文的程序生成秘钥文件以及 secret.xml。\nStep3：机密变量替换# 使用 powershell 脚本解析 Step2 步骤中生成的 secret.xml 文件并替换环境变量的值。\nStep4：启用变量替换# 测试# Development Sit 这里DataBase.DbConnection是null是因为DataBase并不是一个Option。\n可以通过dotnet命令启动程序来查看是否解密成功\n并未做到全自动化，还有很多不足，比如证书如何自动化安装，证书如果有密码如何处理，替换机密变量时Shell脚本的优化、UserSecret集成等。\n"},{"id":26,"href":"/docs/dotnet/%E5%80%BC%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","title":"值类型和引用类型的内存分配","section":"所有文章","content":"值类型和引用类型# C#的类型一共分为两类\n值类型 ValueType 引用类型 ReferenceType 值类型和引用类型都继承自 System.Object 类。不同的是几乎所有的引用类型都直接从 System.Object 继承，而值类型则继承 System.ValueType 。System.ValueType直接派生于System.Object。即System.ValueType本身是一个类类型，而不是值类型。关键在于ValueType重写了Equals()方法，从而对值类型按照实例的值来比较，而不是引用地址来比较。\n区别# 引用类型变量的赋值只复制对对象的引用而不复制对象本身。而将一个值类型变量赋给另一个值类型变量时，将复制包含的值 引用类型可以派生出新的类型，而值类型不能 引用类型可以包含 null 值，值类型不能（可空类型功能允许将 null 赋给值类型） 引用类型存储在堆中。类实例化时会在堆中开辟一部分空间存储类的实例，类实例的引用（指针）还是存储在栈中。值类型总是分配在它声明的地方(作为字段时跟随其所属的实例存储在堆上。作为局部变量时存储在栈上)。 误区：\u0026ldquo;引用类型存储在堆上，值类型保存在栈上\u0026rdquo;，这句话前半部分是正确的，引用类型的实例总是在堆上创建的。但是变量的值是在声明的位置存储的，所以假定一个类中有一个int类型的实例变量，那么这个变量的值是跟对象中的其他数据在一起也就是堆上。只有局部变量（方法内部声明的变量）和方法参数在栈上。\n使用场合# 值类型：在内存管理方面具有更好的效率，但不支持多态不能派生新的类型，适合用做存储数据的载体 引用类型：支持多态可以派生新的类型 内存的逻辑划分之栈和堆# C#程序在CLR上运行时，内存从逻辑上划分两大块：栈、堆，这两个基本元素组成了C#程序的运行环境。\n栈：在程序运行的时候，每个线程(Thread)都会维护一个自己的专属线程堆栈 堆：是程序在运行的时候请求操作系统分配给自己的内存空间，储存着使用的各种对象等信息，跟栈不同的是它们被调用完毕不会立即被清理掉 栈的特征# 栈空间比较小（每个线程只有一个栈占用 1MB，栈内存溢出抛出 StackOverflowException 但是读取速度快 数据只能从栈的顶端插入或删除，是连续存储的，把数据放到栈顶称为入栈，从栈顶删除数据称为出栈​ 存放方法的参数、局部变量、返回地址等值，当一个方法执行完毕后立刻自动清除 栈的结构# 栈帧：每个方法执行都会分配一块独立的内存空间来存储方法运行需要的数据，按后入先出的方式进入和弹出线程栈。\n堆的特征# 堆空间比较大（32位最多分配1.5GB，64位最多分配8TB，堆内存溢出抛出 OutOfMemoryException ，但是读取速度慢 数据存储不连续，与栈不同：堆里的内存能够以任意顺序存入和移除 存放引用类型的对象，通过GC清理 堆的结构# 参考：Drill Into .NET Framework Internals to See How the CLR Creates Runtime Objects ​\n代码运行时内存分配情况# 变量和对象在内存中的分配# 示例代码：\nclass TestClass { public int x; public static string y; } void Test1() { var a=1; var b=new TestClass(); var c=a; var d=b; var e=d.x; var f=TestClass.y; }内存分配情况：\nTest1()方法被调用：系统为该方法创建一个栈桢，用于存储该方法使用到的值类型的变量、指针、调用其他方法的返回地址等 方法执行到 var a=1：变量a的值1首先入栈存储，栈的起始地址为0x000000671b77e5a4 方法执行到 var b=new TestClass()：在堆中开辟一块内存用于存储TestClass实例对象，然后变量b入栈，变量b的值为TestClass实例对象的引用（实际存储的是TestClass实例在堆上的内存地址，也就是指针） 方法执行到 var c=a：将变量c压入栈，因为a是值类型，所以将变量a的值拷贝赋值给c 方法执行到 var d=b：将变量d压入栈，因为b是引用类型，所以将变量b引用的地址赋值给变量d，此时变量b和d都指向堆内存中的TestClass实例对象 方法执行到 var e=d.x时：将变量e压入栈，因为x字段是值类型，所以将x的实际值0（int类型初始化的默认值为0）赋值给e 方法执行到 var f=TestClass.y：将变量f压入栈，因为y字段是引用类型，所以f变量的值为y 字段的引用 方法参数在栈中的分配# 示例代码：\nclass TestClass { public int x; public int sum(int i,int j){ return i+j; } } void Test1() { var a=new TestClass(); int b = 0; b=a.sum(1,2); }内存分配情况：\n​\n方法执行到 var a=new TestClass() : 在堆中开辟一块内存用于存储TestClass实例对象，然后变量a入栈，变量a的值为TestClass实例对象的引用（实际上存储的是TestClass实例在堆上的内存地址，也就是指针） 方法执行到 int b = 0：将局部变量b压入栈，因为b是值类型所以值0存储在栈中 方法执行到 b=a.sum(1,2)：首先两个int类型实参1，2分别入栈，并将sum方法的返回地址压入栈，sum方法执行结束之后应返回至该位置 System.String# 特性一：字符串是不可变的，字符串一经创建便不能更改，不能变长、变短或修改其中的任何字符。 特性二：字符串驻留（字符串池化），CLR可通过一个String对象共享多个完全一致的String内容，这样能减少系统中字符串的数量，从而节省内存。String的驻留机制实际上是在SystemDomain中进行的。 当CLR被加载之后，会在SystemDomain对应的managed heap中创建一个Hashtable，Hashtable中记录了所有在代码中使用字面量声明的字符串实例的引用，Hashtable的Key为字符串本身，Value为字符串对象的地址。 示例代码：\nstatic void Main(string[] args) { //申请一块堆内存，把地址放在Hashtable的key为hello的元素中 string str1 = \u0026#34;hello\u0026#34;; //由于上一句已经创建了key为hello的元素，所以不需要申请新的堆内存 string str2 = \u0026#34;hello\u0026#34;; //编译成MSIL语言时 已经与string str3 = \u0026#34;hello\u0026#34;一样了 string str3 = \u0026#34;\u0026#34; + \u0026#34;e\u0026#34; + \u0026#34;l\u0026#34; + \u0026#34;l\u0026#34; + \u0026#34;o\u0026#34;; //显式new string str4 = new string(new char[] { \u0026#39;h\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39; }); //申请一块堆内存，把地址放在Hashtable的key为hello2的元素中 string str5 = \u0026#34;hello2\u0026#34;; //True 引用同一块堆内存 Console.WriteLine(object.ReferenceEquals(str1, str2).ToString()); //True 也是引用同一块堆内存 Console.WriteLine(object.ReferenceEquals(str1, str3).ToString()); //False 引用了不同的堆内存 Console.WriteLine(object.ReferenceEquals(str1, str4).ToString()); // 先从Hashtable中检索是否有重复的key ，检索到了hello2，所以不需要申请新的堆内存 str2 = \u0026#34;hello2\u0026#34;; //False str2与str1已经不引用同一个堆 Console.WriteLine(object.ReferenceEquals(str1, str2).ToString()); //True 变成与str5引用同一个堆内存 Console.WriteLine(object.ReferenceEquals(str2, str5).ToString()); // 控制台输入两个相同的字符串 str1 = Console.ReadLine(); str2 = Console.ReadLine(); //False 因为 str1 和 str2 两个变量并非字面量声明的字符串，所以不会触发字符串驻留机制 Console.WriteLine(object.ReferenceEquals(str1, str2).ToString()); Console.ReadLine(); }静态字段和属性# 类型的静态字段和静态属性的支持字段（例如 int）存储在类型对象（加载堆）中。\nJIT 会在进行编译时找到这些静态成员的地址，并在之后的编译时硬编码它们，然后写在机器码中。\n这样，再次访问静态成员时就不需要通过类型对象。程序中所有类型的静态成员组成一个全局的数组，它包括每一个类型中的基元类型静态成员的内存地址。\n数组的地址会被钉死 (pinned)，使得它不会被 GC 回收掉（除非卸载应用程序域），这样机器码中的硬编码将一直有意义，直到程序终止。\n"},{"id":27,"href":"/docs/dotnet/%E5%8F%8D%E5%B0%84%E6%8A%80%E6%9C%AF/","title":"反射技术","section":"所有文章","content":"反射提供了封装程序集、模块和类型的对象(Type类型)。可以使用反射动态创建类型的实例，将类型绑定到现有对象，或从现有对象获取类型并调用其方法或访问其字段和属性。\n使用场景# 需要访问程序元数据的特性 检查和实例化程序集中的类型 在运行时构建新类型。使用 System.Reflection.Emit 中的类 执行后期绑定，访问在运行时创建的类型的方法 反射用途# 类型 作用 Assembly 定义和加载程序集，加载程序集清单中列出的模块，以及从此程序集中查找类型并创建该类型的实例 Module 了解包含模块的程序集以及模块中的类等，还可以获取在模块上定义的所有全局方法或其他特定的非全局方法 ConstructorInfo 了解构造器的名称、参数、访问修饰符（如public或private）和实现详细信息（如abstract或virtual）等。使用Type的GetConstructors或GetConstructor方法来调用特定的构造函数 MethodInfo 了解方法的名称、返回类型、参数、访问修饰符（如public或private）和实现详细信息（如abstract或virtual）等。使用Type的GetMethods或GetMethod方法来调用特定的方法 FieldInfo 了解字段的名称、访问修饰符（如public或private）和实现详细信息（如static）等，并获取或设置字段值 EventInfo 了解事件的名称、事件处理程序数据类型、自定义特性、声明类型和反射类型等，并添加或移除事件处理程序 PropertyInfo 了解属性的名称、数据类型、声明类型、反射类型和只读或可写状态等，并获取或设置属性值 ParameterInfo 了解参数的名称、数据类型、参数是输入参数还是输出参数等，以及参数在方法签名中的位置等 反射用到的命名空间# System.Reflection System.Type System.Reflection.Assembly 反射用到的主要类# System.Type ：通过这个类可以访问任何给定数据类型的信息 System.Reflection.Assembly： 可以用于访问给定程序集的信息，或者把这个程序集加载到程序中 System.Type# 一个抽象的基类。Type 有与每种数据类型对应的派生类，使用这个派生类的对象的方法、字段、属性来查找有关该类型的所有信息。\n获取给定类型 Type 值# typeof 运算符\nType t = typeof(string);对象的GetType()方法\nstring s = \u0026#34;guo\u0026#34;; Type t = s.GetType();Type类的静态方法GetType()\nType t = Type.GetType(\u0026#34;System.String\u0026#34;);Type 属性# 属性 描述 Name 数据类型名 FullName 数据类型的完全限定名(包括命名空间名) Namespace 定义数据类型的命名空间名 IsAbstract 指示该类型是否是抽象类型 IsArray 指示该类型是否是数组 IsClass 指示该类型是否是类 IsEnum 指示该类型是否是枚举 IsInterface 指示该类型是否是接口 IsPublic 指示该类型是否是公有的 IsSealed 指示该类型是否是密封类 IsValueType 指示该类型是否是值类型 Type 方法# 方法名称 描述 GetConstructor(), GetConstructors() 返回ConstructorInfo类型，用于取得该类的构造函数的信息 GetEvent(), GetEvents() 返回EventInfo类型，用于取得该类的事件的信息 GetField(), GetFields() 返回FieldInfo类型，用于取得该类的字段（成员变量）的信息 GetInterface(), GetInterfaces() 返回InterfaceInfo类型，用于取得该类实现的接口的信息 GetMember(), GetMembers() 返回MemberInfo类型，用于取得该类的所有成员的信息 GetMethod(), GetMethods() 返回MethodInfo类型，用于取得该类的方法的信息 GetProperty(), GetProperties() 返回PropertyInfo类型，用于取得该类的属性的信息 可以调用这些成员，其方式是调用 Type 的 InvokeMember() 方法，或者调用 MethodInfo , PropertyInfo 和其他类的 Invoke() 方法。\npublic class ReflectClass { public string Address; public int Age { get; set; } public string Sex { get; set; } public string Name { get; set; } public ReflectClass() { } public ReflectClass(string name) { this.Name = name; } public ReflectClass(string name, string sex) { this.Name = name; this.Sex = sex; } public void Show() { Console.WriteLine(\u0026#34;姓名：\u0026#34; + Name + \u0026#34;\\n\u0026#34; + \u0026#34;年龄：\u0026#34; + Age + \u0026#34;\\n\u0026#34; + \u0026#34;性别：\u0026#34; + Sex); } }获取所有构造函数# [TestMethod] public void GetConstructors() { Type t = new ReflectClass().GetType(); // 获取类的所有构造函数 ConstructorInfo[] constructorInfos = t.GetConstructors(); foreach (ConstructorInfo ci in constructorInfos) { // 获取每个构造函数的参数 ParameterInfo[] parameterInfos = ci.GetParameters(); foreach (ParameterInfo p in parameterInfos) { Console.WriteLine(p.ParameterType.ToString() + \u0026#34;\\n\u0026#34; + p.Name + \u0026#34;\\n\u0026#34;); } } Assert.IsTrue(constructorInfos.Length \u0026gt; 0); }动态创建对象# [TestMethod] public void DynamicCreateObject() { Type t = typeof(ReflectClass); Type[] pt = new Type[2]; pt[0] = typeof(string); pt[1] = typeof(string); //根据参数类型获取构造函数 ConstructorInfo ci = t.GetConstructor(pt); //构造Object数组，作为构造函数的输入参数 object[] obj = new object[2] { \u0026#34;wang\u0026#34;, \u0026#34;男\u0026#34; }; //调用构造函数生成对象 object @object = ci.Invoke(obj); //调用生成的对象的方法测试是否对象生成成功 ((ReflectClass)@object).Show(); Assert.IsTrue(true); }Activator 动态创建对象# [TestMethod] public void ActivatorDynamicCreateObject() { Type t = typeof(ReflectClass); object[] obj = new object[2] { \u0026#34;wang\u0026#34;, \u0026#34;男\u0026#34; }; //用Activator的CreateInstance静态方法，生成新对象 object @object = Activator.CreateInstance(t, obj); ((ReflectClass)@object).Show(); Assert.IsTrue(true); }获取类中 Public 属性# [TestMethod] public void GetProperties() { Type t = new ReflectClass().GetType(); PropertyInfo[] propertyInfos = t.GetProperties(); foreach (PropertyInfo p in propertyInfos) { Console.WriteLine(p.Name); } Assert.IsTrue(true); }获取类 Public 方法# [TestMethod] public void GetPublicMethod() { Type t = new ReflectClass().GetType(); MethodInfo[] mi = t.GetMethods(); foreach (MethodInfo method in mi) { Console.WriteLine(method.ReturnType + \u0026#34;|\u0026#34; + method.Name); } Assert.IsTrue(true); }获取类中 Public 字段# [TestMethod] public void GetField() { Type t = new ReflectClass().GetType(); FieldInfo[] fieldInfos = t.GetFields(); foreach (FieldInfo fieldInfo in fieldInfos) { Console.WriteLine(fieldInfo.Name); } Assert.IsTrue(true); }[TestMethod] public void Example_01() { ReflectClass rc = new ReflectClass(); Type t = rc.GetType(); object obj = Activator.CreateInstance(t); FieldInfo address = t.GetField(\u0026#34;Address\u0026#34;); address.SetValue(obj, \u0026#34;Beijing\u0026#34;); PropertyInfo name = t.GetProperty(\u0026#34;Name\u0026#34;); name.SetValue(obj, \u0026#34;wang\u0026#34;, null); PropertyInfo age = t.GetProperty(\u0026#34;Age\u0026#34;); age.SetValue(obj, 20, null); MethodInfo method = t.GetMethod(\u0026#34;Show\u0026#34;); method.Invoke(obj, null); Console.WriteLine(\u0026#34;Address为：\u0026#34; + ((ReflectClass)obj).Address); Assert.IsTrue(true); }Assembly# GetAssembly# [TestMethod] public void GetAssembly() { // 通过程序集名称返回Assembly对象 Assembly assembly = Assembly.Load(\u0026#34;CodeSnippet\u0026#34;); // 通过Assembly获取程序集中类(参数必须是类的全名) Type type = assembly.GetType(\u0026#34;CodeSnippet.Csharp.ReflectClass\u0026#34;); Assert.IsNotNull(type); // 通过Assembly获取程序集中所有的类 Type[] types = assembly.GetTypes(); Assert.IsNotNull(types); // 通过DLL文件名称返回Assembly对象 warning disable S3885 // \u0026#34;Assembly.Load\u0026#34; should be used Assembly assembly2 = Assembly.LoadFrom(\u0026#34;CodeSnippet.dll\u0026#34;); warning restore S3885 // \u0026#34;Assembly.Load\u0026#34; should be used // 通过Assembly获取程序集中类(参数必须是类的全名) Type type2 = assembly2.GetType(\u0026#34;CodeSnippet.Csharp.ReflectClass\u0026#34;); Assert.IsNotNull(type2); // 通过Assembly获取程序集中所有的类 Type[] types2 = assembly2.GetTypes(); Assert.IsNotNull(types2); }通过程序集名称反射# [TestMethod] public void Example_02() { Assembly assembly = Assembly.Load(\u0026#34;CodeSnippet\u0026#34;); //参数必须是类的全名 Type t = assembly.GetType(\u0026#34;CodeSnippet.Csharp.ReflectClass\u0026#34;); object o = Activator.CreateInstance(t, \u0026#34;男\u0026#34;); MethodInfo mi = t.GetMethod(\u0026#34;Show\u0026#34;); mi.Invoke(o, null); Assert.IsNotNull(o); }通过DLL文件反射类型# [TestMethod] public void Example_03() { warning disable S3885 // \u0026#34;Assembly.Load\u0026#34; should be used Assembly assembly = Assembly.LoadFrom(\u0026#34;CodeSnippet.dll\u0026#34;); warning restore S3885 // \u0026#34;Assembly.Load\u0026#34; should be used Type[] types = assembly.GetTypes(); foreach (Type t in types) { if (t.FullName == \u0026#34;CodeSnippet.Csharp.ReflectClass\u0026#34;) { object o = Activator.CreateInstance(t); Assert.IsNotNull(o); } } }BindingFlags# // Specifies flags that control binding and the way in which the search for members // and types is conducted by reflection."},{"id":28,"href":"/docs/dotnet/%E5%9F%BA%E7%A1%80%E5%90%88%E9%9B%86/","title":"基础合集","section":"所有文章","content":"C# 是面向对象的强类型高级语言，内置用于存储不同类型数据的内置数据类型。每种数据类型包含特定的取值范围，使用这些数据类型来表示在应用程序中存储的数据。数据类型进一步又被分为：\n值类型 Value types 引用类型 Reference types 指针类型 Pointer types 基础概念# 值类型# 值类型特点：变量直接存储其值，派生于 System.ValueType。值类型又细分为简单类型、枚举类型、结构类型、可以为 null 的值类型。\n简单类型：\n有符号的整型：sbyte、short、int、long 无符号的整型：byte、ushort、uint、ulong Unicode 字符：char IEEE 二进制浮点：float、double 高精度十进制浮点数：decimal 布尔：bool 引用类型# 引用类型特点：引用类型不直接存储其值，派生于 System.Object，它存储值的引用内存地址。多个变量指向一个内存位置时，如果内存位置的数据是由一个变量改变的，其他变量会自动反映这种值的变化。\n类类型描述：\n所有类型的最终基类：object Unicode 字符串：string 格式为：class C {…} 的用户定义类型 接口类型、数组类型、委托类型，有关数值类型的详细信息。参考：整型类型 / 浮点类型表\n变量# 编译器需要用某个初始值对变量进行初始化之后才能在操作中使用该变量。\n// 语法 \u0026lt;datatype\u0026gt;\u0026lt;variablename\u0026gt;=\u0026lt;value\u0026gt;; // 示例 string name = \u0026#34;wang\u0026#34;; // 同时声明多个 string name1,name2 = \u0026#34;wang\u0026#34;;注意：\n变量是类或结构中的字段，如果没有显式初始化，创建这些变量时，默认值就是类型默认值 方法的局部变量必须在代码中显式初始化才能在语句中使用 在C#中实例化一个引用对象需要使用 new 关键字把该引用指向存储在堆上的一个对象 变量作用域# 变量作用域指：可以访问该变量的代码区域\n注意：\n只要类在某个作用域内，其字段(也称为成员变量)也在该作用域内 局部变量存在于表示声明该变量的块语句或方法结束的右花括号之前的作用域内 在 for、 while 或类似语句中声明的局部变量存在于该循环体内 类型推断# 使用 var 类型预先不用知道变量的类型，编译器可以根据变量的初始化值“推断”变量类型。\nvar name =\u0026#34;wang\u0026#34;;注意：\n变量必须初始化，否则编译器就没有推断变量类型的依据 初始化器不能为空 初始化器必须放在表达式中 不能把初始化器设置为一个对象，除非在初始化器中创建了一个新对象 常量# 常量指：其值在使用过程中不会发生变化的变量。在声明和初始化变量时，在变量的前面加上关键字 const，就可以把该变量指定为一个常量。\nconst string conntionName = \u0026#34;testConntion\u0026#34;;常量具有如下特点：\n常量必须在声明时初始化。指定其值后就不能再改写 常量的值必须能在编译时用于计算。因此不能用从一个变量中提取的值来初始化常量。如果需要这么做，应使用只读字段 readonly 常量总是静态的，但注意：不必(实际上，是不允许)在常量声明中包含修饰符 使用常量的好处：\n常量使程序变得更易于阅读（使用易于读取理解的名称替代了较难读取的数字或字符串） 常量使程序更易于修改 常量更容易避免程序出现错误，如果在声明常量的位置以外将另一个值赋给常量，编译器就会报错 只读字段# 常量的概念是包含不能修改的值的变量。但有时可能需要一些变量，其值不应改变，但在运行前其值是未知的。C#为这种情形提供了另一种类型的变量：只读字段。\nreadonly 关键字比 const 灵活，允许把一个字段设置为常量，但还需要执行一些计算，以确定它的初始值。其规则是：可以在构造函数中给只读字段赋值，但不能在其他地方赋值。只读字段可以是一个实例字段，而不是静态字段，类的每个实例可以有不同的值。与const 字段不同，如果要把只读字段设置为静态，就必须显式声明\n// 实例只读字段 readonly double taxRate; // 静态字段字段 static readonly double taxRate1; BasicsTest() { // 只读字段可以在声明时赋值，也可以在构造函数中赋值 taxRate = 0.8; } static BasicsTest() { // 静态只读字段在类的静态构造函数中赋值 taxRate1 = 0.9; }常量和只读字段的区别# 常量只能在声明语句中初始化，而且必须初始化，初始化之后在任何地方都不能改变。 readonly 字段既可以在声明时初始化，也可以在构造函数中改变它的值。（如果是 实例只读字段 可以在实例构造函数中改变它的值，如果是 静态只读字段 则可以在静态构造函数中改变它的值） 常量的值必须在编译时决定，编译完成之后它的值就被替换为字面量。 readonly 字段的值可以在运行时决定，可以在不同的构造函数中设置不同的值 常量总是像静态字段，在类的外部要通过 类名.常量名 的方式访问。readonly 字段既可以是静态字段，也可以是实例字段 常量在内存中没有存储位置，而 readonly 字段在内存中有存储位置 值类型和引用类型空值# 默认情况下，引用类型在未初始化时具有空值。\n一个字符串变量(或引用类型数据类型的任何其他变量)，但没有赋值。这种情况下它具有空值，这意味着它不指向任何其他内存位置 值类型变量不能为 null ，因为它包含值而不是内存地址。所以必须在使用前为值类型变量分配值 可空类型# C#2.0 为值类型引入了可空类型，允许为值类型变量赋值 null 或声明值类型变量而不为其赋值。\nint? age = null;类型转换# C# 是一门强类型语言，对类型要求比较严格。但是在一定的条件下是可以相互转换的，如将 int 型数据转换成 double 型数据。C# 允许使用两种转换方式：隐式转换、显式转换。\n隐式转换# 隐式转换是系统默认的，不需要加以声明就会自动执行隐式类型转换，在隐式转换过程，编译器无需对转换进行详细检查就能够安全的执行。隐式类型转换是 从低精度数值类型=\u0026gt;高精度数值类型。\nint a = 10; double b = a;// 自动隐式类型转换显式转换# 高精度值=\u0026gt;低精度 进行数据转换时，可能会丢失数据，这时候需要使用显式转换。并且要考虑到可能出现算术溢出。显式转换需要明确指出要转换的类型。显式转换可能导致错误，进行这种转换时编译器会对转换进行溢出检测，如果有溢出说明转换失败，表示源类型不是一个合法的目标类型无法进行类型转换，强制类型转换会造成数据精度丢失。\ndouble a = 10; int b = (int)a;// 显式将double类型转换为int可空类型数据转换=\u0026gt;非可空类型或者另一个可空类型，其中可能会丢失数据，就必须使用显式类型转换。并且如果从可空类型转换为非可空类型时变量值为 null，会抛出 InvalidOperationException 异常。\nint? a = null; int b = (int)a; // System.InvalidOperationException:“可为空的对象必须具有一个值。通过方法进行转换# ToString()\nC#中的类型基类都继承自 Object 类，所以都可以使用 ToString() 来转换成字符串。\nint a = 10; string s = a.ToString();Int.Parse()\n将 string 类型参数转换为 int ，注意： string 类型参数不能为 null ，并且也只能是各种整型，不能是浮点型。\nstring a = \u0026#34;2\u0026#34;; string b = \u0026#34;2.6\u0026#34;; string c = null; int a1 = int.Parse(a);//正常 int a2 = int.Parse(b);//错误:输入字符串格式错误 int a3 = int.Parse(c);//值不能为nullInt.TryParse()\n该方法与 Int.Parse() 方法类似，不同点在于 Int.Parse() 方法无法转换成功时会抛出异常。而 Int.TryParse() 方法在无法进行转换时会返回 false ， Int.TryParse() 方法需要一个 out 类型的参数，如果转换成功， out 参数的值就是正常转换的值，否则返回 false 。\nstring a = \u0026#34;2\u0026#34;; string b = \u0026#34;2.6\u0026#34;; string c = null; int i; bool a1 = int.TryParse(a，out i);//转换成功，i=2 bool a2 = int.TryParse(b， out i);//转换失败，a2=false bool a3 = int.TryParse(c， out i);//转换失败，a3=falseConvert()\nstring a = \u0026#34;2\u0026#34;; int a1 = Convert.ToInt32(a); 方法 说明 Convert.ToInt32() 转换为整型(int) Convert.ToChar() 转换为字符型(char) Convert.ToString() 转换为字符串型(string) Convert.ToDateTime() 转换为日期型(datetime) Convert.ToDouble() 转换为双精度浮点型(double) Conert.ToSingle() 转换为单精度浮点型(float) 自定义转换# 通过继承接口 IConventible 或者 TypeConventer 类，可以实现自定义转换。\n使用 as 运算符转换# as 只能用于引用类型和可为空的类型。使用 as 有很多好处，当无法进行类型转换时，会将对象赋值为 NULL ，避免类型转换时报错或是抛出异常。C# 抛出异常在进行捕获异常并进行处理是很消耗资源的，如果只是将对象赋值为 NULL 的话是几乎不消耗资源的(消耗很小的资源)。\nobject o = \u0026#34;abc\u0026#34;; string s = o as string; //执行第一次类型兼容性检查，并返回结果 if (s != null) Console.WriteLine(\u0026#34;转换成功！\u0026#34;); else Console.WriteLine(\u0026#34;转换失败！\u0026#34;);装箱和拆箱# C#通过装箱和拆箱来实现值类型和引用类型的相互转换，使得任何 value-type 的值都可以转换为 object 类型的值，反之亦可。\n装箱# 装箱是指：将值类型的数据隐式地转换成一个对象类型(object)的数据。执行装箱操作时不可避免的要在堆上申请内存空间，并将堆栈上的值类型数据复制到申请的堆内存空间上，这是要消耗内存和cpu资源的。在执行装箱转换时，也可以使用显式转换。\nint i = 0; object obj = i; //装箱：值类型转换为引用类型拆箱# 拆箱是指：将一个对象类型的数据显式地转换成一个值类型数据。拆箱过程是装箱的逆过程，是将存储在堆上的引用类型值转换为值类型并赋给值类型变量。\n拆箱操作分为两步：\n检查对象实例，确保它是给定值类型的一个装箱值 将该值从实例复制到值类型变量中 int i = 0; object obj = i; //装箱：值类型转换为引用类型 int j = (int)obj; //拆箱：引用类型转换为值类型注意\n装箱可以隐式进行，但拆箱必须显式 在装箱的时候，并不需要显式类型转换。但在拆箱时需要类型转换。因为在拆箱时对象可以被转换为任何类型 装什么拆什么，装箱就是要在托管堆重开辟空间，不但要装数值而且还要装类型。所以说装什么拆什么，也就是用什么值类型装箱，就要用什么值类型拆箱 运算符# 三元运算符# if/else 的简化形式。首先判断一个条件，如果为真返回第一个值，为假返回后一个值。\nint a = 3; bool result = a \u0026gt; 10 ? true : false; //a\u0026gt;10?如果大于返回true否则返回false可空类型和运算符# 在 C# 2.0 中出现了可空类型，允许值类型也可以为空 null，可空类型的实现基于 C#泛型。\n注意：在程序中使用可空类型就必须考虑 null 值在各种运算符一起使用的影响，通常可空类型与一元或二元运算符一起使用时，如果一个操作数为 null 或两个操作数为 null ，结果就是 null 。\nint? a = null; int? c = a + 4; //c=null空合并运算符# 空合并运算符 ?? 提供了快捷方式处理可空类型和引用类型时表示 null 可能的值。\n注意： 只能针对引用类型处理，规则是：\n如果第一个操作数不是null，值就等于第一个操作数的值 如果第一个操作数是null，值就等于第二个操作数的值 int? a = null; int b; b = a ?? 10;//第一个操作数是null，值为第二个操作数.10 a = 3; b = a ?? 10;//第一个操作数不是null，值为第一个操作数.3checked/unchecked# 如果把代码块标记为 checked ， CLR 就会执行栈溢出检测，如果要禁止栈溢出，则可以把代码标记 unchecked 。\n//byte类型最大取值255 byte a = 255; checked { a++; } //这里如果不加checed.++后输出0(不会抛异常，但会丢失数据，溢出的位会被舍弃，所以值为0)，加上后会抛出栈溢出异常 Console.WriteLine(a);is# is 运算符可以检测对象是否与特定类型兼容，兼容表示对象是该类型或者派生自该类型。\n转换规则如下：\n检查对象类型的兼容性，并返回结果 true/false 。 不会抛出异常 如果对象为 null，返回 false object o = \u0026#34;abc\u0026#34;; if (o is string) //执行第一次类型兼容性检查 { string s = (string)o; //执行第二次类型兼容性检查，并转换 Console.WriteLine(\u0026#34;转换成功！\u0026#34;); } else { Console.WriteLine(\u0026#34;转换失败！\u0026#34;); }as# 转换规则如下：\n检查对象类型的兼容性并返回转换结果，如果不兼容则返回 null 不会抛出异常 如果结果判断为空，则强制执行类型转换将抛出 NullReferenceException 异常 object o = \u0026#34;abc\u0026#34;; string s = o as string; //执行第一次类型兼容性检查，并返回结果 if (s != null) Console.WriteLine(\u0026#34;转换成功！\u0026#34;); else Console.WriteLine(\u0026#34;转换失败！\u0026#34;);sizeof# sizeof 运算符可以确定栈中值类型需要的长度(单位为字节)。\nConsole.WriteLine(sizeof(int));//4个字节 Console.WriteLine(sizeof(byte));//1个字节typeof# 返回一个表示特定类型的 System.Type 对象。\nConsole.WriteLine(typeof(int));//System.Int32 Console.WriteLine(typeof(byte));//System.Byte关键字# C# 包含保留字，对编译器有特殊意义。这些保留字称为“关键字”。关键字不能用作变量，类，接口等的名称(标识符)，关键字不能用作标识符(变量名，类，接口等)。但是，它们可以与前缀“@”一起使用。例如，class 是保留关键字，因此不能用作标识符，但可以使用 @class 。\n🎨 关键字的更多信息，访问 MSDN\n枚举# enum 是值类型数据类型。枚举用于声明命名整数常量的列表。可以直接在命名空间，类或结构中使用 enum 关键字定义。\n枚举用于为每个常量指定一个名称，以便可以使用其名称引用常量整数默认情况下，枚举的第一个成员的值为 0，每个连续的枚举成员的值增加 1 枚举可以包括数字数据类型的命名常量，例如 byte，sbyte，short，ushort，int，uint，long 或 ulong 枚举不能与字符串类型一起使用 Enum 是一个抽象类，包含用于枚举的静态帮助器方法\nEnum method Description Format 将指定的枚举类型值转换为指定的字符串格式 GetName 返回指定枚举的指定值的常量的名称 GetNames 返回指定枚举的所有常量的字符串名称数组 GetValues 返回指定枚举的所有常量值的数组 object Parse(type, string) 将一个或多个枚举常量的名称或数值的字符串表示形式转换为等效的枚举对象 bool TryParse(string, out TEnum) 将一个或多个枚举常量的名称或数值的字符串表示形式转换为等效的枚举对象，返回值表示转换是否成功 enum Color { Red， Green， Blue }预处理器指令# #region/#endregion 指令用于把一段代码标记为有给定名称的一个块\ndefine/#undef 结合 #if/#elif/endif 实现条件编译\n#define debug using System; namespace CSharp.Study.Test { class Program { static void Main(string[] args) { #if debug Console.WriteLine(\u0026#34;debug\u0026#34;); #else Console.WriteLine(\u0026#34;other\u0026#34;); #endif } } }\t#if/#elif/#else/#endif 告知编译器是否要编译代码块 #warning/#error 如果编译器遇到#warning指令会向用户显示指令后的文本，之后编译继续。如果是#error 会在显示文本后，编译退出，不会生成IL代码 "},{"id":29,"href":"/docs/dotnet/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","title":"多线程","section":"所有文章","content":"使用多线程可以充分利用 CPU 资源。提高 CPU 的使用率，采用多线程的方式去同时完成几件事情而不互相干扰。在处理大量的 IO 操作或处理的情况需要花费大量的时间时(如:读写文件，视频图像的采集，处理，显示，保存等)有较大优势。\n优点\n多线程可以把占据时间长的程序中的任务放到后台去处理而不影响主程序的运行 程序的运行效率可能会提高 在一些等待的任务实现上如用户输入，文件读取和网络收发数据等，线程比较有用 不足\n如果有大量的线程，会影响性能，因为操作系统需要在它们之间切换 更多的线程需要更多的内存空间 概念了解# 并发(Concurrency)# 逻辑上的同时发生，一个处理器（在不同时刻或者说在同一时间间隔内）\u0026ldquo;同时\u0026quot;处理多个任务。宏观上是并发的，微观上是按排队等待、唤醒、执行的步骤序列执行。并发性是对有限物理资源强制行使多用户共享（多路复用）以提高效率。\n并行(Parallel)# 物理上的同时发生，多核处理器或多个处理器（在同一时刻）同时处理多个任务。并行性允许多个程序同一时刻可在不同 CPU 上同时执行。\n进程(Process)# 程序在计算机上的一次执行活动。运行一个程序、启动一个进程.程序是死的（静态的），进程是活的（动态的）。Windows 系统利用进程把工作划分为多个独立的区域，每个应用程序实例对应一个进程。进程是操作系统分配和使用系统资源的基本单位.进程包含一个运行-ing 应用程序的所有资源、进程（占用的资源）间相互独立。\n线程(Thread)# 轻量级进程，是进程的一个实体（线程本质上是进程中一段并发运行的代码），执行线程、体现程序的真实执行情况，是处理器上系统独立调度和时间分配的最基本的执行单元。同一进程的所有线程共享相同的资源和内存（共享代码，全局变量，环境字符串等），使得线程间上下文切换更快、可以在同一地址空间内访问内存。\n同步# 如果一个程序调用某个方法，等待其执行所有处理后才继续执行，这样的方法是同步的。\n异步# 如果一个程序调用某个方法，在该方法处理完成之前就返回到调用方法，则这个方法是异步的。\n线程创建# 默认创建# C#中使用 Thread 类创建和控制线程，该类允许创建线程，以及设置线程的优先级。\n/// \u0026lt;summary\u0026gt; /// 线程创建 /// \u0026lt;/summary\u0026gt; public static void ThreadCreate_Basic() { static void ThreadMethod() { Thread.Sleep(2000); Console.WriteLine(\u0026#34;子线程结束\u0026#34;); } Console.WriteLine(\u0026#34;程序在启动时创建一个线程，称为主线程\u0026#34;); //创建线程 Thread t = new Thread(ThreadMethod); //启动线程 t.Start(); Console.WriteLine(\u0026#34;主线程结束\u0026#34;); }Thread 构造函数接收 ParameterrizeThreadStart 和 ThreadStart 委托参数，所以也可以这么写：\nThread t = new Thread(new ThreadStart(ThreadMethod));lambad 表达式创建# Thread t = new Thread(() =\u0026gt; Console.WriteLine(\u0026#34;ThreadMethod\u0026#34;));线程调用顺序# /// \u0026lt;summary\u0026gt; /// 线程调用顺序 /// \u0026lt;/summary\u0026gt; /// \u0026lt;remarks\u0026gt; /// 观察输出结果说明 /// 线程是由操作系统调度的，每次哪个线程先被执行不确定，线程的调度是无序的 ///\u0026lt;/remarks\u0026gt; public static void Thread_Order() { Console.WriteLine(\u0026#34;程序在启动时创建一个线程，称为主线程\u0026#34;); Thread t = new Thread(() =\u0026gt; Console.WriteLine(\u0026#34;A\u0026#34;)); Thread t1 = new Thread(() =\u0026gt; Console.WriteLine(\u0026#34;B\u0026#34;)); Thread t2 = new Thread(() =\u0026gt; Console.WriteLine(\u0026#34;C\u0026#34;)); Thread t3 = new Thread(() =\u0026gt; Console.WriteLine(\u0026#34;D\u0026#34;)); t.Start(); t1.Start(); t2.Start(); t3.Start(); Console.WriteLine(\u0026#34;主线程结束\u0026#34;); } 注意：线程是由操作系统调度的，每次哪个线程先被执行可以不同，就是说该例中线程的调度是无序的。不同 PC 运行结果可能不一致，只作示例。\n线程传递数据# 使用带 ParameterrizeThreadStart 委托参数的 Thread 构造函数创建自定义类。把线程方法定义为实例方法，之后初始化实例数据，启动线程。 不带参数：\nThread t = new Thread(() =\u0026gt; Console.WriteLine(\u0026#34;ThreadMethod\u0026#34;));一个参数：\nThread t = new Thread((object message) =\u0026gt; Console.WriteLine(message));多个参数(自定义类)：\nclass Data { public string name; public int age; public Data(string name， int age) { this.name = name; this.age = age; } public void Write() { Console.WriteLine(\u0026#34;name:{0}，age:{1}\u0026#34;， this.name， this.age); } }var data = new Data(\u0026#34;Wang\u0026#34;， 24); Thread t = new Thread(data.Write); t.Start();后台线程# 默认情况下：用 Thread 类创建的线程总是前台线程，线程池中的线程总是后台线程。\n前台线程和后台线程的区别在于：\n前台线程：应用程序必须运行完所有的前台线程才可以退出 后台线程：应用程序可以不考虑其是否已经运行完毕而直接退出，所有的后台线程在应用程序退出时都会自动结束 前台线程阻止进程的关闭\nThread thread = new Thread(() =\u0026gt; { Thread.Sleep(5000); Console.WriteLine(\u0026#34;前台线程执行\u0026#34;); }); thread.Start(); Console.WriteLine(\u0026#34;主线程执行完毕\u0026#34;);这里主线程马上执行完成，并不马上关闭，前台线程等待 5 秒再执行输出，然后控制台退出。\n后台线程不阻止进程的关闭\nThread thread = new Thread(() =\u0026gt; { Thread.Sleep(5000); Console.WriteLine(\u0026#34;前台线程执行\u0026#34;); }) { IsBackground = true }; thread.Start(); Console.WriteLine(\u0026#34;主线程执行完毕\u0026#34;);不等后台线程执行完毕，主线程执行完毕后立即退出，控制台立即退出。\n线程优先级# 之前说到，线程是由操作系统调度的，给线程指定优先级，可以影响调度顺序，C#中 Thread 类的 Priority 属性提供了五种线程优先级别，这是一个枚举对象\nNormal(正常，默认值) Highest (最高) AboseNormal(高于正常) BelowNormal(低于正常) Lowest(最低) Thread normal = new Thread(() =\u0026gt; { Console.WriteLine(\u0026#34;优先级为正常线程\u0026#34;); }); normal.Start(); Thread aboseNormal = new Thread(() =\u0026gt; { Console.WriteLine(\u0026#34;优先级为高于正常线程\u0026#34;); }) { Priority = ThreadPriority.AboveNormal }; aboseNormal.Start(); Thread belowNormal = new Thread(() =\u0026gt; { Console.WriteLine(\u0026#34;优先级为低于正常线程\u0026#34;); }) { Priority = ThreadPriority.BelowNormal }; belowNormal.Start(); Thread highest = new Thread(() =\u0026gt; { Console.WriteLine(\u0026#34;优先级最高线程\u0026#34;); }) { Priority = ThreadPriority.Highest }; highest.Start(); Thread lowest = new Thread(() =\u0026gt; { Console.WriteLine(\u0026#34;优先级最低线程\u0026#34;); }) { Priority = ThreadPriority.Lowest }; lowest.Start(); Console.WriteLine(\u0026#34;主线程执行完毕\u0026#34;); 结果可知：设置优先级并不会指定线程固定执行的顺序，设置线程优先级只是提高了线程被调用的概率，并不是定义 CPU 调用线程的顺序，具体还是要由操作系统内部来调度。\n线程控制# 属性 描述 CurrentThread 获取当前正在运行的线程 IsAlive 获取一个值，该值指示当前线程的执行状态 Name 获取或设置线程的名称 Priority 获取或设置一个值，该值指示线程的调度优先级 ThreadState 获取一个值，该值包含当前线程的状态 方法 描述 Abort 调用此方法通常会终止线程 Join 阻止调用线程，直到某个线程终止时为止 Resume 继续已挂起的线程 Sleep 将当前线程阻止指定的毫秒数 Start 使线程被安排进行执行 Suspend 挂起线程，或者如果线程已挂起，则不起作用 Thread.Sleep()# static void ThreadMethod() { for (int i = 0; i \u0026lt; 10; i++) { Console.WriteLine(\u0026#34;a\u0026#34;); } } static void ThreadMethodSleep() { for (int i = 0; i \u0026lt; 10; i++) { //暂停2s Thread.Sleep(TimeSpan.FromSeconds(2)); Console.WriteLine(\u0026#34;b\u0026#34;); } } Thread t = new Thread(ThreadMethodSleep); t.Start(); ThreadMethod();工作原理 当程序运行时，主线程创建，而后创建线程 t ，该线程首先执行 ThreadMethodSleep 方法中的代码。然后会立即执行 ThreadMethod 方法。关键之处在于在ThreadMethodSleep 方法中加入了 Thread.Sleep 方法调用。这将导致线程执行该代码时，在打印任何数字之前会等待指定的时间(本例中是 2 秒)，当线程处于休眠状态时，它会占用尽可能少的 CPU 时间。结果发现通常后运行的 ThreadMethod 方法中的代码会比独立线程中的 ThreadMethodSleep 方法中的代码先执行。\nThread.Join()# static void ThreadMethod() { for (int i = 0; i \u0026lt; 10; i++) { Console.WriteLine(\u0026#34;a\u0026#34;); } }static void ThreadMethodSleep() { for (int i = 0; i \u0026lt; 20; i++) { //暂停2s Thread.Sleep(TimeSpan.FromSeconds(2)); Console.WriteLine(\u0026#34;b\u0026#34;); } } Thread t = new Thread(ThreadMethodSleep); t.Start(); Thread.Sleep(TimeSpan.FromSeconds(5)); t.Abort(); static void ThreadMethodSleep() { for (int i = 0; i \u0026lt; 10; i++) { //暂停2s Thread.Sleep(TimeSpan.FromSeconds(2)); Console.WriteLine(\u0026#34;b\u0026#34;); } } Thread t = new Thread(ThreadMethodSleep); t.Start(); t.Join(); ThreadMethod();工作原理 程序运行后，创建线程 t ，调用 ThreadMethodSleep() 方法，该方法循环打印 3 个\u0026quot;b\u0026rdquo;，但是每次打印前都要暂停 2s，在主程序中调用 t.join 方法，该方法允许等待线程 t 完成，只有 t 线程完成后才会继续执行主程序的代码，该例中就是主线程等待 t 线程完成后再继续执行，主线程等待时处于阻塞状态。\nSuspend/Resume# 需要多线程编程时为了挂起与恢复线程可以使用 Thread 类的 Suspend() 与 Resume() 方法。\n注意：这两个方法已经过时\nThread.Abort()# static void ThreadMethodSleep() { for (int i = 0; i \u0026lt; 20; i++) { //暂停2s Thread.Sleep(TimeSpan.FromSeconds(2)); Console.WriteLine(\u0026#34;b\u0026#34;); } } Thread t = new Thread(ThreadMethodSleep); t.Start(); Thread.Sleep(TimeSpan.FromSeconds(5)); t.Abort();工作原理 程序运行后，创建线程 t ，调用 ThreadMethodSleep() 方法，该方法循环打印 20 个\u0026quot;b\u0026quot;，但是每次打印前都要暂停 2s，在主线程中设置等待 6s 后调用 t.Abort() 方法，这有可能给线程注入了 ThreadAbortException 异常，导致线程被终结。这非常危险，因为该异常可以在任何时刻发生并可能彻底摧毁应用程序。另外，使用该技术也不一定总能终止线程。目标线程可以通过处理该异常并调用 Thread.ResetAbort 方法来拒绝被终止。因此并不推荐使用 Abort 方法来关闭线程。可优先使用一些其他方法，比如提供一个 CancellationToken 方法来，取消线程的执行。\nThread.ThreadState# 通过 Thread.ThreadState 属性读取当前线程状态。\nstatic void ThreadMethodSleep() { for (int i = 0; i \u0026lt; 3; i++) { //暂停2s Thread.Sleep(TimeSpan.FromSeconds(2)); Console.WriteLine(\u0026#34;b\u0026#34;); } } Thread t = new Thread(ThreadMethodSleep); Console.WriteLine(\u0026#34;创建线程，线程状态:{0}\u0026#34;， t.ThreadState); t.Start(); Console.WriteLine(\u0026#34;线程调用Start()方法，线程状态:{0}\u0026#34;， t.ThreadState); Thread.Sleep(TimeSpan.FromSeconds(5)); Console.WriteLine(\u0026#34;线程休眠5s，线程状态:{0}\u0026#34;， t.ThreadState); t.Join(); Console.WriteLine(\u0026#34;等待线程结束，线程状态:{0}\u0026#34;， t.ThreadState);工作原理 程序运行后，创建线程 t (Unstarted)-\u0026gt; t.start() (Running)-\u0026gt; t.sleep() (WaitSleepJoin)-\u0026gt; t.join() 线程结束(Stopped)\n异常处理# static void ThreadMethodA() { throw new Exception(\u0026#34;AError\u0026#34;); } static void ThreadMethodB() { try { throw new Exception(\u0026#34;BError\u0026#34;); } catch (Exception ex) { Console.WriteLine(\u0026#34;Error:{0}\u0026#34;， ex.Message); } } Thread t = new Thread(ThreadMethodB); t.Start(); t.Join(); try { Thread t1 = new Thread(ThreadMethodA); t1.Start(); } catch (Exception e) { Console.WriteLine(\u0026#34;Error:{0}\u0026#34;， e.Message); } static void AddThread(object e) { Console.WriteLine(\u0026#34;当前线程ID:{0}\u0026#34;， Thread.CurrentThread.ManagedThreadId); } ThreadPool.GetMaxThreads(out int workThread， out int ioThread); Console.WriteLine(\u0026#34;工作线程数:{0}，io线程数{1}\u0026#34;， workThread， ioThread); for (int i = 0; i \u0026lt; 5; i++) { ThreadPool.QueueUserWorkItem(AddThread); workThread = ioThread = 0; } Console.WriteLine($\u0026#34;{workThread}，{ioThread}\u0026#34;);工作原理 程序运行后，定义了两个会抛出异常的线程，其中一个对异常进行了处理，另一个没有，可以看到 ThreadMethodB() 方法中的异常没有被主程序包裹线程启动的 try/catch代码块捕获到，所以如果直接使用线程，一般不要在主程序线程中抛出异常，而在线程代码中使用 try/catch 代码块。\n线程池 ThreadPool# 创建线程需要时间，如果有不同的短任务要完成，就可以事先创建许多线程，在应完成这些任务时发出请求。这个线程数最好在需要更多的线程时增加，在需要释放资源时减少。C#中不需要自己创建维护这样一个列表，该列表由 ThreadPool 类托管。该类会在需要时增减池中线程的线程数，直到最大线程数，线程数的值是可配置的。如果线程池中个数到达了设置的极限，还是有更多的作业要处理，最新的作业就要排队，且必须等待线程完成其任务。\nstatic void AddThread(object e) { Console.WriteLine(\u0026#34;当前线程ID:{0}\u0026#34;， Thread.CurrentThread.ManagedThreadId); } ThreadPool.GetMaxThreads(out int workThread， out int ioThread); Console.WriteLine(\u0026#34;工作线程数:{0}，io线程数{1}\u0026#34;， workThread， ioThread); for (int i = 0; i \u0026lt; 5; i++) { ThreadPool.QueueUserWorkItem(AddThread); workThread = ioThread = 0; } Console.WriteLine($\u0026#34;{workThread}，{ioThread}\u0026#34;);ThreadPool.GetMaxThreads(out workThread， out ioThread) 接收两个 out int 类型参数返回最大工作线程数和 io 线程数，for 循环中使用ThreadPool.QueueUserWorkItem() 方法传递 WaitCallback 类型委托，将 AddThread() 方法赋予线程池中的线程，线程池收到请求后，如果线程池还没有运行，就会创建一个线程池，并启动第一个线程，如果已经启动，且有一个空闲线程来完成任务，就把该任务传递给这个线程。\n线程池使用限制# 线程池中所有线程都是后台线程，如果进程的所有前台线程都结束了，所有的后台线程就会停止，不能把入池的线程改为前台线程 不能给入池的线程设置优先级或名称 入池的线程只能用于时间较短的任务，如果线程要一直运行，就应使用 Thread 类创建一个线程 对于COM对象，入池的所有线程都是多线程单元(MTA)线程，许多 COM 对象都需要单线程单元(STA) "},{"id":30,"href":"/docs/dotnet/%E5%A7%94%E6%89%98%E5%92%8C%E4%BA%8B%E4%BB%B6/","title":"委托和事件","section":"所有文章","content":"委托# 委托是一个类，它定义了方法的类型，指明了这个委托类型的变量可接受的函数，表示对具有特定参数列表和返回类型的方法的引用，使得可以将方法当作另一个方法的参数来进行传递\n不管什么函数只要返回值类型和参数能匹配委托所指定的返回值类型和参数能匹配上，那么这个函数就能存储为一个委托变量的引用。\n为什么需要委托# 委托可以将方法作为参数 逻辑解耦，保持稳定 代码复用，保证项目规范 委托使用步骤# 使用 delegate 关键字定义委托 声明委托对应的方法 实例化委托将方法作为参数传入 class DelegateTest { //step01：使用delegate关键字定义委托 public delegate int Sum(int x， int y); static void Main(string[] args) { // step03：实例化委托将方法作为参数传入 Sum sum = new Sum(new DelegateTest().Add); int result = sum.Invoke(1， 2); Console.WriteLine(result); Console.ReadKey(); } // step02：声明委托对应的方法 public int Add(int x， int y) { return x + y; } } 使用 delegate 关键字定义委托 声明委托对应的方法 实例化委托将方法作为参数传入 至此，一个委托就完成了。\n匿名方法定义委托# 上面说到完成一个委托要分三步走缺一步都不行，但是微软可能感觉这么实现比较麻烦，非要把三步做成两步来走！所以就用匿名方法来简化上边的三个步骤。\n// step01：首先用delegate定义一个委托 public delegate int Sum(int x， int y); static void Main(string[] args) { // step02：使用匿名方法的写法把一个方法赋值给委托 Sum sum = delegate (int x， int y) { return x + y; }; int result = sum.Invoke(1， 2); Console.WriteLine(result); }step01：使用 delegate 关键字定义委托 step02：使用匿名方法的写法把一个方法赋值给委托\n这时会发现这里省略了定义方法这一步，将三步简化成了两步。\nLambda 表达式定义委托# 微软对C#的设计理念是简单易用。这时候发现对匿名方法的方式依旧不太满意，就想方设法的来简化 delegate(int x， int y) { return x + y; } 这个匿名方法，Lambda 就出现了。\nlambda 运算符 =\u0026gt; 左边列出了需要的参数，右边定义了赋予 lambda 变量的方法实现代码。\n// step01：首先用delegate定义一个委托 public delegate int Sum(int x， int y); static void Main(string[] args) { // 方法一： Sum sum1 = (int x， int y) =\u0026gt; { return x + y; }; int result1 = sum1(1， 2); // 方法二： Sum sum2 = (x， y) =\u0026gt; { return x + y; }; int result2 = sum2(1， 2); // 方法三： Sum sum3 = (x， y) =\u0026gt; x + y; int result3 = sum3(1， 2); }方法一：简单的把 delegate 去掉，在 () 与 {} 之间加上 =\u0026gt; 方法二：在方法一的基础上把参数类型都干掉了 方法三：要干就干彻底些，把 {} 以及 return 关键字都去掉了\n注意：这三种方法随便怎么写都行\nLambda 表达式简写# 如果 lambda 表达式只有一句，方法块内就可以省略花括号和 return 语句，这时编译器会添加一条隐式的 return 语句。\nFunc\u0026lt;double， double\u0026gt; func = param =\u0026gt; param * param;等价于\nFunc\u0026lt;double， double\u0026gt; func = param =\u0026gt; { return param * 2; };泛型委托# 随着.Net版本的不断升级，微软又来玩新花样了，不管是匿名方法还是 Lambda 表达式，完成一个委托的应用，都逃不过两个步骤，一步是定义一个委托，另一步是用一个方法来实例化一个委托。微软干脆把这两步都合成一步来走了。用 Func 来简化一个委托的定义。\nstatic void Main(string[] args) { //方法一： Func\u0026lt;int, int, int\u0026gt; add1 = (int x, int y) =\u0026gt; { return x + y; }; int result1 = add1(1， 2); //方法二： Func\u0026lt;int, int, int\u0026gt; add2 = (x， y) =\u0026gt; { return x + y; }; int result2 = add2(1， 2); //方法三： Func\u0026lt;int， int， int\u0026gt; add3 = (x， y) =\u0026gt; x + y; int result3 = add3(1， 2); }至此一个委托的应用就可用 Func\u0026lt;int， int， int\u0026gt; add3 = (x， y) =\u0026gt; x + y; 一句话来完成了，其中的 Func 就是所谓的泛型委托。\n微软提供了 Action\u0026lt;T\u0026gt; 和 Func\u0026lt;T\u0026gt; 两种泛型委托，用于简化方法定义。\nAction# 表示引用一个 void 返回类型的方法，可以传递最多16种不同的参数类型，没有泛型参数的 Action 类可调用没有参数的方法。\n// Action：无参数 Action action1 = () =\u0026gt; { Console.WriteLine(\u0026#34;啦啦啦啦\u0026#34;); }; action1(); // Action：一个参数 Action\u0026lt;string\u0026gt; action2 = p =\u0026gt; { Console.WriteLine(\u0026#34;啦啦啦啦，name:{0}\u0026#34;,p); }; action2(\u0026#34;wang\u0026#34;); // Action：多个参数 Action\u0026lt;string, int\u0026gt; action3 = (name,age) =\u0026gt; { Console.WriteLine(\u0026#34;啦，name:{0}，age:{1}\u0026#34;, name,age); }; action3(\u0026#34;wang\u0026#34;,25);Func# Func\u0026lt;T\u0026gt; 允许调用带返回类型的方法，可以传递 16种不同类型的参数和一个返回类型，Func\u0026lt;out TResult\u0026gt; 委托类型可以调用带返回值且无参数的方法。\n总结\nAction\u0026lt;T\u0026gt; 用于没有返回值的方法（参数根据自己情况进行传递） Func\u0026lt;T\u0026gt; 用于有返回值的方法（参数根据自己情况传递） 记住无返回就用 Action\u0026lt;T\u0026gt;，有返回就用 Func\u0026lt;T\u0026gt;。\n表达式树# 表达式树其实与委托已经没什么关系了，如果非要扯上关系，表达式树是存放委托的容器。如果非要说的更专业一些，表达式树是存取 Lambda 表达式的一种数据结构。要用 Lambda 表达式的时候，直接从表达式中获取出来 Compile() 就可以直接用了。\nstatic void Main(string[] args) { Expression\u0026lt;Func\u0026lt;int, int, int\u0026gt;\u0026gt; exp = (x, y) =\u0026gt; x + y; Func\u0026lt;int, int, int\u0026gt; fun = exp.Compile(); int result = fun(1, 2); }Invoke# Sum sum = delegate (int x, int y) { return x + y; }; int result = sum.Invoke(1, 2); //等价于 int result = sum(1,2);委托数组# 定义 Math 类提供两个静态方法接收一个 double 类型的参数，用于计算倍数和阶乘。\nclass Math { public static double MultipleTwo(double value) { return value * 2; } public static double Square(double value) { return value * value; } }public void Delegate_Array() { // 定义委托数组 Func\u0026lt;double, double\u0026gt;[] delegates = [ Math.MultipleTwo, Math.Square ]; // 使用委托数组 for (int i = 0; i \u0026lt; delegates.Length; i++) { Console.WriteLine(delegates[i](3.7)); Console.WriteLine(delegates[i](3)); } }多播委托# 之前的每个委托都只包含一个方法调用，调用委托的次数与调用方法的次数相同，如果要调用多个方法，就需要多次显式调用这个委托。\n但委托中也可以包含多个方法，称为多播委托。多播委托可以按顺序调用多个方法，为此委托的签名必须返回void，否则就只能得到委托最后调用的最后一个方法的结果。\nFunc\u0026lt;double, double\u0026gt; func = Math.MultipleTwo; func += Math.Square; var result = func(3.0); Console.WriteLine(result);只返回了3.0阶乘的值\n+= 和 -=# 多播委托使用 += 和 -=，在委托中增加或删除方法调用。\nstatic void Main(string[] args) { Action action = Print.First; action += Print.Second; action(); Action action2 = Print.First; action2 += Print.Second; action2 -= Print.First; action2(); Console.ReadKey(); } class Print { public static void First() { Console.WriteLine(\u0026#34;FirstMethod\u0026#34;); } public static void Second() { Console.WriteLine(\u0026#34;SecondMethod\u0026#34;); } }如果要使用多播委托，就要知道对同一个委托调用方法链的顺序并未正式定义，因此要避免编写依赖于特定顺序调用方法的代码。\n多播委托异常处理# 使用多播委托，意味着多播委托里包含一个逐个调用的委托集合，如果集合其中一个方法抛出异常.整个迭代就会停止。\nAction action = () =\u0026gt; { Console.WriteLine(\u0026#34;hello\u0026#34;); throw new Exception(); }; action += () =\u0026gt; { Console.WriteLine(\u0026#34;world\u0026#34;); }; action();委托只调用了第一个方法，因为第一个方法抛出了异常，委托的迭代停止\nGetInvocationList# 使用 Delegate的GetInvocationList() 方法迭代方法列表。\npublic void Delegate_GetInvocationList() { Action action = () =\u0026gt; { Console.WriteLine(\u0026#34;hello\u0026#34;); throw new Exception(); }; action += () =\u0026gt; { Console.WriteLine(\u0026#34;world\u0026#34;); }; var delegates = action.GetInvocationList(); // 如果不处理异常程序在抛出异常后停止 //foreach (Action item in delegates) //{ // item(); //} // 这里必须显式指定item类型为Action委托 foreach (Action item in delegates) { // 修改后，程序在捕获异常后，会迭代下一个方法 try { item(); } catch (Exception error) { Console.WriteLine(error.Message); } } }修改后，程序在捕获异常后，会迭代下一个方法。\n闭包的陷阱# https://www.cnblogs.com/aehyok/p/3730417.html\n源码：\nList\u0026lt;Action\u0026gt; list = new List\u0026lt;Action\u0026gt;(); for (int i = 0; i \u0026lt; 5; i++) { Action t = () =\u0026gt; Console.WriteLine(i.ToString()); list.Add(t); } foreach (Action t in list) { t(); }IL反编译\nList\u0026lt;Action\u0026gt; list = new List\u0026lt;Action\u0026gt;(); TempClass tempClass = new TempClass(); for (tempClass.i = 0; tempClass.i \u0026lt; 5; tempClass.i++) { Action t = tempClass.TempFunc; list.Add(t); } foreach (Action t in list) { t(); } public class TempClass { public int i; public void TempFunc() { Console.WriteLine(i.ToString()); } }所谓的闭包对象，指的是上面这种情形中的 TempClass 对象。如果匿名方法（Lambda表达式）引用了某个局部变量，编译器就会自动将该引用提升到该闭包对象中。即将for循环中的变量 i 修改成了引用闭包对象的公共变量 i。这样一来，即使代码执行后离开了原局部变量 i 的作用域(如for循环)，包含该闭包对象的作用域也还存在。\n在Lambda表达式(或匿名方法)中所引用的外部变量称为捕获变量。而捕获变量的表达式就称为闭包。捕获的变量会在真正调用委托时“赋值”，而不是在捕获时“赋值”，即总是使用捕获变量的最新的值\n注意：从C#5.0开始，foreach认为循环变量都应该是“新”的变量。所以，每次循环中创建委托时捕获的变量都不是同一个变量。所以遍历时使用foreach会自动捕获不同变量\n修改一下源代码\nList\u0026lt;Action\u0026gt; list = new List\u0026lt;Action\u0026gt;(); for (int i = 0; i \u0026lt; 5; i++) { int temp = i; Action t = () =\u0026gt; Console.WriteLine(temp.ToString()); list.Add(t); } foreach (Action t in list) { t(); }\n事件# 事件是一种引用类型，实际上也是一种特殊的委托。事件基于委托，是提供了发布/订阅机制的委托，事件是将委托封装，并对外公布了订阅和取消订阅的接口。\n有关事件的重要事项# 1、事件提供了对它的私有控制委托的结构化访问。我们无法直接访问该委托。\n2、事件中可用的操作比委托要少，对于事件我们只可以添加、删除或调用事件处理程序。\n3、事件被触发时，它调用委托来依次调用调用列表中的方法。\n有关事件的概念# 发布者（Publisher）：发布某个事件的类或结构，其他类可以在该事件发生时得到通知。\n订阅者（Subscriber）：注册并在事件发生时得到通知的类或结构。\n事件处理程序（event handler）：由订阅者注册到事件的方法，在发布者触发事件时执行。\n触发（raise）事件：调用（invoke）或触发（fire）事件的术语。当事件触发时，所有注册到它的方法都会被依次调用。\n发布订阅模式示例# /// \u0026lt;summary\u0026gt; /// 发布者 /// \u0026lt;/summary\u0026gt; public class Pub { // 定义事件所需委托 public delegate void OpenEventHandler(); // 使用委托类型定义事件 public event OpenEventHandler OpenEvent; /// \u0026lt;summary\u0026gt; /// 定义事件触发的函数 /// \u0026lt;/summary\u0026gt; public void Open() { // 这个简单的修改可确保在检查空值和发送通知之间，如果一个不同的线程移除了所有OpenEvent订阅者，将不会引发NullReferenceException异常 OpenEventHandler openEventHandler = OpenEvent; Console.WriteLine(\u0026#34;总服务上线...\u0026#34;); // 为确保有事件可用需要使用?. OpenEvent?.Invoke(); } }/// \u0026lt;summary\u0026gt; /// 事件订阅者A /// \u0026lt;/summary\u0026gt; public class ServiceA { public void ServiceAOpen() { Console.WriteLine(\u0026#34;服务A已连接\u0026#34;); } } /// \u0026lt;summary\u0026gt; /// 事件订阅者B /// \u0026lt;/summary\u0026gt; public class ServiceB { public void ServiceBOpen() { Console.WriteLine(\u0026#34;服务B已连接\u0026#34;); } }调用\npublic void Example_01() { Pub pub = new(); ServiceA serviceA = new(); ServiceB serviceB = new(); // 事件订阅 pub.OpenEvent += serviceA.ServiceAOpen; pub.OpenEvent += serviceB.ServiceBOpen; // 调用函数触发事件 pub.Open(); }标准 .NET事件模式# 委托类型的名称都应该以EventHandler 结束 委托的原型定义：有一个 void 返回值，并接受两个输入参数： 委托原型具有两个参数：sender表示事件触发者，e表示事件参数；一个 Object 类型，一个 EventArgs 类型(或继承自EventArgs) 事件的命名为委托去掉 EventHandler 之后剩余的部分 继承自 EventArgs 的类型应该以 EventArgs 结尾 public class Pub { /// \u0026lt;summary\u0026gt; /// 自定义事件参数以EventArgs结尾 /// \u0026lt;/summary\u0026gt; public class OpenEventArgs { public OpenEventArgs() { } } // 标准事件模式委托名称以EventHandler结尾 // 委托的原型定义：有一个 void 返回值，并接受两个输入参数：一个 Object 类型，一个 EventArgs 类型(或继承自EventArgs) public delegate void OpenEventHandler(object sender, OpenEventArgs e); // 事件的命名为委托去掉 EventHandler 之后剩余的部分 public event OpenEventHandler Open; public void OpenConn() { Console.WriteLine(\u0026#34;总服务上线...\u0026#34;); OpenEventArgs e = new(); Open?.Invoke(this, e); } } public class ServiceA { public void ServiceAOpen(object sender, Pub.OpenEventArgs e) { Console.WriteLine(\u0026#34;服务B已连接\u0026#34;); } } public class ServiceB { public void ServiceBOpen(object sender, Pub.OpenEventArgs e) { Console.WriteLine(\u0026#34;服务B已连接\u0026#34;); } } public void Example() { Pub pub = new(); ServiceA serviceA = new(); ServiceB serviceB = new(); // 事件订阅 pub.Open += serviceA.ServiceAOpen; pub.Open += serviceB.ServiceBOpen; // 调用函数触发事件 pub.OpenConn(); }参考# https://www.cnblogs.com/jujusharp/archive/2011/08/04/2127999.html https://www.cnblogs.com/HQFZ/p/4903400.html https://www.cnblogs.com/wangjiming/p/8300103.html "},{"id":31,"href":"/docs/dotnet/%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B/","title":"并行编程","section":"所有文章","content":"并行开发要做的事情就是将任务分摊给硬件线程去并行执行来达到负载和加速，传统的代码都是串行的，就一个主线程，为了实现加速而开了很多工作线程，这些工作线程就是软件线程。\nParallel# Parallel 类是对线程的抽象，位于 System.Threading.Tasks 名称空间下,提供了 任务和数据并行性 .在Parallel 下有三个常用的方法 Invoke 、 For 、ForEach，其中：\nParallel.Invoke 用于任务并行性 Parallel.ForEach/Parallel.For 用于数据并行性 任务并行性# Parallel.Invoke# 如果多个任务应并行运行，就可以使用 Parallel.Invoke() 方法将串行的代码并行化。\npublic void Parallel_Example_01() { var watch = Stopwatch.StartNew(); watch.Start(); Run1(); Run2(); Run3(); watch.Stop(); Console.WriteLine(\u0026#34;串行开发,总耗时{0}\u0026#34;, watch.ElapsedMilliseconds); watch.Restart(); Parallel.Invoke(Run1, Run2, Run3); watch.Stop(); Console.WriteLine(\u0026#34;并行开发,总耗时{0}\u0026#34;, watch.ElapsedMilliseconds); static void Run1() { Console.WriteLine(\u0026#34;Run1,我需要1s\u0026#34;); Thread.Sleep(1000); } static void Run2() { Console.WriteLine(\u0026#34;Run2,我需要2s\u0026#34;); Thread.Sleep(2000); } static void Run3() { Console.WriteLine(\u0026#34;Run3,我需要3s\u0026#34;); Thread.Sleep(3000); } Assert.IsTrue(true); } 主程序启动时，先顺序调用Run1(),Run()2,Run3()方法，这是串行的。而后使用Parallel.Invoke()将三个方法并行调用。\n执行顺序# public void Parallel_Example_02() { Console.WriteLine(\u0026#34;主线程启动,线程ID:{0}\u0026#34;, Thread.CurrentThread.ManagedThreadId); Parallel.Invoke( () =\u0026gt; Run1(\u0026#34;task1\u0026#34;), () =\u0026gt; Run2(\u0026#34;task2\u0026#34;), () =\u0026gt; Run3(\u0026#34;task3\u0026#34;)); Console.WriteLine(\u0026#34;主线程结束,线程ID:{0}\u0026#34;, Thread.CurrentThread.ManagedThreadId); static void Run1(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); for (int i = 0; i \u0026lt; 5; i++) { Console.WriteLine(\u0026#34;a\u0026#34;); } } static void Run2(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); for (int i = 0; i \u0026lt; 5; i++) { Console.WriteLine(\u0026#34;b\u0026#34;); } } static void Run3(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); for (int i = 0; i \u0026lt; 5; i++) { Console.WriteLine(\u0026#34;c\u0026#34;); } } Assert.IsTrue(true); } 结果可知： 没有固定顺序，每个Task可能是不同的线程去执行，也可能是相同的。主线程必须等Invoke中的所有方法执行完成后返回才继续向下执行。以后设计并行的时候，要考虑每个Task任务尽可能差不多，如果相差很大，比如一个时间非常长，其他都比较短，这样一个线程可能会影响整个任务的性能。这点非常重要(就是说Invoke会阻塞主线程)。\n数据并行性# Parallel.For# Parallel.For是 for 的多线程实现，串行代码中也有一个for，但是那个for并没有用到多核。而Paraller.For它会在底层根据硬件线程的运行状况来充分的使用所有的可利用的硬件线程。\npublic void Parallel_Example_For() { for (int i = 0; i \u0026lt; 3; i++) { ConcurrentBag\u0026lt;int\u0026gt; bag = new ConcurrentBag\u0026lt;int\u0026gt;(); var watch = Stopwatch.StartNew(); watch.Start(); for (int j = 0; j \u0026lt; 20000000; j++) { bag.Add(i); } watch.Stop(); Console.WriteLine(\u0026#34;串行添加,总数20000000,耗时{0}\u0026#34;, watch.ElapsedMilliseconds); watch.Restart(); Parallel.For(0, 20000000, j =\u0026gt; { bag.Add(j); }); watch.Stop(); Console.WriteLine(\u0026#34;并行添加,总数20000000,耗时{0}\u0026#34;, watch.ElapsedMilliseconds); Console.WriteLine(\u0026#34;***********************************\u0026#34;); } Assert.IsTrue(true); }向一个线程安全的集合插入数据,使用串行的 for 耗时与使用并行的 Parallel.For 差异： Parallel.ForEach# Parallel.ForEach 是 foreach 的多线程实现，都能对IEnumerable\u0026lt;T\u0026gt; 类型对象进行遍历。Parallel.ForEach的特殊之处在于它使用多线程来执行循环体内的代码段。\npublic void Parallel_Example_ForEach() { ConcurrentBag\u0026lt;int\u0026gt; bag = new ConcurrentBag\u0026lt;int\u0026gt;(); Parallel.For(0, 10, j =\u0026gt; { bag.Add(j); }); Console.WriteLine(\u0026#34;集合总数:{0}\u0026#34;, bag.Count); Parallel.ForEach(bag, item =\u0026gt; { Console.WriteLine(item); }); Assert.IsTrue(true); }中断# Parallel.For：添加ParallelLoopState参数，该实例提供了Break和Stop方法来帮助实现中断 ParallelLoopState.Break()：在完成当前的这轮工作之后，不再执行后继的工作，但在当前这轮工作开始之前“已经在执行”的工作，则必须完成。但并不能执行完所有的循环 ParallelLoopState.Stop()：不但不会再创建新的线程执行并行循环，而且当前“已经在执行”的工作也应该被中止 ParallelLoopState.Break()# public void Parallel_Example_For_Break() { int maxCount = 1000; ConcurrentBag\u0026lt;int\u0026gt; bag = new ConcurrentBag\u0026lt;int\u0026gt;(); var watch = Stopwatch.StartNew(); watch.Start(); Parallel.For(0, 2000, (j, state) =\u0026gt; { if (bag.Count == maxCount) { state.Break(); //return是必须的,否则依旧会继续执行 return; } bag.Add(j); }); watch.Stop(); Console.WriteLine(\u0026#34;集合元素个数{0}\u0026#34;, bag.Count); Assert.AreEqual(maxCount, bag.Count); }ParallelLoopState.Stop()# public void Parallel_Example_For_Stop() { int maxCount = 1000; ConcurrentBag\u0026lt;int\u0026gt; bag = new ConcurrentBag\u0026lt;int\u0026gt;(); for (int j = 0; j \u0026lt; 5; j++) { bag = new ConcurrentBag\u0026lt;int\u0026gt;(); Parallel.For(0, 2000, (i, state) =\u0026gt; { if (bag.Count == maxCount) { state.Stop(); return; } bag.Add(i); }); Console.WriteLine(\u0026#34;集合元素个数{0}\u0026#34;, bag.Count); Console.WriteLine(\u0026#34;*************************************************\u0026#34;); Assert.AreEqual(maxCount, bag.Count); } }注意# Stop仅仅通知其他迭代尽快结束，而Break不仅通知其他迭代尽快结束，同时还要保证退出之前要完成LowestBreakIteration之前的迭代。 例如，对于从 0 到 1000 并行迭代的for循环，如果从第 100 此迭代开始调用Break，则低于 100 的所有迭代仍会运行，从 101 到 1000 的迭代则不必要。而调用Stop方法不保证低于 100 的所有迭代都会运行。\n异常处理# 任务是并行计算的，处理过程中可能会产生n多的异常。\nException# Exception是可以捕获到两个异常的。\npublic void Parallel_Example_Exception() { Console.WriteLine(\u0026#34;主线程启动,线程ID:{0}\u0026#34;, Thread.CurrentThread.ManagedThreadId); try { Parallel.Invoke(() =\u0026gt; Run1(\u0026#34;task1\u0026#34;), () =\u0026gt; Run2(\u0026#34;task2\u0026#34;), () =\u0026gt; Run3(\u0026#34;task3\u0026#34;)); } catch (Exception ex) { Console.WriteLine(ex.Message); } Console.WriteLine(\u0026#34;主线程结束,线程ID:{0}\u0026#34;, Thread.CurrentThread.ManagedThreadId); static void Run1(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); throw new Exception(\u0026#34;Run1出现异常\u0026#34;); } static void Run2(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); } static void Run3(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); throw new Exception(\u0026#34;Run3出现异常\u0026#34;); } Assert.IsTrue(true); }\nAggregateException# public void Parallel_Example_AggregateException() { Console.WriteLine(\u0026#34;主线程启动,线程ID:{0}\u0026#34;, Thread.CurrentThread.ManagedThreadId); try { Parallel.Invoke(() =\u0026gt; Run1(\u0026#34;task1\u0026#34;), () =\u0026gt; Run2(\u0026#34;task2\u0026#34;), () =\u0026gt; Run3(\u0026#34;task3\u0026#34;)); } catch (AggregateException ex) { // AggregateException捕获并行产生的一组异常集合 foreach (var item in ex.InnerExceptions) { Console.WriteLine(item); } } static void Run1(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); throw new Exception(\u0026#34;Run1出现异常\u0026#34;); } static void Run2(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); } static void Run3(string taskName) { Console.WriteLine(\u0026#34;任务名：{0}线程ID:{1}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId); throw new Exception(\u0026#34;Run3出现异常\u0026#34;); } Console.WriteLine(\u0026#34;主线程结束,线程ID:{0}\u0026#34;, Thread.CurrentThread.ManagedThreadId); Assert.IsTrue(true); }Invoke方法中调用了一个产生异常的方法，但是结果显示异常并不会影响其它方法及主线程的执行。\nParallel.For肯定快吗?# 在实现多线程时，为了防止多个线程同时处理同一个变量而导致变量处于\u0026quot;薛定谔状态\u0026quot;，引入了\u0026quot;锁\u0026quot;的概念，即在每一时刻只有获得\u0026quot;锁\u0026quot;的线程才能操作目标变量。如果在Parallel.For中也需要操作一个全局变量，就意味着即使这是并行计算，大家也需要排队操作全局变量，此时Parallel.For可能远远不如传统的for循环来的快。\npublic void Parallel_Example_Performance() { Stopwatch stopWatch = new Stopwatch(); var obj = new object(); long num = 0; stopWatch.Start(); for (int i = 0; i \u0026lt; 10000; i++) { for (int j = 0; j \u0026lt; 60000; j++) { num++; } } stopWatch.Stop(); Console.WriteLine(\u0026#34;for run \u0026#34; + stopWatch.ElapsedMilliseconds + \u0026#34; ms.\u0026#34;); stopWatch.Reset(); stopWatch.Start(); Parallel.For(0, 10000, item =\u0026gt; { for (int j = 0; j \u0026lt; 60000; j++) { lock (obj) { num++; } } }); stopWatch.Stop(); Console.WriteLine(\u0026#34;ParallelFor run \u0026#34; + stopWatch.ElapsedMilliseconds + \u0026#34; ms.\u0026#34;); Assert.IsTrue(true); }\nParallelOptions# 属性 描述 CancellationToken 获取或设置与此 ParallelOptions 实例关联的 CancellationToken MaxDegreeOfParallelism 获取或设置此 ParallelOptions 实例所允许的并发任务的最大数目 "},{"id":32,"href":"/docs/dotnet/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/","title":"异步编程","section":"所有文章","content":"对于多线程，经常使用的是 Thread。在了解 Task 之前，如果要使用多核的功能可能就会自己来开线程，然而这种线程模型在 .net 4.0 之后被一种称为 基于“任务的编程模型” 所冲击，这就是 Task。\nTask 会比 Thread 具有更小的性能开销，Task 是架构在 Thread 之上的就是说 Task 最终还是会抛给线程去做，并且任务跟线程不是一对一的关系，比如开 10 个任务并不是说会开 10 个线程，这一点任务有点类似线程池，但是任务相比线程池有很小的开销和精确的控制。Task 类的表示单个操作不返回一个值，通常以异步方式执行，Task 对象是 \u0026quot;基于任务的异步模式“ 首次引入 .NET Framework 4 中。\n因为由执行工作 Task 对象通常以异步方式执行在线程池线程上而不是以同步方式在主应用程序线程，可以使用Status 属性，以及 IsCanceled,IsCompleted, 和 IsFaulted属性，以确定任务的状态。\n相关概念理解# 同步（Synchronous） 异步 (Asynchronous) 阻塞 (Blocking) 非阻塞(Nonblocking) 同步/异步指的是在客户端\n同步意味着：客户端提出了一个请求以后，在回应之前只能等待 异步意味着：客户端提出一个请求以后，还可以继续提其他请求\n阻塞/非阻塞指的是服务器端\n阻塞意味着：服务器接受一个请求后，在返回结果以前不能接受其他请求 非阻塞意味着：服务器接受一个请求后，尽管没有返回结果，还是可以继续接受其他请求\n同步与异步# 同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)\n所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。\n而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果,而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。(典型的异步编程模型比如Node.js)\n同步通信机制\n你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，\u0026ldquo;我查一下\u0026rdquo;，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）\n异步通信机制\n书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过\u0026quot;回电\u0026quot;这种方式来回调\n阻塞与非阻塞# 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态，阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程\nExample\n你打电话问书店老板有没有《分布式系统》这本书，如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果，在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关\n模型图例# 单线程同步模型# 多线程模型# 异步模型# 基础# 创建任务# new TaskFactory()# 使用实例化的TaskFactory类\nvar t1 = new TaskFactory().StartNew(() =\u0026gt; Console.WriteLine(\u0026#34;new TaskFactory().StartNew\u0026#34;));Task.Factory# 使用Task静态属性Factory\nvar t2 = Task.Factory.StartNew(() =\u0026gt; Console.WriteLine(\u0026#34;Task.Factory\u0026#34;));new Task()# 使用Task的构造函数, 实例化Task对象时，任务不会立即执行，而是指定Created状态，通过Task.Start()方法启动\nvar t3 = new Task(() =\u0026gt; Console.WriteLine(\u0026#34;Task Constructor\u0026#34;)); t3.Start();Task.Run# .Net4.5 新增功能使用Task类的Run方法\nvar t4 = Task.Run(() =\u0026gt; Console.WriteLine(\u0026#34;Task.Run\u0026#34;));注意：使用Task.Run/Task.Factory.StartNew/new TaskFactory().StartNew()方法运行的任务会立即开始工作，无需显式调用这些任务的Start方法\n同步任务# 任务不一定要使用线程池中的线程，也可以使用其他线程，任务也可以同步进行，以相同的线程作为主调线程\nstatic void Main(string[] args) { var t1 = new Task(() =\u0026gt; TaskMethod(\u0026#34;t1\u0026#34;)); t1.Start(); Console.WriteLine(\u0026#34;主线程调用结束\u0026#34;); Console.ReadKey(); } public static void TaskMethod(string taskName) { Console.WriteLine(\u0026#34;Task {0} 运行在线程id为{1}的线程上。是否是线程池中线程？:{2}\u0026#34;, taskName, Thread.CurrentThread.ManagedThreadId, Thread.CurrentThread.IsThreadPoolThread); }var t1 = new Task(() =\u0026gt; TaskMethod(\u0026#34;t1\u0026#34;)); t1.RunSynchronously(); Console.WriteLine(\u0026#34;主线程调用结束\u0026#34;); Console.ReadKey();使用单独线程的任务# 如果任务的代码需要长时间运行，应该使用TaskCreationOptions.LongRuning告诉任务调度器创建一个新线程，而不是使用线程池中的线程。此时线程可以不受线程池管理\nvar t1 = new Task(TaskMethod, TaskCreationOptions.LongRunning); t1.Start();Task生命周期# 状态 描述 Created 该任务已初始化，但尚未被计划 WaitingForActivation 该任务正在等待 .NET Framework 基础结构在内部将其激活并进行计划 WaitingToRun 该任务已被计划执行，但尚未开始执行 Running 该任务正在运行，但尚未完成 WaitingForChildrenToComplete 该任务已完成执行，正在隐式等待附加的子任务完成 RanToCompletion 已成功完成执行的任务 Canceled 该任务已通过对其自身的 CancellationToken 引发 OperationCanceledException 对取消进行了确认，此时该标记处于已发送信号状态；或者在该任务开始执行之前，已向该任务的 CancellationToken 发出了信号 Faulted 由于未处理异常的原因而完成的任务 Task任务控制# 方法 描述 Task.Wait task1.Wait();就是等待任务执行完成，task 的状态变为 Completed Task.WaitAll 待所有的任务都执行完成 Task.WaitAny 等待任何一个任务完成就继续向下执行 Task.ContinueWith 第一个 Task 完成后自动启动下一个 Task，实现 Task 的延续 CancellationTokenSource CancellationTokenSource 通过 cancellation 的 tokens 来取消一个 Task Task返回类型# void# 不关心结果，返回 void 类型\n[TestMethod] public void Task_Result_Void() { Console.WriteLine($\u0026#34;不关心结果,返回Void,--Start,线程Id:{Thread.CurrentThread.ManagedThreadId}\u0026#34;); Print(); Console.WriteLine($\u0026#34;不关心结果,返回Void,--End,线程Id:{Thread.CurrentThread.ManagedThreadId}\u0026#34;); Assert.IsTrue(true); static async void Print() { await Task.Run(() =\u0026gt; { Console.WriteLine($\u0026#34;Hello, 线程Id:{ Thread.CurrentThread.ManagedThreadId}\u0026#34;); }); } }Task# 关心是否完成，返回 Task 类型\npublic void Task_Result_Task() { Console.WriteLine($\u0026#34;看电视中...,线程Id:{Thread.CurrentThread.ManagedThreadId}\u0026#34;); Console.WriteLine(\u0026#34;突然停电，看下是不是跳闸了\u0026#34;); var task = OpenMainsSwitch(); Console.WriteLine($\u0026#34;没电了先玩会儿手机吧，线程Id为：{Thread.CurrentThread.ManagedThreadId}\u0026#34;); Thread.Sleep(100); // 等着电源开关被打开 task.Wait(); Console.WriteLine($\u0026#34;又有电了,继续看电视...,线程Id:{Thread.CurrentThread.ManagedThreadId}\u0026#34;); Assert.IsTrue(true); static async Task OpenMainsSwitch() { Console.WriteLine($\u0026#34;准备打开电源开关，线程Id：{ Thread.CurrentThread.ManagedThreadId}\u0026#34;); await Task.Run(() =\u0026gt; { Console.WriteLine($\u0026#34;打开电源开关, 线程Id:{ Thread.CurrentThread.ManagedThreadId}\u0026#34;); Thread.Sleep(2000); }); Console.WriteLine($\u0026#34;电源开关打开了，线程Id：{ Thread.CurrentThread.ManagedThreadId}\u0026#34;); } }Task\u0026lt;T\u0026gt;# 调用方法要从调用中获取一个T类型的值，异步方法的返回类型就必须是Task\u0026lt;T\u0026gt;。调用方法从Task的Result属性获取的就是T类型的值\npublic async Task Task_Result_TaskTAsync() { string message = $\u0026#34;Today is {DateTime.Today:D}\\n\u0026#34; + \u0026#34;Today\u0026#39;s hours of leisure: \u0026#34; + $\u0026#34;{await GetLeisureHoursAsync()}\u0026#34;; Console.WriteLine(message); Assert.IsTrue(true); static async Task\u0026lt;int\u0026gt; GetLeisureHoursAsync() { DayOfWeek today = await Task.FromResult(DateTime.Now.DayOfWeek); int leisureHours = today is DayOfWeek.Saturday || today is DayOfWeek.Sunday ? 16 : 5; return leisureHours; } }连续任务# 在指定任务完成后调用另一个指定任务\npublic void Task_ContinueWith_Example() { Task\u0026lt;string\u0026gt; t1 = new Task\u0026lt;string\u0026gt;( () =\u0026gt; TaskMethod1(\u0026#34;t1\u0026#34;)); Console.WriteLine(\u0026#34;Task1-创建,状态为:{0}\u0026#34;, t1.Status); t1.Start(); Console.WriteLine(\u0026#34;Task1-启动,状态为:{0}\u0026#34;, t1.Status); Console.WriteLine(t1.Result); Console.WriteLine(\u0026#34;Task1-完成,状态为:{0}\u0026#34;, t1.Status); Task t2 = t1.ContinueWith(TaskMethod2); Console.WriteLine(\u0026#34;Task2,状态为:{0}\u0026#34;, t2.Status); static string TaskMethod1(string taskName) { var result = string.Format($\u0026#34;Task:{taskName} 运行在线程id:{ Thread.CurrentThread.ManagedThreadId}的线程上,\u0026#34; + $\u0026#34;是否是线程池中线程？:{Thread.CurrentThread.IsThreadPoolThread}\u0026#34;); return result; } static void TaskMethod2(Task t) { Console.WriteLine($\u0026#34;TaskID:{ t.Id} 运行在线程id:{Thread.CurrentThread.ManagedThreadId}的线程上。是否是线程池中线程？:{Thread.CurrentThread.IsThreadPoolThread}\u0026#34;); } Assert.IsTrue(true); }使用TaskContinuationOptions枚举的值可以指定连续任务只有在起始任务成功或失败结束时启动\nTask t2 = t1.ContinueWith(TaskMethod2, TaskContinuationOptions.NotOnCanceled);嵌套Task# 关联嵌套# 在创建cTask时，加入了参数TaskCreationOptions.AttachedToParent，这个时候，cTask和pTask就会建立关联，cTask就会成为pTask的一部分\n[TestMethod] public void Task_Relevance_Example() { var pTask = Task.Factory.StartNew(() =\u0026gt; { var cTask= Task.Factory.StartNew(() =\u0026gt; { Console.WriteLine(\u0026#34;Childen task finished!\u0026#34;); }, TaskCreationOptions.AttachedToParent); Console.WriteLine(\u0026#34;Parent task finished!\u0026#34;); }); pTask.Wait(); Console.WriteLine(\u0026#34;Flag\u0026#34;); Assert.IsTrue(true); }非关联嵌套# 外层的pTask运行完后，并不会等待内层的cTask，直接向下走先输出了Flag。这种嵌套有时候相当于创建两个Task，但是嵌套在一起的话，在Task比较多时会方便查找和管理，并且还可以在一个Task中途加入多个Task，让进度并行前进\n[TestMethod] public void Task_NoRelevance_Example() { var pTask = Task.Factory.StartNew(() =\u0026gt; { Task.Factory.StartNew(() =\u0026gt; { Console.WriteLine(\u0026#34;Childen task finished!\u0026#34;); }); Console.WriteLine(\u0026#34;Parent task finished!\u0026#34;); }); pTask.Wait(); Console.WriteLine(\u0026#34;Flag\u0026#34;); Assert.IsTrue(true); }在Task内部创建Task，如果父任务在子任务之前结束，父任务状态就显示为WaitingForChilderenToComplete。所有的子任务也结束时，父任务的状态就改为RanToCompletion，如果使用TaskContinuationOptions枚举值创建子任务时会有不同结果，取消父任务也会取消子任务\nTask取消# 单个任务# [TestMethod] public void Task_CancellationToken_SingleTask_Example() { CancellationTokenSource cts = new CancellationTokenSource(); Task t1 = Task.Run(() =\u0026gt; { for (int i = 0; i \u0026lt; 30; i++) { if (cts.Token.IsCancellationRequested) { cts.Token.ThrowIfCancellationRequested(); } else { Thread.Sleep(500); Console.WriteLine(\u0026#34;任务t1,共执行30次,当前第{0}次\u0026#34;, i + 1); } } }, cts.Token); Thread.Sleep(2000); // 传达取消请求 cts.Cancel(); Console.WriteLine($\u0026#34;已停止,Status{t1.Status}\u0026#34;); Assert.IsTrue(true); }多个任务# [TestMethod] public void Task_CancellationToken_MultiTask_Example() { CancellationTokenSource cts1 = new CancellationTokenSource(); CancellationTokenSource cts2 = new CancellationTokenSource(); // 任何Task处于取消状态时其余也将取消 CancellationTokenSource ctsCombine = CancellationTokenSource.CreateLinkedTokenSource(cts1.Token, cts2.Token); Task t1 = Task.Run(() =\u0026gt; { for (int i = 0; i \u0026lt; 30; i++) { if (!ctsCombine.IsCancellationRequested) { Thread.Sleep(500); Console.WriteLine(\u0026#34;任务t1,共执行30次,当前第{0}次\u0026#34;, i + 1); } } }, ctsCombine.Token); Task t2 = Task.Run(() =\u0026gt; { for (int i = 0; i \u0026lt; 30; i++) { if (!ctsCombine.IsCancellationRequested) { Thread.Sleep(500); Console.WriteLine(\u0026#34;任务t2,共执行30次,当前第{0}次\u0026#34;, i + 1); } } }, ctsCombine.Token); Thread.Sleep(2000); cts1.Cancel(); Console.WriteLine($\u0026#34;t1:Status_{t1.Status},t2:Status_{t2.Status}\u0026#34;); Assert.IsTrue(true); }定时取消# static void Main(string[] args) { CancellationTokenSource cts = new CancellationTokenSource(); cts.CancelAfter(8000); Task t1 = Task.Run(() =\u0026gt; { for (int i = 0; i \u0026lt; 30; i++) { if (cts.Token.IsCancellationRequested) { cts.Token.ThrowIfCancellationRequested(); } else { Thread.Sleep(500); Console.WriteLine(\u0026#34;任务t1,共执行30次,当前第{0}次\u0026#34;, i); } } }, cts.Token); try { t1.Wait(); } catch (AggregateException e) { foreach (var item in e.InnerExceptions) { Console.WriteLine(item); } } Console.ReadKey(); }工作原理 程序运行主线程创建-\u0026gt;创建CancellationTokenSource对象-\u0026gt;设置task在指定毫秒数后取消(这里是 8000)-\u0026gt;创建task并传入CancellationTokenSource对象生成的token，循环打印 1~30，取消标记为true则抛出异常中止任务，false则正常输出。在输出前等待 500 毫秒(避免 8000 毫秒还没到任务就已经执行完成)-\u0026gt;使用try/catch包裹t1.Wait()等待任务执行完成语句，并捕获处理异常。这里任务在执行完 15 次的时候被取消\n取消时回调# CancellationTokenSource.Token.Register()，使用Register，向取消标记登记一个回调方法。应用程序调用CancellationTokenSource 对象的 Cancel 方法时，这个回调就会运行。但是不能保证这个方法在什么时候执行,可能在任务执行完自己的取消处理之前或之后,也可能在那个过程之中\n[TestMethod] public void Task_CancellationToken_Register_Example() { CancellationTokenSource cts = new CancellationTokenSource(); var token = cts.Token; cts.CancelAfter(8000); token.Register(Callback); Task t1 = Task.Run(() =\u0026gt; { for (int i = 0; i \u0026lt; 30; i++) { if (token.IsCancellationRequested) { token.ThrowIfCancellationRequested(); } else { Thread.Sleep(500); Console.WriteLine(\u0026#34;任务t1,共执行30次,当前第{0}次\u0026#34;, i); } } }, token); try { t1.Wait(); } catch (AggregateException e) { foreach (var item in e.InnerExceptions) { Console.WriteLine(item); } } static void Callback() { Console.WriteLine(\u0026#34;Register登记的任务取消回调函数\u0026#34;); } Assert.IsTrue(true); }问题记录# async/await并不能提升性能?# 问题描述：所谓的异步操作就是A线程在执行任务的时候，执行到一半再把任务交给B线程，然后A线程开始等待B的执行完成了，这不还是同步的吗?\n异步编程不能提高性能。异步编程只是提供一种简单的编程模型来提高系统的响应能力，比如，如果在UI线程上执行长时间IO操作，在操作完成之前界面就处在无法操作的状态。 可以提高性能的是并行技术，比如任务并行库（TPL，Task Parallel Library）、并行LINQ（PLINQ）等，这些技术可以充分利用CPU来提高计算性能。一般来说，耗时的IO操作使用异步简化代码，耗时的计算操作使用并行来提高性能\n比如服务端最大处理请求是100个线程，那么同步模式下，150个请求过来，就有50个请求需要等待执行。async/await 模式下，正在执行的100个线程 可以空闲出来 处理后来的50个请求，前面100个请求异步完成后，再通过上下文切换到当前的100个线程，处理完后续的流程。工作线程是在不停的切换过程中提升了并发效率。而在单个请求中，async/await是有线程上下文切换的性能损耗，所以在处理一个本来就很快速的逻辑,例如读一个Redis缓存，那么性能会有比较显著的下降\n总结：异步编程只是提高了线程的利用率，针对一个本来就很“快”的操作，可能异步还不如同步。因为线程上下文的切换也会带来性能损耗\nasync/await死锁问题# 可能发生死锁的程序类型# WPF/WinForm程序 asp.net(不包括asp.net core)程序 什么情况下会产生死锁?# 调用 Task.Wait() 或者 Task.Result 立刻产生死锁的充分条件\n调用 Wait()或Result的代码位于UI线程 Task的实际执行在其他线程，且需要返回UI线程 死锁的原因?# UWP、WPF、Windows Forms程序的 UI 线程都是单线程的。为了让使用了async/await的代码像使用同步代码一样简单，WPF 程序的Application类在构造的时候会将主UI线程 Task的同步上下文设置为DispatcherSynchronizationContext的实例，当Task的任务结束时，会从AsyncMethodStateMachine中调用Awaiter的OnComplete()方法，而await后续方法的执行靠的就是OnComplete()方法中一层层调用到 DispatcherSynchronizationContext里的Post方法\n/// \u0026lt;summary\u0026gt; /// Asynchronously invoke the callback in the SynchronizationContext. /// \u0026lt;/summary\u0026gt; public override void Post(SendOrPostCallback d, Object state) { // Call BeginInvoke with the cached priority. Note that BeginInvoke // preserves the behavior of passing exceptions to // Dispatcher.UnhandledException unlike InvokeAsync. This is // desireable because there is no way to await the call to Post, so // exceptions are hard to observe. _dispatcher.BeginInvoke(_priority, d, state); }这里就是问题的关键！！！\n如果_dispatcher.BeginInvoke(_priority, d, state);这句代码在后台线程。那么此时UI线程处于Wait()/Result调用中的阻塞状态，BeginInvoke中的任务是无论如何也无法执行到的，于是无论如何都无法完成这个Post任务，即无论如何也无法退出此异步任务的执行，于是Wait()便无法完成等待，产生死锁\nExample\nDoAsync().Wait(); async Task DoAsync() { await Task.Run(() =\u0026gt; { }); }无论是WPF还是UWP，只要在UI线程上调用上述代码，必然死锁\nThere Is No Thread# 读写文件，访问网络，这些 IO 阻塞的操作执行时，里面根本就没有线程。详情请阅读：There Is No Thread\n还有另一些操作，也没有后台线程的参与，于是也不存在从后台线程回到主线程导致死锁的情况。如Task.Yield，还有InvokeAsync，它们也不会造成死锁。如果是控制台程序，或者一个普通的非UI线程，其SynchronizationContext为null，那么异步任务执行完后不需要回到原有线程，也不会造成死锁\n不会造成死锁的充分条件# 异步操作执行完后不需要回到原有线程（例如非 UI 线程和控制台线程） 异步操作不需要单独的线程执行任务 如何避免死锁# 在 UI 线程，如果使用了async/await，就尽量不要再使用Task.Wait()/Task.Result了，就一直异步一条路走到黑好了（微软称其为Async All the Way） 如果可能，尽量在异步任务后添加.ConfigureAwait(false);这样，异步任务后面继续执行的代码就不会回到原UI线程了，而是直接从线程池中再取出一个线程执行；这样，即便UI线程后续可能有别的原因造成阻塞，也不会产生死锁了；把原来的代码改成这样，就不会死锁了 只能是一路 async/await。微软将其描述为：async/await 会像病毒一样在你的代码中传播。\nOthers have also noticed the spreading behavior of asynchronous programming and have called it “contagious” or compared it to a zombie virus.\n这句话的原文参见：Async/Await - Best Practices in Asynchronous Programming\n如果你是类库提供者，因为不确定调用者程序是WPF/Winform..，为了防止代码调用者在同步方法中使用Wait()/Result调用异步方法，还需要考虑添加.ConfigureAwait(false);\nasync Task DoAsync() { await Task.Run(() =\u0026gt; { }).ConfigureAwait(false); }这一句的目的是防止执行上下文切换回 UI 线程。\n这样，即便真的使用 DoAsync().Wait() 也不会发生死锁。注意，整个方法调用链都需要使用 .ConfigureAwait(false) 才能够防止线程切换，在调用方的 Wait() 方法中发生死锁。\n更多死锁相关# https://blog.walterlv.com/post/deadlock-in-task-wait.html https://blog.walterlv.com/post/deadlock-of-invoke-in-lazy.html https://blog.walterlv.com/post/deadlock-if-await-in-ui-lock-context.html https://blog.walterlv.com/post/task-wait-may-cause-long-time-waiting.html 解决方法\nhttps://blog.walterlv.com/post/using-configure-await-to-avoid-deadlocks.html https://blog.walterlv.com/post/convert-async-to-sync-by-push-frame.html 参考\nhttps://blog.csdn.net/WPwalter/article/details/78370706 https://docs.microsoft.com/en-us/archive/msdn-magazine/2013/march/async-await-best-practices-in-asynchronous-programming https://www.cnblogs.com/qingfenglin/p/12058267.html https://www.cnblogs.com/liqingwen/p/5844095.html https://www.cnblogs.com/zhaoshujie/p/11082753.html https://q.cnblogs.com/q/107005/ https://rubikscode.net/2018/06/11/asynchronous-programming-in-net-benefits-and-tradeoffs-of-using-valuetask/ https://blog.scooletz.com/2018/05/14/task-async-await-valuetask-ivaluetasksource-and-how-to-keep-your-sanity-in-modern-net-world/ https://www.cnblogs.com/ms27946/p/understanding-task-valuetask.html https://www.cnblogs.com/ittranslator/p/13703279.html https://devblogs.microsoft.com/dotnet/understanding-the-whys-whats-and-whens-of-valuetask/ https://www.cnblogs.com/wcrBlog/p/11690460.html https://docs.microsoft.com/zh-cn/dotnet/csharp/programming-guide/concepts/async/async-return-types#generalized-async-return-types-and-valuetasktresult https://q.cnblogs.com/q/124633/ https://www.cnblogs.com/dudu/p/9860959.html#!comments http://labs.criteo.com/2018/10/net-threadpool-starvation-and-how-queuing-makes-it-worse/ https://www.cnblogs.com/xishuai/p/asp-net-sync-over-async.html "},{"id":33,"href":"/docs/dotnet/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"数据结构","section":"所有文章","content":"C数组# 数组是一种特殊类型的数据类型，它可以使用特殊语法 顺序存储固定数量的值。\n数组声明：\nint [] intArr;数组初始化：使用new关键字同时声明和初始化数组，下面三种方式等价\nint[] intArr = new int[5]; int[] intArr = new int[5]{1， 2， 3， 4， 5}; int[] intArr = {1， 2， 3， 4， 5};延迟初始化：可以先声明后再初始化数组\nstring[] strArr， strArr; strArr = new string[5]{ \u0026#34;1st Element\u0026#34;，\u0026#34;2nd Element\u0026#34;， \u0026#34;3rd Element\u0026#34;}; strArr = new string[]{ \u0026#34;1st Element\u0026#34;，\u0026#34;2nd Element\u0026#34;， \u0026#34;3rd Element\u0026#34;};索引访问数组中元素：\nintArr[索引位置];常用方法和属性：\n方法名称 描述 GetLength(int维度) 返回指定维度中的元素数 GetLowerBound(int维度) 返回指定维度的最低索引 GetUpperBound(int维度) 返回指定维度的最高索引 GetValue(int index) 返回指定索引处的值 属性 描述 Length 返回数组中元素的总数 [TestMethod] public void ArrayDefinition() { // 数组可以先声明后赋值,也可以声明同时赋值,下面的方式是等价的,数组中必须存储同一类型数据,这在数组被定义时就已经确定 // 第一种 int[] intArr = new int[5]; intArr[0] = 1; intArr[1] = 2; intArr[2] = 3; intArr[3] = 4; intArr[4] = 5; // 第二种 int[] intArr2 = new int[5] { 1, 2, 3, 4, 5 }; // 第三种 int[] intArr3 = { 1, 2, 3, 4, 5 }; // 注意这里是维度不是索引 Console.WriteLine(\u0026#34;GetLength(int维度):返回指定维度中的元素数,值为：{0}\u0026#34;, intArr.GetLength(0)); Console.WriteLine(\u0026#34;GetLowerBound(int维度):返回指定维度的最低索引,值为：{0}\u0026#34;, intArr.GetLowerBound(0)); Console.WriteLine(\u0026#34;GetUpperBound(int维度):返回指定维度的最高索引,值为：{0}\u0026#34;, intArr.GetUpperBound(0)); Console.WriteLine(\u0026#34;GetValue(int index):\t返回指定索引处的值,值为：{0}\u0026#34;, intArr.GetValue(2)); Console.WriteLine(\u0026#34;属性:Length:返回数组中元素的总数,值为：{0}\u0026#34;, intArr.Length); // 使用索引来访问数组元素 Console.WriteLine(\u0026#34;使用索引访问数组元素,索引为2的值为：{0}\u0026#34;, intArr[2]); // 试图访问数组中不存在的索引元素,会发生数组越界 Assert.ThrowsException\u0026lt;IndexOutOfRangeException\u0026gt;(() =\u0026gt; { Console.WriteLine(\u0026#34;使用索引访问数组元素,索引为10的值为：{0}\u0026#34;, intArr[10]); }); for (int i = 0; i \u0026lt; intArr.Length; i++) { Console.WriteLine(intArr[i]); } foreach (var item in intArr) { Console.WriteLine(item); } Person p1 = new() { Address = \u0026#34;wang\u0026#34; }; Person p2 = new() { Address = \u0026#34;li\u0026#34; }; Person[] persons = new Person[2] { p1, p2 }; Assert.AreEqual(\u0026#34;wang\u0026#34;, persons[0].Address); Assert.AreEqual(\u0026#34;li\u0026#34;, persons[1].Address); }多维数组# 多维数组是行和列的二维系列。多维数组又称为矩形数组；在本质上，是个一维数组的列表。\n[TestMethod] public void MultidimensionalArray() { // 下面的两种创建方式等价 // 第一种 int[,] intArray1 = { { 1, 1 }, { 1, 2 }, { 1, 3 } }; //第二种 int[,] intArray2 = new int[3, 4] { /* 初始化化一个三行四列的数组 */ {0, 1, 2, 3} , /* 初始化索引号为 0 的行 */ {4, 5, 6, 7} , /* 初始化索引号为 1 的行 */ {8, 9, 10, 11} /* 初始化索引号为 2 的行 */ }; // 获取数组中第3行第4个元素 Console.WriteLine(\u0026#34;二维数组中的元素是通过使用下标（即数组的行索引和列索引）来访问,值为：{0}\u0026#34;, intArray2[2, 3]); Console.WriteLine(\u0026#34;属性:Length:返回数组中元素的总数,值为：{0}\u0026#34;, intArray1.Length); Assert.AreEqual(11, intArray2[2, 3]); }可以使用两个索引访问多维数组的值。第一个索引用于行，第二个索引用于列。两个索引都从零开始。\n锯齿状数组# 锯齿状数组是数组的数组。Jagged数组直接存储数组而不是任何其他数据类型值。锯齿状数组用两个方括号 [][] 初始化。\n第一个括号指定数组的大小，第二个括号指定将作为值存储的数组的维度。(锯齿状数组总是存储一个数组)，二维数组的大小是矩形的。\n例如： 3×3个元素。而锯齿数组的大小设置是比较灵活的，在锯齿数组中，每一行都可以有不同的大小\n[TestMethod] public void JaggedArray() { int[][] intJaggedArray = new int[2][]; intJaggedArray[0] = new int[3] { 1, 2, 3 }; intJaggedArray[1] = new int[2] { 4, 5 }; Assert.AreEqual(1, intJaggedArray[0][0]); Assert.AreEqual(3, intJaggedArray[0][2]); Assert.AreEqual(5, intJaggedArray[1][1]); }Array# .NET提供了一个抽象类 Array ，作为所有数组的基类。它提供了用于创建，操作，搜索和排序数组的静态方法。\n属性 描述 IsFixedSize 获取一个值，该值指示数组是否带有固定大小 IsReadOnly 获取一个值，该值指示数组是否只读 Length 获取一个 32 位整数，该值表示所有维度的数组中的元素总数 LongLength 获取一个 64 位整数，该值表示所有维度的数组中的元素总数 Rank 获取数组的秩（维度） 方法 描述 Clear 根据元素的类型，设置数组中某个范围的元素为零、为 false 或者为 null Copy(Array,Array,Int32) 从数组的第一个元素开始复制某个范围的元素到另一个数组的第一个元素位置。长度由一个 32 位整数指定 CopyTo(Array,Int32) 从当前的一维数组中复制所有的元素到一个指定的一维数组的指定索引位置。索引由一个 32 位整数指定 GetLength 获取一个 32 位整数，该值表示指定维度的数组中的元素总数 GetLongLength 获取一个 64 位整数，该值表示指定维度的数组中的元素总数 GetLowerBound 获取数组中指定维度的下界 GetType 获取当前实例的类型。从对象（Object）继承 GetUpperBound 获取数组中指定维度的上界 GetValue(Int32) 获取一维数组中指定位置的值。索引由一个 32 位整数指定 IndexOf(Array,Object) 搜索指定的对象，返回整个一维数组中第一次出现的索引 Reverse(Array) 逆转整个一维数组中元素的顺序 SetValue(Object, Int32) 给一维数组中指定位置的元素设置值。索引由一个 32 位整数指定 Sort(Array) 使用数组的每个元素的 IComparable 实现来排序整个一维数组中的元素 ToString 返回一个表示当前对象的字符串。从对象（Object）继承 [TestMethod] public void ArrayClass() { Array arr = Array.CreateInstance(typeof(int), 3); for (int i = 0; i \u0026lt; 3; i++) { // 第一个参数是value,第二个参数是index arr.SetValue(i, i); } Console.WriteLine(\u0026#34;IsFixedSize:数组是否带有固定大小,值为：{0}\u0026#34;, arr.IsFixedSize); Console.WriteLine(\u0026#34;IsReadOnly :数组是否只读,值为：{0}\u0026#34;, arr.IsReadOnly); Console.WriteLine(\u0026#34;Length :32位整数,数组元素总数,值为：{0}\u0026#34;, arr.Length); Console.WriteLine(\u0026#34;LongLength :64位整数,数组元素总数,值为：{0}\u0026#34;, arr.LongLength); Console.WriteLine(\u0026#34;Rank :数组的维度,值为：{0}\u0026#34;, arr.Rank); Array.Clear(arr, 0, 3); for (int i = 0; i \u0026lt; arr.Length; i++) { Assert.AreEqual(0, arr.GetValue(i)); } // 显式将arr转换为数组 int[] arr2 = (int[])arr; for (int i = 0; i \u0026lt; arr2.Length; i++) { Assert.AreEqual(0, arr2[i]); } }非泛型集合# 每个集合类都实现 IEnumerable接口，因此可以使用 foreach 循环访问集合中的值。System.Collections 命名空间中包括以下非泛型集合：\n类型 用法 ArrayList ArrayList存储任何类型的对象，如数组。但是，当数组自动增长时，无需像数组那样指定ArrayList的大小 SortedList SortedList存储键和值对。它默认按键的升序自动排列元素。C＃包括泛型和非泛型SortedList集合 Stack Stack以LIFO样式存储值(后进先出)。它提供了一个Push()方法来添加一个值，Pop()和Peek()方法来检索值。C＃包括通用和非通用堆栈 Queue 队列以FIFO样式(先进先出)存储值。它保持添加值的顺序。它提供了一个Enqueue()方法来添加值，还提供了一个Dequeue()方法来从集合中检索值。C＃包括通用和非通用队列 Hashtable Hashtable存储键和值对。它通过比较键的哈希值来检索值 BitArray BitArray管理一个紧凑的位值数组，表示为布尔值，其中true表示该位为on(1)，false表示该位为off(0) ArrayList# 可以包含任何数据类型的元素。类似于数组，但是在添加元素时不需要指定大小， ArrayList 的大小会自动增长。\n要点：\n可以存储任何数据类型的项(元素) 添加元素时会自动调整大小 可以包含多个null 可以使用 foreach 或 for 循环或索引器访问 属性 描述 Capacity 获取或设置ArrayList可以包含的元素数 Count 获取ArrayList中实际包含的元素数 IsFixedSize 获取一个值，该值指示ArrayList是否具有固定大小 IsReadOnly 获取一个值，该值指示ArrayList是否为只读 Item 获取或设置指定索引处的元素 方法 描述 Add()/AddRange() Add()方法在ArrayList的末尾添加单个元素。 AddRange()方法将指定集合中的所有元素添加到ArrayList中 Insert()/InsertRange() Insert()方法在ArrayList中的指定索引处插入单个元素。 InsertRange()方法从ArrayList中的指定索引开始插入指定collection的所有元素 Remove()/RemoveRange() Remove()方法从ArrayList中删除指定的元素。 RemoveRange()方法从ArrayList中删除一系列元素 RemoveAt() 从ArrayList中删除指定索引处的元素 Sort() 对ArrayList的整个元素进行排序 Reverse() 反转整个ArrayList中元素的顺序 Contains 检查ArrayList中是否存在指定的元素。如果存在则返回true，否则返回false Clear 删除ArrayList中的所有元素 CopyTo 将所有元素或元素范围复制到compitible Array GetRange 从ArrayList返回指定索引中指定数量的元素 IndexOf 搜索指定的元素并返回零基索引(如果找到)。如果找不到元素，则返回-1 ToArray 从ArrayList返回compitible数组 [TestMethod] public void ArrayList() { ArrayList arrayList = new(); arrayList.Add(\u0026#34;wang\u0026#34;); arrayList.Add(1); // ArrayList允许插入null arrayList.Add(null); foreach (var item in arrayList) { Console.WriteLine(item); } Assert.AreEqual(\u0026#34;wang\u0026#34;, arrayList[0]); }SortedList# SortedList 集合默认按键的升序存储键值对。SortedList 类实现了 IDictionary 和 ICollection 接口，因此可以通过键和索引访问元素。\n要点：\nC#具有泛型和非泛型 SortedList SortedList 按键的升序存储键值对。键必须是唯一的，不能为null，而值可以为null或重复项 非泛型 SortedList 存储任何数据类型的键和值。因此，需要将值转换为适当的数据类型 键值对可以强制转换为 DictionaryEntry 使用索引器访问单个值。SortedList 索引器接受键并返回与之关联的值 属性 描述 Capacity 获取或设置SortedList实例可以存储的元素数 Count 获取SortedList中实际包含的元素数 IsFixedSize 获取SortedList中实际包含的元素数 IsReadOnly 获取一个值，该值指示SortedList是否为只读 Item 获取或设置SortedList中指定键的元素 Keys 获取SortedList的键列表 Values 获取SortedList中的值列表 方法 描述 Add(object key， object value) 将键值对添加到SortedList中 Remove(object key) 删除具有指定键的元素 RemoveAt(int index) 删除指定索引处的元素 Contains(object key) 检查SortedList中是否存在指定的键 Clear() 从SortedList中删除所有元素 GetByIndex(int index) 返回存储在内部数组中的索引值 GetKey(int index) 检返回存储在内部数组中指定索引处的键 IndexOfKey(object key) 返回存储在内部数组中的指定键的索引 IndexOfValue(object value) 返回存储在内部数组中的指定值的索引 [TestMethod] public void SortedList() { SortedList sortedList = new(); sortedList.Add(2, \u0026#34;wang\u0026#34;); sortedList.Add(5, \u0026#34;li\u0026#34;); sortedList.Add(3, 5); // SortedList键可以是任何数据类型，但不能在同一SortedList中添加不同数据类型的键。 Assert.ThrowsException\u0026lt;InvalidOperationException\u0026gt;(() =\u0026gt; { sortedList.Add(\u0026#34;wang\u0026#34;, 32); }); for (int i = 0; i \u0026lt; sortedList.Count; i++) { Console.WriteLine(\u0026#34;key:{0}，value:{1}\u0026#34;, sortedList.GetKey(i), sortedList.GetByIndex(i)); } foreach (DictionaryEntry item in sortedList) { Console.WriteLine(\u0026#34;key:{0}，value:{1}\u0026#34;, item.Key, item.Value); } }Stack# 以 LIFO 样式存储元素（后进先出）。C#包括通用和非通用堆栈，非泛型堆栈。Stack允许空值以及重复值。它提供了一个 Push() 方法来添加一个值， Pop() 或 Peek() 方法来检索值。\n要点：\n最后添加的元素将是首先出现的元素LIFO(后进先出) 使用 Push() 方法添加元素 Pop() 方法返回并从堆栈顶部删除元素。在空 Stack 上调用 Pop() 方法将引发异常 Peek() 方法返回 Stack 中最顶层的元素 属性 方法 Count 返回Stack中元素的总数 方法 描述 Push 在堆栈顶部插入一个项目 Peek 返回堆栈中的顶部项 Pop 从堆栈顶部删除并返回项目 Contains 检查堆栈中是否存在项目 Clear 从堆栈中删除所有项目 [TestMethod] public void Stack() { Stack stack = new(); stack.Push(\u0026#34;1\u0026#34;); stack.Push(1); stack.Push(false); foreach (var item in stack) { Console.WriteLine(item); } }Queue# 以FIFO样式(先进先出)存储元素。与Stack集合完全相反，它按照添加顺序包含元素。队列集合允许多个空值和重复值。使用 Enqueue() 方法添加值，使用Dequeue()方法从队列中检索值。\n要点：\n首先添加的元素将首先出现FIFO(先进先出) 使用Enqueue()方法添加元素 Dequeue()方法返回并从队列的开头删除元素。在空队列上调用Dequeue()方法将引发异常 Peek()方法总是返回最顶层的元素 属性 描述 Count 返回Stack中元素的总数 方法 描述 Enqueue 将项添加到队列中 Dequeue 从队列的开头删除并返回一个项目 Peek 返回队列中的第一个项目 Contains 检查项目是否在队列中 Clear 从队列中删除所有项目 TrimToSize 将队列的容量设置为队列中的实际项目数 [TestMethod] public void Queue() { Queue queue = new(); queue.Enqueue(\u0026#34;1\u0026#34;); queue.Enqueue(1); queue.Enqueue(false); foreach (var item in queue) { Console.WriteLine(item); } }Hashtable# 类似于通用字典集合。Hashtable集合存储键值对。通过计算每个密钥的哈希码来优化查找，并在内部将其存储在不同的存储桶中，然后在访问值时匹配指定密钥的哈希码。\n要点：\n存储Key必须唯一的任何数据类型的键值对 键不能为null，而值可以为null 通过比较键的哈希码来检索项目。因此性能比 Dictionary 集合慢 使用默认的哈希码提供程序，即 object.GetHash()。还可以使用自定义哈希码提供程序 将 DictionaryEntry 与 foreach 语句一起使用以迭代 Hashtable 属性 描述 Count 获取Hashtable中键/值对的总数 IsReadOnly 获取布尔值，指示Hashtable是否为只读 Item 获取或设置与指定键关联的值 Keys 获取Hashtable中的键的ICollection Values 获取Hashtable中值的ICollection 方法 描述 Add 将具有键和值的项添加到哈希表中 Remove 从散列表中删除具有指定键的项 Clear 从哈希表中删除所有项目 Contains 检查哈希表是否包含特定密钥 ContainsKey 检查哈希表是否包含特定密钥 ContainsValue 检查哈希表是否包含特定值 GetHash 返回指定键的哈希码 [TestMethod] public void Hashtable() { Hashtable hashtable = new() { { 1, \u0026#34;wang\u0026#34; }, { 3, false }, { 2, \u0026#34;li\u0026#34; } }; foreach (DictionaryEntry item in hashtable) { Console.WriteLine(\u0026#34;key:{0}, value:{1}\u0026#34;, item.Key, item.Value); } }BitArray# BitArray 类管理一个紧凑型的位值数组，它使用布尔值来表示，其中true表示位是开启的(1)，false 表示位是关闭的(0)。当需要存储位但是事先不知道位数时，则使用点阵列。可以使用整型索引从点阵列集合中访问各项，索引从零开始。\n属性 描述 Count 获取 BitArray 中包含的元素个数。 IsReadOnly 获取一个值，表示 BitArray 是否只读。 Item 获取或设置 BitArray 中指定位置的位的值。 Length 获取或设置 BitArray 中的元素个数。 方法 描述 public BitArray And( BitArray value ); 对当前的 BitArray 中的元素和指定的 BitArray 中的相对应的元素执行按位与操作。 public bool Get( int index ); 获取 BitArray 中指定位置的位的值。 public BitArray Not(); 把当前的 BitArray 中的位值反转，以便设置为 true 的元素变为 false，设置为 false 的元素变为 true。 public BitArray Or( BitArray value ); 对当前的 BitArray 中的元素和指定的 BitArray 中的相对应的元素执行按位或操作。 public void Set( int index, bool value ); 把 BitArray 中指定位置的位设置为指定的值。 public void SetAll( bool value ); 把 BitArray 中的所有位设置为指定的值。 public BitArray Xor( BitArray value ); 对当前的 BitArray 中的元素和指定的 BitArray 中的相对应的元素执行按位异或操作。 泛型集合# 同传统的集合相比，泛型集合是一种强类型的集合，它解决了类型安全问题，同时避免了集合中每次的装箱与拆箱的操作，提升了性能。\nList\u0026lt;T\u0026gt;# List\u0026lt;T\u0026gt; 在C#应用程序中是一种快捷、易于使用的泛型集合类型，使用泛型编程为编写面向对象程序增加了极大的效率和灵活性，不会强行对值类型进行装箱和拆箱，或对引用类型进行向下强制类型转换。\n名称 描述 Add 将对象添加到 List的结尾处 AddRange 将指定集合的元素添加到 List的末尾 AsReadOnly 返回当前集合的只读 IList包装 BinarySearch(T) 使用默认的比较器在整个已排序的 List中搜索元素，并返回该元素从零开始的索引 BinarySearch(T, IComparer) 使用指定的比较器在整个已排序的 List中搜索元素，并返回该元素从零开始的索引 BinarySearch(Int32, Int32, T, IComparer) 使用指定的比较器在已排序 List的某个元素范围中搜索元素，并返回该元素从零开始的索引 Clear 从 List中移除所有元素 Contains 确定某元素是否在 List中 ConvertAll 将当前 List\u0026lt;T中的元素转换为另一种类型，并返回包含转换后的元素的列表 CopyTo(T[]) 将整个 List\u0026lt;T复制到兼容的一维数组中，从目标数组的开头开始放置 Exists 确定 List\u0026lt;T是否包含与指定谓词所定义的条件相匹配的元素 Find 搜索与指定谓词所定义的条件相匹配的元素，并返回整个 List中的第一个匹配 元素 FindIndex(Predicate) 搜索与指定谓词所定义的条件相匹配的元素，并返回整个List 中第一个匹配元素的从零开始的索引 ForEach 对 List的每个元素执行指定操作。 GetEnumerator 返回循环访问 List的枚举器 IndexOf(T) 搜索指定的对象，并返回整个 List中第一个匹配项的从零开始的索引 Insert 将元素插入 List的指定索引处 InsertRange 将集合中的某个元素插入 List的指定索引处 LastIndexOf(T) 搜索指定的对象，并返回整个 List中最后一个匹配项的从零开始的索引 Remove 从 List中移除特定对象的第一个匹配项 Reverse() 将整个 List中元素的顺序反转 Sort() 使用默认比较器对整个 List中的元素进行排序 Stack\u0026lt;T\u0026gt;# 以 后进先出 的方式维护数据的集合，包含 pop() 和 push() 从栈内压入或移除数据。\nQuenue\u0026lt;T\u0026gt;# 以 先进先出 的方式访问数据，使用 Enqueue() 和 Dequeue()添加数据和移除数据。\nSortedSet\u0026lt;T\u0026gt;# 这个类中的数据是排序的，在插入和移除数据之后仍然能自动排序，需要向其构造函数中传递一个实现了IComparer\u0026lt;T\u0026gt;，该接口定义了Compare方法。\nObservableCollection\u0026lt;T\u0026gt;# 表示能在添加、移除或者刷新整个列表时提供通知的动态数据集合， ReadOnlyObservableCollection\u0026lt;T\u0026gt; 的操作与之类似，不过是只读的ObservableCollection\u0026lt;T\u0026gt; 实现了一个名为CollectionChanged事件，该事件在插入新的数据或者移除数据时触发。\nDictionary\u0026lt;k,v\u0026gt;# 提供快速的基于键值的元素查找。结构是：Dictionary \u0026lt;[key],[value]\u0026gt;，当有很多元素的时候可以用它。在使用前，必须声明它的键类型和值类型。\n数组池# 如果需要多次创建/销毁数组,为了减少GC操作,可以通过ArrayPool类使用数组池\n[TestMethod] public void ArrayPool() { // maxArrayLengthDefaultValue: 1024 * 1024 // maxArraysPerBucketDefaultValue: 50 ArrayPool\u0026lt;int\u0026gt; arrayPool = ArrayPool\u0026lt;int\u0026gt; .Create(maxArrayLength: 4000, maxArraysPerBucket: 10); // 使用预定义的共享池 ArrayPool\u0026lt;int\u0026gt; sharePool = ArrayPool\u0026lt;int\u0026gt;.Shared; Console.WriteLine($\u0026#34;{arrayPool},{sharePool}\u0026#34;); Assert.IsTrue(sharePool != null); }数组/ArrayList/List区别# 数组：针对特定类型固定长度，值不可为null，在声明数组的时候必须指定数组的长度，可有多个维度 Array：数组的另一种创建方式抽象类，作为所有数组的基类，针对任意类型固定长度，值可以为null，输出会被替换为0 ArrayList：针对任意类型、任意长度的，值可以为null，存储或检索值类型时通常发生装箱和拆箱操作，带来很大的性能耗损 List：强类型的集合，固定类型、任意长度，值不可为null，是类型安全的 枚举器# 迭代器# 索引器# Indexer 是一种特殊类型的属性，允许以访问数组相同的方式访问类或结构。除了使用带有方括号和参数的此关键字定义的属性外，它与属性相同。\n索引器与属性相同，除了它使用带有方括号的此关键字定义，该参数具有参数 可以通过具有不同类型的参数来覆盖索引器 不支持使用索引器的Ref和out参数 索引器可以作为接口成员包含在内 public \u0026lt;return typethis[\u0026lt;parameter typeindex] { Get{ // return the value from the specified index } Set{ // set values at the specified index } }public class Indexer { private int[] indexs = new int[10]; public int this[int index] { get { return indexs[index]; } set { indexs[index] = value; } } } /* Indexer是一种特殊类型的属性，允许以与其内部集合的数组相同的方式访问类或结构。 除了使用带有方括号和参数的此关键字定义的属性外，它与属性相同。 */ Console.WriteLine(\u0026#34;********************索引器*********************\u0026#34;); Indexer indexer = new Indexer(); indexer[0] = 1; indexer[1] = 2; Console.WriteLine(indexer[1]);可观察的集合# 如果需要知道集合中的元素何时删除或添加的信息，就可以使用 ObservableCollection\u0026lt;T\u0026gt; 类。.Net Core中要使用，需要引用Nuget包System.ObjectModel。这个类的名称空间是System.Collections.ObjectModel。\nObservableCollection\u0026lt;T\u0026gt; 类派生自 Collection\u0026lt;T\u0026gt; 基类。该基类用于创建自定义集合。并在内部使用List类。重写基类中的虚方法SetItem()和RemoveItem(),以触发 CollectionChanged 事件。这个类的用户就可以使用 INotifyCollectionChanged 接口注册这个事件。\n/// \u0026lt;summary\u0026gt; /// 可观察的集合 /// \u0026lt;/summary\u0026gt; [TestMethod] public void ObservableArray() { var arr = new ObservableCollection\u0026lt;string\u0026gt;(); arr.CollectionChanged += (object sender, NotifyCollectionChangedEventArgs e) =\u0026gt; { if (e.OldItems != null) { Console.WriteLine($\u0026#34;index:{e.OldStartingIndex}\u0026#34;); Console.WriteLine(\u0026#34;old items:\u0026#34;); foreach (var item in e.OldItems) { Console.WriteLine(item); } } if (e.NewItems != null) { Console.WriteLine($\u0026#34;index:{e.NewStartingIndex}\u0026#34;); Console.WriteLine(\u0026#34;new items:\u0026#34;); foreach (var item in e.NewItems) { Console.WriteLine(item); } } }; arr.Add(\u0026#34;One\u0026#34;); arr.Add(\u0026#34;Two\u0026#34;); arr.Insert(1, \u0026#34;Three\u0026#34;); arr.Remove(\u0026#34;One\u0026#34;); }不可变集合# 如果对象可以改变其状态，就很难在多个同时运行的任务中使用。这些集合必须同步。\n如果对象不能改变其状态，就很容易在多个线程中使用。不能改变的对象称为不变的对象。\n不能改变的集合称为不变的集合。\n为了使用不可变的集合。可以添加Nuget包 System.Collections.Immutable。命名空间 System.Collections.Immutable 中的集合类。\n在使用不变数组的每个阶段，都没有复制完整的集合。相反，不变类型使用了共享状态，仅在需要时复制集合。\n注意：先填充集合，再将它变成不变的数组会更高效。\npublic void ImmutableArray() { // 先正常创建个集合 var accounts = new List\u0026lt;string\u0026gt;() { \u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34; }; // 使用ToImmutableList扩展方法创建一个不变的集合。 // 也可以像其他集合那样枚举，只是不能改变。 ImmutableList\u0026lt;string\u0026gt; immutableList = accounts.ToImmutableList(); foreach (var item in immutableList) { Console.WriteLine(item); } }"},{"id":34,"href":"/docs/dotnet/%E6%B3%9B%E5%9E%8B%E6%8A%80%E6%9C%AF/","title":"泛型技术","section":"所有文章","content":".Net 从2.0版开始支持泛型。泛型允许在编译时实现类型安全。允许创建一个数据结构而不限于特定的数据类型。当使用该数据结构时，编译器保证它使用的类型与类型安全是相一致的。泛型提供了类型安全，但是没有造成任何性能损失和代码臃肿。泛型不仅限于类，还可用于接口、方法、委托\u0026hellip;。\n为什么使用泛型# 泛型主要具有以下优势：\n类型安全 避免装箱拆箱带来的性能损耗 二进制代码重用 ArrayList arrs = new ArrayList { \u0026#34;wang\u0026#34;， 100 };问题一：这里如果将 item 设置为 int 类型遍历集合，会抛出异常，因为集合项中存在string 类型\nforeach (var item in arrs) { Console.WriteLine(item); }问题二：遍历时不可避免装箱/拆箱操作\nforeach (var item in arrs) { Console.WriteLine(item); }非泛型集合\nvar arr1 = new ArrayList(); arr1.Add(10);//Add方法参数值是object类型，这里将int-\u0026gt;object arr1.Add(\u0026#34;wang\u0026#34;);//Add方法参数值是object类型，这里将int-\u0026gt;object foreach (int item in arr1)//这里如果用int类型遍历集合，就挂掉了 { Console.WriteLine(item);//读取时要进行拆箱 }泛型集合\n/*泛型集合在使用时定义好类型，之后就不存在装箱拆箱; * 因为已经定义当前集合只能存入int类型，也就不能存入其他类型 * 编译时就会报错，错误应及早发现 */ var arr2 = new List\u0026lt;int\u0026gt;(); arr2.Add(10); foreach (var item in arr2) { Console.WriteLine(item); }通过参数化类型来实现在同一份代码上操作多种数据类型，利用“参数化类型”将类型抽象化，从而实现灵活的复用。每个集合的详细规范可以在 System.Collection.Generic 名称空间下找到。\n泛型工作机制# 泛型是延迟声明的：即定义的时候没有指定具体的参数类型，把参数类型的声明推迟到了调用的时候才指定参数类型。 延迟思想在程序架构设计的时候很受欢迎。例如：分布式缓存队列、EF的延迟加载等等。\n控制台程序最终会编译成一个exe程序，exe 被点击时，会经过JIT(即时编译器)的编译，最终生成二进制代码，才能被计算机执行。泛型加入到语法后，VS自带的编译器又做了升级，升级之后编译时遇到泛型，会做特殊的处理：生成占位符。再次经过JIT编译的时候，会把上面编译生成的占位符替换成具体的数据类型。\n泛型方法# public class Print { public void PrintType\u0026lt;T\u0026gt;() where T : new() { T t = new(); Console.WriteLine(t.GetType()); } }[TestMethod] public void GenericityMethod() { Print p = new(); p.PrintType\u0026lt;int\u0026gt;(); p.PrintType\u0026lt;double\u0026gt;(); }泛型类# public class MyArray\u0026lt;T\u0026gt; { public T t; }[TestMethod] public void GenericityClass() { MyArray\u0026lt;int\u0026gt; genericInt = new(); genericInt.t = 123; Console.WriteLine(genericInt.t); MyArray\u0026lt;string\u0026gt; genericStr = new(); genericStr.t = \u0026#34;123\u0026#34;; Console.WriteLine(genericStr.t); }default# default 用于将泛型类型初始化为 null 或 0 。\nT t = default(T);泛型接口# public interface IDAL\u0026lt;T\u0026gt; { void Add(T t); } public class ClassADAL\u0026lt;T\u0026gt; : IDAL\u0026lt;T\u0026gt; { public void Add(T t) { Console.WriteLine(t); } } public class ClassBDAL\u0026lt;T\u0026gt; : IDAL\u0026lt;T\u0026gt; { public void Add(T t) { Console.WriteLine(t); } }泛型委托# public delegate void SayHi\u0026lt;T\u0026gt;(T t);[TestMethod] public void GenericityDelegate() { SayHi\u0026lt;int\u0026gt; a = new((p) =\u0026gt; { Console.WriteLine(p); }); a.Invoke(123); SayHi\u0026lt;string\u0026gt; b = new((p) =\u0026gt; { Console.WriteLine(p); }); b.Invoke(\u0026#34;123\u0026#34;); }注意事项# 泛型在声明的时候可以不指定具体的类型，但是在使用时必须指定具体类型。\nPrint\u0026lt;int\u0026gt; iPrint = new Print\u0026lt;int\u0026gt;();这里的类型是int，如果存在继承并且子类也是泛型的，那么继承的时候可以不指定具体类型\nclass Print\u0026lt;T\u0026gt; { public T t; } //这里继承时没有指定泛型类型 class ConsolePrint\u0026lt;T\u0026gt; : Print\u0026lt;T\u0026gt; { }同上，类实现泛型接口也是如此。\n泛型约束# 所谓的泛型约束，就是约束类型 T ，使 T 必须遵循一定的规则。比如 T 必须继承自某个类，或者 T 必须实现某个接口等。\n类型 描述 T:calss 类型参数必须是引用类型，包括任何类、接口、委托或数组类型 T:stauct 类型参数必须是值类型。可以指定除 Nullable 以外的任何值类型 T:new() 类型参数必须具有无参数的公共构造函数。当与其他约束一起使用时，new() 约束必须最后指定 T:\u0026lt;基类名\u0026gt; 类型参数必须是指定的基类或派生自指定的基类 T:\u0026lt;接口名称\u0026gt; 类型参数必须是指定的接口或实现指定的接口。可以指定多个接口约束。约束接口也可以是泛型的 T1:T2 类型T1派生自泛型类型T2,该约束也被称为裸类型约束 class Person { public static void PintSayHello() { } } interface ISport { void Sport(); } /// \u0026lt;summary\u0026gt; /// 约束T必须是Person类型或者是Person的子类并且实现了ISport接口且T类型中必须有无参构造函数 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; class Show\u0026lt;T\u0026gt; where T : Person， ISport， new() { } /// \u0026lt;summary\u0026gt; /// 约束T必须是引用类型并且实现了ISport接口且T类型中必须有无参构造函数 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; class Show2\u0026lt;T\u0026gt; where T : class， ISport， new() { } /// \u0026lt;summary\u0026gt; /// 约束T必须是值类型并且实现了ISport接口 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; class Show3\u0026lt;T\u0026gt; where T : struct， ISport { } 注意：泛型约束可以同时约束多个，有多个泛型约束时，new() 约束一定是在最后。\n泛型协变与逆变# 协变和逆变在.NET 4.0的时候出现，只能放在接口或者委托的泛型参数前。\nout： 协变，用来修饰返回值 in：逆变，用来修饰传入参数 在C#中声明泛型接口时，可以使用 in 和 out 参数来控制这个泛型是协变还是逆变的（逆变有时也被翻译成抗变）协变和逆变是用来描述 如果泛型存在继承关系时，两个泛型类是否能够直接赋值的问题。比如派生泛型 IInterface\u0026lt;Child\u0026gt; 是否能被赋值给 IInterface\u0026lt;Parent\u0026gt;。\n协变：只能是方法参数# public interface ICustomerListIn\u0026lt;in T\u0026gt; { void Show(T t); } /// \u0026lt;summary\u0026gt; /// 泛型协变(子类到父类的转换) /// \u0026lt;/summary\u0026gt; /// \u0026lt;remarks\u0026gt; /// out：协变covariant，用来修饰返回值 /// \u0026lt;/remarks\u0026gt; [TestMethod] public void GenericityCovariant() { // 直接声明Animal类 Animal animal = new Animal(); Console.WriteLine($\u0026#34;{animal.GetType()}\u0026#34;); // 直接声明Cat类 Cat cat = new Cat(); Console.WriteLine($\u0026#34;{cat.GetType()}\u0026#34;); // 声明子类对象指向父类 Animal animal2 = new Cat(); Console.WriteLine($\u0026#34;{animal2.GetType()}\u0026#34;); // 声明Animal类的集合 List\u0026lt;Animal\u0026gt; listAnimal = new List\u0026lt;Animal\u0026gt;(); foreach (var item in listAnimal) { Console.WriteLine($\u0026#34;{item.GetType()}\u0026#34;); } // 声明Cat类的集合 List\u0026lt;Cat\u0026gt; listCat = new List\u0026lt;Cat\u0026gt;(); foreach (var item in listCat) { Console.WriteLine($\u0026#34;{item.GetType()}\u0026#34;); } #if debug // 一只Cat属于Animal，一群Cat也应该属于Animal。但实际上这样声明是错误的：因为List\u0026lt;Cat\u0026gt;和List\u0026lt;Animal\u0026gt;之间没有父子关系 List\u0026lt;Animal\u0026gt; list = new List\u0026lt;Cat\u0026gt;(); #endif // 泛型协变，IEnumerable泛型参数类型使用了out修饰 ICustomerListOut\u0026lt;Animal\u0026gt; customerList1 = new CustomerListOut\u0026lt;Animal\u0026gt;(); Console.WriteLine($\u0026#34;{customerList1.GetType()}\u0026#34;); ICustomerListOut\u0026lt;Animal\u0026gt; customerList2 = new CustomerListOut\u0026lt;Cat\u0026gt;(); Console.WriteLine($\u0026#34;{customerList2.GetType()}\u0026#34;); Assert.IsTrue(true); }逆变：只能是返回值# public interface ICustomerListIn\u0026lt;in T\u0026gt; { void Show(T t); }/// \u0026lt;summary\u0026gt; /// 泛型逆变(父类到子类的转换) /// \u0026lt;/summary\u0026gt; /// \u0026lt;remarks\u0026gt; /// int：协变contravariant，用来修饰返回值(子类到父类的转换) /// \u0026lt;/remarks\u0026gt; [TestMethod] public void GenericityContravariant() { // 直接声明Animal类 Animal animal = new Animal(); Console.WriteLine($\u0026#34;{animal.GetType()}\u0026#34;); // 直接声明Cat类 Cat cat = new Cat(); Console.WriteLine($\u0026#34;{cat.GetType()}\u0026#34;); // 声明子类对象指向父类 Animal animal2 = new Cat(); Console.WriteLine($\u0026#34;{animal2.GetType()}\u0026#34;); // 声明Animal类的集合 List\u0026lt;Animal\u0026gt; listAnimal = new List\u0026lt;Animal\u0026gt;(); foreach (var item in listAnimal) { Console.WriteLine($\u0026#34;{item.GetType()}\u0026#34;); } // 声明Cat类的集合 List\u0026lt;Cat\u0026gt; listCat = new List\u0026lt;Cat\u0026gt;(); foreach (var item in listCat) { Console.WriteLine($\u0026#34;{item.GetType()}\u0026#34;); } ICustomerListIn\u0026lt;Cat\u0026gt; customerListCat1 = new CustomerListIn\u0026lt;Cat\u0026gt;(); Console.WriteLine($\u0026#34;{customerListCat1.GetType()}\u0026#34;); ICustomerListIn\u0026lt;Cat\u0026gt; customerListCat2 = new CustomerListIn\u0026lt;Animal\u0026gt;(); Console.WriteLine($\u0026#34;{customerListCat2.GetType()}\u0026#34;); Assert.IsTrue(true); }高性能泛型缓存# 静态字典缓存和常用的泛型缓存的性能相比，泛型缓存性能是非常优异的。泛型缓存是 JIT 产生全新的类，内存直接分配，由CPU查找内存地址。静态字典缓存需要根据地址去寻址查找。\n/// \u0026lt;summary\u0026gt; /// 类中的静态类型无论实例化多少次，在内存中只会有一个 /// 静态构造函数只会执行一次 /// 在泛型类中，T类型不同 /// 每个不同的T类型，都会产生一个不同的副本，所以会产生不同的静态属性、不同的静态构造函数 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; gma warning disable S1118 // Utility classes should not have public constructors public class GenericCache\u0026lt;T\u0026gt; gma warning restore S1118 // Utility classes should not have public constructors { gma warning disable S3963 // \u0026#34;static\u0026#34; fields should be initialized inline static GenericCache() { _CachedValue = string.Format(\u0026#34;{0}_{1}\u0026#34;， typeof(T).FullName， DateTime.Now.ToString(\u0026#34;yyyyMMddHHmmss.fff\u0026#34;)); } gma warning restore S3963 // \u0026#34;static\u0026#34; fields should be initialized inline gma warning disable S2743 // Static fields should not be used in generic types private static readonly string _CachedValue = \u0026#34;\u0026#34;; gma warning restore S2743 // Static fields should not be used in generic types public static string GetCache() { return _CachedValue; } }/// \u0026lt;summary\u0026gt; /// 泛型会为不同的类型都创建一个副本 /// 所以静态构造函数会执行4次，而且每次静态属性的值都是一样的 /// 利用泛型的这一特性，可以实现缓存 /// 注意：只能为不同的类型缓存一次。泛型缓存比字典缓存效率高。泛型缓存不能主动释放 /// \u0026lt;/summary\u0026gt; [TestMethod] public void GenericityCache() { for (int i = 0; i \u0026lt; 5; i++) { Console.WriteLine(GenericCache\u0026lt;int\u0026gt;.GetCache()); Console.WriteLine(GenericCache\u0026lt;long\u0026gt;.GetCache()); Console.WriteLine(GenericCache\u0026lt;DateTime\u0026gt;.GetCache()); Console.WriteLine(GenericCache\u0026lt;string\u0026gt;.GetCache()); } Assert.IsTrue(true); }\n参考# https://www.cnblogs.com/dotnet261010/p/9034594.html https://www.cnblogs.com/yilezhu/p/10029782.html https://www.cnblogs.com/aehyok/p/3384637.html "},{"id":35,"href":"/docs/dotnet/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/","title":"线程同步","section":"所有文章","content":"当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作。直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程又处于等待状态，这种时候很容易出现问题。\n争用条件# 如果两个或多个线程访问相同的对象。并且对共享状态的访问没有同步，就会出现争用条件。\nclass StateObject { private int state = 5; public void ChangeState() { state++; if (state == 5) { Console.WriteLine(\u0026#34;value=5\u0026#34;); } state = 5; } }public static void ThreadSync_Lock_Example_01() { StateObject m = new StateObject(); Thread t1 = new Thread(ChangeState); t1.Start(m); Console.ReadKey(); static void ChangeState(object o) { StateObject m = o as StateObject; while (true) { m.ChangeState(); } } }此时运行程序是没有输出的，因为 StateObject 类中 state 初始值是5，if 条件不会进入,随后又将 state 重新初始化为5。\n两个线程执行\npublic static void ThreadSync_Lock_Example_02() { StateObject m = new StateObject(); Thread t1 = new Thread(ChangeState); Thread t2 = new Thread(ChangeState); t1.Start(m); t2.Start(m); Console.ReadKey(); static void ChangeState(object o) { StateObject m = o as StateObject; while (true) { m.ChangeState(); } } }此时会不停的打印\u0026quot;value=5\u0026quot;，原因在于：一个线程在判断语句处时，另一个线程可能又将 state 的值改为了5，而导致输出合法。\n死锁# class Deadlock { static StateObject o1 = new StateObject(); static StateObject o2 = new StateObject(); public static void DeadlockA(object o) { lock (o1) { Console.WriteLine(\u0026#34;我是线程{0},我锁定了对象o1\u0026#34;, o); lock (o2) { Console.WriteLine(\u0026#34;我是线程{0},我锁定了对象o2\u0026#34;, o); } } } public static void DeadlockB(object o) { lock (o2) { Console.WriteLine(\u0026#34;我是线程{0},我锁定了对象o2\u0026#34;, o); lock (o1) { Console.WriteLine(\u0026#34;我是线程{0},我锁定了对象o1\u0026#34;, o); } } } } Thread t1 = new Thread(Deadlock.DeadlockA); Thread t2 = new Thread(Deadlock.DeadlockB); t1.Start(\u0026#34;t1\u0026#34;); t2.Start(\u0026#34;t2\u0026#34;); t1 线程执行 DeadlockA() 方法顺序锁定o1和o2 t2 线程执行 DeadlockB() 方法顺序锁定o2和o1 当前结果显示t1线程锁定了o1后，t2线程在t1线程锁定o1后抢占进来，锁定了o2。t2在等t1解锁,t1在等t2解锁，都处于挂起状态在等对方解锁，这就形成了死锁，线程将无限等待下去。\n这个问题应该从一开始就设计好锁定顺序，也可以为锁定义超时时间来处理，保证“上锁”这个操作在一个线程上执行也是避免死锁的方法之一。\nC#中有多个用于多线程的同步技术\nlock语句 Interlocked类 Monitor类 SpinLock类 WaitHandle类 Mutex类 Semapphore类 Event类 Barrier类 ReaderWriteLockSlim类 其中lock语句/Interlocked类/Monitor类可用于进程内存的同步，其它几个提供了多进程之间的线程同步。\nLock# C#使用 lock 语句锁定在线程中共享的变量，如果一个线程锁定了变量，另一个线程就必须等待该锁定的解除。\nstatic void ChangeState(object o) { StateObject m = o as StateObject; while (true) { //给变量m加锁 lock (m) { m.ChangeState(); } } }因为实例的对象也可以用于外部的同步访问，而且不能在类自身控制这种访问，所以应采用SyncRoot模式，创建私有对象，将这个对象用于 lock 语句。\nprivate static object syncRoot= new object(); static void ChangeState(object o) { StateObject m = o as StateObject; while (true) { lock (aync) { m.ChangeState(); } } }注意\nlock只能锁定对象，即引用类型，不能锁定值类型 lock不能锁定空值,因为null是不需要被释放的 不能锁定string类型,虽然它也是引用类型的。因为字符串类型被CLR暂留，这意味着整个程序中任何给定字符串都只有一个实例，具有相同内容的字符串上放置了锁，就将锁定应用程序中该字符串的所有实例 避免锁定public类型,如果该实例可以被公开访问，则 lock(this) 可能会有问题，因为不受控制的代码也可能会锁定该对象 锁是否必须是静态类型？# 如果被锁定的方法是静态的，那么这个锁必须是静态类型。这样就是在全局锁定了该方法，不管该类有多少个实例，都要排队执行。\n如果被锁定的方法不是静态的，那么不能使用静态类型的锁，因为被锁定的方法是属于实例的。只要该实例调用锁定方法不产生损坏就可以，不同实例间是不需要锁的。这个锁只锁该实例的方法，而不是锁所有实例的方法。\nclass ThreadSafe { private static object _locker = new object(); void Go() { lock (_locker) { ......//共享数据的操作 （Static Method）,使用静态锁确保所有实例排队执行 } } private object _locker2=new object(); void GoTo() { lock(_locker2) //共享数据的操作，非静态方法，是用非静态锁，确保同一个实例的方法调用者排队执行 } }同步对象可以兼作它 lock 的对象。比如：\nclass ThreadSafe { private List \u0026lt;string\u0026gt; _list = new List \u0026lt;string\u0026gt;(); void Test() { lock (_list) { _list.Add (\u0026#34;Item 1\u0026#34;); } } }Monitors# lock 其实是 Monitors 的简洁写法。\nlock (syncRoot) { m.ChangeState(); }两者其实是一样的\nMonitor.Enter(syncRoot); try { m.ChangeState(); } finally { Monitor.Exit(syncRoot); }Mutex# 互斥锁是一个互斥的同步对象，同一时间有且仅有一个线程可以获取它。可以实现进程级别上线程的同步。\npublic static void ThreadSync_Mutex_Example_01() { for (int i = 0; i \u0026lt; 3; i++) { //在不同的线程中调用受互斥锁保护的方法 Thread test = new Thread(MutexMethod); test.Start(); } Console.Read(); static void MutexMethod() { //实例化一个互斥锁 Mutex mutex = new Mutex(); Console.WriteLine(\u0026#34;{0} 请求获取互斥锁\u0026#34;, Thread.CurrentThread.ManagedThreadId); mutex.WaitOne(); Console.WriteLine(\u0026#34;{0} 已获取到互斥锁\u0026#34;, Thread.CurrentThread.ManagedThreadId); Console.WriteLine(\u0026#34;{0} 准备释放互斥锁\u0026#34;, Thread.CurrentThread.ManagedThreadId); // 释放互斥锁 mutex.ReleaseMutex(); Console.WriteLine(\u0026#34;{0} 已经释放互斥锁\u0026#34;, Thread.CurrentThread.ManagedThreadId); } }互斥锁的带有三个参数的构造函数\ninitiallyOwned : 如果 initiallyOwned 为 true，互斥锁的初始状态就是被所实例化的线程所获取，否则实例化的线程处于未获取状态 name：该互斥锁的名字，在操作系统中只有一个命名为name的互斥锁mutex，如果一个线程得到这个name的互斥锁，其他线程就无法得到这个互斥锁了，必须等待那个线程对这个线程释放 createNew：如果指定名称的互斥体已经存在就返回false，否则返回true "},{"id":36,"href":"/docs/dotnet/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","title":"面向对象","section":"所有文章","content":"类（Class）# 类中的数据和函数称为类的成员，除了这些成员外，类还可以包含嵌套的类型(如其它类)，成员的可访问性有：\npublic protected internalprotected private internal 数据成员# 数据成员指包含类的数据：字段、常量和事件的成员，数据成员可以是静态成员，类成员总是实例成员，除非用 static 进行显式声明。\n函数成员# 函数成员提供了操作类中数据的某些功能，包括方法、属性、构造函数和终结器、运算符以及索引器\n方法是与某个类相关的函数，与数据成员一样，函数成员默认为实例成员，使用 static 修饰符可以把方法定义为静态方法 属性是可以从客户端访问的函数组，访问方式与访问类的公共字段类似，C# 为读写类中的属性提供了专用语法，所以不必使用名称中嵌有 Get 或 set 的方法 构造函数是在实例化对象时自动调用的特殊函数，必须与所属的类同名，且不能有返回类型，构造函数用于初始化字段的值 终结器类似于构造函数，在CLR 检测到不再需要某个对象时调用它，它们名称与类相同，但前面有一个 ~ 运算符执行的最简单的操作就是加法和减法。 两个整数相加时严格地说是对整数使用 + 运算符，C#允许指定把已有的运算符应用于自己的类（运算符重载） 索引器允许对象以数组或集合的方式进行索引 方法（Method）# 方法声明# C#中方法的定义包括：任意方法修饰符(如方法的可访问性)、返回值的类型，然后依次是方法名和输入参数的列表和方法体。每个参数都包括参数的类型名和在方法体中的引用名称。 如果方法有返回值， return 语句就必须与返回值一起使用。\n[modifiers] return_type MethodName([parameters]) { // Method body }class Test { /// \u0026lt;summary\u0026gt; /// 实例方法 /// \u0026lt;/summary\u0026gt; public void Show() { Console.WriteLine(\u0026#34;Test下实例方法\u0026#34;); } /// \u0026lt;summary\u0026gt; /// 静态方法属于类本身 /// \u0026lt;/summary\u0026gt; public static void Show2() { Console.WriteLine(\u0026#34;Test下静态方法\u0026#34;); } }方法调用# 在实例化类得到类的对象后，即可通过 对象.方法名称 进行方法调用。\n// 实例方法调用 Test test = new Test(); test.Show();// 静态方法调用 Test.Show2(); 注意：使用 static 修饰的方法属于类的本身，无法使用类的实例化对象进行调用，使用类名.方法名即可\n表达式方法体# 如果方法的实现只有一条语句，C# 为方法定义提供了一个简化的语法：表达式体方法，使用 =\u0026gt; 区分操作符左边的声明和操作符右边的实现代码。\npublic void PrintName() =\u0026gt; Console.WriteLine(_name);命名参数# 参数一般需要按定义的顺序传送给方法，命名参数允许按任意顺序传递。\nclass Program { static void Main(string[] args) { //下面两种调用方式结果是一样的 Print(\u0026#34;hello\u0026#34;， \u0026#34;world\u0026#34;); Print(b: \u0026#34;world\u0026#34;， a: \u0026#34;hello\u0026#34;); Console.ReadKey(); } static void Print(string a， string b) { Console.WriteLine(\u0026#34;{0}，{1}\u0026#34;， a， b); } }可选参数# 参数也可以是可选的，必须为可选参数提供默认值，可选参数还必须是方法定义的最后一个参数。\nstatic void Print(string a， string b = \u0026#34;world\u0026#34;) { Console.WriteLine(\u0026#34;{0}，{1}\u0026#34;， a， b); }Print(\u0026#34;hello\u0026#34;);//输出hello，world Print(\u0026#34;hello\u0026#34;，\u0026#34;wang\u0026#34;);//输出hello，wang个数可变的参数# 使用 params[] 数组的方式可以定义数量可变的参数，如果 params[] 关键字与方法签名定义的多个参数一起使用，则只能使用一次，而且必须是最后一个参数。\n方法重载# 方法名相同，但参数的个数或类型不同。\nstatic void Print(string a) { Console.WriteLine(\u0026#34;{0}\u0026#34;， a); } static void Print(string a， string b = \u0026#34;world\u0026#34;) { Console.WriteLine(\u0026#34;{0}，{1}\u0026#34;， a， b); }注意：\n两个方法不能仅在返回类型上有区别\n两个方法不能仅根据参数是声明为 ref 还是 out 来区分\n局部函数# 局部函数只能在声明该局部函数的方法内部调用\npublic void LocalMethod() { static int Add(int x, int y) =\u0026gt; x + y; int result = Add(1, 2); Console.WriteLine(result); }扩展方法# 扩展方法允许创建扩展其他类型的方法。扩展方法需要是静态方法，并且在静态类中声明。\n枚举# 枚举是值类型，包含一组命名的常量\npublic enum Colors { Red = 1, Green = 2, Blue = 3 }属性（Property）# 它是一个方法或一对方法，在客户端代码看来，它(们)是一个字段。\n属性定义# public string SomeProperty { get { return \u0026#34;This is the property value\u0026#34;; } set { //type string } }只读和只写属性# 在属性定义中省略 set 访问器，就可以创建只读属性；同样在属性定义中省略 get 访问器，就可以创建只写属性。\nclass Program { private string age; private string name; //只读属性 public string Age { get { return age; } } //只写属性 public string Name { set { value= name; } } }属性的访问修饰符# C# 允许给属性的 get 和 set 访问器设置不同的访问修饰符，所以属性可以有公有的 get 访问器和私有或受保护的 set 访问器。有助于控制属性的设置方式。\n自动实现的属性# 如果属性的 get 和 set 访问器中没有任何逻辑，就可以使用自动实现的属性，使用自动实现的属性，就不能在属性设置中验证属性的有效性。\nclass Program { public string Age { get; set; } public string Name { get; set; } static void Main(string[] args) { Console.ReadKey(); } }构造函数# 声明基本构造函数的语法就是声明一个与包含的类同名的方法，但该方法没有返回类型。\n构造函数声明# class Person { Person(){} }注意：没有必要给类显式提供构造函数，原因在于：如果没有在类中没有提供任何构造函数，编译器会在后台创建一个默认的无参构造函数用来把所有的成员字段初始化为标准的默认值。\n构造函数重载# 构造函数重载遵循与其他方法相同的规则，就是说允许为构造函数提供任意多的重载。\nclass Program { static void Main(string[] args) { //调用无参构造函数实例化对象 Person person1 = new Person(); //调用带参数的构造函数实例化对象 Person person2 = new Person(3); //因为带name参数的构造函数是private的，所以这里无法实例化 //Person person3 = new Person(20， \u0026#34;wang\u0026#34;); Console.ReadKey(); } } class Person { private int age; private string name; public Person() { } public Person(int age) { //使用this关键字区分成员字段和同名参数 this.age = age; } private Person(int age， string name) { this.age = age; this.name = name; } } class Person { private int age; private string name; private Person(int age， string name) { this.age = age; this.name = name; } }这个例子没有为 Person 类定义任何公有的或受保护的构造函数。这就使 Person 不能使用 new 运算符在外部代码中实例化(但可以在 Person 中编写一个公有静态属性或方法，以实例化该类)。 这在下面两种情况下是有用的：\n类仅用作某些静态成员或属性的容器，因此永远不会实例化它 希望类仅通过调用某个静态成员函数来实例化(单例模式） 注意：如果提供了带参数的构造函数，编译器就不会隐式的自动创建默认的构造函数。\n构造函数初始化器# 有时，在一个类中有几个构造函数，以容纳某些可选参数，这些构造函数包含一些共同的代码。需要做到从构造函数中调用其他构造函数时可以使用构造函数初始化器。\nclass Program { static void Main(string[] args) { Person person1 = new Person(20); Person person2 = new Person(20， \u0026#34;li\u0026#34;); Console.WriteLine(\u0026#34;person1:age={0}，name={1}\u0026#34;， person1.age， person1.name); Console.WriteLine(\u0026#34;person2:age={0}，name={1}\u0026#34;， person2.age， person2.name); Console.ReadKey(); } } class Person { public int age; public string name; public Person(int age) { this.age = age; this.name = \u0026#34;wang\u0026#34;; } public Person(int age， string name) { this.age = age; this.name = name; } }上面的例子是一个简单的构造函数重载，然后通过调用不同的构造函数实例化对象，Person 类的两个构造函数初始化了相同的字段 age ，显然最好把所有的代码放在一个地方，C#中使用构造函数初始化器，可以实现此目的：\nclass Program { static void Main(string[] args) { Person person1 = new Person(20); Person person2 = new Person(20， \u0026#34;li\u0026#34;); Console.WriteLine(\u0026#34;person1:age={0}，name={1}\u0026#34;， person1.age， person1.name); Console.WriteLine(\u0026#34;person2:age={0}，name={1}\u0026#34;， person2.age， person2.name); Console.ReadKey(); } } class Person { public int age; public string name; public Person(int age) { this.age = age; this.name = \u0026#34;wang\u0026#34;; } public Person(int age， string name) : this(age) { this.age = age; this.name = name; } }这里 this 关键字仅调用参数最匹配的那个构造函数。\n注意：构造函数初始化器在构造函数的函数体之前执行。C#构造函数初始化器可以包含对同一个类的另一个构造函数的调用(使用前面介绍的语法)，也可以包含对直接基类的构造函数的调用(使用相同的语法，但应使用 base 关键字代替 this。初始化器中不能有多个调用。\n静态类# 如果类只包含静态的方法和属性，该类就是静态的。静态类在功能上与使用私有静态函数创建的类相同，不能创建静态类的实例。\n静态构造函数# 静态构造函数只执行一次，而前面的构造函数是实例构造函数，只要创建类的对象，就会被执行。编写静态构造函数的一个原因是，类有一些静态字段或属性，需要在第一次使用类之前，从外部源中初始化这些静态字段和属性。\n注意：.Net 运行库没有确保什么时候执行静态构造函数，所以不应把要求在某个特定时刻(例如，加载程序集时)执行的代码放在静态构造函数中。也不能预计不同类的静态构造函数按照什么顺序执行。但是，可以确保静态构造函数最多运行一次，即在代码引用类之前调用它\n在C#中，通常在第一次调用类的任何成员之前执行静态构造函数。静态构造函数没有访问修饰符，其他C#代码从来不调用它，但在加载类时，总是由.NET运行库调用它，所以像 public 或 private 这样的访问修饰符就没有任何意义。出于同样原因，静态构造函数不能带任何参数，一个类也只能有一个静态构造函数。很显然，静态构造函数只能访问类的静态成员，不能访问类的实例成员。\n无参数的实例构造函数与静态构造函数可以在同一个类中同时定义。尽管参数列表相同，但这并不矛盾，因为在加载类时执行静态构造函数，而在创建实例时执行实例构造函数，所以何时执行哪个构造函数不会有冲突。如果多个类都有静态构造函数，先执行哪个静态构造函数就不确定。此时静态构造函数中的代码不应依赖于其他静态构造函数的执行情况。 另一方面，如果任何静态字段有默认值，就在调用静态构造函数之前指定它们。\n参数传递# C#中，方法、构造函数可以拥有参数，当调用方法或者构造函数时，需要提供参数，而参数的传递方式有两种（以方法为例）：\n按值传递# 值类型对象传递给方法时，传递的是值类型对象的副本而不是值类型对象本身\npublic void ParamByVal() { static void SetIntValue(int i) { i += 100; } int i = 1; SetIntValue(i); // i=1,i是值类型按值传递，此处传递给方法的其实是变量i的副本而不是对象本身 Assert.AreEqual(1, i); }按引用传递# 对于引用类型对象，其实也是按值传递的，但是不像值类型传递的是一个副本，引用类型传递的是引用地址。在方法中使用这个地址去修改对象的成员，自然就会影响到原来的对象\n注意：如果值类型对象中含有引用类型的成员，那么当值类型对象在传递给方法时，副本中克隆的是引用类型成员的地址，而不是引用类型对象的副本，所以在方法中修改此引用类型对象成员中的成员等也会影响到原来的引用类型对象。\npublic void ParamByReference() { static void SetIntArrValue(List\u0026lt;int\u0026gt; arr) { arr.Add(100); } var arr = new List\u0026lt;int\u0026gt;() { 1, 2, 3, 4, 5 }; Console.WriteLine(JsonConvert.SerializeObject(arr)); SetIntArrValue(arr); // [1,2,3,4,5,100] Console.WriteLine(JsonConvert.SerializeObject(arr)); }特殊情况string# 尽管 string 属于引用类型，但它在参数传递时表现出了按值传递的特色\npublic void ParamByString() { static void SetStringValue(string oldStr) { oldStr = \u0026#34;world\u0026#34;; } string str = \u0026#34;hello\u0026#34;; SetStringValue(str); // 此处正常理解应该返回world,因为str是引用类型。 // 但其实因为string的“不变性”，所以在被调用方法中执行 oldStr=\u0026#34;world\u0026#34;时，此时并不会直接修改oldStr中的\u0026#34;hello\u0026#34;值为\u0026#34;world\u0026#34;，因为string类型是不变的，不可修改的 // 此时内存会重新分配一块内存，然后把这块内存中的值修改为 “world”，然后把内存中地址赋值给oldStr变量，但此时str仍然指向 \u0026#34;hello\u0026#34;字符，而oldStr却改变了指向，它指向了\u0026#34;world\u0026#34;字符串 Console.WriteLine(str); }实际引用传递# 引用传递可以理解为就是对象本身传递，而非一个副本或者地址，一般使用 in、out、ref 关键字声明参数是引用传递。　in# in 修饰的参数表示参数通过引用传递，但是参数是只读的，所以在调用方法时必须先初始化\npublic void ParamByIn() { static void SetIntValue(in int i) { // i += 100; // 因为in修饰的参数为只读所以不能直接赋值 Console.WriteLine($\u0026#34;{i}\u0026#34;); } int i = 1; SetIntValue(i); // i=1,虽然是按引用传递但是in修饰的参数是只读所以无法在方法内部为i赋值 Assert.AreEqual(1, i); }ref# ref 关键字使参数按引用传递。其效果是，当控制权传递回调用方法时，在方法中对参数的任何更改都将反映在该变量中。\n若要使用 ref 参数，则方法定义和调用方法都必须显式使用 ref 关键字\npublic void ParamByRef() { static void SetIntValue(ref int i) { i += 100; // ref修饰的参数会按引用传递 } int i = 1; SetIntValue(ref i); // ref修饰的参数方法定义和调用方法都必须显式使用ref关键字 Assert.AreEqual(101, i); }out# out 关键字使参数按引用传递。与ref关键字类似，不同之处在于ref要求变量必须在传递之前进行初始化而out不需要但是在方法返回前必须为参数赋值。\n若要使用 out 参数，方法定义和调用方法都必须显式使用out关键字\npublic void ParamByOut() { static void SetIntValue(out int i) { i = 100; // out修饰的参数会按引用传递,在方法返回前必须给i赋值 } SetIntValue(out int i); // out参数，方法定义和调用方法都必须显式使用out关键字 Assert.AreEqual(100, i); } ref 和 in都是引用传递，而且要求调用方法前需要提前初始化，但是与in不同的是，调用时ref关键字不能省略，且参数必须是变量，不能是常量 ref 和 out都是引用传递，且在调用时候，ref 和 out 关键字不能省略，且参数必须是变量，不能是常量，但是ref要求调用方法前需要提前初始化，且无需在调用方法结束前赋值 与 in 和 out 不同的是，在调用方法中时，可以读写整个 ref 参数对象及它的成员 结构# 结构是值类型# 结构是会影响性能的值类型，但根据使用结构的方式，这种影响可能是正面的，也可能是负面的。\n正面影响是：为结构分配内存时，速度非常快，因为它们将内联或者保存在栈中。 在结构超出了作用域被删除时，速度也很快 负面影响是：只要把结构作为参数来传递或者把一个结构赋予另一个结构(如A-B，其 中A和 B是结构)，结构的所有内容就被复制，而对于类，则只复制引用。 这样就会有性能损失，根据结构的大小，性能损失也不同 注意：结构主要用于小的数据结构。但当把结构作为参数传递给方法时，应把它作为 ref 参数传递，以避免性能损失，此时只传递了结构在内存中的地址，这样传递速度就与在类中的传递速度一样快了。但如果这样做，就必须注意被调用的方法可以改变结构的值\n结构不支持继承# 结构(和C#中的其他类型一样)最终派生于类 System.Object。因此结构也可以访问 System.Object 的方法。在结构中，甚至可以重写 System.Object 中的方法（如重写Tostring)方法。 结构的继承链是：每个结构派生自 System.ValueType 类 ，System.ValueType 类又派生自 System.Object 。 ValueType 并没有给 Object 添加任何新成员，但提供了一些更适合结构的实现方式。\n注意：不能为结构提供其他基类，每个结构都派生自 ValueType\n结构的构造函数# 为结构定义构造函数的方式与为类定义构造函数的方式相同，但不允许定义无参数的构造函数。\n注意：.Net运行库禁止在C#结构内定义无参构造函数\n类和结构的区别# 结构与类的区别在于它们在内存中的存储方式、访问方式(类是存储在堆上的引用类型，而结构是存储在栈上的值类型)和它们的一些特征(如结构不支持继承。较小的数据类型使用结构可提高性能。但在语法上，结构与类非常相似，主要的区别是使用关键字 struct 代替 class 来声明结构。对于类和结构，都使用关键字 new 来声明实例创建对象并对其进行初始化。\n匿名类型# 匿名类型只是一个继承自 Object 且没有名称的类。该类的定义从初始化器中推断，类似于隐式类型化的变量。\nvar person = new { Name = \u0026#34;wang\u0026#34;， Age = 22 };继承# 在面向对象编程中，有两种截然不同的继承类型，实现继承和接口继承。C# 不支持多重继承但可以派生自另一个类和任意多的接口。\n实现继承：表示一个类型派生自一个基类型，它拥有该基类型的所有成员字段和函数，在需要给现有类型添加功能或者许多相关类型共享一组重要的公共功能时这种类型继承非常有用 接口继承：表示一个类型只继承了函数的签名，没有继承任何的实现代码 实现继承# /// \u0026lt;summary\u0026gt; /// 基类 /// \u0026lt;/summary\u0026gt; class Person { /// \u0026lt;summary\u0026gt; /// 使用virtual关键字定义的方法允许在派生类中使用override重写 /// \u0026lt;/summary\u0026gt; public virtual void SayHello() { Console.WriteLine(\u0026#34;基类的SayHello\u0026#34;); } } /// \u0026lt;summary\u0026gt; /// 派生自Person /// \u0026lt;/summary\u0026gt; class ChinaPerson : Person { /// \u0026lt;summary\u0026gt; /// 使用override关键字重写基类的SayHello方法 /// \u0026lt;/summary\u0026gt; public override void SayHello() { Console.WriteLine(\u0026#34;你好\u0026#34;); } } /// \u0026lt;summary\u0026gt; /// 派生自Person /// \u0026lt;/summary\u0026gt; class ThailandPerson : Person { public override void SayHello() { Console.WriteLine(\u0026#34;萨瓦迪卡\u0026#34;); } }把一个基类函数声明为 virtual，就可以在任何派生类中重写该函数，virtual 也适用于属性。\n注意：成员字段和静态函数都不能声明为 virtual ，因为这个概念只对类中的实例成员有意义\n接口继承# 表示一个类型只继承了函数的签名，没有继承任何实现代码。在需要指定该类型具有某些可用的特性时，最好使用这种类型的继承。接口名称通常以字母 I 开头，以便知道这是一个接口。C#支持多接口继承和单一实现继承，接口继承中又分为隐式实现和显式实现。\ninterface IPerson { void SayHello(); } /// \u0026lt;summary\u0026gt; /// 隐式实现接口 /// \u0026lt;/summary\u0026gt; class ChinaPerson : IPerson { public void SayHello() { Console.WriteLine(\u0026#34;你好\u0026#34;); } } /// \u0026lt;summary\u0026gt; /// 显式实现接口 /// \u0026lt;/summary\u0026gt; class ThailandPerson : IPerson { void IPerson.SayHello() { Console.WriteLine(\u0026#34;莎娃迪卡\u0026#34;); } }对于隐式实现的接口调用这两种方式都可以：\nChinaPerson chinaPerson = new ChinaPerson(); IPerson person = new ChinaPerson(); person.SayHello(); chinaPerson.SayHello();对于显式实现的接口调用只能使用接口调用：\nIPerson thailandPerson = new ThailandPerson(); thailandPerson.SayHello();隐藏方法# 如果签名相同的方法在基类和派生类中都进行了声明，但该方法没有声明为 virtual 和 override，派生类会隐藏基类方法。\nclass Person { public void SayHello() { Console.WriteLine(\u0026#34;基类的SayHello\u0026#34;); } } class ChinaPerson : Person { //提示:隐藏继承的成员Person.SayHello，如果有意的，请使用关键字new public void SayHello() { Console.WriteLine(\u0026#34;你好\u0026#34;); } }调用基类方法# C#中可以使用 base. 这种语法来调用方法的基类版本。\nclass Person { public virtual void SayHello() { Console.WriteLine(\u0026#34;基类的SayHello\u0026#34;); } } class ChinaPerson : Person { public override void SayHello() { base.SayHello(); Console.WriteLine(\u0026#34;你好\u0026#34;); } }派生类构造函数执行# 首先定义基类 A，为了方便查看，显式指明基类的无参构造函数\nclass A { public int Age { get; set; } public string Name { get; set; } public A() { Console.WriteLine(\u0026#34;A类无参构造函数\u0026#34;); } }然后定义B类继承自A类\nclass B : A { public B() { Console.WriteLine(\u0026#34;B类无参构造函数\u0026#34;); } }实例化B类\nstatic void Main(string[] args) { B b = new B(); Console.ReadKey(); }输出： A类无参构造函数 B类无参构造函数\n实例化子类时，只可以new子类，执行顺序为：先执行父类构造函数=\u0026gt;再执行子类构造函数\n如果父类存在多个构造函数会怎么样？\nclass A { public int Age { get; set; } public string Name { get; set; } public A() { Console.WriteLine(\u0026#34;A类无参构造函数\u0026#34;); } public A(int age， string name) { Console.WriteLine(\u0026#34;A类带参构造函数\u0026#34;); } } class B : A { public B() { Console.WriteLine(\u0026#34;B类无参构造函数\u0026#34;); } }再次实例化B类\nstatic void Main(string[] args) { B b = new B(); Console.ReadKey(); }输出： A类无参构造函数 B类无参构造函数\n实例化子类时，会先执行父类的构造函数(默认为父类的无参构造函数)，也可以在子类中使用base关键字指定调用父类的哪个构造函数\nclass Program { static void Main(string[] args) { B b = new B(3); Console.ReadKey(); } } class A { public int Age { get; set; } public A() { Console.WriteLine(\u0026#34;A类无参构造函数\u0026#34;); } public A(int age) { Console.WriteLine(\u0026#34;A类带参构造函数\u0026#34;); } } class B : A { public B() : base(3) { Console.WriteLine(\u0026#34;B类无参构造函数调用父类带参构造函数\u0026#34;); } }输出： A类带参构造函数 B类无参构造函数调用父类带参构造函数\n总结：\n实例化父类时，可以使用 new 子类，执行构造函数顺序为：执行父类构造函数=\u0026gt;执行子类构造函数 实例化子类时，只可以 new 子类，执行顺序同上 父类实例化后，只能执行父类的方法，获得父类的属性等 实例化子类后，可同时执行子类和父类的方法和属性，如同名方法，则执行子类的方法 子类构造函数可以使用 base 关键字指定调用的父类构造函数 类和结构都是创建对象的模板，每个对象都包含数据，并提供了处理和访问数据的方法。类定义了类的每个对象(称为实例)可以包含什么数据和功能。还可以定义处理在这些字段中存储的数据的功能。\n抽象类和抽象函数# C#中允许把类或函数声明为abstract ，抽象类不能被实例化。抽象函数也不能直接实现，必须在非抽象的派生类中重写 如果类包含抽象函数，则该类也必须被声明为抽象的 抽象方法只在派生类中真正实现，这表明抽象方法只存放函数原型不涉及主体代码 派生自抽象类的类需要实现其基类的抽象方法，才能实例化对象 使用 override 关键字可在派生类中实现抽象方法，经 override 声明重写的方法称为重写基类方法，其签名必须与 override 方法的签名相同 密封类和密封方法# C#允许把类和方法声明为 sealed ，对于类这表示不能继承。对于方法这表示不能重写该方法。\n抽象类和接口的区别# 相同点\n都可以被继承 都不能被实例化 都包含方法声明 派生类必须实现未实现的方法 区别\n抽象基类可以定义字段/属性/方法实现.接口只能定义属性/索引器/事件/方法声明 抽象类是一个不完整的类，需要通过集成进一步细化。而接口更像是一个行为规范表明能做什么 接口是可以被多重实现的，可以有多个类实现接口，因为类的单一继承性，抽象类只能被单一继承 抽象类实现继承需要使用 override 关键字，接口则不用 如果抽象类实现接口，可以把接口方法映射到抽象类中作为抽象方法不必实现，而在抽象类的子类中实现接口方法 抽象类表示的是这个对象是什么；接口表示的是这个对象能做什么；使用抽象类是为了代码的复用，使用接口是为了实现多态性 普通类和抽象类的区别# 都可以被继承 抽象类不能实例化，普通类允许实例化 抽象方法只包含方法声明而且必须包含在抽象类中 子类继承抽象类必须实现抽象类中的抽象方法除非子类也是抽象类 抽象类中可以包含抽象方法和实例方法 "},{"id":37,"href":"/docs/elk/1.1elastaticsearch%E5%85%A5%E9%97%A8/","title":"1.1 Elastatic Search入门","section":"所有文章","content":"Elasticsearch 简称 ES，是一个开源、高扩展的分布式全文检索引擎，可以实现近乎实时的存储、检索数据且扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。ES 底层是开源库 Lucene，ES 实现了对 Lucene 的封装，并提供 REST 风格的操作接口开箱即用。通过简单的 RESTful API 来隐藏Lucene的复杂性，从而让全文搜索变得简单。\nElasticSearch 对比 Solr# Solr 利用 Zookeeper 进行分布式管理， Elasticsearch 自身带有分布式协调管理功能 Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式 Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能由第三方插件提供 Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch ElasticSearch 安装# 注意：ES 使用 Java 开发，使用 Lucene 作为核心，所以需要配置好java环境（jdk1.8 以上）\n下载地址：ElasticSearch 官网，如果下载比较慢可以试试：newbe.pro\nWindows 平台下载完成直接解压即可，目录结构如下：\nbin // 可执行二进制文件 config // 配置信息目录 lib // jar包存放目录,比如lucene相关的jar包 logs // 日志 modulES // 模块 plugins // 插件ElasticSearch 配置# 调整内存# 修改 conf\\jvm.option 文件\n-Xms1g -Xmx1g 修改为自己定义的值，比如 -xms256m -xmx256m 防止因为内存不足无法启动开启跨域# 修改 conf\\elasticsearch.yml 文件，在末尾加入如下代码：\nhttp.cors.enabled: true http.cors.allow-origin: \u0026#34;*\u0026#34; network.host: 127.0.0.1ElasticSearch 启动# 双击 bin 目录下的 elasticsearch.bat 启动：\n:warning: ES集群之间使用tcp进行通信，9300 是tcp通信端口，9200 是http协议端口\n浏览器测试访问：\nElasticsearch-head# 通过安装 ElasticSearch 的 head 插件，可以实现图形化查看索引数据。下载地址\n下载完成后解压即可，目录结构如下：\nElasticsearch-head 依赖于 node.js 所以需要先保证本地有 node.js 的环境：\nC:\\Users\\Administrator\u0026gt;node -v v14.17.3使用 npm 还原依赖：\nD:\\Elasticsearch\\elasticsearch-head-master\u0026gt;npm install 注意：如果下载速度较慢，可以切换淘宝镜像使用 cnpm\n启动 Elasticsearch-head：\nD:\\Elasticsearch\\elasticsearch-head-master\u0026gt;npm run start \u0026gt; elasticsearch-head@0.0.0 start D:\\Elasticsearch\\elasticsearch-head-master \u0026gt; grunt server Running \u0026#34;connect:server\u0026#34; (connect) task Waiting forever... Fatal error: Port 9100 is already in use by another procESs. npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! elasticsearch-head@0.0.0 start: `grunt server` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the elasticsearch-head@0.0.0 start script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: npm ERR! C:\\Users\\Administrator\\AppData\\Roaming\\npm-cache\\_logs\\2022-03-05T16_39_04_056Z-debug.log这里报错：Port 9100 is already in use by another procESs. ，原因是 9100 端口被占用，查看哪个进程占用的端口号并结束该进程：\nD:\\Elasticsearch\\elasticsearch-head-master\u0026gt;netstat -ano | findstr \u0026#34;9100\u0026#34; TCP 0.0.0.0:9100 0.0.0.0:0 LISTENING 12276 TCP 127.0.0.1:53459 127.0.0.1:9100 TIME_WAIT 0 D:\\Elasticsearch\\elasticsearch-head-master\u0026gt;taskkill -pid 12276 -F 成功: 已终止 PID 为 12276 的进程。重新启动：\nD:\\Elasticsearch\\elasticsearch-head-master\u0026gt;npm run start \u0026gt; elasticsearch-head@0.0.0 start D:\\Elasticsearch\\elasticsearch-head-master \u0026gt; grunt server Running \u0026#34;connect:server\u0026#34; (connect) task Waiting forever... Started connect web server on http://localhost:9100浏览器访问：\nok，至此完成 Elasticsearch-head 的安装启动。\nElasticsearch 核心概念# Elasticsearch 是面向文档（document oriented ）的，这意味着它可以存储整个对象或文档（document ）。然而它不仅会存储，还会索引( index )每个文档的内容使之可以被搜索。在Elasticsearch中，可以对文档（而非成行或列的数据）进行索引、搜索、排序、过滤。Elasticsearch 对比传统关系型数据库如下：\nRDBMS ‐\u0026gt; DatabasES ‐\u0026gt; TablES ‐\u0026gt; Rows ‐\u0026gt; Columns Elasticsearch ‐\u0026gt; IndicES ‐\u0026gt; TypES ‐\u0026gt; Documents ‐\u0026gt; Fields\nindex 索引# 一个索引就是一个拥有几分相似特征的文档的集合。比如客户数据索引、产品目录索引、订单数据索引。索引由一个名字来标识（名称必须全部小写），当要对这个索引中的文档进行索引、搜索、更新和删除时都要使用到这个名字。一个集群中可以定义任意多的索引。可类比SqlServer中的数据库\ntype 类型# 一个索引中可以定义一种或多种类型。一个类型是索引的一个逻辑上的分类/分区，其语义完全自己定义。通常会为具有一组共同字段的文档定义一个类型。假设运营一个博客平台并且将所有的数据存储到一个索引中。在这个索引中，可以为用户数据定义一个类型，为博客数据定义另一个类型。可类比SqlServer中的表\n:rotating_light: 注意：ES 7.0 以及之后的版本中 Type 被废弃。一个 index 中只有一个默认的 type，即 _doc\nFiled字段# 相当于数据表的字段，对文档数据根据不同属性进行的分类标识 。\nmapping 映射# mapping 在处理数据的方式和规则方面做一些限制，如某个字段的数据类型、默认值、分析器、是否被索引等等，这些都可以在映射里设置，其它就是处理ES里面数据的一些使用规则设置也叫做映射，按最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。相当于SqlServer中的创建表的过程，设置主键外键等等\ndocument 文档# 一个文档是一个可被索引的基础信息单元。比如：客户文档、产品文档。文档以JSON（ Javascript Object Notation ）格式表示。一个 index/type 里可以存储任意多的文档。注意：尽管一个文档物理上存在于一个索引之中，但文档必须被索引赋予一个索引的 type 。 插入索引库以文档为单位，类比与数据库中的一行数据\ncluster 集群# 一个集群就是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认是“elasticsearch”。一个节点只能通过指定某个集群的名字，来加入这个集群。\nnode 节点# 一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能。一 个节点由一个名字来标识，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动时候赋予节点。\n一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做 elasticsearch 的集群中，这意味着，如果网络中启动了若干个节点，并假定它们能够相互发现彼此， 它们将会自动地形成并加入到一个叫 elasticsearch 的集群中。\n一个集群里可以拥有任意多个节点。而且如果当前网络中没有运行任何 Elasticsearch 节点， 这时启动一个节点，会默认创建并加入一个叫做 elasticsearch 的集群。\nshards 分片# 一个索引可以存储超出单个节点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch 提供了将索引划分成多份的能力，这些份就叫做分片。当创建一个索引时，可以指定想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因：\n允许水平分割/扩展内容容量 允许在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量 至于一个分片怎样分布，它的文档怎样聚合返回给搜索请求，是完全由Elasticsearch管理的，对于用户来说这些都是透明的。\nreplicas 复制# 在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。\n复制之所以重要，有两个主要原因\n在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。 扩展搜索量/吞吐量，因为搜索可以在所有的复制上并行运行。总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，可以在任何时候动态地改变复制的数量，但是事后不能改变分片的数量。 默认情况下，Elasticsearch 中的每个索引被分片5个主分片和1个复制，这意味着如果集群中有两个节点，索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。\n"},{"id":38,"href":"/docs/elk/1.2elastaticsearch%E9%85%8D%E7%BD%AE/","title":"1.2 Elastatic Search配置","section":"所有文章","content":"配置文件所在目录路径：安装目录/config/elasticsearch.yml\ncluster.name: elasticsearch\n配置集群名称。默认为 elasticsearch，如果在同一网段下有多个集群，可以用这个属性来区分不同的集群\nnode.name: “Franz Kafka”\n节点名称。默认为随机指定一个name列表中名字，该列表在ES的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字，大部分是漫威动漫里的人物名称\nnode.master: true\n指定该节点是否有资格被选举成为 node ，默认为 true。ES 默认集群中的第一台启动的机器为 master ，如果这台挂了就会重新选举 master\nnode.data: true\n指定该节点是否存储索引数据，默认为 true。如果节点配置 node.master:false 并且 node.data: false ，则该节点将只起到负载均衡作用\nindex.number_of_shards: 5\n设置默认索引分片个数，默认为5片。索引分片对ES的查询性能有很大的影响，在生产环境应该选择适合的分片大小\nindex.number_of_replicas: 1\n设置默认索引副本个数，默认为1个副本。此处1个副本是指 index.number_of_shards 的一个完全拷贝；默认5个分片1个拷贝。即总分片数为10\npath.conf: /path/to/conf\n设置配置文件存储路径。默认是ES根目录下的 config 文件夹\npath.data:/path/to/data1,/path/to/data2\n设置索引数据存储路径。默认是ES根目录下的 data 文件夹，可以设置多个存储路径，用逗号分割\npath.work:/path/to/work\n设置临时文件存储路径。默认是ES根目录下的 work 文件夹\npath.logs: /path/to/logs\n设置日志文件存储路径。默认是ES根目录下的 logs 文件夹\npath.plugins: /path/to/plugins\n设置插件的存放路径。默认是ES根目录下的 plugins 文件夹\nbootstrap.mlockall: true\n设置为 true 来锁住内存。因为当jvm开始 swapping 时es的效率会降低，所以要保证它不swap，可以把ES_MIN_MEM 和 ES_MAX_MEM 两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过ulimit -l unlimited命令\nnetwork.bind_host: 192.168.0.1\n设置绑定的ip地址，可以是ipv4或ipv6的，默认为 0.0.0.0\nnetwork.publish_host: 192.168.0.1\n设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，必须是个真实的ip地址\nnetwork.host: 192.168.0.1\n同时设置 bind_host 和 publish_host (上面两个参数)\ntransport.tcp.port: 9300\n设置节点间交互的tcp端口，默认是 9300\ntransport.tcp.compress: true\n设置是否压缩tcp传输时的数据，默认为 false 不压缩\nhttp.port: 9200\n设置对外服务的http端口，默认为 9200\nhttp.max_content_length: 100mb\n设置内容的最大容量，默认 100mb\nhttp.enabled: false\n是否使用http协议对外提供服务，默认为 true 开启\ngateway.type: local\ngateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器，其它文件系统的设置\ngateway.recover_after_nodes: 1\n设置集群中N个节点启动时进行数据恢复，默认为1\ngateway.recover_after_time: 5m\n设置初始化数据恢复进程的超时时间，默认是5分钟\ngateway.expected_nodes: 2\n设置集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复\ncluster.routing.allocation.node_initial_primaries_recoveries: 4\n初始化数据恢复时，并发恢复线程的个数，默认为4\ncluster.routing.allocation.node_concurrent_recoveries: 2\n添加删除节点或负载均衡时并发恢复线程的个数，默认为4\nindices.recovery.max_size_per_sec: 0\n设置数据恢复时限制的带宽，如入 100mb ，默认为0，即无限制。\nindices.recovery.concurrent_streams: 5\n设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5\ndiscovery.zen.minimum_master_nodes: 1\n设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）\ndiscovery.zen.ping.timeout: 3s\n设置集群中自动发现其它节点时 ping 连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错\ndiscovery.zen.ping.multicast.enabled: false\n设置是否打开多播发现节点，默认是true\ndiscovery.zen.ping.unicast.hosts: [“host1”, “host2:port”, “host3 [portX-portY] “]\n设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点\n上面是在安装时配置文件中就自带的配置项外，在实际使用过程还可能使用到下面的配置：\nthreadpool: search: type: fixed min: 60 max: 80 queue_size: 1000 // 配置es服务器的执行查询操作时所用线程池，fix固定线程数的线程池。index : store: type: memory // 表示索引存储在内存中，当然es不太建议这么做。经本人测试，做查询时，使用内存索引并不会比正常的索引快。index.mapper.dynamic: false // 禁止自动创建mapping。默认情况下，es可以根据数据类型自动创建mappingindex.query.parse.allow_unmapped_fields: false // 不能查找没有在mapping中定义的属性安装时自带的配置文件只包含一部分比较核心的配置项，更多的配置内容需要自己边搞边查了。更多配置参考\n"},{"id":39,"href":"/docs/elk/1.3%E4%BD%BF%E7%94%A8kibana%E6%93%8D%E4%BD%9Ces/","title":"1.3使用 Kibana操作 Es","section":"所有文章","content":"之前说到 ES 提供了 RESTful 风格的接口以便于我们操作，需要借助能够发送HTTP请求的工具调用这些API，工具是可以任意的，包括网页浏览器，当然也可以使用比如 Postman / Talend API tester等工具。这里为了学习 ElK 所以选择使用 Kibana，关于 Kibana 如何安装参考其他文章。\n集群相关# 查看集群健康信息# GET _cat/health?vepoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1646502528 17:48:48 elasticsearch green 1 1 3 3 0 0 0 0 - 100.0%主要字段描述：\ncluster：集群名称 status：集群状态 node.total：集群中的节点数 node.data：集群中的数据节点数 shards：集群中总的分片数量 pri：主分片数量，英文全称为 private relo：复制分片总数 unassign：未指定的分片数量，是应有分片数和现有的分片数的差值（包括主分片和复制分片） 集群共有 green 、yellow 、 red 三种状态：\ngreen 代表一切正常，集群功能齐全 yellow 代表所有数据都是可用的，但是某些复制没有被分配（集群功能齐全） red 代表因为某些原因，某些数据不可用。如果是red状态，数据很有可能已经丢失 可以在请求中添加 help 参数来查看每个操作返回结果字段的描述\nGET _cat/health?helpepoch | t,time | seconds since 1970-01-01 00:00:00 timestamp | ts,hms,hhmmss | time in HH:MM:SS cluster | cl | cluster name status | st | health status node.total | nt,nodeTotal | total number of nodes node.data | nd,nodeData | number of nodes that can store data shards | t,sh,shards.total,shardsTotal | total number of shards pri | p,shards.primary,shardsPrimary | number of primary shards relo | r,shards.relocating,shardsRelocating | number of relocating nodes init | i,shards.initializing,shardsInitializing | number of initializing nodes unassign | u,shards.unassigned,shardsUnassigned | number of unassigned shards pending_tasks | pt,pendingTasks | number of pending tasks max_task_wait_time | mtwt,maxTaskWaitTime | wait time of longest task pending active_shards_percent | asp,activeShardsPercent | active number of shards in percent ES中许多API都可以添加 help 参数来显示字段含义，如果觉得返回的东西太多看着烦，也可以人为指定返回的字段，比如：\nGET _cat/health?h=cluster,status\u0026amp;vcluster status elasticsearch green查看集群中节点信息# GET _cat/nodes?vip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 127.0.0.1 28 59 11 dilm * WANGPENGLIANG查看集群中索引信息# GET _cat/indices?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open .kibana_task_manager_1 BT3RImw0S9mVrEwQaKIc1Q 1 0 2 0 41.3kb 41.3kb green open .apm-agent-configuration 82PMto3PSt2UsRf7qYmfJg 1 0 0 0 283b 283b green open .kibana_1 xSc4xPL6TXica1mIT8005A 1 0 12 6 60.4kb 60.4kb更多的查看和监视 ElastaticSearch 的API查看：官网文档\n索引相关（Index）# 创建索引# 创建名为 movies 的 index ，两种写法等同，名字不能包含特殊字符，只能小写，不能以- , _ , + 开头，不能超过255字节。\n第一种方式：\nPUT movies第二种方式：本质是 PUT http://ip:9200/test，kibana 做了优化因此写不写之前的 / 都可以\nPUT /movies第三种方式：当向一个不存在的索引写入文档时，索引会自动被创建\nPUT movies/_doc/1 { \u0026#34;name\u0026#34;:\u0026#34;大话西游\u0026#34; }查看索引# 如果试图访问一个不存在的索引会报错。\nGET movies删除索引# 如果试图删除一个不存在的索引会报错。\nDELETE movies查看某字母开头的索引# GET _cat/indices/m*?v查询所有索引# GET _cat/indicesmappings / settings# 创建索引时指定 map# PUT movies { \u0026#34;mappings\u0026#34; : { \u0026#34;properties\u0026#34; : { \u0026#34;name\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34; } } } }创建索引后指定 map# PUT moviesPUT movies/_mapping { \u0026#34;properties\u0026#34; : { \u0026#34;name\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34; } } }创建索引时同时指定# 创建索引时指定分片数和副本数。\nPUT movies { \u0026#34;mappings\u0026#34; : { \u0026#34;properties\u0026#34; : { \u0026#34;name\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34; } } }, \u0026#34;settings\u0026#34; : { \u0026#34;index\u0026#34; : { \u0026#34;number_of_shards\u0026#34; : 1, \u0026#34;number_of_replicas\u0026#34; : 2 } } }修改副本数量# PUT movie/_settings { \u0026#34;index\u0026#34; : { \u0026#34;number_of_replicas\u0026#34; : 3 } }修改分片数量# 分片数量必须在索引创建时指定，创建后无法修改。尝试修改时会报错：\n# 请求 PUT movie/_settings { \u0026#34;index\u0026#34; : { \u0026#34;number_of_shards\u0026#34; : 3 } } # 响应 { \u0026#34;error\u0026#34;: { \u0026#34;root_cause\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;illegal_argument_exception\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Can\u0026#39;t update non dynamic settings [[index.number_of_shards]] for open indices [[movie/BPnIxSCwTvWNtze-4gDJaw]]\u0026#34; } ], \u0026#34;type\u0026#34;: \u0026#34;illegal_argument_exception\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Can\u0026#39;t update non dynamic settings [[index.number_of_shards]] for open indices [[movie/BPnIxSCwTvWNtze-4gDJaw]]\u0026#34; }, \u0026#34;status\u0026#34;: 400 }数据相关# 语法# 添加\n*****************添加************************* // 如果不传id, 则系统自动生成一个UUID POST /index/type/ { \u0026#34;属性名\u0026#34;:修改值 } # 或者 POST /index/type/id { \u0026#34;属性名\u0026#34;:修改值 } *****************修改************************* # 没有带上的属性会被清除 POST /index/type/id { \u0026#34;属性名\u0026#34;:修改值 } *****************查询************************* GET /index/type/id *****************删除************************* # 只是逻辑删除, 将其标记为 `delete` ，数据越来越多时, ES会自动物理删除 DELETE /index/type/id实例# "},{"id":40,"href":"/docs/go/01%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"01开发环境搭建","section":"所有文章","content":"🚩 人生苦短，Let\u0026rsquo;s go ，本系列所有测试代码均托管在：代码地址\n参考：\n李文周的博客\n跟煎鱼学 Go\n《Go语言编程》\n《Go入门指南》\n《Go语言圣经》\nGo 语言环境安装# 学习之前需要先安装GO语言的环境\n官网下载地址：https://golang.org/dl/ 官方镜像：https://golang.google.cn/dl/ Windows 平台和 Mac 平台推荐下载可执行文件版，Linux 平台下载压缩文件版。本机操作系统是 Windows，在下载地址中找到 .msi 后缀的安装包：\n下载到本地并安装，建议安装到指定目录下：\n通过 go version 测试是否安装成功：\nC:\\Users\\Administrator\u0026gt;go version go version go1.17.5 windows/amd64Go 支持以下操作系统：\nLinux FreeBSD MacOS Windows 针对其它平台的安装需要的话自行查找相关资料。\nGOPATH# GOPATH 是一个环境变量，用来指定工作目录。所有的 go 文件，都需要放在 GoPath 下的 src 目录下才能够编译运行。但是这么做存在几个问题：\n在项目中使用第三方类库时 通过 go get 命令拉取下来的包会直接下载到 GoPath 目录下的 src 包下，这就导致自己写的代码和第三方的文件混在一起，对于管理 Golang 项目的包是非常麻烦的。而且每个如果项目都需要同样的依赖，那么就会在不同的 GoPath 的 src 中下载大量重复的第三方依赖包，同样会占用大量的磁盘空间。\n能否通过给不同的项目设置不同的 GoPath 来解决依赖项目结构混乱问题？\n这么做便于管理项目，每个项目都是不同的 GoPath ，对于管理多个项目而言，能够非常清晰的处理项目结构。否则如果把所有项目都放在同一个 GoPath 的 src 包下，项目的结构就会变得非常混乱，难以管理。\n但是当需要依赖第三方的包的时候，上面的方式解决不了依赖重复的问题\n第三方依赖的包和自己的包混在一起，会给项目文件管理带来一定的麻烦。不同的 GoPath 都需要下载依赖，那么磁盘中重复的依赖就会非常多，会占用大量的磁盘空间。\n所以，究竟是设置一个GoPath目录，解决依赖重复的问题；还是设置不同的GoPath目录，解决Golang项目结构混乱的问题，这是一个有争议性的问题。为了解决这所有的问题，Golang 最终引入了 GoModule 的概念。\nGo Module# 在 go version\u0026lt;1.11前，使用 GOPATH 来构建应用，但在Go1.11版本之后不再推荐。go module 是Go语言从 1.11 版本之后官方推出的版本管理工具。\nModules 官方定义为：\nModules 是相关 Go 包的集合，是源代码交换和版本控制的单元。Go语言命令直接支持使用 Modules，包括记录和解析对其他模块的依赖性，Modules 替换旧的基于 GOPATH 的方法，来指定使用哪些源文件\n注意：Golang1.11和1.12 版本虽然已经引入了 GoModule 的概念，但是默认是不开启的，如果需要开启，需要配置环境变量：GO111MODULE=on，默认是 off。而在 Golang1.13 及以上的版本中，GoModule 的默认配置为 auto ，即 GoModule 会通过目录下是否有 go.mod 文件来判断是否开启 GoModule 。所以Golang1.13+ 的版本中就不再需要额外配置 GO111MODULE 属性。\nGO111MODULE=off ：禁用 go module，编译时会从 GOPATH 和 vendor 文件夹中查找包 GO111MODULE=on： 启用 go module，编译时会忽略 GOPATH 和 vendor 文件夹只根据 go.mod 下载依赖 GO111MODULE=auto：默认值，当项目在 GOPATH/src 目录之外，并且项目根目录有 go.mod 文件时，开启 go module Windows 下手动开启 GO111MODULE：\nset GO111MODULE=on 或者 set GO111MODULE=autoMacOS 或者 Linux 下手动开启 GO111MODULE：\nexport GO111MODULE=on 或者 export GO111MODULE=auto有了 GoModule 之后，GoPath 是不是就可以被舍弃了？\n不是的！之前说过 GoPath 所引出的问题，就是因为第三方类库的包所导致的，所以在有了 GoModule 之后，GoPath 和 GoModule 就分别负责不同的职责，共同为项目服务。\nGoPath 用来存放从网上拉取的第三方依赖包 GoModule 用来存放自己的Golang项目文件，当项目需要依赖第三方的包时通过 GoModule 目录下的 go.mod 文件来引用 GoPath 目录 src 包下的第三方依赖即可 这样既解决了原来只能局限在 GoPath/src 包下编程的问题，也解决了第三方依赖包难以管理和重复依赖占用磁盘空间的问题。在引入 GoModule 之后，不会直接在 GoPath 目录进行编程，而是把 GoPath 作为一个第三方依赖包的仓库，真正的工作空间在 GoModule 目录下。\nGo Module设置# 使用 go mod init 模块名称 命令对目录进行初始化操作，即可将这个目录设置为 GoModule 目录。\nD:\\GoProject\u0026gt;go mod init goProject初始化命令执行完毕之后，会在 D:\\GoProject\u0026gt; 目录下生成一个 go.mod 文件，该文件就是用来引入 GoPath 目录下的第三方依赖的文件。\n初始化之后的 go.mod 文件\nmodule goProject go 1.17当需要引入 GoPath 目录下的第三方依赖包的时候，只需要在 go.mod 目录下添加依赖名称，GoModule 就会自动把第三方依赖包下载到 GoPath 目录下。例如下面的 go.mod 文件：\nmodule go_module_demo go 1.17 require ( github.com/astaxie/beego v1.12.1 github.com/go-sql-driver/mysql v1.5.0 )在这个 go.mod 文件中引入了两个依赖，分别是：beego框架 v1.12.1版本 和 mysql驱动 v1.5.0版本 。\n常用命令如下：\n命令 作用 go mod download 下载依赖包到本地（默认为 GOPATH/pkg/mod 目录） go mod edit 编辑 go.mod 文件 go mod graph 打印模块依赖图 go mod init 初始化当前文件夹，创建 go.mod 文件 go mod tidy 增加缺少的包，删除无用的包 go mod vendor 将依赖复制到 vendor 目录下 go mod verify 校验依赖 go mod why 解释为什么需要依赖 GO PROXY# 国内的网络因为防火墙的存在导致有些Go语言的第三方包无法直接通过 go get 命令获取。GOPROXY 是Go官方提供的一种通过中间代理商来为用户提供包下载服务的方式。要使用 GOPROXY 只需要设置环境变量 GOPROXY 即可。\n目前公开的代理服务器的地址有：\ngoproxy.io goproxy.cn：（推荐）由国内的七牛云提供 Windows 下设置 GOPROXY ：\ngo env -w GOPROXY=https://goproxy.cn,directMacOS 或 Linux 下设置 GOPROXY ：\nexport GOPROXY=https://goproxy.cn Go 在 1.13 版本之后 GOPROXY 默认值为 https://proxy.golang.org，在国内可能会存在下载慢或者无法访问的情况，所以建议将 GOPROXY 设置为国内的 goproxy.cn\n下载指定版本：\n执行 go get 命令，在下载依赖包的同时还可以指定依赖包的版本。\n运行 go get -u 命令会将项目中的包升级到最新的次要版本或者修订版本 运行 go get -u=patch 命令会将项目中的包升级到最新的修订版本 运行 go get [包名]@[版本号] 命令会下载对应包的指定版本或者将对应包升级到指定的版本 注意：go get [包名]@[版本号]命令中版本号可以是 x.y.z 的形式，例如 go get foo@v1.2.3，也可以是 git 上的分支或 tag，例如 go get foo@master，还可以是 git 提交时的哈希值，例如 go get foo@e3702bed2\nHello, World# 老规矩先搞一个 hello world 看看，创建 GoProject 目录，目录格式如下：\nD:\\GoProject\u0026gt;tree 卷 Data 的文件夹 PATH 列表 卷序列号为 189B-A748 D:. └─srcgo mod init# 使用 go module 模式新建项目时，需要通过 go mod init 项目名 命令对项目进行初始化，该命令会在项目根目录下生成 go.mod 文件。比如：\nD:\\GoProject\\src\u0026gt;go mod init goProject编写代码# package main import \u0026#34;fmt\u0026#34; func main() { /* go 语言的hello world */ fmt.Println(\u0026#34;Hello, World!\u0026#34;) }第一行：package main，定义包名，必须在源文件中非注释的第一行指明这个文件属于哪个包，比如：package main 表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。类似于 C# 中的 namespace，表示处于哪个命名空间下。\n第二行：import \u0026quot;fmt\u0026quot;，告诉 Go 编译器这个程序需要使用 fmt 包的函数或其他元素，fmt 包实现了格式化 IO（输入/输出）的函数。类似于在 C# 中需要引用其他 namespace 中的函数时需要使用 using。\n第三行：func main()，表示程序开始执行的函数。main 函数是每一个可执行程序所必须包含的，一般来说都是在启动后第一个执行的函数（如果有 init() 函数则会先执行该函数）。类似于C#中作为入口方法的Main()方法。\n第四行：/*...*/： 注释，单行使用//，多行使用/**/ 这没什么好说的。\n第五行：fmt.Println(...): 用于将字符串输出到控制台，并在最后自动增加换行字符 \\n。类似于 C# 中的 Console.WriteLine() /Console.Write()。\ngo build# go build 命令表示将源代码编译成可执行文件。在 D:\\GoProject\\src\u0026gt; 目录下执行：\nD:\\GoProject\\src\u0026gt;go build test.go D:\\GoProject\\src\u0026gt;dir 驱动器 D 中的卷是 Data 卷的序列号是 189B-A748 D:\\GoProject\\src 的目录 2022/01/04 周二 16:12 1,924,096 test.exe 2022/01/04 周二 15:57 111 test.go编译得到的可执行文件会保存在执行编译命令的当前目录下，如果是windows平台会在当前目录下找到 test.exe 可执行文件。\n可在终端直接执行该 test.exe 文件：\nD:\\GoProject\\src\u0026gt;test.exe Hello, World!go run# Go 是一门编译型语言，Go 语言的工具链将源代码及其依赖转换成计算机的机器指令（静态编译）。Go语言提供的工具都通过一个单独的命令 go 调用，go 命令有一系列子命令。最简单的一个子命令就是 run。这个命令编译一个或多个以 .go 结尾的源文件，链接库文件，并运行最终生成的可执行文件。\n跨平台编译# 默认 go build 的可执行文件都是当前操作系统可执行的文件，如果想在 windows 下编译一个 linux 下可执行文件，可以这么做：\n指定目标操作系统的平台和处理器架构：\nSET CGO_ENABLED=0 // 禁用CGO SET GOOS=linux // 目标平台是linux SET GOARCH=amd64 // 目标处理器架构是amd64使用了cgo的代码是不支持跨平台编译的\n然后再执行 go build 命令，得到的就是能够在 linux 平台运行的可执行文件了。\nMac 下编译 Linux 和 Windows平台 64位 可执行程序：\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go buildLinux 下编译 Mac 和 Windows 平台64位可执行程序：\nCGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go buildWindows下编译Mac平台64位可执行程序：\nSET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 go build现在，开启 Go 语言学习之旅。\n"},{"id":41,"href":"/docs/go/02%E5%8F%98%E9%87%8F%E5%92%8C%E5%B8%B8%E9%87%8F/","title":"02变量和常量","section":"所有文章","content":"变量和常量是编程中必不可少的部分，也是比较好理解的一部分。\n标识符# 编程语言中标识符指：由程序员定义的具有特殊意义的词，比如变量名、常量名、函数名等。 Go语言中标识符由字母数字和_(下划线）组成，并且只能以字母和_开头且区分大小写。 比如：abc, _123, a123。\n关键字# 关键字指：编程语言中预先定义好的具有特殊含义的标识符。 关键字和保留字都不建议用作变量名。Go 语言中类似 C# 的关键字有25个，只能在特定语法结构中使用：\nbreak default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var除此之外Go语言中还有30多个预定义的名字，比如 int 和 ture 等，主要对应内建的常量、类型和函数：\n内建常量: true false iota nil 内建类型: int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr float32 float64 complex128 complex64 bool byte rune string error 内建函数: make len cap new append copy close delete complex real imag panic recover通常在 Go 语言编程中推荐的命名方式是驼峰命名。如：ReadAll，不推荐下划线命名。\n变量# 变量声明# 变量声明语法如下：\nvar 变量名字 类型 = 表达式\t// 指定变量类型但不赋值，使用默认值 var v1 int // 省略表达式，使用数值类型对应的零值初始化（0） var v2 string // 省略表达式，使用字符串对应的零值初始化（空字符串） var v3 [10]int // 会创建长度为10的数据 var v4 []int // 数组切片 var v5 struct { // {0} f int } var v6 *int // 指针,因未被初始化所以默认值为nil var v7 map[string]int // map,key为string类型，value为int类型,默认值为map[] var v8 func(a int) int // 函数类型,因未被初始化所以默认值为nil,直接调用会抛出空指针异常 fmt.Println(v1, v2, v3, v4, v5, v6, v7, v8)注意：\nGo 语言中变量声明采用类型后置方式，需要先声明变量名称再声明变量类型 语句最后不需要加;（如果需要一行写多条语句需要，但不推荐这么干） 如果定义的是局部变量，则必须使用，否则编译报错 批量声明# // 多变量声明使用此方式避免重复写var var ( v1 int v2 string )或者这样：\nvar n1, n2, n3 string n1, n2, n3 = \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;再或者这样：\nvar n4, n5, n6 = \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;变量初始化# 通常情况下 类型 或 = 表达式 两个部分可以省略其中的一个。如果省略的是类型信息，将根据初始化表达式来推导变量的类型信息。如果初始化表达式被省略，那么将用零值初始化该变量。\n数值类型变量对应的零值是 0 布尔类型变量对应的零值是 false 字符串类型对应的零值是 空字符串 接口或引用类型（包括slice、map、chan和函数）变量对应的零值是 nil 数组或结构体等聚合类型对应的零值是每个元素或字段对应类型的零值 零值初始化机制可以确保每个声明的变量总是有一个良好定义的值，以保证不存在未初始化的变量。\n1：指定类型但不赋值# 指定类型但不赋值，将使用类型的默认零值。\nvar name string // 省略表达式，使用字符串对应的零值初始化（空字符串） var age int // 省略表达式，使用数值类型对应的零值初始化（0） fmt.Println(name, age)2：使用类型推断# var address = \u0026#34;beijing\u0026#34; fmt.Println(address)3：简短声明# 简短声明，以名字 := 表达式 形式声明变量，变量的类型根据表达式来自动推导。\nsex := \u0026#34;男\u0026#34; fmt.Println(sex)4：使用 new 函数# 调用内建的 new 函数创建变量。表达式 new(T)将创建一个 T 类型的匿名变量，初始化为 T 类型的零值，然后返回变量地址，返回的指针类型为*T。\np := new(int) // p, *int 类型, 指向匿名的 int 变量 fmt.Println(*p) // \u0026#34;0\u0026#34; *p = 2 // 设置 int 匿名变量的值为 2 fmt.Println(*p) // \u0026#34;2\u0026#34;new 函数创建变量和普通变量声明语句方式创建变量没有什么区别，除了不需要声明一个临时变量的名字外，还可以在表达式中使用 new(T)。其实这就是一种语法糖，而不是一个新的基础概念。new 函数使用通常相对比较少，因为对于结构体来说，直接用字面量语法创建新变量的方法会更灵活。由于 new 只是一个预定义的函数，它并不是一个关键字，因此可以将 new 名字重新定义为别的类型。例如下面的例子：\nfunc delta(old, new int) int { return new - old }由于 new 被定义为 int 类型的变量名，因此在 delta 函数内部无法使用内置的 new 函数。\n全局变量# 全局声明变量，如果没有使用不会编译报错。\npackage main var ( author string address string ) func main() { }匿名变量# 在使用多重赋值时，如果想要忽略某个值，可以使用 匿名变量（anonymous variable）。 匿名变量用一个下划线_表示，比如：\n// 该函数返回两个值 func getName() (firstName, lastName string) { return \u0026#34;wangpengliang\u0026#34;, \u0026#34;lizimeng\u0026#34; } func main() { // _ 代表匿名变量,匿名变量将会被忽略 result, _ := getName() fmt.Println(result) }匿名变量不占用命名空间，不会分配内存，所以匿名变量之间不存在重复声明。 (在Lua等编程语言里，匿名变量也被叫做哑元变量)\n注意：\n函数外的每个语句都必须以关键字开始（var、const、func等） := 不能使用在函数外 _ 多用于占位，表示忽略值 变量生命周期# 变量的生命周期指的是在程序运行期间变量有效存在的时间段。\n对于在包一级声明的变量来说，它们生命周期和整个程序的运行周期一致 在局部变量的声明周期是动态的：从每次创建一个新变量的声明语句开始，直到该变量不再被引用为止，然后变量的存储空间可能被回收 函数的参数变量和返回值变量都是局部变量。它们在函数每次被调用的时候创建 这里需要注意一个问题，看以下代码：\nvar global *int func f() { var x int x = 1 global = \u0026amp;x } func g() { y := new(int) *y = 1 }f() 里的 x 变量必须在堆上分配，因为它在函数退出后依然可以通过包一级的 global 变量找到，虽然它是在函数内部定义的。用Go语言的术语说，这个 x 局部变量从函数 f 中逃逸了。相反，当 g 函数返回时，变量 *y 将是不可达的，也就是说可以马上被回收的。因此：*y 并没有从函数 g 中逃逸，虽然这里用的是 new 方式。编译器会自动选择在栈上还是在堆上分配局部变量的存储空间 而不是用 var 还是 new 声明变量的方式区分。\n变量赋值# 使用赋值语句可以更新一个变量的值，最简单的赋值语句是将要被赋值的变量放在=的左边，新值的表达式放在=的右边。\nx = 1 // 命名变量的赋值 *p = true // 通过指针间接赋值 person.name = \u0026#34;bob\u0026#34; // 结构体字段赋值 count[x] = count[x] * scale // 数组、slice或map的元素赋值特定的二元算术运算符和赋值语句的复合操作有一个简洁形式，例如上面最后的语句可以重写为：\ncount[x] *= scale这样可以省去对变量表达式的重复计算。数值变量也可以支持 ++ 递增和 -- 递减语句\nv := 1 v++ // 等价方式 v = v + 1；v 变成 2 v-- // 等价方式 v = v - 1；v 变成 1除此之外Go语言还支持多重赋值，在不支持多重赋值的语言中，交换两个变量的内容需要引入一个中间变量，但是Go语言中不需要，比如：\nvar i int = 10 var j int = 20 i, j = j, i包和文件# Go 语言中的包与C#中的 namespace 的概念类似，目的都是为了支持模块化、封装、单独编译和代码重用。每个Go文件都只能属于一个包。一个包可以由许多以 .go 为扩展名的源文件组成，因此文件名和包名一般来说都是不相同的。\n包初始化顺序# 如果包中含有多个 .go 源文件，将按照发给编译器的顺序进行初始化，Go语言的构建工具首先会将 .go 文件根据文件名排序，然后依次调用编译器编译。\n包级别变量处理# 对于在包级别声明的变量，如果有初始化表达式则用表达式初始化，如果存在没有初始化表达式的，可以用一个特殊的 init 初始化函数来简化初始化工作。每个文件可以包含多个 init 初始化函数。\nfunc init() { }init 初始化函数除了不能被调用或引用外，其他行为和普通函数类似。每个文件中的 init 初始化函数，在程序开始执行时按照声明的顺序被自动调用。 每个包在解决依赖的前提下，以导入声明的顺序初始化，每个包只会被初始化一次。因此，如果 a 包 导入了 b 包，那么在 a 包初始化的时候可以认为 b 包必然已经初始化过了。初始化工作是自下而上进行的， main 包最后被初始化。这种方式可以确保在 main 函数执行之前所有依赖的包都已经完成初始化。\n导出包# Go 语言中根据首字母的大小写来确定可以访问的权限。如果首字母大写则可以被其他的包访问；如果首字母小写，则只能在本包中使用。该规则适用于全局变量、全局常量、类型、结构字段、函数、方法等。可以简单的理解成：首字母大写是公有的，首字母小写是私有的。只能访问包导出的名字，未导出的名字不能被包外的代码访问。\n导入包# 使用包成员需要使用 import 关键字导入，但不能形成导入循环。\n导入系统包：\nimport \u0026#34;fmt\u0026#34; 相对路径导入包：导入同一目录下 test 包\nimport \u0026#34;./test\u0026#34; 绝对路径导入包：导入 gopath/src/oldboy/python 包\nimport \u0026#34;oldboy/python\u0026#34;导入包并启用别名：导入fmt并启用别名 f2\nimport f2 \u0026#34;fmt\u0026#34;将 fmt 启用别名.可以直接使用内容而不用再添加 fmt 。比如 fmt.Println 可以直接写成 Println\nimport . \u0026#34;fmt\u0026#34; import _\nimport _ \u0026#34;fmt\u0026#34; 这表示只使用该包的 init 函数，并不使用该包的其他内容。这种形式的 import ，在 import时就执行了 fmt 包中的 init 函数。\n注意：未使用的导入包，会被编译器视为错误 (不包括 \u0026quot;import _\u0026quot;)。实例如下：\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { }编译错误：\n./main.go:4:2: imported and not used: \u0026#34;fmt\u0026#34;作用域# 一个声明语句将程序中的实体和一个名字关联，比如一个函数或一个变量。声明语句的作用域是指源代码中可以有效使用这个名字的范围。\n作用域和生命周期不能混为一谈。声明语句的作用域对应的是一个源代码的文本区域；它是一个编译时的属性。一个变量的生命周期是指程序运行时变量存在的有效时间段，在此时间区域内它可以被程序的其他部分引用；是一个运行时的概念。\n声明语句对应的词法域决定了作用域范围的大小。对于内置的类型、函数和常量，比如 int、len和 true 等是在全局作用域的，因此可以在整个程序中直接使用。任何在函数外部（也就是包级语法域）声明的名字可以在同一个包的任何源文件中访问的。对于导入的包，例如 tempconv 导入的 fmt 包，则是对应源文件级的作用域，因此只能在当前的文件中访问导入的 fmt 包，当前包的其它源文件无法访问在当前源文件导入的包。还有许多声明语句，比如 tempconv.CToF 函数中的变量 c，则是局部作用域的，它只能在函数内部（甚至只能是局部的某些部分）访问。\n常量# 常量表达式的值在编译期计算，而不是在运行期。每种常量的潜在类型都是基础类型：boolean、string或数字。Go语言中常量指：编译期间就已知且不可改变的值。使用 const 关键字定义常量。\nconst PI float64 = 3.14159265358979323846 // 显式类型定义,常量名称推荐全大写 const LENGTH int = 10 // 隐式类型定义,其实也是使用类型推导 const WIDTH = 20 // 多重定义 const ( size int64 = 1024 eof = -1 // 无类型整型常量 ) // 或者这样 const a, b, c = 1, false, \u0026#34;hello world\u0026#34; // 常量的多重赋值iota# 常量声明可以使用 iota 常量生成器初始化，它用于生成一组以相似规则初始化的常量，但是不用每行都写一遍初始化表达式。在一个 const 声明语句中，在第一个声明的常量所在行的 iota 将会被置为 0 ，然后在每一个有常量声明的行加 1。(Go语言没有枚举类型，可以使用 const+iota 模拟)\n关键字 iota 定义常量组中从0开始按行计数的自增枚举值。iota 在 const 关键字出现时将被重置为0 (const内部的第一行之前)，const中每新增一行常量声明将使 iota 计数一次。\n普通常量组：如果不指定类型和初始化值，则与上一行非空常量右值相同\nconst ( Windows = 0 Linux MaxOS ) fmt.Println(Windows, Linux, MaxOS) // output: 0 0 0结合 iota 实现枚举：第一个 iota 等于0，每当 iota 在新的一行被使用，它的值自增1\nconst ( Sunday = iota // 0 Monday // 1,通常省略后续行行表达式。 Tuesday // 2 Wednesday // 3 Thursday // 4 Friday // 5 Saturday // 6 ) fmt.Println(Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)iota 插队：\nconst ( a1 = iota // 0 a2 // 1 b1 = \u0026#34;hello\u0026#34; // 独立值hello,iota+=1 b2 // 如不指定类型和初始化值，则与上一行非空常量右值相同,所以是hello;iota+=1 c1 = iota // 恢复自增,4 c2 // 5 ) fmt.Println(a1, a2, b1, b2, c1, c2) // output:0 1 hello hello 4 5iotl 忽略：使用 _ 忽略某些值\nconst ( d1 = iota d2 _ d3 ) fmt.Println(d1, d2, d3) // output:0 1 3iota 定义数量级\nconst ( _ = iota // _表示将0忽略 KB = 1 \u0026lt;\u0026lt; (10 * iota) // 表示1左移十位，转换为十进制就是1024 MB = 1 \u0026lt;\u0026lt; (10 * iota) GB = 1 \u0026lt;\u0026lt; (10 * iota) TB = 1 \u0026lt;\u0026lt; (10 * iota) PB = 1 \u0026lt;\u0026lt; (10 * iota) )同一常量组中，可以提供多个 iota，它们各自增⻓。\nconst ( a, b = iota + 1, iota + 2 // a=iota+1 b=iota+2 =\u0026gt; 1,2 c, d // c=iota(1)+1 b=iota(2)+1 =\u0026gt; 2,3 ) fmt.Println(a, b, c, d)"},{"id":42,"href":"/docs/go/03%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"03基本数据类型","section":"所有文章","content":"布尔类型# Go语言中的布尔类型与其他语言基本一致，关键字也为 bool 。布尔型数据只有 true / false 两个值。\nvar a1 = false var a2 = true fmt.Println(a1, a2)注意：\n布尔类型变量的默认值为 false Go 语言中不允许将整型强制转换为布尔型 布尔型无法参与数值运算，也无法与其他类型进行转换 复数# 复数有实部和虚部，complex64 的实部和虚部为32位，complex128 的实部和虚部为64位，用的比较少不做详细记录。\nvar c1 complex64 c1 = 1 + 2i var c2 complex128 c2 = 2 + 3i fmt.Println(c1) fmt.Println(c2)整型# 整型分为以下两个大类：有符号整形按长度分为：int8、int16、int32、int64，对应的无符号整型：uint8、uint16、uint32、uint64\n类型 范围 占用空间(字节) int8 (-128 到 127) -2^7 到 2^7-1 1 Byte int16 (-32768 到 32767) -2^15 到 2^15-1 2 Byte int32 (-2147483648 到 2147483647) -2^31 到 2^31-1 4 Byte int64 (-9223372036854775808 到 9223372036854775807) -2^63 到 2^63-1 8 Byte uint8 (0 到 255) 0 到 2^8-1 1 Byte uint16 (0 到 65535) 0 到 2^16-1 2 Byte uint32 (0 到 4294967295) 0 到 2^32-1 4 Byte uint64 (0 到 18446744073709551615) 0 到 2^64-1 8 Byte 特殊整型# 类型 描述 uint 32 位操作系统上就是 uint32，64 位操作系统上就是 uint64 int 32 位操作系统上就是 int32，64 位操作系统上就是 int64 uintptr 无符号整型，用于存放一个指针 注意： 在使用 int 和 uint 类型时，不能假定它是 32 位或 64 位的整型，而是考虑 int 和 uint 可能在不同平台上的差异\n字节(Byte)# 字节也叫 Byte，是计算机数据的基本存储单位。1Byte(字节)=8bit(位) 1024Byte(字节)=1KB。中文字符在 unicode 下占2个字节，在 utf-8 编码下占3个字节，go 默认编码是 utf-8。\nunsafe.Sizeof(n1) 是 unsafe包的一个函数，可以返回变量占用的字节数。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { var a int8 = 120 fmt.Printf(\u0026#34;%T\\n\u0026#34;, a) fmt.Println(unsafe.Sizeof(a)) }输出：\nPS D:\\GoProject\u0026gt; go run .\\test.go int8 1数字字面量语法# Go1.13 版本之后引入了数字字面量语法，便于以二进制、八进制或十六进制浮点数的格式定义数字，例如：\nfunc numberLiteralsSyntax() { // 代表二进制的 101101，相当于十进制的 45 v1 := 0b00101101 fmt.Printf(\u0026#34;value:%v type:%T \\n\u0026#34;, v1, v1) // 代表八进制的377，相当于十进制的 255 v2 := 0o377 fmt.Printf(\u0026#34;value:%v type:%T \\n\u0026#34;, v2, v2) // 代表十六进制的 1 除以 2²，也就是 0.25 v3 := 0x1p-2 fmt.Printf(\u0026#34;value:%v type:%T \\n\u0026#34;, v3, v3) // 使用“_”分隔数字 v4 := 123_456 fmt.Printf(\u0026#34;value:%v type:%T \\n\u0026#34;, v4, v4) }借助 fmt 函数以不同进制形式显示整数\nfunc convertOutput() { // 十进制 var a int = 10 fmt.Printf(\u0026#34;十进制:%d 二进制:%b \\n\u0026#34;, a, a) // %d表示十进制,%b表示二进制 // 八进制以0开头 var b int = 077 fmt.Printf(\u0026#34;八进制:%o 二进制:%d\\n\u0026#34;, b, b) // %o表示八进制,%d表示十进制 // 十六进制 以 0x 开头 var c int = 0xff fmt.Printf(\u0026#34;十六进制:%x 十六进制大写:%X 十进制:%d 变量类型:%T \\n\u0026#34;, c, c, c, c) //%x 表示十六进制,%X 表示大写的十六进制,%d 表示十进制,%T 查看变量类型 // int不同长度转换 var num1 int8 = 127 num2 := int32(num1) fmt.Printf(\u0026#34;value:%v type:%T \\n\u0026#34;, num2, num2) }不同长度转换# package main import ( \u0026#34;fmt\u0026#34; ) func main() { var num1 int8 num1 = 127 num2 := int32(num1) fmt.Printf(\u0026#34;值:%v 类型%T\u0026#34;, num2, num2) }浮点型# Go 语言支持两种浮点型数：float32 和 float64。\n这两种浮点型数据格式遵循 IEEE 754 标准\nfloat32 最大范围约为 3.4e38，可以使用常量定义：math.MaxFloat32 float64 最大范围约为 1.8e308，可以使用常量定义：math.MaxFloat64 打印浮点数时可以使用 fmt 包配合动词 %f，比如：\nvar f float64 = 3.1415926 fmt.Printf(\u0026#34;%f\\n\u0026#34;, f) // 默认保留6位小数 fmt.Printf(\u0026#34;%.2f\\n\u0026#34;, f) // 保留2位小数 fmt.Printf(\u0026#34;值:%v,类型:%T \\n\u0026#34;, f, f) // 浮点数默认类型是float64 fmt.Println(math.MaxFloat32) // 输出float32最大值 fmt.Println(math.MaxFloat64) // 输出float64最大值 // 科学计数法表示浮点类型 n1 := 5.1234e2 n2 := 5.1234e2 n3 := 5.1234e-2 fmt.Println(\u0026#34;n1=\u0026#34;, n1, \u0026#34;n2=\u0026#34;, n2, \u0026#34;n3=\u0026#34;, n3)\t精度丢失问题# 精度丢失是几乎所有的编程语言都有的问题，是典型的二进制浮点数精度损失问题。在定长条件下，二进制小数和十进制小数互转可能有精度丢失，Go也不例外，观察以下代码：\nfunc floatPrecisionLossTest() { d := 1129.6 fmt.Println(d * 100) // 此处结果应该是：112960，实际打印的却是：112959.99999999999 m1 := 8.2 fmt.Printf(\u0026#34;值:%v--类型:%T \\n\u0026#34;, m1, m1) m2 := 3.8 fmt.Printf(\u0026#34;值:%v--类型:%T \\n\u0026#34;, m2, m2) fmt.Println(m1 - m2) // 此处结果应该是：4.4，实际打印：4.3999999999999995 }解决精度丢失问题# 使用第三方包需要使用 go mod ，关于 go mod 参考之前的章节。引入第三方包解决经度丢失问题：\nPS D:\\GoProject\\src\u0026gt; go get github.com/shopspring/decimal go: downloading github.com/shopspring/decimal v1.3.1 go get: added github.com/shopspring/decimal v1.3.1import ( \u0026#34;github.com/shopspring/decimal\u0026#34; )/* 使用第三方包解决float精度丢失问题：go get github.com/shopspring/decimal 文档：https://pkg.go.dev/github.com/shopspring/decimal#section-readme */ func floatPrecisionLossSolveTest() { a := decimal.NewFromFloat(1129.6) b := decimal.NewFromInt(100) fmt.Println(a.Mul(b)) // output:112960 c := decimal.NewFromFloat(8.2) d := decimal.NewFromFloat(3.8) fmt.Println(c.Sub(d)) // output:4.4 // 初始化一个变量 d0 := decimal.NewFromFloat(0) // 设置精度 为三位 四舍五入的精度 decimal.DivisionPrecision = 3 fmt.Println(d0) // 加法 Add var f1 float64 = 2.1 var i1 int = 3 fmt.Println(decimal.NewFromFloat(f1).Add(decimal.NewFromFloat(float64(i1)))) // 2.1 + 3: float和int相加=\u0026gt;output: \u0026#34;5.1\u0026#34; var f2 float64 = 2.1 var f3 float64 = 3.1 fmt.Println(decimal.NewFromFloat(f2).Add(decimal.NewFromFloat(f3))) // 2.1 + 3.1 (float和float相加)=\u0026gt;output: \u0026#34;5.2\u0026#34; var f4 float64 = 2 var f5 float64 = 3 fmt.Println(decimal.NewFromFloat(f4).Add(decimal.NewFromFloat(f5))) // 2 + 3 (int和int相加 可以直接相加 d1 = num1+num2)=\u0026gt; output: \u0026#34;5\u0026#34; // 减法 Sub var f7 float64 = 3.1 var f8 int = 2 d1 := decimal.NewFromFloat(f7).Sub(decimal.NewFromFloat(float64(f8))) // 3.1 - 2 float和int相减 =\u0026gt; output: \u0026#34;1.1\u0026#34; fmt.Println(d1) var n1 float64 = 2.1 var n2 float64 = 3.1 fmt.Println(decimal.NewFromFloat(n1).Sub(decimal.NewFromFloat(n2))) // 2.1 - 3.1 (float和float相减)=\u0026gt;output: \u0026#34;-1\u0026#34; var n3 int = 2 var n4 int = 3 fmt.Println(decimal.NewFromFloat(float64(n3)).Sub(decimal.NewFromFloat(float64(n4)))) // 2 - 3 (int和int相减 d1 = num1 - num2) =\u0026gt; output: \u0026#34;-1\u0026#34; // 乘法 Mul var n5 float64 = 3.1 var n6 int = 2 fmt.Println(decimal.NewFromFloat(n5).Mul(decimal.NewFromFloat(float64(n6)))) // 3.1 * 2 float和int相乘 =\u0026gt; output: \u0026#34;6.2\u0026#34; var n7 float64 = 2.1 var n8 float64 = 3.1 fmt.Println(decimal.NewFromFloat(n7).Mul(decimal.NewFromFloat(n8))) // 2.1 * 3.1 (float和float相乘) =\u0026gt; output: \u0026#34;6.51\u0026#34; var n9 int = 2 var n10 int = 3 fmt.Println(decimal.NewFromFloat(float64(n9)).Mul(decimal.NewFromFloat(float64(n10)))) // 2 * 3 int和int相乘(d1 = num1 * num2) =\u0026gt; output: \u0026#34;6\u0026#34; // 除法 Div var n11 int = 2 var n12 int = 3 fmt.Println(decimal.NewFromFloat(float64(n11)).Div(decimal.NewFromFloat(float64(n12)))) // 2 / 3 = 0.6666666666666667 =\u0026gt; output: \u0026#34;0.6666666666666667\u0026#34; // float64 和 int 相除 var num13 float64 = 2.1 var num14 int = 3 fmt.Println(decimal.NewFromFloat(num13).Div(decimal.NewFromFloat(float64(num14)))) // output: \u0026#34;0.7\u0026#34; // float64 和 float64 相除 var num15 float64 = 2.1 var num16 float64 = 0.3 fmt.Println(decimal.NewFromFloat(num15).Div(decimal.NewFromFloat(num16))) // output: \u0026#34;7\u0026#34; // int 和 int 相除 并保持3位精度 var num17 int = 2 var num18 int = 3 decimal.DivisionPrecision = 3 result := decimal.NewFromFloat(float64(num17)).Div(decimal.NewFromFloat(float64(num18))) // 2/3 = 0.667 =\u0026gt; output: \u0026#34;0.667\u0026#34; fmt.Println(result) }科学计数法表示# n1 := 5.1234e2 n2 := 5.1234e2 n3 := 5.1234e-2 fmt.Println(\u0026#34;n1=\u0026#34;, n1, \u0026#34;n2=\u0026#34;, n2, \u0026#34;n3=\u0026#34;, n3)字符串# Go 语言中，一个字符串是一个不可改变的字节序列。字符串可以包含任意的数据，包括byte值0，但是通常用来保存人类可读的文本。\nGo的字符串是由 Utf-8 编码之后的字节序列，所以不能修改。\n1个汉字占用3个字节 1个英文字母占用1个字节 Go使用 rune（1个int32类型的数字） 表示中文字符，使用 byte（1个uint8类型的数字）表示英文。Go语言中组成字符串的最小单位是字符，存储的最小单位是字节，字符串本身不支持修改。字节是数据存储的最小单元，每个字节的数据都可以用整数表示，例如一个字节储存的字符 a，实际存储的是 97 而非字符的字形，将这个实际存储的内容用数字表示的类型，称之为 byte。\nlen# 内置的 len 函数用于返回一个字符串中的字节数目（不是 rune 字符数目），索引操作 s[i] 返回第 i 个字节的字节值，i 必须满足 0 ≤ i\u0026lt; len(s) 条件约束。\ns := \u0026#34;hello, world\u0026#34; fmt.Println(len(s)) // \u0026#34;12\u0026#34; fmt.Println(s[0], s[7]) // \u0026#34;104 119\u0026#34; (\u0026#39;h\u0026#39; and \u0026#39;w\u0026#39;)如果试图访问超出字符串索引范围的字节将会导致 panic 异常：\nc := s[len(s)] // panic: index out of range第 i 个字节并不一定是字符串的第 i 个字符，因为对于非 ASCII 字符的 UTF8 编码会要两个或多个字节。\n比如：\ns := \u0026#34;abc北京\u0026#34; fmt.Printf(\u0026#34;字节长度：%d \\n\u0026#34;, len(s)) //output:9 // 返回字符串每个字节的值 for i := 0; i \u0026lt; len(s); i++ { fmt.Println(s[i]) }输出：\n字节长度：9 97 // a 98 // b 99 // c 229 // 北 140 // 北 151 // 北 228 // 京 186 // 京 172 // 京英文字母占用一个字节：97：a/98：b/99：c，汉字占用三个字节：229/140/151组成北，228/186/172组成京\n如果要获取字符串中字符的个数，需要先把字符串转换成 []rune 类型，然后用 len() 函数获取字符个数：\nr := []rune(s) fmt.Print(len(r)) // output:5字符串不可变性# 字符串的值是不可变的：一个字符串包含的字节序列永远不会被改变，当然也可以给一个字符串变量分配一个新字符串值。可以像下面这样将一个字符串追加到另一个字符串：\ns := \u0026#34;left foot\u0026#34; t := s s += \u0026#34;, right foot\u0026#34;这并不会导致原始的字符串值被改变，但是变量 s 将因为 += 语句持有一个新的字符串值，但是 t 依然是包含原先的字符串值。\nfmt.Println(s) // \u0026#34;left foot, right foot\u0026#34; fmt.Println(t) // \u0026#34;left foot\u0026#34;因为字符串是不可修改的，因此尝试修改字符串内部数据的操作也是被禁止的：\ns[0] = \u0026#39;L\u0026#39; // compile error: cannot assign to s[0]或者使用 Sprintf ：不会直接打印而是生成一个新的字符串\nvar result = fmt.Sprintf(\u0026#34;%s%s\u0026#34;, q1, q2) fmt.Println(result)字符串字面量# Golang 支持两种类型的字符串字面量：\n非解释型表示法，需用用反引号\u0026quot;`\u0026ldquo;把字符序列包起来 解释型表示法，需要用双引号\u0026quot;\u0026ldquo;包裹字符序列 区别在于：前者表示所见即所得的(除了回车符)。后者所表示的值中转义符会起作用\n// 字符串字面量语法：可以定义一个多行字符串 var s1 string = \u0026#34;hello\u0026#34; var s2 string = `hello world` `字符串转义符# 所谓的解释型字符串就是用双引号括起来的字符串(\u0026rdquo;\u0026quot;)，其中的转义字符会被替换掉，这些转义字符包括：\n\\a // 响铃 \\b // 退格 \\f // 换页 \\n // 换行 \\r // 回车 \\t // 制表符 \\u // Unicode 字符 \\v // 垂直制表符 \\\u0026#34; // 双引号 \\\\ // 反斜杠Go语言字符编码# Go 语言采用的字符编码方案从属于 Unicode 编码规范。Go 语言的代码正是由 Unicode 字符组成的，且源码文件必须使用 UTF-8 编码格式进行存储。如果源码文件中出现了非 UTF-8 编码的字符，那么在构建、安装以及运行的时候，go 命令会报错 illegal UTF-8 encoding 。当一个 string 类型的值被转换为 []rune 类型值的时候，其中的字符串会被拆分成一个个的 Unicode 字符。\n截取字符串# 可以通过下面的语法截取字符串中的内容：\nstr := \u0026#34;abcdefg\u0026#34;\tt1 := str[1:4] //startIndex=1,endIndex=4此时 t1 的内容为 bcd，该语法通过下标索引的方式截取字符串中的内容，特点是 \u0026ldquo;左含右不含\u0026rdquo;。也就是说新的子串包含源串索引为 1 的字符，而不包含源串索引为 4 的字符。\n如果要从源串的开始处截取可以省略第一个索引：\nt2 := str[:4] //省略第一个索引从0开始，startIndex=0,endIndex=4 t2 的内容为 \u0026ldquo;abcd\u0026rdquo;。\n如果要从源串的某个位置开始一直截取到末尾，可以省略第二个索引：\nt3 := str[1:] //省略第二个索引，从1开始截取到末尾 t3 的内容为 \u0026ldquo;cdef\u0026rdquo;\n访问越界问题：如果试图访问超出字符串索引范围的字节将会在运行时导致 panic 异常：\nt4 := str[:10] runtime error: slice bounds out of range [:10] with length 7 数组越界\n遍历字符串# 可以通过下标索引字符串中的字节，所以可以用这种方式遍历字符串：\np := \u0026#34;abc你好\u0026#34; for i := 0; i \u0026lt; len(p); i++ { fmt.Printf(\u0026#34;%c\u0026#34;, p[i]) }输出：\nabcä% å¥%可见在字符串中含有非单字节的字符时这种方法是不正确的。range 函数解决这个问题：\nfor _, v := range s { fmt.Printf(\u0026#34;%c\u0026#34;, v) }输出：\nabc你好 带有 range 子句的 for 语句会先把被遍历的字符串值拆成一个字节序列，然后再试图找出这个字节序列中包含的每一个 UTF-8 编码值，或者说每一个 Unicode 字符。因此在 range for 语句中，赋给第二个变量的值是UTF-8 编码值代表的那个 Unicode 字符，类型是 rune\n字符串分割# url := \u0026#34;www.baidu.com\u0026#34; strArray := strings.Split(url, \u0026#34;.\u0026#34;) fmt.Println(strArray)字符串 Join# fmt.Println(strings.Join(strArray, \u0026#34;.\u0026#34;))前缀判断# fmt.Println(strings.HasPrefix(url, \u0026#34;www\u0026#34;))后缀判断# fmt.Println(strings.HasSuffix(url, \u0026#34;com\u0026#34;))修改字符串# Golang 中不能修改字符串的内容，就是说不能通过 s[i] 这种方式修改字符串中的字符。要修改字符串的内容，可以先将字符串的内容复制到一个可写的变量中，一般是 []byte 或 []rune 类型的变量，然后再进行修改。\n注意：如果要对字符串中的字节进行修改，就转换为 []byte 类型，如果要对字符串中的字符修改，就转换为 []rune 类型，转换类型的过程中会自动复制数据\n修改字符串中的字节([]byte) 对于单字节字符来说可以用这种方式进行修改：\nss := \u0026#34;hello world\u0026#34; value := []byte(ss) // 转换为[]byte value[5] = \u0026#39;,\u0026#39; // 将空格替换为“,” fmt.Printf(\u0026#34;%s\\n\u0026#34;, ss) fmt.Printf(\u0026#34;%s\\n\u0026#34;, value)输出：\nhello world hello,world修改字符串中的字符([]rune)\nsss := \u0026#34;一梦三两年\u0026#34; value2 := []rune(sss) // 转换为[]rune value2[2] = \u0026#39;四\u0026#39; value2[3] = \u0026#39;五\u0026#39; fmt.Println(sss) fmt.Println(string(value2))输出：\n一梦三两年 一梦四五年 注意：string 类型的 0 值是长度为 0 的字符串，即空字符串 \u0026quot;\u0026rdquo;\nstrconv 包# 除了字符串、字符、字节之间的转换，字符串和数值之间的转换也比较常见。由 strconv 包提供这类转换功能。\n将一个整数转为字符串，一种方法是用 fmt.Sprintf 返回一个格式化的字符串；另一个方法是用strconv.Itoa() ：\nx := 123 y := fmt.Sprintf(\u0026#34;%d\u0026#34;, x) fmt.Println(y, strconv.Itoa(x)) // \u0026#34;123 123\u0026#34; “整数到ASCII”FormatInt 和 FormatUint 函数可以用不同的进制来格式化数字：\nfmt.Println(strconv.FormatInt(int64(x), 2)) // \u0026#34;1111011\u0026#34;fmt.Printf 函数的 %b 、%d、%o 和%x 等参数提供功能往往比 strconv 包的 Format 函数方便很多，特别是在需要包含有附加额外信息的时候：\ns := fmt.Sprintf(\u0026#34;x=%b\u0026#34;, x) // \u0026#34;x=1111011\u0026#34;如果要将一个字符串解析为整数，可以使用 strconv 包的Atoi或ParseInt函数，还有用于解析无符号整数的ParseUint 函数：\nx, err := strconv.Atoi(\u0026#34;123\u0026#34;) // x is an int y, err := strconv.ParseInt(\u0026#34;123\u0026#34;, 10, 64) // base 10, up to 64 bitsParseInt 函数的第三个参数是用于指定整型数的大小；例如16表示int16，0则表示int。在任何情况下，返回的结果y总是int64类型，可以通过强制类型转换将它转为更小的整数类型。\n有时候也会使用 fmt.Scanf 来解析输入的字符串和数字，特别是当字符串和数字混合在一行的时候，它可以灵活处理不完整或不规则的输入。\n字符类型# 在Go语言中支持两个字符类型，一个是byte（实际上是uint8的别名），代表UTF-8字符串的单个字节的值；另一个是rune，代表单个Unicode字符。\n一个 string 类型的值既可以被拆分为一个包含多个字符的序列，也可以被拆分为一个包含多个字节的序列。\n前者由以 rune 为元素类型的切片表示 后者由以 byte 为元素类型的切片代表 rune 是Go语言特有的一个基本数据类型，它的一个值就代表一个字符，即：一个Unicode 字符(就是一个中文字符，占3个字节)\n看以下代码:\ns := \u0026#34;helloworld 世界你好\u0026#34; fmt.Printf(\u0026#34;string:%q\\n\u0026#34;, s) // 原文格式输出 fmt.Printf(\u0026#34;rune(char):%q\\n\u0026#34;, []rune(s)) // 输出[]rune切片 fmt.Printf(\u0026#34;rune(hex):%x\\n\u0026#34;, []rune(s)) // 采用16进制数表示 fmt.Printf(\u0026#34;bytes(hex):% x\\n\u0026#34;, []byte(s)) // 输出[]byte切片输出:\nstring:\u0026#34;helloworld 世界你好\u0026#34; rune(char):[\u0026#39;h\u0026#39; \u0026#39;e\u0026#39; \u0026#39;l\u0026#39; \u0026#39;l\u0026#39; \u0026#39;o\u0026#39; \u0026#39;w\u0026#39; \u0026#39;o\u0026#39; \u0026#39;r\u0026#39; \u0026#39;l\u0026#39; \u0026#39;d\u0026#39; \u0026#39; \u0026#39; \u0026#39;世\u0026#39; \u0026#39;界\u0026#39; \u0026#39;你\u0026#39; \u0026#39;好\u0026#39;] rune(hex):[68 65 6c 6c 6f 77 6f 72 6c 64 20 4e16 754c 4f60 597d] bytes(hex):68 65 6c 6c 6f 77 6f 72 6c 64 20 e4 b8 96 e7 95 8c e4 bd a0 e5 a5 bd结果分析：\n第二行输出说明：字符串在被转换为 []rune 类型的值时每个字符都会成为一个独立的 rune 类型的元素值。 由于每个 rune 底层的值都是采用 UTF-8 编码值来表达的，所以第三行采用 16进制数 来表示上述字符串，每一个16进制的字符分别表示一个字符，可以看到，当遇到中文字符时，由于底层存储需要更大的空间，所以使用的16进制数字也比较大，比如 4e16 和 754c 分别代表世和界。 如果将整个字符的 UTF-8 编码值都拆成字节序列时，就变成了第四行的输出，可以看到一个中文字符底层占用了三个byte，比如e4 b8 96 / e7 95 8c分别对应UFT-8编码值的 4e16 和 754c，也就是中文字符中的世和界。 总结： string 类型的值会由若干个 Unicode 字符组成，每个 Unicode 字符都可以由一个 rune 类型的值来承载。这些字符在底层都会被转换为 UTF-8 编码值，而这些 UTF-8 编码值又会以字节序列的形式表达和存储。所以：一个 string 类型的值在底层就是一个能够表达若干个 UTF-8 编码值的字节序列。\n"},{"id":43,"href":"/docs/go/04%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%92%8C%E8%BF%90%E7%AE%97%E7%AC%A6/","title":"04流程控制和运算符","section":"所有文章","content":"流程控制# If# score := 60 if score \u0026gt;= 90 { fmt.Println(\u0026#34;A\u0026#34;) } else if score \u0026gt; 70 { fmt.Println(\u0026#34;B\u0026#34;) } else { fmt.Println(\u0026#34;C\u0026#34;) }If 特殊写法# 可以在 if 表达式之前添加一个执行语句，再根据变量值进行判断。这种写法可以将返回值与判断放在一行进行处理，而且返回值的作用范围被限制在 if、else 语句组合中。这么做的好处在于：在编程中，变量的作用范围越小，所造成的问题可能性越小，每一个变量代表一个状态，有状态的地方，状态就会被修改，函数的局部变量只会影响一个函数的执行，但全局变量可能会影响所有代码的执行状态，因此限制变量的作用范围对代码的稳定性有很大的帮助。\nif score := 60; score \u0026gt;= 90 { fmt.Println(\u0026#34;A\u0026#34;) } else if score \u0026gt; 75 { fmt.Println(\u0026#34;B\u0026#34;) } else { fmt.Println(\u0026#34;C\u0026#34;) }for# 条件表达式返回 true 时循环体不停地进行循环，直到条件表达式返回 false 时自动退出循环，例如：\nsum := 0 for i := 0; i \u0026lt; 5; i++ { sum += i // 1+2+3+4 } fmt.Println(sum)for 循环的初始语句可以被忽略，但是初始语句后的分号必须要写，例如：\ni := 0 for ; i \u0026lt; 10; i++ { fmt.Println(i) }for 循环的初始语句和结束语句都可以省略，类似于C#中的 while（满足条件表达式时持续循环，否则结束循环。），比如：\nj := 0 // 循环的初始语句和结束语句都可以省略: for j \u0026lt; 10 { fmt.Println(j) j++ }无限循环：\nfor { fmt.Print(\u0026#34;hello word\u0026#34;) }for 循环可以通过break、goto、return、panic 语句强制退出循环。\nfor range# Go 语言中可以使用 for range 遍历数组、切片、字符串、map 及通道（channel）。 通过 for range 遍历的返回值有以下规律：\n数组、切片、字符串返回索引和值 map 返回键和值 channel 只返回通道内的值 c := [...]int{1, 2, 3} for _, v := range c { fmt.Printf(\u0026#34;value:%d\\n\u0026#34;, v) }switch case# 使用 switch 语句可方便地对大量的值进行条件判断。\nsex := \u0026#34;男\u0026#34; switch sex { case \u0026#34;男\u0026#34;: fmt.Println(\u0026#34;男性\u0026#34;) case \u0026#34;女\u0026#34;: fmt.Println(\u0026#34;女性\u0026#34;) default: fmt.Println(\u0026#34;无效的输入！\u0026#34;) }Go语言规定每个switch只能有一个default分支。\n一个分支可以有多个值，多个case值中间使用英文逗号分隔。比如：\nswitch n := 7; n { case 1, 3, 5, 7, 9: fmt.Println(\u0026#34;奇数\u0026#34;) case 2, 4, 6, 8: fmt.Println(\u0026#34;偶数\u0026#34;) default: fmt.Println(n) }分支还可以使用表达式，这时候switch语句后面不需要再跟判断变量。例如：\nage := 30 switch { case age \u0026lt; 25: fmt.Println(\u0026#34;好好学习吧\u0026#34;) case age \u0026gt; 25 \u0026amp;\u0026amp; age \u0026lt; 35: fmt.Println(\u0026#34;好好工作吧\u0026#34;) case age \u0026gt; 60: fmt.Println(\u0026#34;好好享受吧\u0026#34;) default: fmt.Println(\u0026#34;活着真好\u0026#34;) }fallthrough语法可以执行满足条件的case的下一个case，是为了兼容C语言中的case设计的。\ns := \u0026#34;a\u0026#34; switch { case s == \u0026#34;a\u0026#34;: fallthrough case s == \u0026#34;b\u0026#34;: fmt.Println(\u0026#34;b\u0026#34;) case s == \u0026#34;c\u0026#34;: fmt.Println(\u0026#34;c\u0026#34;) default: fmt.Println(\u0026#34;...\u0026#34;) }输出：\nbgoto# goto 语句通过标签进行代码间的无条件跳转。C#中也有只是不推荐使用，只在特定场景下才考虑使用。因为goto可以无条件地转移到过程中指定的行会造成程序流程的混乱，使理解和调试程序都产生困难。Go语言中使用 goto 语句能简化一些代码的实现过程。 例如双层嵌套的for循环要退出时：\n// 示例一：内层循环打印到2时结束，外层循环也随即结束 var breakFlag bool for i := 0; i \u0026lt; 10; i++ { for j := 0; j \u0026lt; 10; j++ { if j == 2 { // 设置退出标签 breakFlag = true break } fmt.Printf(\u0026#34;%v-%v\\n\u0026#34;, i, j) } // 外层for循环判断 if breakFlag { break } }使用 goto 简化\nfor i := 0; i \u0026lt; 10; i++ { for j := 0; j \u0026lt; 10; j++ { if j == 2 { // 设置退出标签 goto breakTag } fmt.Printf(\u0026#34;%v-%v\\n\u0026#34;, i, j) } } return // 标签 breakTag: fmt.Println(\u0026#34;结束for循环\u0026#34;)break# break 语句可以结束 for 、 switch 和 select 的代码块。break语句还可以在语句后面添加标签，如果加了标签就会跳出标签对应的for循环，标签要求必须定义在对应的 for、 switch 和 select 的代码块上。 例如：\nfunc breakTest() { BREAKDEMO1: for i := 0; i \u0026lt; 10; i++ { for j := 0; j \u0026lt; 10; j++ { if j == 2 { break BREAKDEMO1 // 如果加了标签就会跳出标签对应的for循环 } fmt.Printf(\u0026#34;%v-%v\\n\u0026#34;, i, j) } } }continue# continue 语句可以结束当前循环，开始下一次的循环迭代过程，仅限在for循环内使用。在 continue语句后添加标签时，表示开始标签对应的循环。例如：\nfunc processControlContinue() { forloop1: for i := 0; i \u0026lt; 5; i++ { // forloop2: for j := 0; j \u0026lt; 5; j++ { if i == 2 \u0026amp;\u0026amp; j == 2 { continue forloop1 } fmt.Printf(\u0026#34;%v-%v\\n\u0026#34;, i, j) } } for i := 0; i \u0026lt; 10; i++ { if i == 2 { continue } fmt.Println(i) } }运算符# 运算符用于在程序运行时执行数学或逻辑运算，Go 语言内置的运算符有：\n算术运算符 关系运算符 逻辑运算符 位运算符 赋值运算符 算术运算符# 运算符 描述 + 相加 - 相减 * 相乘 / 相除 % 求余 注意： ++（自增）和--（自减）在Go语言中是单独的语句，并不是运算符。\n关系运算符# 运算符 描述 == 检查两个值是否相等，如果相等返回 True 否则返回 False。 != 检查两个值是否不相等，如果不相等返回 True 否则返回 False。 \u0026gt; 检查左边值是否大于右边值，如果是返回 True 否则返回 False。 \u0026gt;= 检查左边值是否大于等于右边值，如果是返回 True 否则返回 False。 \u0026lt; 检查左边值是否小于右边值，如果是返回 True 否则返回 False。 \u0026lt;= 检查左边值是否小于等于右边值，如果是返回 True 否则返回 False。 逻辑运算符# 运算符 描述 \u0026amp;\u0026amp; 逻辑 AND 运算符。 如果两边的操作数都是 True，则为 True，否则为 False。 || 逻辑 OR 运算符。 如果两边的操作数有一个 True，则为 True，否则为 False。 ! 逻辑 NOT 运算符。 如果条件为 True，则为 False，否则为 True。 位运算符# 位运算符对整数在内存中的二进制位进行操作。\n运算符 描述 \u0026amp; 参与运算的两数各对应的二进位相与。 （两位均为1才为1） | 参与运算的两数各对应的二进位相或。 （两位有一个为1就为1） ^ 参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1。 （两位不一样则为1） \u0026laquo; 左移n位就是乘以2的n次方。 “a\u0026laquo;b”是把a的各二进位全部左移b位，高位丢弃，低位补0。 \u0026raquo; 右移n位就是除以2的n次方。 “a\u0026raquo;b”是把a的各二进位全部右移b位。 赋值运算符# 运算符 描述 = 简单的赋值运算符，将一个表达式的值赋给一个左值 += 相加后再赋值 -= 相减后再赋值 *= 相乘后再赋值 /= 相除后再赋值 %= 求余后再赋值 \u0026laquo;= 左移后赋值 \u0026raquo;= 右移后赋值 \u0026amp;= 按位与后赋值 |= 按位或后赋值 ^= 按位异或后赋值 "},{"id":44,"href":"/docs/go/05%E6%95%B0%E7%BB%84/","title":"05数组","section":"所有文章","content":"数组是由固定长度的特定类型元素组成的序列，数组可以由零个或多个元素组成（默认情况下，数组的每个元素都被初始化为元素类型对应的零值），数组的长度是固定的，因此在Go语言中很少直接使用数组。和数组对应的类型是 Slice（切片），它是可以增长和收缩的动态序列，slice 功能也更灵活，但是要理解 slice 工作原理的话需要先理解数组。\n创建数组# // 数组创建,使用类型零值初始化 func createArrayDeclar() { var arr [3]int // array of 3 integers fmt.Println(arr[0]) // print the first element fmt.Println(arr[len(arr)-1]) // print the last element, a[2] }数组字面值# // 数组创建,使用数字字面值语法 func createArrayDeclar2() { var arr [3]int = [3]int{1, 2, 3} fmt.Println(arr[0]) // fmt.Println(a[10]) invalid array index 10 (out of bounds for 3-element array),数组越界 }数组字面值中，如果数组的长度位置出现的是…省略号，表示数组的长度根据初始化值的个数来计算。\nfunc createArrayDeclar3() { arr := [...]int{1, 2, 3} fmt.Println(arr[0]) }指定数组第1个元素值为100,第9个元素值为200,数组长度就是10\nfunc createArrayDeclar4() { arr := [...]int{1: 100, 9: 200} fmt.Println(arr) }数组比较# 数组可以直接进行比较，当数组内的元素都一样的时候表示两个数组相等。\nq := [...]int{11, 22, 33} w := [...]int{11, 22, 33} fmt.Println(q == w)数组遍历# func traversalArray() { var arr [3]int = [3]int{1, 2, 3} for i := 0; i \u0026lt; len(arr); i++ { fmt.Printf(\u0026#34;index:%d, value:%d\\n\u0026#34;, i, arr[i]) } // 使用range遍历数组 for i, v := range arr { fmt.Printf(\u0026#34;index:%d, value:%d\\n\u0026#34;, i, v) } // 使用range遍历数组:如果需要值但希望忽略索引，可以通过使用_ blank标识符替换索引来实现 for _, v := range arr { fmt.Printf(\u0026#34;value:%d\\n\u0026#34;, v) } }多维数组# func multidimensionalArray() { array := [3][4]int{ {0, 1, 2, 3}, /* 第一行索引为 0 */ {4, 5, 6, 7}, /* 第二行索引为 1 */ {8, 9, 10, 11}, /* 第三行索引为 2 */ } for i, item := range array { fmt.Printf(\u0026#34;%d the element of is %v \\n\u0026#34;, i, item) } }0 the element of is [0 1 2 3] 1 the element of is [4 5 6 7] 2 the element of is [8 9 10 11]数组作为参数传递# 数组可以作为函数的参数传入，数组作为函数参数传入用的是值传递的方式(拷贝)。在函数内改变数组元素并不影响外层数组。\nfunc passByValue(arr [3]int) { arr[0] = 1 }\t// 数组是值类型：意味着当它被分配给一个新变量时，将把原始数组的副本分配给新变量。如果对新变量进行了更改不会在原始数组中反映 e := [...]int{11, 22, 33} fmt.Println(e[0]) passByValue(e) fmt.Println(e[0])输出：\n11 11如果想要改变就只能使用指针，在函数内部改变的数组的值，也会改变外面的数组的值。\nfunc passByReference(arr *[3]int) { arr[0] = 100 }\t// 使用指针后函数内部对数组的更改将反应到原数组上 r := [...]int{11, 22, 33} fmt.Println(r[0]) passByReference(\u0026amp;r) fmt.Println(r[0])输出：\n11 100这里只是玩一下，正常这种情况下都是用切片来解决，而不是用数组。\n这里的 * 和 \u0026amp; 的区别：\n\u0026amp; 是取地址符号 , 即取得某个变量的地址 , 如 ; \u0026amp;a * 是指针运算符 , 可以表示一个变量是指针类型 , 也可以表示一个指针变量所指向的存储单元 , 也就是这个地址所存储的值 Slice （切片）代表变长的序列，序列中每个元素都有相同的类型。一个 slice 类型一般写作 []T ，其中 T 代表 slice 中元素的类型；slice 的语法和数组很像，只是没有固定长度而已。\nslice 的底层引用一个数组对象。一个 slice 由三个部分构成：指针、长度和容量。指针指向第一个 slice 元素对应的底层数组元素的地址，要注意的是 slice 的第一个元素并不一定就是数组的第一个元素。长度对应slice 中元素的数目；长度不能超过容量，容量一般是从 slice 的开始位置到底层数据的结尾位置。内置的 len 和 cap 函数分别返回 slice的长度和容量。多个 slice 之间可以共享底层的数据，并且引用的数组部分区间可能重叠。\n"},{"id":45,"href":"/docs/go/06%E5%88%87%E7%89%87/","title":"06切片","section":"所有文章","content":"切片定义# func sliceDeclar() { var s1 []int // 定义存放int类型的切片 var s2 []string // 定义存放string类型的切片 fmt.Println(s1, s2) fmt.Println(s1 == nil, s2 == nil) }创建切片和创建数组非常相似，如果在 [] 指定了值，那么创建的是一个数组，反之就是一个切片\n创建空切片# 空切片在底层数组包含 0 个元素，也没有分配任何存储空间。一般用于表示空集合。\nfunc createEmptySlice() { slice1 := []int{} slice2 := make([]int, 0) fmt.Println(slice1, slice2) fmt.Println(slice1 == nil, slice2 == nil) }基于数组得到切片# func createSliceByArray() { arr := [...]int{1, 2, 3, 4, 5, 6, 7, 8, 9} fmt.Println(arr) fmt.Println(arr[0:4]) // =\u0026gt;[1 2 3 4] 基于数组得到切片,从0开始到第4个结束（不包含4）.原则：左包含右不包含 fmt.Println(arr[:4]) // =\u0026gt;[1 2 3 4] 省略第一个参数，默认从0开始 fmt.Println(arr[3:]) // =\u0026gt;[4 5 6 7 8 9] 省略第二个参数，默认到len(a1)结束 fmt.Println(arr[:]) // =\u0026gt;[1 2 3 4 5 6 7 8 9] 两个参数都省略，默认从0开始到len(a1-1)结束 }输出：\n[1 2 3 4 5 6 7 8 9] [1 2 3 4] [1 2 3 4] [4 5 6 7 8 9] [1 2 3 4 5 6 7 8 9]基于切片得到切片# func createSliceBySlice() { arr := [...]int{1, 2, 3, 4, 5, 6, 7, 8, 9} arr1 := arr[0:4] fmt.Println(arr1) fmt.Printf(\u0026#34;len(s5):%d cap(s5):%d \\n\u0026#34;, len(arr1), cap(arr1)) //由切片得到切片 arr2 := arr1[2:4] fmt.Println(arr2) fmt.Printf(\u0026#34;len(s5):%d cap(s5):%d \\n\u0026#34;, len(arr2), cap(arr2)) }输出：\n[1 2 3 4] len(s5):4 cap(s5):9 [3 4] len(s5):2 cap(s5):7 直接创建并初始化# func createSlice() { s1 := []int{1, 3, 4, 5, 67, 88} s2 := []string{\u0026#34;北京\u0026#34;, \u0026#34;上海\u0026#34;, \u0026#34;山西\u0026#34;} fmt.Println(s1, s2) fmt.Println(s1 == nil, s2 == nil) fmt.Printf(\u0026#34;len(s1):%d cap(s1):%d \\n\u0026#34;, len(s1), cap(s1)) fmt.Printf(\u0026#34;len(s2):%d cap(s2):%d \\n\u0026#34;, len(s2), cap(s2)) }使用 make 创建切片# 以上大部分都是基于数组来创建切片，如果需要动态的创建一个切片，可以使用内置的make()函数，格式如下：\nmake([]T, size, cap)其中：\nT:切片的元素类型 size:切片中元素的数量 cap:切片的容量 func createSliceByMake() { slice1 := make([]string, 5) // 使用make创建一个长度5，容量为10的切片 slice2 := make([]string, 5, 10) fmt.Println(slice1, slice2) // fmt.Println(slice2[6]) // 虽然创建的切片对应底层数组的大小为 10，但是不能访问索引值 5 以后的元素,其实相当于底层数组长度是10但是切片只覆盖到了0~5 }需要说明的是，切片对应的底层数组的大小为指定的容量。比如对于上面的例子，指定了 slice2 的容量为 10，那么 slice2 对应的底层数组的大小就是 10。虽然创建的切片对应底层数组的大小为 10，但是不能访问索引值 5 以后的元素，比如：\nfmt.Println(slice2[6])输出：\npanic: runtime error: index out of range [6] with length 5虽然创建的切片对应底层数组的大小为 10，但是不能访问索引值 5 以后的元素，其实相当于：底层数组长度是10但是切片 slice2 只覆盖到了 0~5。\n切片的长度和容量# arr := [...]int{1, 2, 3, 4, 5, 6, 7, 8, 9}示例一：\ns1 := arr[3:] // [4 5 6 7 8 9] fmt.Println(s1) // 切片的长度是元素的个数,切片的容量是底层数组从切片的第一个元素到最后一个元素, fmt.Printf(\u0026#34;len(s1):%d cap(s1):%d \\n\u0026#34;, len(s1), cap(s1))输出：\n[4 5 6 7 8 9] len(s1):6 cap(s1):6 示例二：\ns2 := arr[4:8] // [5 6 7 8] fmt.Println(s2) // 切片的长度是元素的个数,所以len=4,切片的容量是底层数组从切片的第一个元素到最后一个元素,所以这里就是从4到9 fmt.Printf(\u0026#34;len(s2):%d cap(s2):%d \\n\u0026#34;, len(s2), cap(s2))输出：\n[5 6 7 8] len(s2):4 cap(s2):5 切片的本质# 切片的本质就是对底层数组的封装，它包含了三个信息：底层数组的指针、切片的长度 len 和切片的容量 cap。参考自： 李文周的博客\n举个例子，现在有一个数组a := [8]int{0, 1, 2, 3, 4, 5, 6, 7}，切片s1 := a[:5]，示意图如下：\n切片s2 := a[3:6]，示意图如下：\n注意：现在两个切片共享同一个底层数组，因为切片的本质就是对底层数组的封装，所以如果一个切片修改了该底层数组的共享部分，另一个切片也能感知到\n切片判断是否为空# 切片之间是不能比较的，不能使用==操作符来判断两个切片是否含有全部相等元素。 切片唯一合法的比较操作是和 nil 比较。 一个 nil 值的切片并没有底层数组，一个 nil 值的切片的长度和容量都是0。但是不能说一个长度和容量都是0的切片一定是 nil ，例如下面的示例：\nfunc compareSlice() { var q1 []int // len(q1)=0;cap(q1)=0;q1==nil; 没有被初始化所以q1==nil is true fmt.Printf(\u0026#34;len(q1):%d cap(q1):%d q1==nil:%t \\n\u0026#34;, len(q1), cap(q1), q1 == nil) q2 := []int{} // len(q2)=0;cap(q2)=0;q2!=nil; 这里是定义了元素为空的数组,所以q2==nil is false fmt.Printf(\u0026#34;len(q2):%d cap(q2):%d q2==nil:%t \\n\u0026#34;, len(q2), cap(q2), q2 == nil) q3 := make([]int, 0) // len(q3)=0;cap(q3)=0; q3!=nil; 这里使用了make所以十分分配内存的只不过cap和len都为0而已,所以q3==nil is false fmt.Printf(\u0026#34;len(q3):%d cap(q3):%d q3==nil:%t \\n\u0026#34;, len(q3), cap(q3), q3 == nil) }所以要判断一个切片是否是空的，要是用len(s) == 0来判断，不应该使用s == nil来判断。\n切片的赋值拷贝# 下面代码演示了拷贝前后两个变量共享底层数组，之前也说过：对一个切片的修改会影响另一个切片的内容，这点需要特别注意。\nfunc shareArraySlice() { w1 := make([]int, 3) // [0 0 0] w2 := w1 // 将w1直接赋值给w2，w1和w2共用一个底层数组 w2[0] = 100 fmt.Println(w1) // [100 0 0] fmt.Println(w2) // [100 0 0] }切片遍历# 切片的遍历方式和数组是一致的，支持索引遍历和for range遍历。\nfunc traversalSlice() { slice := make([]int, 3) // [0 0 0] for i := 0; i \u0026lt; len(slice); i++ { fmt.Println(i, slice[i]) } for index, value := range slice { fmt.Println(index, value) } }append# Go语言的内建函数 append() 可以为切片动态添加元素。 可以一次添加一个元素，可以添加多个元素，也可以添加另一个切片中的元素（后面加…）。\nfunc appendSlice() { slice := make([]int, 3) // 创建切片：[0 0 0] slice = append(slice, 1) // 切片中添加第一个元素 1 slice = append(slice, 2, 3, 4, 5, 6) // 继续添加元素 2,3,4,5,6 slice2 := []int{7, 8, 9} // 创建新的切片 slice = append(slice, slice2...) // 将新的切片中的元素都放到w3中,这里...代表将slice2中的元素拆分 fmt.Println(slice) // 输出：[0 0 0 1 2 3 4 5 6 7 8 9] }**注意：**如果使用 append() 切片可以不被初始化,会自动扩容并添加元素。\nvar s []int s = append(s, 1, 2, 3)每个切片会指向一个底层数组，这个数组的容量够用就添加新增元素。当底层数组不能容纳新增的元素时，切片就会自动按照一定的策略进行“扩容”，此时该切片指向的底层数组就会更换。“扩容”操作往往发生在 append() 函数调用时，所以我们通常都需要用原变量接收append函数的返回值。\n例如：\nfunc appendDilatationSlice() { var numSlice []int for i := 0; i \u0026lt; 10; i++ { numSlice = append(numSlice, i) fmt.Printf(\u0026#34;%v len:%d cap:%d ptr:%p\\n\u0026#34;, numSlice, len(numSlice), cap(numSlice), numSlice) } }输出：\n[0] len:1 cap:1 ptr:0xc000012088 [0 1] len:2 cap:2 ptr:0xc0000120d0 [0 1 2] len:3 cap:4 ptr:0xc000010200 [0 1 2 3] len:4 cap:4 ptr:0xc000010200 [0 1 2 3 4] len:5 cap:8 ptr:0xc00000c340 [0 1 2 3 4 5] len:6 cap:8 ptr:0xc00000c340 [0 1 2 3 4 5 6] len:7 cap:8 ptr:0xc00000c340 [0 1 2 3 4 5 6 7] len:8 cap:8 ptr:0xc00000c340 [0 1 2 3 4 5 6 7 8] len:9 cap:16 ptr:0xc00010e080 [0 1 2 3 4 5 6 7 8 9] len:10 cap:16 ptr:0xc00010e080从上面的结果可以看出：\nappend()函数将元素追加到切片的最后并返回该切片 切片 numSlice 的容量按照1，2，4，8，16这样的规则自动进行扩容，每次扩容后都是扩容前的2倍 切片的扩容策略# 可以通过查看 $GOROOT/src/runtime/slice.go 源码，其中扩容相关代码如下：\nnewcap := old.cap doublecap := newcap + newcap // 1.首先判断如果新申请容量(cap)大于2倍的旧容量(old.cap):那么最终容量等于新申请的容量(cap) if cap \u0026gt; doublecap { newcap = cap } else { // 2.否则判断如果旧切片的长度小于1024，则最终容量等于旧容量(old.cap)x2 if old.len \u0026lt; 1024 { newcap = doublecap } else { // 3. 否则判断如果旧切片长度大于等于1024 ，则最终容量从旧容量（old.cap）开始循环增加原来的1/4，即 newcap=old.cap,for {newcap += newcap/4} 直到最终容量大于等于新申请的容量cap，即newcap \u0026gt;= cap // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } }从上面的代码可以看出以下内容：\n首先判断如果新申请容量 cap 大于2倍的旧容量 old.cap，最终容量 newcap 等于新申请的容量 cap\n否则判断如果旧切片的长度小于 1024 ，则最终容量 newcap 等于旧容量 old.cap 的两倍\n否则判断如果旧切片长度大于等于 1024 ，则最终容量 newcap 从旧容量 old.cap 开始循环增加原来的1/4，即 newcap=old.cap,for {newcap += newcap/4} 直到最终容量 newcap 大于等于新申请的容量cap，即 newcap \u0026gt;= cap\n如果最终容量 cap 计算值溢出，则最终容量 cap 就是新申请容量 cap\n需要注意：切片扩容会根据切片中元素的类型不同而做不同的处理，比如 int 和 string 类型的处理方式就不一样。\ncopy# 首先来看一个问题：\na := []int{1, 2, 3, 4, 5} b := a fmt.Println(a) // [1 2 3 4 5] fmt.Println(b) // [1 2 3 4 5] b[0] = 1000 fmt.Println(a) // [1000 2 3 4 5] fmt.Println(b) // [1000 2 3 4 5]由于切片是引用类型，所以 a 和 b 其实都指向了同一块内存地址。修改 b 的同时 a 的值也会发生变化。\ncopy()函数可以迅速地将一个切片的数据复制到另外一个切片空间中，使用格式如下：\ncopy(destSlice, srcSlice []T)其中：\nsrcSlice: 数据来源切片 destSlice: 目标切片 举个例子：\nc := []int{1, 2, 3, 4, 5} d := make([]int, 5) copy(d, c) // 使用copy()函数将切片c1中的元素复制到切片c2 fmt.Println(c) // [1 2 3 4 5] fmt.Println(d) // [1 2 3 4 5] c[0] = 1000 fmt.Println(c) // [1000 2 3 4 5] fmt.Println(d) // [1 2 3 4 5]从切片中删除元素# Go语言中并没有删除切片元素的专用方法，我们可以使用切片本身的特性来删除元素。 代码如下：\n// 从切片中删除元素 c3 := []int{30, 31, 32, 33, 34, 35, 36, 37} // 要删除索引为2的元素32 c3 = append(c3[:2], c3[3:]...) // 其实这就是利用append的特性修改了切片内容再返回 fmt.Println(c3) // [30 31 33 34 35 36 37]总结：要从切片c3中删除索引为 index 的元素，操作方法是 c3 = append(c3[:index], c3[index+1:]...)\n"},{"id":46,"href":"/docs/go/07map/","title":"07map","section":"所有文章","content":"Go语言中提供映射关系的容器为 map，内部使用散列表（hash）实现。是一种无序的基于key-value的数据结构，map 是引用类型，必须初始化才能使用。\nmap 定义# map 定义语法如下：\nmap[KeyType]ValueType KeyType：表示键的类型 ValueType：表示键对应的值的类型 map 类型的变量默认初始值为 nil，需要使用 make()函数来分配内存。语法为：\nmake(map[KeyType]ValueType, [cap])其中 cap 表示 map 的容量，该参数虽然不是必须的，但是应该在初始化时就为其指定一个合适的容量。\nmap 基本使用# 内置的 make 函数可以创建一个 map\nfunc createMap() { users := make(map[string]int, 8) users[\u0026#34;小王\u0026#34;] = 18 users[\u0026#34;小李\u0026#34;] = 2 fmt.Println(users) fmt.Println(users[\u0026#34;小王\u0026#34;]) fmt.Printf(\u0026#34;type of a:%T\\n\u0026#34;, users) }也可以使用 map 字面值语法创建，支持在声明的时候填充元素，例如：\nfunc createMap2() { users := map[string]int{ \u0026#34;小周\u0026#34;: 22, \u0026#34;小张\u0026#34;: 23, } fmt.Println(users) fmt.Println(users[\u0026#34;小王\u0026#34;]) fmt.Printf(\u0026#34;type of a:%T\\n\u0026#34;, users) }创建空的 map 的表达式是\nmap[string]int{}判断某个键是否存在# 格式如下:\nvalue,ok := map[key]示例代码：\nfunc existMap() { users := map[string]int{ \u0026#34;小周\u0026#34;: 22, \u0026#34;小张\u0026#34;: 23, } // 如果返回值是bool值通常使用ok接收，约定俗称 v, ok := users[\u0026#34;小张\u0026#34;] if ok { fmt.Println(v) } else { fmt.Println(\u0026#34;不存在\u0026#34;) } }map 遍历# Go语言中使用 for range 遍历 map。\nusers := map[string]int{ \u0026#34;小周\u0026#34;: 22, \u0026#34;小张\u0026#34;: 23, } for k, v := range users { fmt.Println(k, v) }\t只想遍历 key 时可以这么写：\nfor k := range users { fmt.Println(k) }注意： 遍历 map 时的元素顺序与添加键值对的顺序无关。\n删除键值对# 使用 delete() 内建函数从 map 中删除一组键值对，函数格式如下：\ndelete(map, key) map ：表示要删除键值对的map key ：表示要删除的键值对的键 示例代码如下：\nfunc delMap() { users := map[string]int{ \u0026#34;小周\u0026#34;: 21, \u0026#34;小张\u0026#34;: 22, } for k, v := range users { fmt.Println(k, v) } delete(users, \u0026#34;小周\u0026#34;) for k, v := range users { fmt.Println(k, v) } }注意：这些操作是安全的，即使元素不在map中也没有关系；如果找失败将返回 value 类型对应的零值。\n按照指定顺序遍历# map 的迭代顺序是不确定的，并且不同的哈希函数实现可能导致不同的遍历顺序。实践中遍历的顺序是随机的，每一次遍历的顺序都不相同。这是故意的，每次都使用随机的遍历顺序可以强制要求程序不会依赖具体的哈希函数实现。如果需要按顺序遍历 key/value 对，必须显式地对 key 进行排序\nfunc orderTraversalMap() { users := map[string]int{ \u0026#34;1\u0026#34;: 22, \u0026#34;2\u0026#34;: 23, \u0026#34;3\u0026#34;: 23, \u0026#34;4\u0026#34;: 23, \u0026#34;5\u0026#34;: 23, \u0026#34;6\u0026#34;: 23, \u0026#34;7\u0026#34;: 23, \u0026#34;8\u0026#34;: 23, } // 这里看到map的迭代顺序是不确定随机的，并且不同的哈希函数实现可能导致不同的遍历顺序 for k, v := range users { fmt.Println(k, v) } fmt.Println(\u0026#34;************排序后：***********************\u0026#34;) // 如果需要按顺序遍历 key/value，必须显式地对key进行排序 // 1.取出map中的所有key存入切片keys var keys = make([]string, 0, 200) for key := range users { keys = append(keys, key) } // 2.对切片进行排序 sort.Strings(keys) // 3.按照排序后的key遍历map for _, key := range keys { fmt.Println(key, users[key]) } }元素为 map 类型的切片# 下面的代码演示了切片中的元素为map类型时的操作：\nfunc sliceValueMap() { var mapSlice = make([]map[string]string, 3) for index, value := range mapSlice { fmt.Printf(\u0026#34;index:%d value:%v\\n\u0026#34;, index, value) } fmt.Println(\u0026#34;after init\u0026#34;) // 对切片中的map元素进行初始化 mapSlice[0] = make(map[string]string, 10) mapSlice[0][\u0026#34;name\u0026#34;] = \u0026#34;wangpengliang\u0026#34; mapSlice[0][\u0026#34;password\u0026#34;] = \u0026#34;123456\u0026#34; mapSlice[0][\u0026#34;address\u0026#34;] = \u0026#34;北京\u0026#34; for index, value := range mapSlice { fmt.Printf(\u0026#34;index:%d value:%v\\n\u0026#34;, index, value) } }值为切片类型的 map# 下面的代码演示了map中值为切片类型的操作：\nfunc mapValueslice() { var sliceMap = make(map[string][]string, 3) fmt.Println(sliceMap) fmt.Println(\u0026#34;after init\u0026#34;) key := \u0026#34;中国\u0026#34; value, ok := sliceMap[key] if !ok { value = make([]string, 0, 2) } value = append(value, \u0026#34;北京\u0026#34;, \u0026#34;上海\u0026#34;) sliceMap[key] = value fmt.Println(sliceMap) }"},{"id":47,"href":"/docs/go/08%E5%87%BD%E6%95%B0/","title":"08函数","section":"所有文章","content":"函数指：可重复使用的、用于执行指定任务的代码块。Go语言中支持函数、匿名函数和闭包，函数在Go语言中属于“一等公民”。\n函数定义# 函数定义格式如下：\nfunc 函数名(参数)(返回值){ 函数体 }注意：\n函数名：由字母、数字、下划线组成。但函数名的第一个字母不能是数字。同一个包内函数名也称不能重名 参数：参数由参数变量和参数变量的类型组成，多个参数之间使用 , 分隔 返回值：返回值由返回值变量和其变量类型组成，也可以只写返回值的类型，多个返回值必须用 () 包裹，并用 , 分隔 函数体：实现指定功能的代码块 比如：定义求两数之和的函数：\nfunc func1(x int, y int) int { return x + y }函数的参数和返回值都是可选的，比如：可以定义无参数无返回值的函数：\nfunc func2() { fmt.Println(\u0026#34;hello world\u0026#34;) }函数调用# 通过 函数名() 的方式调用函数，比如：\nfunc main() { sum := func1(1, 2) func2() fmt.Println(sum) }参数# 类型简写# 函数的参数中如果相邻变量的类型相同，则可以省略类型，比如：\nfunc func4(x, y int) int { return x + y }可变参数# 可变参数是指函数的参数数量不固定。可变参数通过在参数名后加...标识。比如：\nfunc func5(x ...int) int { sum := 0 for _, v := range x { sum += v } return sum }调用：\na := func5(1) b := func5(2, 3) c := func5(2, 3, 4) fmt.Println(a, b, c) // 1 5 9固定参数搭配可变参数使用时，可变参数要放在固定参数的后面，比如：\nfunc func6(x int, y ...int) int { for _, v := range y { x += v } return x }本质上，函数的可变参数是通过切片实现的。\n返回值# Go语言中通过 return 关键字向外输出返回值。\n多返回值# Go语言中函数支持多返回值，函数如果有多个返回值时必须用 () 将所有返回值包裹起来。比如：\nfunc func7(x, y int) (int, int) { sum := x + y sub := x - y return sum, sub }返回值命名# 函数定义时可以给返回值命名，并在函数体中直接使用这些变量，最后通过 return 关键字返回。比如：\nfunc func8(x, y int) (sum, sub int) { sum = x + y sub = x - y // 这里可以直接return,不需要指定sum和sub return sum, sub }返回值补充# 当函数返回值类型为 slice 时，nil 可以看做是一个有效的 slice ，没必要显式返回一个长度为0的切片。\nfunc func9(x string) []int { if x == \u0026#34;\u0026#34; { return nil // 没必要返回[]int{} } return []int{0} }变量作用域# 全局变量# 全局变量是定义在函数外部的变量，在程序整个运行周期内都有效。 在函数中可以访问到全局变量。\npackage main import \u0026#34;fmt\u0026#34; // 定义全局变量value var value int64 = 10 func test() { fmt.Printf(\u0026#34;value=%d\\n\u0026#34;, value) // 函数中可以访问全局变量value } func main() { test() // value=10 }局部变量# 局部变量分为两种：\n函数内定义的变量无法在该函数外使用 如果局部变量和全局变量重名，优先访问局部变量 语句块定义的变量，只在 if、for、switch 语句内有效 函数类型与变量# 定义函数类型# 可以使用 type 关键字来定义一个函数类型，比如：\ntype calculation func(int, int) int上面定义了一个 calculation 类型，它是一种函数类型，接收两个 int 类型的参数并且返回一个 int 类型的返回值。凡是满足这个条件的函数都是 calculation 类型的函数，例如下面的 sum 和 sub 都是 calculation 类型。\n// calculation类型的函数sum func sum(x, y int) int { return x + y } // calculation类型的函数sub func sub(x, y int) int { return x - y }sum 和 sub 都能赋值给 calculation 类型的变量。\nvar calc1 calculation = sum var calc2 calculation = sub函数类型变量# 可以声明函数类型的变量并且为该变量赋值：\nfunc main() { var a calculation = sum fmt.Printf(\u0026#34;type of a:%T\\n\u0026#34;, a) // type of c:main.calculation fmt.Println(a(1, 2)) // 像调用sum一样调用a var b calculation = sub fmt.Printf(\u0026#34;type of b:%T\\n\u0026#34;, b) // type of c:main.calculation fmt.Println(b(1, 2)) // 像调用sub一样调用b }type of a:main.calculation 3 type of b:main.calculation -1高阶函数# 函数作为参数# // 将函数作为参数传递，该函数接收两个int类型变量x/y,一个函数参数sum。 func functionAsArgument(x, y int, sum func(int, int) int) int { return sum(x, y) } func func1(x int, y int) int { return x + y } func functionAsArgumentTest() { ret2 := functionAsArgument(10, 20, func1) fmt.Println(ret2) //30 }函数作为返回值# // 接收一个切片参数patients,返回一个函数 func functionAsTheReturnValue(patients []string) func(string) bool { // 定义匿名函数并返回 return func(name string) bool { for _, soul := range patients { if soul == name { return true } } return false } } func functionAsTheReturnValueTest() { testValue := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;f\u0026#34;} result := functionAsTheReturnValue(testValue) // 调用筛选器函数获取字母是否已存在 fmt.Println(result(\u0026#34;a\u0026#34;)) // true fmt.Println(result(\u0026#34;ff\u0026#34;)) // false }匿名函数# 已经知道函数可以作为返回值，但是在Go语言函数内部不能再像之前那样定义函数了，只能定义匿名函数。匿名函数就是没有函数名的函数，匿名函数的定义格式如下：\nfunc(参数)(返回值){ 函数体 }匿名函数因为没有函数名，所以没办法像普通函数那样调用，所以匿名函数需要保存到某个变量或者作为立即执行函数:\nfunc anonymousFunc() { // 将匿名函数保存到变量 add := func(x, y int) { fmt.Println(x + y) } // 通过变量调用匿名函数 add(1, 2) // 匿名函数作为立即执行函数,一般用于匿名函数只用于一次的情况下就不需要再指定变量存储 func(x, y int) { fmt.Println(x - y) }(1, 2) }匿名函数多用于实现回调函数和闭包。\n闭包# 闭包是函数式编程语言中的概念。指内层函数引用了外层函数中的变量或称为引用了自由变量（全局变量）的函数，其返回值也是一个函数。在Go语言中可以理解为匿名函数与其所引用环境的组合。\n闭包只是在形式和表现上像函数，但实际上不是函数。函数是一些可执行的代码，这些代码在函数被定义后就确定了，不会在执行时发生变化，所以一个函数只有一个实例。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。所谓引用环境是指在程序执行中的某个点所有处于活跃状态的约束所组成的集合。其中的约束是指一个变量的名字和其所代表的对象之间的联系。那么为什么要把引用环境与函数组合起来呢？这主要是因为在支持嵌套作用域的语言中，有时不能简单直接地确定函数的引用环境。这样的语言一般具有这样的特性\n函数是一等公民（First-class value），即函数可以作为另一个函数的返回值或参数，还可以作为一个变量的值。 函数可以嵌套定义，即在一个函数内部可以定义另一个函数。\n比如：\nfunc add() func(int) int { var x int return func(y int) int { x += y return x } } func addTest() { var f = add() fmt.Println(f(10)) //10 fmt.Println(f(20)) //30 fmt.Println(f(30)) //60 }上述代码中\nvar x int return func(y int) int { x += y return x }此时 f 就是一个闭包，f 不仅仅是存储了一个函数的返回值，同时存储了一个闭包的状态。该状态会一直存在外部被赋值的变量 f 中，直到 f 被销毁，整个闭包才被销毁。\n再看一个例子：\nfunc add2(x int) func(int) int { return func(y int) int { x += y return x } } func add2Test() { var f = add2(10) fmt.Println(f(10)) //20 fmt.Println(f(20)) //40 fmt.Println(f(30)) //70 }函数 add2 返回了一个函数，返回的这个函数就是一个闭包。这个函数本身中没有定义变量 x 的，而是引用了它所在的环境（函数 add2）中的变量 x。\n每调用一次函数 add2，就形成了一个新的环境，对应的闭包中，函数都是同一个函数，环境却是引用不同的环境。变量 x 是函数 add2 中的局部变量，这个变量不会在函数 add2 的栈中分配，因为函数 add2 返回后，对应的栈就失效了，add2 返回的那个函数中变量 x 就引用了一个失效的位置。所以闭包的环境中引用的变量不能够在栈上分配。\n闭包的陷阱# TODO\ndefer 语句# Go语言中 defer 语句会将其后面跟随的语句进行延迟处理。在 defer 归属的函数即将返回时，将延迟处理的语句按 defer 定义的逆序执行。先被 defer 的语句最后被执行，最后被 defer 的语句，最先被执行。比如：\n// defer将后面的语句延迟到函数即将退出时逆序执行,一般常用于资源释放 func deferTest() { fmt.Println(\u0026#34;start\u0026#34;) defer fmt.Println(\u0026#34;...\u0026#34;) fmt.Println(\u0026#34;end\u0026#34;) }start end ...函数中存在多个 defer 时,逆序执行后进先出，比如：\nfunc deferTest2() { fmt.Println(\u0026#34;start\u0026#34;) defer fmt.Println(\u0026#34;1111\u0026#34;) defer fmt.Println(\u0026#34;2222\u0026#34;) defer fmt.Println(\u0026#34;3333\u0026#34;) fmt.Println(\u0026#34;end\u0026#34;) }start end 3333 2222 1111由于 defer 语句延迟调用的特性，所以 defer 语句一般用于处理资源释放问题。比如：资源清理、文件关闭、解锁及记录时间等。\ndefer 执行时机# Go语言的函数中 return 语句在底层并不是原子操作，它分为两步：\n给返回值赋值 执行 RET 指令 defer 语句执行的时机是在返回值赋值操作后，执行 RET 指令前。如下图所示：\n"},{"id":48,"href":"/docs/go/09%E6%8C%87%E9%92%88/","title":"09指针","section":"所有文章","content":"指针类型# 任何程序数据载入内存后，在内存都有内存的地址这就是指针。而为了保存一个数据在内存中的地址，就需要指针变量。一个指针的值是一个变量的地址。一个指针对应变量在内存中的存储位置。\n例如：\nx := 1 // 声明int类型变量x p := \u0026amp;x // \u0026amp;x用于获取变量x的内存地址，返回一个指向x的指针p fmt.Println(*p) // *p用户获取指针p指向变量的值 *p = 2 // 可以重新给*p指针赋值 fmt.Println(x) // \u0026#34;2\u0026#34;输出：\n1 2 用 var x int 声明语句声明一个变量，\u0026amp;x 表达式（取x变量的内存地址）将产生一个指向该整数变量的指针，指针对应的数据类型是 *int，名字为 p ，可以理解为：“p指针指向变量x”或者“p指针保存了x变量的内存地址”。同时 *p 表达式对应p指针指向的变量的值。一般 *p 表达式读取指针指向的变量的值，这里为int类型的值，同时因为 *p 对应一个变量，所以该表达式也可以出现在赋值语句的左边，表示更新指针所指向的变量的值。\n注意：因为指针包含了一个变量的地址，因此如果将指针作为参数调用函数，那将可以在函数中通过该指针来更新变量的值\n\u0026amp;x：获取变量x的内存地址，返回一个指向x的指针 *p：获取指针p指向变量的值 看一下 b := \u0026amp;a 的图示：\n总结： 取地址操作符 \u0026amp; 和取值操作符 * 是一对互补操作符，\u0026amp; 取出地址，* 根据地址取出地址指向的值。\n变量、指针地址、指针变量、取地址、取值的相互关系和特性如下：\n对变量进行取地址 \u0026amp; 操作，可以获得这个变量的指针变量 指针变量的值是指针地址 对指针变量进行取值 *操作，可以获得指针变量指向的原变量的值 指针传值\nfunc modify1(x int) { x = 100 } func modify2(x *int) { *x = 100 } func main() { a := 10 modify1(a) fmt.Println(a) // 10 modify2(\u0026amp;a) fmt.Println(a) // 100 }new和make# 先来看一个例子：\nfunc main() { var a *int *a = 100 fmt.Println(*a) var b map[string]int b[\u0026#34;wangpengliang\u0026#34;] = 100 fmt.Println(b) }执行上面的代码会引发 panic，为什么呢？ 在Go语言中对于引用类型的变量，在使用的时候不仅要声明，还要为它分配内存空间，否则值就没办法存储。而对于值类型的声明不需要分配内存空间，是因为它们在声明的时候已经默认分配好内存空间。Go语言中 new 和 make 是内建的两个函数，主要用来分配内存。\n这里 panic原因在于：\nvar a *int 只是声明了一个指针变量 a 但是没有初始化，指针作为引用类型需要初始化后才会拥有内存空间，才可以赋值。比如：\nvar a *int a = new(int)var b map[string]int 只是声明变量 b 是一个 map 类型变量而未初始化。需要初始化后才可以赋值，比如：\nvar b map[string]int b = make(map[string]int, 10)new# new 是一个内置的函数，函数签名如下：\nfunc new(Type) *Type其中，\nType 表示类型，new 函数只接受一个参数，这个参数是一个类型 *Type表示类型指针，new 函数返回一个指向该类型内存地址的指针 使用 new 函数得到的是一个类型的指针，并且该指针对应的值为该类型的零值。比如：\nfunc main() { a := new(int) b := new(bool) fmt.Printf(\u0026#34;%T\\n\u0026#34;, a) // *int fmt.Printf(\u0026#34;%T\\n\u0026#34;, b) // *bool fmt.Println(*a) // 0 fmt.Println(*b) // false }\tmake# make 也是用于内存分配的，与 new 区别在于它只用于 slice、map以及 channel 的内存创建，而且它返回的类型就是这三个类型本身，而不是他们的指针类型。\n因为这三种类型就是引用类型，所以就没有必要返回他们的指针了\n函数签名如下：\nfunc make(t Type, size ...IntegerType) Typenew与make的区别# 二者都是用来做内存分配的。 make 只用于slice、map 、channel 的初始化，返回这三个引用类型本身 new 用于类型的内存分配，并且内存对应的值为类型零值，返回的是指向类型的指针 "},{"id":49,"href":"/docs/go/10%E5%8F%8D%E5%B0%84/","title":"10反射","section":"所有文章","content":"Go语言中变量分为两部分：\n类型信息：预先定义好的元信息 值信息：程序运行过程中可动态变化的 反射介绍# 反射是指在程序运行期对程序本身进行访问和修改的能力。程序编译时，变量将被转换为内存地址，变量名不会被编译器写入到可执行部分。这就是说程序运行时无法获取自身的信息。而支持反射的语言可以在程序编译期将变量的反射信息，如字段名称、类型信息、结构体信息等整合到可执行文件中，并给程序提供接口访问反射信息，这样就可以在程序运行期获取类型的反射信息，并且有能力修改它们。\nGo语言运行期使用 reflect 包访问程序的反射信息。reflect 包实现了运行时反射，允许程序操作任意类型的对象。典型用法是用 interface{} 保存一个值，通过调用 TypeOf 获取其动态类型信息，返回一个Type 类型值。调用 ValueOf 函数返回一个Value类型值，该值代表运行时的数据。\nGo的反射系统无法获取到一个可执行文件空间中或者是一个包中的所有类型信息，需要配合使用标准库中对应的词法、语法解析器和抽象语法树（AST）对源码进行扫描后才能获得。\nreflect包# Go语言的反射机制中，任何接口值都由是 一个具体类型 和 具体类型的值 两部分组成的。 Go语言中反射的相关功能由内置的 reflect 包提供，任意接口值在反射中都可以理解为由 reflect.Type 和 reflect.Value 两部分组成，并且 reflect 包提供了 reflect.TypeOf 和 reflect.ValueOf 两个函数来获取任意对象的Value 和 Type 。\ntype name/type kind# 反射中关于类型划分为两种：类型（Type）和种类（Kind）。因为在Go语言中可以使用type关键字构造很多自定义类型，种类（Kind） 指的是对象归属的品种，类型（Type) 指的是系统原生数据类型。比如 map[string]int64 与 map[string]interface{} 它们的类型并不一样，但是都属于map这个种类。\n举个例子，定义了两个指针类型和两个结构体类型，通过反射查看它们的类型和种类：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) type myInt int64 func reflectType(x interface{}) { t := reflect.TypeOf(x) fmt.Printf(\u0026#34;type:%v kind:%v\\n\u0026#34;, t.Name(), t.Kind()) } func main() { var a *float32 // 指针 var b myInt // 自定义类型 var c rune // 类型别名 reflectType(a) // type: kind:ptr reflectType(b) // type:myInt kind:int64 reflectType(c) // type:int32 kind:int32 type person struct { name string age int } type book struct{ title string } var d = person{ name: \u0026#34;沙河小王子\u0026#34;, age: 18, } var e = book{title: \u0026#34;《跟小王子学Go语言》\u0026#34;} reflectType(d) // type:person kind:struct reflectType(e) // type:book kind:struct } 注意：Go语言的反射中像数组、切片、Map、指针等类型的变量，它们的.Name()都是返回空。\nreflect 包中定义的Kind类型如下：\ntype Kind uint const ( Invalid Kind = iota // 非法类型 Bool // 布尔型 Int // 有符号整型 Int8 // 有符号8位整型 Int16 // 有符号16位整型 Int32 // 有符号32位整型 Int64 // 有符号64位整型 Uint // 无符号整型 Uint8 // 无符号8位整型 Uint16 // 无符号16位整型 Uint32 // 无符号32位整型 Uint64 // 无符号64位整型 Uintptr // 指针 Float32 // 单精度浮点数 Float64 // 双精度浮点数 Complex64 // 64位复数类型 Complex128 // 128位复数类型 Array // 数组 Chan // 通道 Func // 函数 Interface // 接口 Map // 映射 Ptr // 指针 Slice // 切片 String // 字符串 Struct // 结构体 UnsafePointer // 底层指针 )TypeOf# Go语言中使用 reflect.TypeOf() 可以获得任意值的类型对象（reflect.Type），程序通过类型对象可以访问任意值的类型信息。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func reflectType(x interface{}) { v := reflect.TypeOf(x) fmt.Printf(\u0026#34;type:%v\\n\u0026#34;, v) } func main() { var a float32 = 3.14 reflectType(a) // type:float32 var b int64 = 100 reflectType(b) // type:int64 }ValueOf# Go语言中使用 reflect.ValueOf()返回的是 reflect.Value 类型，其中包含了原始值的值信息。reflect.Value与原始值之间可以互相转换。\n方法 说明 Interface() interface {} 将值以 interface{} 类型返回，可以通过类型断言转换为指定类型 Int() int64 将值以 int 类型返回，所有有符号整型均可以此方式返回 Uint() uint64 将值以 uint 类型返回，所有无符号整型均可以此方式返回 Float() float64 将值以双精度（float64）类型返回，所有浮点数（float32、float64）均可以此方式返回 Bool() bool 将值以 bool 类型返回 Bytes() []bytes 将值以字节数组 []bytes 类型返回 String() string 将值以字符串类型返回 通过反射获取值# // reflect.ValueOf()可以获取reflect.Value类型，其中包含了原始值的值信息 func reflectValue(x interface{}) { v := reflect.ValueOf(x) k := v.Kind() switch k { case reflect.Int64: // v.Int()从反射中获取整型的原始值，然后通过int64()强制类型转换 fmt.Printf(\u0026#34;type is int64, value is %d\\n\u0026#34;, int64(v.Int())) case reflect.Float32: // v.Float()从反射中获取浮点型的原始值，然后通过float32()强制类型转换 fmt.Printf(\u0026#34;type is float32, value is %f\\n\u0026#34;, float32(v.Float())) case reflect.Float64: // v.Float()从反射中获取浮点型的原始值，然后通过float64()强制类型转换 fmt.Printf(\u0026#34;type is float64, value is %f\\n\u0026#34;, float64(v.Float())) } } // 通过反射获取对象的值reflect.Value func getValue() { var a float32 = 3.14 var b int64 = 100 reflectValue(a) // type is float32, value is 3.140000 reflectValue(b) // type is int64, value is 100 // 将int类型的原始值转换为reflect.Value类型 c := reflect.ValueOf(10) fmt.Printf(\u0026#34;type c :%T\\n\u0026#34;, c) // type c :reflect.Value }通过反射设置值# 如果想在函数中通过反射修改变量的值时需要注意：函数参数传递的是值拷贝，必须传递变量地址才能修改变量值。反射中使用专有的Elem()方法来获取指针对应的值。\n// 通过反射设置值时如果函数参数传递的是值拷贝 func reflectSetValue1(x interface{}) { v := reflect.ValueOf(x) fmt.Printf(\u0026#34;value:%v,kind:%v\u0026#34;, v, v.Kind()) if v.Kind() == reflect.Int64 { v.SetInt(200) // 修改的是副本,reflect包会引发panic } } // 通过反射设置值时必须传递变量地址才能修改变量值 func reflectSetValue2(x interface{}) { v := reflect.ValueOf(x) // 反射中使用 Elem()方法获取指针对应的值 if v.Elem().Kind() == reflect.Int64 { v.Elem().SetInt(200) } } func setValue() { var a int64 = 100 // reflectSetValue1(a) //panic: reflect: reflect.Value.SetInt using unaddressable value reflectSetValue2(\u0026amp;a) fmt.Println(a) }isNil()# func (v Value) IsNil() boolIsNil() 判断 v 持有的值是否为 nil 。v持有的值的分类必须是通道、函数、接口、映射、指针、切片之一，否则会导致panic\nisValid()# func (v Value) IsValid() boolIsValid() 判断否持有一个值。如果 v 是 Value 零值会返回 false ，此时v除了IsValid、String、Kind之外的方法都会导致panic\n代码示例# IsNil() 常被用于判断指针是否为空；IsValid() 常被用于判定返回值是否有效。\nfunc isNilAndisValid() { // *int类型空指针 var a *int fmt.Println(\u0026#34;var a *int IsNil:\u0026#34;, reflect.ValueOf(a).IsNil()) // nil值 fmt.Println(\u0026#34;nil IsValid:\u0026#34;, reflect.ValueOf(nil).IsValid()) // 实例化一个匿名结构体 b := struct{}{} // 尝试从结构体中查找\u0026#34;abc\u0026#34;字段 fmt.Println(\u0026#34;不存在的结构体成员:\u0026#34;, reflect.ValueOf(b).FieldByName(\u0026#34;abc\u0026#34;).IsValid()) // 尝试从结构体中查找\u0026#34;abc\u0026#34;方法 fmt.Println(\u0026#34;不存在的结构体方法:\u0026#34;, reflect.ValueOf(b).MethodByName(\u0026#34;abc\u0026#34;).IsValid()) // map c := map[string]int{} // 尝试从map中查找一个不存在的键 fmt.Println(\u0026#34;map中不存在的键：\u0026#34;, reflect.ValueOf(c).MapIndex(reflect.ValueOf(\u0026#34;wang\u0026#34;)).IsValid()) }结构体反射# 任意值通过 reflect.TypeOf() 获得反射对象信息后，如果它的类型是结构体，可以通过反射值对象（reflect.Type）的 NumField() 和 Field() 方法获得结构体成员的详细信息。reflect.Type 中与获取结构体成员相关的的方法如下：\n方法 说明 Field(i int) StructField 返回索引对应的结构体字段信息 NumField() int 返回结构体成员字段数量 FieldByName(name string) (StructField, bool) 根据给定字符串返回字符串对应的结构体字段信息 FieldByIndex(index []int) StructField 多层成员访问时，根据 []int 提供的每个结构体的字段索引，返回字段信息 FieldByNameFunc(match func(string) bool) (StructField,bool) 根据传入的匹配函数匹配需要的字段 NumMethod() int 返回该类型的方法集中方法的数目 Method(int) Method 返回该类型方法集中的第i个方法 MethodByName(string)(Method, bool) 根据方法名返回该类型方法集中的方法 StructField 类型用来描述结构体中的一个字段的信息。定义如下：\ntype StructField struct { // Name是字段的名字。PkgPath是非导出字段的包路径，对导出字段该字段为\u0026#34;\u0026#34;。 // 参见http://golang.org/ref/spec#Uniqueness_of_identifiers Name string PkgPath string Type Type // 字段的类型 Tag StructTag // 字段的标签 Offset uintptr // 字段在结构体中的字节偏移量 Index []int // 用于Type.FieldByIndex时的索引切片 Anonymous bool // 是否匿名字段 }代码示例：当使用反射得到一个结构体数据之后可以通过索引依次获取其字段信息，也可以通过字段名去获取指定的字段信息。\ntype student struct { Name string `json:\u0026#34;name\u0026#34;` Score int `json:\u0026#34;score\u0026#34;` } func main() { stu1 := student{ Name: \u0026#34;小王子\u0026#34;, Score: 90, } t := reflect.TypeOf(stu1) fmt.Println(t.Name(), t.Kind()) // student struct // 通过for循环遍历结构体的所有字段信息 for i := 0; i \u0026lt; t.NumField(); i++ { field := t.Field(i) fmt.Printf(\u0026#34;name:%s index:%d type:%v json tag:%v\\n\u0026#34;, field.Name, field.Index, field.Type, field.Tag.Get(\u0026#34;json\u0026#34;)) } // 通过字段名获取指定结构体字段信息 if scoreField, ok := t.FieldByName(\u0026#34;Score\u0026#34;); ok { fmt.Printf(\u0026#34;name:%s index:%d type:%v json tag:%v\\n\u0026#34;, scoreField.Name, scoreField.Index, scoreField.Type, scoreField.Tag.Get(\u0026#34;json\u0026#34;)) } }编写函数 printMethod(s interface{}) 遍历打印s包含的方法：\n// 给student添加两个方法 Study和Sleep(注意首字母大写,小写表示不可导出反射无法读取到) func (s student) Study() string { msg := \u0026#34;好好学习，天天向上。\u0026#34; fmt.Println(msg) return msg } func (s student) Sleep() string { msg := \u0026#34;好好睡觉，快快长大。\u0026#34; fmt.Println(msg) return msg } // 反射获取结构体方法并调用 func printMethod(x interface{}) { rType := reflect.TypeOf(x) rValue := reflect.ValueOf(x) fmt.Println(rType.NumMethod()) for i := 0; i \u0026lt; rValue.NumMethod(); i++ { methodType := rValue.Method(i).Type() fmt.Printf(\u0026#34;method name:%s\\n\u0026#34;, rType.Method(i).Name) fmt.Printf(\u0026#34;method:%s\\n\u0026#34;, methodType) // 通过反射调用方法传递的参数必须是 []reflect.Value 类型 var args = []reflect.Value{} rValue.Method(i).Call(args) } }2 method name:Sleep method:func() string 好好睡觉，快快长大。 method name:Study method:func() string 好好学习，天天向上。总结# 使用反射可以写出更灵活的代码。但是反射不应该被滥用，原因有以下三个：\n基于反射的代码是极其脆弱的，反射中的类型错误会在真正运行的时候才会引发 panic 而不是在编译期 大量使用反射的代码通常难以理解 反射的性能低下，基于反射实现的代码通常比正常代码运行速度慢一到两个数量级 "},{"id":50,"href":"/docs/go/11%E7%BB%93%E6%9E%84%E4%BD%93/","title":"11结构体","section":"所有文章","content":"自定义类型# Go语言中有一些基本的数据类型，如string、整型、浮点型、布尔等数据类型， 使用type关键字来定义自定义类型。\n自定义类型是定义了一个全新的类型。可以基于内置的基本类型定义，也可以通过 struct 定义。例如：\n// 将MyInt定义为int类型 type MyInt int通过 type 关键字的定义，MyInt 就是一种新的类型，具有 int 的特性。\n类型别名# 类型别名是Go1.9版本添加的新功能。类型别名规定：TypeAlias 只是Type的别名，本质上TypeAlias与Type是同一个类型。\ntype TypeAlias = Type之前见过的rune和byte就是类型别名，定义如下：\ntype byte = uint8 type rune = int32自定义类型/类型别名区别# 类型别名与类型定义表面上看只有一个等号的差异，通过下面的这段代码来理解它们之间的区别：\n// 类型定义 type NewInt int // 类型别名 type MyInt = int func main() { var a NewInt var b MyInt fmt.Printf(\u0026#34;type of a:%T\\n\u0026#34;, a) // type of a:main.NewInt fmt.Printf(\u0026#34;type of b:%T\\n\u0026#34;, b) // type of b:int }结果显示a的类型是 main.NewInt，表示main包下定义的NewInt类型。b的类型是int。MyInt类型只会在代码中存在，编译完成时并不会有MyInt类型。\n结构定义# Go语言的结构体（struct）和其他语言的类（class）有同等的地位，但Go语言放弃了大量面向对象特性，只保留了组合（composition）这个最基础的特性。Go语言中可以通过 struct 来实现面向对象。\n使用 type 和 struct 关键字来定义结构体，具体代码格式如下：\ntype 类型名 struct { 字段名 字段类型 字段名 字段类型 … }其中：\n类型名：标识自定义结构体的名称。在同一个包内不能重复 字段名：表示结构体字段名。结构体中的字段名必须唯一 字段类型：表示结构体字段的具体类型 比如：定义一个表示矩形的结构\ntype Rect struct { width float64 height float64 }同样类型的字段也可以写在一行，看起来更简洁\ntype Rect struct { width, height float64 }语言内置的基础数据类型是用来描述一个值的，而结构体是用来描述一组值的。本质上是一种聚合型的数据类型。\n结构实例化# 最简单的实例化方式：\nvar rect Rect fmt.Printf(\u0026#34;%p %T \\n\u0026#34;, \u0026amp;rect, rect) rect.height = 13.4 rect.width = 21. fmt.Printf(\u0026#34;%p %T \\n\u0026#34;, \u0026amp;rect, rect) fmt.Println(rect.height, rect.width)0xc0000120a0 main.Rect 0xc0000120a0 main.Rect 13.4 21因为结构是值类型，所以定义结构体类型变量就会分配内存，如果不给结构体中的字段赋值，默认就会是该类型的零值。而后可以通过.来访问结构体的字段\n创建指针类型结构：\n通过使用 new 关键字对结构体进行实例化，得到的是结构体的内存地址。\nvar rect = new(Rect) // Go语言中支持对结构体指针直接使用.来访问结构体的成员 rect.height = 13.4 rect.width = 21.4 // 这里因为使用new()返回的已经是指针类型,所以打印输出时不需要加\u0026amp;取址 fmt.Printf(\u0026#34;%T %p\\n\u0026#34;, rect, rect)*main.Rect 0xc0000aa070使用结构体的地址实例化：\n使用\u0026amp;对结构体进行取地址操作相当于对该结构体类型进行了一次new实例化操作。\nvar rect = \u0026amp;Rect{} rect.height = 13.4 rect.width = 21.4 fmt.Printf(\u0026#34;%T %p\\n\u0026#34;, rect, rect)结构初始化# 默认：没有初始化的结构体，其成员变量都是对应其类型的零值。\nvar rect Rect fmt.Printf(\u0026#34;%#v \\n\u0026#34;, rect)main.Rect{width:0, height:0}使用键值对初始化：\n使用键值对初始化时，键对应结构体的字段，值对应该字段的初始值。\nrect := Rect{width: 10.5, height: 3.5} fmt.Printf(\u0026#34;%#v \\n\u0026#34;, rect)也可以对结构体指针进行键值对初始化，比如：\n// 对结构体指针进行键值初始化 rect2 := \u0026amp;Rect{width: 10.5, height: 3.5} fmt.Printf(\u0026#34;%#v \\n\u0026#34;, rect2)如果字段没有初始值,可以省略，那么被省略的值就是该字段的零值。\n// 如果字段没有初始值,可以省略,那么被省略的值就是该字段的零值 rect3 := Rect{width: 100.0} fmt.Printf(\u0026#34;%#v \\n\u0026#34;, rect3)\t使用值的列表初始化：\n初始化结构体的时候可以简写，也就是初始化的时候不写键，直接写值：\nrect := Rect{10.5, 3.5} fmt.Printf(\u0026#34;%#v \\n\u0026#34;, rect) rect2 := \u0026amp;Rect{10.5, 3.5} fmt.Printf(\u0026#34;%#v \\n\u0026#34;, rect2)使用这种格式初始化时，需要注意：\n必须初始化结构体的所有字段 初始值的填充顺序必须与字段在结构体中的声明顺序一致 该方式不能和键值初始化方式混用 匿名结构体# 在定义一些临时数据结构等场景下可以使用匿名结构体。\n// 匿名结构体 var user struct { name string age int } user.name = \u0026#34;wangpengliang\u0026#34; user.age = 18 fmt.Printf(\u0026#34;%v \\n\u0026#34;, user)空结构体# 空结构体不占用内存空间。\nvar a struct{} fmt.Println(unsafe.Sizeof(a)) // 0结构体内存布局# 结构体占用一块连续的内存。\nTODO：在 Go 中恰到好处的内存对齐\n构造函数# Go语言的结构体没有构造函数，可以自己实现。 因为struct是值类型，如果结构体比较复杂的话，值拷贝性能开销会比较大，所以构造函数返回的是结构体指针类型。\n// 如果不初始化,字段值为类型零值 type Person struct { name string age int address string hobby []string }// 第一种方式,使用指定值初始化结构体,返回指针类型 func NewPerson(name, address string, age int, hobby []string) *Person { instance := new(Person) instance.name = name instance.address = address instance.age = age instance.hobby = hobby return instance } // 第二种方式,使用\u0026amp;初始化结构体,返回指针类型 func NewPerson2(name, address string, age int) *Person { return \u0026amp;Person{ name: name, address: address, age: age, } }Go中不支持函数重载，但是可以通过两个名称不同的构造函数来模拟实现构造函数重载。\na := NewPerson(\u0026#34;wangpengliang\u0026#34;, \u0026#34;beijing\u0026#34;, 18, []string{\u0026#34;java\u0026#34;, \u0026#34;go\u0026#34;}) fmt.Println(a) b := NewPerson2(\u0026#34;wangpengliang\u0026#34;, \u0026#34;beijing\u0026#34;, 18) fmt.Println(b)\t方法和接收者# Go语言中的方法（Method）是一种作用于特定类型变量的函数。这种特定类型变量叫做接收者（Receiver）方法的定义格式如下：\nfunc (接收者变量 接收者类型) 方法名(参数列表) (返回参数) { 函数体 }其中：\n接收者变量：接收者中的参数变量名在命名时，官方建议使用接收者类型名称首字母的小写，而不是self、this之类的命名。例如，Person类型的接收者变量应该命名为 p，Connector类型的接收者变量应该命名为c等 接收者类型：接收者类型和参数类似，可以是指针类型和非指针类型 方法名、参数列表、返回参数：具体格式与函数定义相同 简单理解：因为Go语言中没有Class的概念，所以不存在实例化一个类调用其中某个方法这种做法，Go语言中的方法其实就是给指定结构添加方法。比如：\n// 给结构体Person定义方法,所谓方法在go中就是定义了接受者的函数 func (p Person) say1() { fmt.Printf(\u0026#34;name: %s,age：%d \\n\u0026#34;, p.name, p.age) } func (p Person) addAge1() { p.age = p.age + 1 }方法与函数的区别在于：函数不属于任何类型，方法属于特定的类型。\n值类型的接收者# 当方法作用于值类型接收者时，Go语言会在代码运行时将接收者的值复制一份。在值类型接收者的方法中可以获取接收者的成员值，但修改操作只是针对副本，无法修改接收者变量本身。比如：\n// 给结构体Person定义方法,所谓方法在go中就是定义了接受者的函数 func (p Person) say1() { fmt.Printf(\u0026#34;name: %s,age：%d \\n\u0026#34;, p.name, p.age) } func (p Person) addAge1() { p.age = p.age + 1 }\tvar p1 Person = Person{\u0026#34;zhansan\u0026#34;, 16, \u0026#34;beijing\u0026#34;, []string{}} p1.addAge1() p1.say1() var p2 *Person = \u0026amp;Person{\u0026#34;lisi\u0026#34;, 16, \u0026#34;shanghai\u0026#34;, []string{}} p2.addAge1() p2.say1()name: zhansan,age：16 name: lisi,age：16 指针类型的接收者# 指针类型的接收者由一个结构体的指针组成，由于指针的特性，调用方法时修改接收者指针的任意成员变量，在方法结束后，修改都是有效的。\nfunc (p *Person) say2() { fmt.Printf(\u0026#34;name: %s,age：%d \\n\u0026#34;, p.name, p.age) } func (p *Person) addAge2() { p.age = p.age + 1 }\tvar p3 Person = Person{\u0026#34;zhansan\u0026#34;, 16, \u0026#34;beijing\u0026#34;, []string{}} p3.addAge2() p3.say2() var p4 *Person = \u0026amp;Person{\u0026#34;lisi\u0026#34;, 16, \u0026#34;beijing\u0026#34;, []string{}} p4.addAge2() p4.say2()name: zhansan,age：17 name: lisi,age：17 什么时候使用指针类型接收?\n需要修改接收者中的值 接收者是拷贝代价比较大的大对象 保证一致性，如果有某个方法使用了指针接收者，那么其他的方法也应该使用指针接收者。 任意类型添加方法# Go语言中，接收者的类型可以是任何类型，不仅仅是结构体，任何类型都可以拥有方法。比如：基于内置的int类型使用 type 关键字可以定义新的自定义类型，然后为自定义类型添加方法。\n// MyInt 将int定义为自定义MyInt类型 type MyInt int // SayHello 为MyInt添加一个SayHello的方法 func (m MyInt) SayHello() { fmt.Println(\u0026#34;Hello, 我是一个int。\u0026#34;) } func main() { var m1 MyInt m1.SayHello() //Hello, 我是一个int。 m1 = 100 fmt.Printf(\u0026#34;%#v %T\\n\u0026#34;, m1, m1) //100 main.MyInt }注意事项： 非本地类型不能定义方法，不能给别的包的类型定义方法。\n结构体的匿名字段# 结构体允许其成员字段在声明时没有字段名而只有类型，这种没有名字的字段就称为匿名字段。\n// 匿名字段的说法并不代表没有字段名，而是默认会采用类型名作为字段名，结构体要求字段名称必须唯一，因此一个结构体中同种类型的匿名字段只能有一个 type Book struct { string float64 } func main() { book := Book{ \u0026#34;go语言编程\u0026#34;, 100.00, } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, book) // main.Book{string:\u0026#34;go语言编程\u0026#34;, float64:100} fmt.Println(book.string, book.float64) //北京 go语言编程 100 }注意：这里匿名字段的说法并不代表没有字段名，而是默认会采用类型名作为字段名，结构体要求字段名称必须唯一，因此一个结构体中同种类型的匿名字段只能有一个。\n嵌套结构体# 一个结构体中可以嵌套包含另一个结构体或结构体指针，比如：\n// 地址结构体 type Address struct { Province string City string } // 用户结构体 type User struct { Name string Gender string Address Address } func main() { user := User{ Name: \u0026#34;wangpengliang\u0026#34;, Gender: \u0026#34;男\u0026#34;, Address: Address{ Province: \u0026#34;山西\u0026#34;, City: \u0026#34;长治\u0026#34;, }, } fmt.Printf(\u0026#34;user=%#v\\n\u0026#34;, user) }user=main.User{Name:\u0026#34;wangpengliang\u0026#34;, Gender:\u0026#34;男\u0026#34;, Address:main.Address{Province:\u0026#34;山西\u0026#34;, City:\u0026#34;长治\u0026#34;}}嵌套匿名字段# 上面user结构体中嵌套的Address结构体也可以采用匿名字段的方式，匿名字段默认使用类型名作为字段名。比如：\n// 地址结构体 type Address struct { province string city string } // 用户结构体 type User struct { name string gender string address Address // 该字段为具名字段 Address // 嵌套的Address结构体也可以采用匿名字段的方式 } func main() { user := User{ name: \u0026#34;wangpengliang\u0026#34;, gender: \u0026#34;男\u0026#34;, address: Address{ province: \u0026#34;山西\u0026#34;, city: \u0026#34;长治\u0026#34;, }, Address: Address{ province: \u0026#34;北京\u0026#34;, city: \u0026#34;北京\u0026#34;, }, } fmt.Printf(\u0026#34;user=%#v\\n\u0026#34;, user) }user=main.User{name:\u0026#34;wangpengliang\u0026#34;, gender:\u0026#34;男\u0026#34;, address:main.Address{province:\u0026#34;山西\u0026#34;, city:\u0026#34;长治\u0026#34;}, Address:main.Address{province:\u0026#34;北京\u0026#34;, city:\u0026#34;北京\u0026#34;}}当访问结构体成员时会先在结构体中查找该字段，找不到再去嵌套的匿名字段中查找。\n嵌套结构体字段名冲突# 嵌套结构体内部可能存在相同的字段名。这种情况下为了避免歧义需要通过指定具体的内嵌结构体字段名。\n// 地址结构体 type Address struct { province string city string createTime string } // 邮箱结构体 type Email struct { account string createTime string } // 用户结构体 type User struct { name string gender string address Address // 该字段为具名字段 Address // 嵌套的Address结构体也可以采用匿名字段的方式 Email } func main() { // 具名字段赋值 user := User{ name: \u0026#34;wangpengliang\u0026#34;, gender: \u0026#34;男\u0026#34;, address: Address{ province: \u0026#34;山西\u0026#34;, city: \u0026#34;长治\u0026#34;, }, } fmt.Printf(\u0026#34;user=%#v\\n\u0026#34;, user) // 匿名字段 user1 := User{ name: \u0026#34;wangpengliang\u0026#34;, gender: \u0026#34;男\u0026#34;, Address: Address{ province: \u0026#34;山西\u0026#34;, city: \u0026#34;长治\u0026#34;, }, } fmt.Printf(\u0026#34;user1=%#v\\n\u0026#34;, user1) var user2 User user2.name = \u0026#34;wangpengliang\u0026#34; user2.gender = \u0026#34;男\u0026#34; // user2.createTime = \u0026#34;2019\u0026#34; //ambiguous selector user2.createTime user2.Address.createTime = \u0026#34;2000\u0026#34; //指定Address结构体中的createTime user2.Email.createTime = \u0026#34;2000\u0026#34; //指定Email结构体中的createTime }user=main.User{name:\u0026#34;wangpengliang\u0026#34;, gender:\u0026#34;男\u0026#34;, address:main.Address{province:\u0026#34;山西\u0026#34;, city:\u0026#34;长治\u0026#34;, createTime:\u0026#34;\u0026#34;}, Address:main.Address{province:\u0026#34;\u0026#34;, city:\u0026#34;\u0026#34;, createTime:\u0026#34;\u0026#34;}, Email:main.Email{account:\u0026#34;\u0026#34;, createTime:\u0026#34;\u0026#34;}} user=main.User{name:\u0026#34;wangpengliang\u0026#34;, gender:\u0026#34;男\u0026#34;, address:main.Address{province:\u0026#34;\u0026#34;, city:\u0026#34;\u0026#34;, createTime:\u0026#34;\u0026#34;}, Address:main.Address{province:\u0026#34;山西\u0026#34;, city:\u0026#34;长治\u0026#34;, createTime:\u0026#34;\u0026#34;}, Email:main.Email{account:\u0026#34;\u0026#34;, createTime:\u0026#34;\u0026#34;}}结构体字段可见性# 结构体中字段大写开头表示可公开访问，小写表示私有（仅在定义当前结构体的包中可访问）。\n结构体与JSON序列化# JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。易于阅读和编写。同时也易于机器解析和生成。JSON键值对是用来保存JS对象的一种方式，键/值对组合中的键名写在前面并用双引号\u0026quot;\u0026quot;包裹，使用冒号:分隔，然后紧接着值；多个键值之间使用英文,分隔。\n// Student type Student struct { ID int Gender string Name string } // Class type Class struct { Title string Students []*Student } func jsonSerializeTest() { c := \u0026amp;Class{ Title: \u0026#34;101\u0026#34;, Students: make([]*Student, 0, 200), } for i := 0; i \u0026lt; 10; i++ { stu := \u0026amp;Student{ Name: fmt.Sprintf(\u0026#34;stu%02d\u0026#34;, i), Gender: \u0026#34;男\u0026#34;, ID: i, } c.Students = append(c.Students, stu) } // JSON序列化：结构体--\u0026gt;JSON格式的字符串 data, err := json.Marshal(c) if err != nil { fmt.Println(\u0026#34;json marshal failed\u0026#34;) return } fmt.Printf(\u0026#34;json:%s\\n\u0026#34;, data) //JSON反序列化：JSON格式的字符串--\u0026gt;结构体 str := `{\u0026#34;Title\u0026#34;:\u0026#34;101\u0026#34;,\u0026#34;Students\u0026#34;:[{\u0026#34;ID\u0026#34;:0,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu00\u0026#34;},{\u0026#34;ID\u0026#34;:1,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu01\u0026#34;},{\u0026#34;ID\u0026#34;:2,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu02\u0026#34;},{\u0026#34;ID\u0026#34;:3,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu03\u0026#34;},{\u0026#34;ID\u0026#34;:4,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu04\u0026#34;},{\u0026#34;ID\u0026#34;:5,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu05\u0026#34;},{\u0026#34;ID\u0026#34;:6,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu06\u0026#34;},{\u0026#34;ID\u0026#34;:7,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu07\u0026#34;},{\u0026#34;ID\u0026#34;:8,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu08\u0026#34;},{\u0026#34;ID\u0026#34;:9,\u0026#34;Gender\u0026#34;:\u0026#34;男\u0026#34;,\u0026#34;Name\u0026#34;:\u0026#34;stu09\u0026#34;}]}` c1 := \u0026amp;Class{} err = json.Unmarshal([]byte(str), c1) if err != nil { fmt.Println(\u0026#34;json unmarshal failed!\u0026#34;) return } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, c1) }结构体标签（Tag）# Tag是结构体的元信息，可以在运行时通过反射读取出来。 Tag在结构体字段的后方定义，由一对反引号包裹起来，格式如下：\n`key1:\u0026#34;value1\u0026#34; key2:\u0026#34;value2\u0026#34;`结构体tag由一个或多个键值对组成。键与值使用冒号分隔，值用双引号括起来。同一个结构体字段可以设置多个键值对tag，不同的键值对之间使用空格分隔。\n注意事项： 为结构体编写Tag时，必须严格遵守键值对的规则。结构体标签的解析代码的容错能力很差，一旦格式写错，编译和运行时都不会提示任何错误，通过反射也无法正确取值。例如不要在key和value之间添加空格。\nGo 中标签最常见的用途比如 marshalling。看一下来自 JSON 包的函数 Marshal 如何使用它（源代码）：\nimport ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { type T struct { F1 int `json:\u0026#34;f_1\u0026#34;` F2 int `json:\u0026#34;f_2,omitempty\u0026#34;` F3 int `json:\u0026#34;f_3,omitempty\u0026#34;` F4 int `json:\u0026#34;-\u0026#34;` } t := T{1, 0, 2, 3} b, err := JSON.Marshal(t) if err != nil { panic(err) } fmt.Printf(\u0026#34;%s\\n\u0026#34;, b) // {\u0026#34;f_1\u0026#34;:1,\u0026#34;f_3\u0026#34;:2} }xml 包也利用了标签 - https://golang.org/pkg/encoding/xml/#MarshalIndent.\nORM\n像 GORM 这样的对象关系映射工具，也广泛使用标签 - 例子.\n摘要数据（Digesting forms data）\nhttps://godoc.org/github.com/gorilla/schema\n其他（Other）\n标签的更多潜在用例，如配置管理，结构的默认值，验证，命令行参数描述等（众所周知的结构标记列表）。\n练习题一# func exercises01Test() { make := make(map[int]*int) slice := []int{0, 1, 2, 3} for index, value := range slice { make[index] = \u0026amp;value } for k, v := range make { fmt.Println(k, \u0026#34;=\u0026gt;\u0026#34;, *v) } }输出：\n0 =\u0026gt; 3 1 =\u0026gt; 3 2 =\u0026gt; 3 3 =\u0026gt; 3思考：这里输出map的value为什么都是3?\n调整代码：输出指针地址\nfor index, value := range slice { fmt.Printf(\u0026#34;%p \\n\u0026#34;, \u0026amp;value) make[index] = \u0026amp;value }0xc000012088 0xc000012088 0xc000012088 0xc000012088 这里其实就可以看出来了，\u0026amp;stu 指向了同一个内存地址，当遍历到最后一个元素时，将3写入了该地址。导致映射所有值都相同。for range 创建了每个元素的副本，而不是直接返回每个元素的引用，如果使用该值变量的地址作为指向每个元素的指针，就会导致错误，迭代时返回的变量是一个迭代过程中根据切片依次赋值的新变量，所以值的地址总是相同的，导致结果不如预期。\n修改代码：\nfunc exercises02Test() { make := make(map[int]*int) slice := []int{0, 1, 2, 3} for index, value := range slice { // 循环中使用新的变量接收 item := value fmt.Printf(\u0026#34;%p \\n\u0026#34;, \u0026amp;item) make[index] = \u0026amp;item } for k, v := range make { fmt.Println(k, \u0026#34;=\u0026gt;\u0026#34;, *v) } }0xc000012088 0xc0000120c0 0xc0000120c8 0xc0000120d0 3 =\u0026gt; 3 0 =\u0026gt; 0 1 =\u0026gt; 1 2 =\u0026gt; 2这个问题很像C#学习委托时遇到的闭包问题。上面问题还可以使用传统的 for 循环处理：\nfunc exercises03Test() { make := make(map[int]*int) slice := []int{0, 1, 2, 3} for i := 0; i \u0026lt; len(slice); i++ { make[i] = \u0026amp;slice[i] } for k, v := range make { fmt.Println(k, \u0026#34;=\u0026gt;\u0026#34;, *v) } }0xc0000101e0 0xc0000101e8 0xc0000101f0 0xc0000101f8 0 =\u0026gt; 0 1 =\u0026gt; 1 2 =\u0026gt; 2 3 =\u0026gt; 3 练习题二# 因为 slice 和 map 这两种数据类型都包含了指向底层数据的指针，因此在需要复制它们时要特别注意。来看下面的例子：\ntype Test struct { name string age int8 dreams []string } func (t *Test) setDreams(dreams []string) { t.dreams = dreams } func exercises02Test() { t := Test{name: \u0026#34;wangpengliang\u0026#34;, age: 18} data := []string{\u0026#34;吃饭\u0026#34;, \u0026#34;睡觉\u0026#34;, \u0026#34;搞钱\u0026#34;} t.setDreams(data) // 真的想修改t.dreams吗？ data[1] = \u0026#34;不睡觉\u0026#34; fmt.Println(t.dreams) // }[吃饭 不睡觉 搞钱]这里因为 slice 和 map 这两种数据类型都包含了指向底层数据的指针所以修改了 slice 导致结构体内容也被修改，正确做法应该是：方法中使用传入的slice的拷贝进行结构体赋值。\nfunc (t *Test) setDreams(dreams []string) { t.dreams = make([]string, len(dreams)) copy(t.dreams, dreams) }\tt := Test{name: \u0026#34;wangpengliang\u0026#34;, age: 18} data := []string{\u0026#34;吃饭\u0026#34;, \u0026#34;睡觉\u0026#34;, \u0026#34;搞钱\u0026#34;} t.setDreams(data) data[1] = \u0026#34;不睡觉\u0026#34; fmt.Println(t.dreams) [吃饭 睡觉 搞钱]"},{"id":51,"href":"/docs/go/12%E6%8E%A5%E5%8F%A3/","title":"12接口","section":"所有文章","content":"接口（interface）定义了一个对象的行为规范，只定义规范具体对象来实现规范的细节。Go语言中接口（interface）是一种抽象类型。与C#中接口的定义是一样的，相较于具体类型比如字符串、切片、结构体等（更注重“我是什么”），接口类型更注重“能做什么”。接口类型像是一种约定。Go语言中提倡使用面向接口的编程方式实现解耦。\n接口类型# 接口是一种由程序员定义的类型，一个接口类型就是一组方法的集合，它规定了需要实现的所有方法。相较于使用结构体类型，当使用接口类型说明：相比于它是什么更关心它能做什么。\n接口定义# 每个接口类型由任意个方法签名组成，定义格式如下：\ntype 接口类型名 interface{ 方法名1( 参数列表1 ) 返回值列表1 方法名2( 参数列表2 ) 返回值列表2 … }其中：\n接口类型名：Go语言的接口在命名时，一般会在单词后面添加er，就像C#中接口定义通常以I 开头，接口名要能突出该接口的类型含义 方法名：当方法名首字母是大写且这个接口类型名首字母也是大写时，这个方法可以被接口所在的包（package）之外的代码访问 参数列表、返回值列表：参数列表和返回值列表中的参数变量名可以省略 比如，定义一个包含Write方法的Writer接口\ntype Writer interface{ Write([]byte) error }当看到一个Writer接口类型的值时，不知道它是什么，唯一知道的就是可以通过调用它的Write方法来做一些事。\n实现接口的条件# 接口规定了一个需要实现的方法列表，Go 语言中一个类型只要实现了接口中规定的所有方法，就称它实现了这个接口。在C#或者Java语言中都需要显式声明类实现了哪些接口，Go语言中则使用隐式声明的方式实现接口。\n值接收者和指针接收者# 之前介绍了在定义结构体方法时既可以使用值接收者也可以使用指针接收者。那么对于实现接口来说使用值接收者和使用指针接收者有什么区别呢？通过一个例子来看一下。\n我们定义一个Mover接口，它包含一个Move方法。\ntype Move interface { Move() }值接收者实现接口# 定义一个Dog结构体类型，并使用值接收者为其定义一个Move方法\ntype Dog struct{} // Move 使用值接收者定义Move方法实现Mover接口 func (d Dog) Move() { fmt.Println(\u0026#34;狗会动\u0026#34;) }此时实现Mover接口的是Dog类型。\nvar x Mover // 声明一个Mover类型的变量x var d1 = Dog{} // d1是Dog类型 x = d1 // 可以将d1赋值给变量x x.Move() var d2 = \u0026amp;Dog{} // d2是Dog指针类型 x = d2 // 也可以将d2赋值给变量x x.Move()狗会动 狗会动上面的代码中可以发现，使用值接收者实现接口之后，不管是结构体类型还是对应的结构体指针类型的变量都可以赋值给该接口变量。\n指针接收者实现接口# 再来测试一下使用指针接收者实现接口有什么区别。\n// Cat 猫结构体类型 type Cat struct{} // Move 使用指针接收者定义Move方法实现Mover接口 func (c *Cat) Move() { fmt.Println(\u0026#34;猫会动\u0026#34;) }此时实现Mover接口的是*Cat类型，可以将*Cat类型的变量直接赋值给Mover接口类型的变量x。\nvar c2 = \u0026amp;Cat{} // c2是*Cat类型 x = c2 // 可以将c2当成Mover类型 x.Move()但是不能将Cat类型的变量赋值给Mover接口类型的变量x。\n// 下面的代码无法通过编译 var c1 = Cat{} // c1是Cat类型 x = c1 // 不能将c1当成Mover类型由于Go语言中有对指针求值的语法糖，对于值接收者实现的接口，无论使用值类型还是指针类型都没有问题。但是并不总是能对一个值求址，所以对于指针接收者实现的接口要额外注意。\n类型与接口# 一个类型实现多个接口# 一个类型可以同时实现多个接口，而接口间彼此独立，不知道对方的实现。例如狗不仅可以叫，还可以动。可以分别定义Sayer接口和Mover接口，代码示例如下。\n// Sayer 接口 type Sayer interface { Say() } // Mover 接口 type Mover interface { Move() }Dog既可以实现Sayer接口，也可以实现Mover接口。\ntype Dog struct { name string } // Move 使用值接收者定义Move方法实现Mover接口 func (d Dog) Move() { fmt.Println(\u0026#34;狗会动\u0026#34;) } // 实现Sayer接口 func (d Dog) Say() { fmt.Printf(\u0026#34;%s会叫汪汪汪\\n\u0026#34;, d.name) }同一个类型实现不同的接口互相不影响使用。\nvar d = Dog{Name: \u0026#34;旺财\u0026#34;} var s Sayer = d var m Mover = d s.Say() // 对Sayer类型调用Say方法 m.Move() // 对Mover类型调用Move方法多种类型实现同一接口# Go语言中不同的类型还可以实现同一接口。例如不仅狗可以动，汽车也可以动。可以使用如下代码体现：\n// 实现Mover接口 func (d Dog) Move() { fmt.Printf(\u0026#34;%s会动\\n\u0026#34;, d.Name) } // Car 汽车结构体类型 type Car struct { Brand string } // Move Car类型实现Mover接口 func (c Car) Move() { fmt.Printf(\u0026#34;%s速度70迈\\n\u0026#34;, c.Brand) }这样在代码中就可以把狗和汽车当成一个会动的类型来处理，不必关注它们具体是什么，只需要调用Move方法即可。\nvar x Mover x = Dog{name: \u0026#34;旺财\u0026#34;} x.Move() x = Car{brand: \u0026#34;宝马\u0026#34;} x.Move()一个接口的所有方法，不一定需要由一个类型完全实现，接口的方法可以通过在类型中嵌入其他类型或者结构体来实现。\n// 洗衣机 type WashingMachine interface { // 清洗 wash() // 烘干 dry() } // 海尔洗衣机 type haier struct { dryer // 嵌入甩干器 } // 实现WashingMachine接口的wash()方法 func (h haier) wash() { fmt.Println(\u0026#34;洗刷刷\u0026#34;) } // 甩干机 type dryer struct{} func (d dryer) dry() { fmt.Println(\u0026#34;甩一甩\u0026#34;) }接口组合# 接口与接口之间可以通过互相嵌套形成新的接口类型，例如Go标准库io源码中就有很多接口之间互相组合的示例。\n// src/io/io.go type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } type Closer interface { Close() error } // ReadWriter 是组合Reader接口和Writer接口形成的新接口类型 type ReadWriter interface { Reader Writer } // ReadCloser 是组合Reader接口和Closer接口形成的新接口类型 type ReadCloser interface { Reader Closer } // WriteCloser 是组合Writer接口和Closer接口形成的新接口类型 type WriteCloser interface { Writer Closer }对于这种由多个接口类型组合形成的新接口类型，同样只需要实现新接口类型中规定的所有方法就算实现了该接口类型。\n接口也可以作为结构体的一个字段，看一段Go标准库sort源码中的示例。\n// src/sort/sort.go // Interface 定义通过索引对元素排序的接口类型 type Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } // reverse 结构体中嵌入了Interface接口 type reverse struct { Interface }通过在结构体中嵌入一个接口类型，从而让该结构体类型实现了该接口类型，并且还可以改写该接口的方法。\n// Less 为reverse类型添加Less方法，重写原Interface接口类型的Less方法 func (r reverse) Less(i, j int) bool { return r.Interface.Less(j, i) }Interface类型原本的Less方法签名为Less(i, j int) bool，此处重写为r.Interface.Less(j, i)，即通过将索引参数交换位置实现反转。\n在这个示例中还有一个需要注意的地方是reverse结构体本身是不可导出的（结构体类型名称首字母小写），sort.go中通过定义一个可导出的Reverse函数来让使用者创建reverse结构体实例。\nfunc Reverse(data Interface) Interface { return \u0026amp;reverse{data} }这样做的目的是保证得到的reverse结构体中的Interface属性一定不为nil，否者r.Interface.Less(j, i)就会出现空指针panic。\n此外在Go内置标准库database/sql中也有很多类似的结构体内嵌接口类型的使用示例。\n空接口# 空接口是指没有定义任何方法的接口类型。因此任何类型都可以视为实现了空接口。也正是因为这个特性，空接口类型的变量可以存储任意类型的值。\n// Any 不包含任何方法的空接口类型 type Any interface{} type Person struct{} // 空接口类型的变量可以存储任意类型的值 func emptyInterfaceTest() { // 声明空接口类型变量 var x Any x = \u0026#34;你好\u0026#34; // 字符串型 fmt.Printf(\u0026#34;type:%T value:%v\\n\u0026#34;, x, x) x = 100 // int型 fmt.Printf(\u0026#34;type:%T value:%v\\n\u0026#34;, x, x) x = true // 布尔型 fmt.Printf(\u0026#34;type:%T value:%v\\n\u0026#34;, x, x) x = Person{} // 结构体类型 fmt.Printf(\u0026#34;type:%T value:%v\\n\u0026#34;, x, x) }通常在使用空接口类型时不必使用type关键字声明，可以像下面的代码一样直接使用interface{}。\nvar x interface{} // 声明一个空接口类型变量x空接口作为函数参数# 使用空接口实现可以接收任意类型的函数参数。\n// 空接口作为函数参数 func print(a interface{}) { fmt.Printf(\u0026#34;type:%T value:%v\\n\u0026#34;, a, a) }空接口作为map的值# 使用空接口实现可以保存任意值的字典。\nfunc emptyInterfaceTest4() { var person = make(map[string]interface{}) person[\u0026#34;name\u0026#34;] = \u0026#34;wangpengliang\u0026#34; person[\u0026#34;age\u0026#34;] = 18 person[\u0026#34;married\u0026#34;] = false fmt.Println(person) }接口值# 由于接口类型的值可以是任意一个实现了该接口的类型值，所以接口值除了需要记录具体值之外，还需要记录这个值属于的类型。也就是说接口值由“类型”和“值”组成，鉴于这两部分会根据存入值的不同而发生变化，称之为接口的动态类型和动态值。\n通过一个示例来加深对接口值的理解，示例代码中，定义了一个Mover接口类型和两个实现了该接口的Dog和Car结构体类型。\ntype Mover interface { Move() } type Dog struct { Name string } func (d *Dog) Move() { fmt.Println(\u0026#34;狗在跑~\u0026#34;) } type Car struct { Brand string } func (c *Car) Move() { fmt.Println(\u0026#34;汽车在跑~\u0026#34;) }首先创建一个Mover接口类型的变量m。\nvar m Mover此时，接口变量m是接口类型的零值，也就是它的类型和值部分都是nil，就如下图所示。 可以使用m == nil来判断此时的接口值是否为空。\nfmt.Println(m == nil) // true注意：不能对一个空接口值调用任何方法，否则会产生panic。\nm.Move() // panic: runtime error: invalid memory address or nil pointer dereference接下来将一个*Dog结构体指针赋值给变量m，此时m的动态类型会被设置为*Dog，动态值为结构体变量的拷贝。\nm = \u0026amp;Dog{Name: \u0026#34;旺财\u0026#34;}\n然后给接口变量m赋值为一个*Car类型的值。此时接口值的动态类型为*Car，动态值为nil。\nm = new(Car)\n注意：此时接口变量m与nil并不相等，因为它只是动态值的部分为nil，而动态类型部分保存着对应值的类型。\nfmt.Println(m == nil) // false接口值是支持相互比较的，当且仅当接口值的动态类型和动态值都相等时才相等。\nvar ( x Mover2 = new(Dog2) y Mover2 = new(Car2) ) fmt.Println(x == y) // false有一种特殊情况需要特别注意，如果接口值的保存的动态类型相同，但是这个动态类型不支持互相比较（比如切片），那么对它们相互比较时就会引发 panic。\nvar z interface{} = []int{1, 2, 3} fmt.Println(z == z) // panic: runtime error: comparing uncomparable type []int类型断言# 接口值可能赋值为任意类型的值，如何从接口值获取其存储的具体数据呢？可以借助标准库 fmt 包的格式化打印获取到接口值的动态类型。\nvar m Mover m = \u0026amp;Dog{Name: \u0026#34;旺财\u0026#34;} fmt.Printf(\u0026#34;%T\\n\u0026#34;, m) // *main.Dog m = new(Car) fmt.Printf(\u0026#34;%T\\n\u0026#34;, m) // *main.Car而fmt包内部其实是使用反射的机制在程序运行时获取到动态类型的名称。而想要从接口值中获取到对应的实际值需要使用类型断言，其语法格式如下。\nx.(T)其中：\nx：表示接口类型的变量 T：表示断言x可能是的类型。 该语法返回两个参数，第一个参数是x转化为T类型后的变量，第二个值是一个布尔值，若为true则表示断言成功，为false则表示断言失败。\n比如：\nvar n Mover = \u0026amp;Dog{Name: \u0026#34;旺财\u0026#34;} v, ok := n.(*Dog) if ok { fmt.Println(\u0026#34;类型断言成功\u0026#34;) v.Name = \u0026#34;富贵\u0026#34; // 变量v是*Dog类型 } else { fmt.Println(\u0026#34;类型断言失败\u0026#34;) }如果对一个接口值有多个实际类型需要判断，推荐使用switch语句来实现。\n// justifyType 对传入的空接口类型变量x进行类型断言 func justifyType(x interface{}) { switch v := x.(type) { case string: fmt.Printf(\u0026#34;x is a string，value is %v\\n\u0026#34;, v) case int: fmt.Printf(\u0026#34;x is a int is %v\\n\u0026#34;, v) case bool: fmt.Printf(\u0026#34;x is a bool is %v\\n\u0026#34;, v) default: fmt.Println(\u0026#34;unsupport type！\u0026#34;) } }由于接口类型变量能够动态存储不同类型值的特点，所以很多人会滥用接口类型（特别是空接口）来实现编码过程中的便捷。只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要定义接口。切记不要为了使用接口类型而增加不必要的抽象，导致不必要的运行时损耗。\n在 Go 语言中接口是一个非常重要的概念和特性，使用接口类型能够实现代码的抽象和解耦，也可以隐藏某个功能的内部实现，但是缺点就是在查看源码的时候，不太方便查找到具体实现接口的类型。切记：接口是一种类型，一种抽象的类型。它是一个只要求实现特定方法的抽象类型。\n小技巧： 下面的代码可以在程序编译阶段验证某一结构体是否满足特定的接口类型。\n// 摘自gin框架routergroup.go type IRouter interface{ ... } type RouterGroup struct { ... } var _ IRouter = \u0026amp;RouterGroup{} // 确保RouterGroup实现了接口IRouter上面的代码中也可以使用 var _ IRouter = (*RouterGroup)(nil) 进行验证。\n"},{"id":52,"href":"/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/channel/","title":"Channel","section":"所有文章","content":"channel# 上一章学习了 goroutine 的使用方式。但是单纯的将函数并发执行并没有意义。函数与函数间需要交换数据才能体现并发执行的意义。虽然可以使用共享内存进行数据交换，但是共享内存在不同的 goroutine 中容易发生竞态问题。为了保证数据交换的正确性，很多并发模型中必须使用互斥量对内存进行加锁，但这种做法势必造成性能问题。\nGo语言采用的并发模型是 CSP（Communicating Sequential Processes） 提倡：通过通信共享内存而不是通过共享内存实现通信。\n如果把 goroutine 比作是Go程序并发的执行体，channel就是它们之间的连接。channel 是可以让一个 goroutine 发送特定值到另一个 goroutine 的通信机制。\nGo语言中的通道 channel 是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是说：声明 channel 时需要为其指定元素类型。\nchannel 类型# channel 是 Go 语言中一种特有的类型。声明格式如下：\nvar 变量名称 chan 元素类型其中：\nchan ：关键字 元素类型：是指通道中传递元素的类型 比如：\nvar ch1 chan int // 声明一个传递整型的通道 var ch2 chan bool // 声明一个传递布尔型的通道 var ch3 chan []int // 声明一个传递int切片的通道channel 零值# 未初始化的通道类型变量其默认零值是 nil。\nvar ch chan int fmt.Println(ch) // \u0026lt;nil\u0026gt;channel 初始化# 声明的通道类型变量需要使用内置的 make 函数初始化之后才能使用。格式如下：\nmake(chan 元素类型, [缓冲大小])其中：channel 的缓冲大小是可选的。比如：\nch4 := make(chan int) ch5 := make(chan bool, 1) // 声明一个缓冲区大小为1的通道channel 操作# 通道共有 发送（send）、接收(receive）和 关闭（close） 三种操作。发送和接收操作都使用\u0026lt;-符号。\n比如定义一个通道：\nch := make(chan int)发送 send# 将一个值发送到通道中。\nch \u0026lt;- 10 // 把10发送到ch中接收 receive# 从一个通道中接收值。\nx := \u0026lt;- ch // 从ch中接收值并赋值给变量x \u0026lt;-ch // 从ch中接收值，忽略结果关闭 close# 通过调用内置的close函数来关闭通道。\nclose(ch)注意：通道值是可以被垃圾回收掉的。通道通常由发送方执行关闭操作，并且只有在接收方明确等待通道关闭的信号时才需要执行关闭操作。它和关闭文件不一样，通常在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。\n关闭后的通道有以下特点：\n对一个关闭的通道再发送值会导致 panic 对一个关闭的通道进行接收会一直获取值直到通道为空 对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值 关闭一个已经关闭的通道会导致 panic 无缓冲的通道# 无缓冲的通道又称为阻塞的通道。看如下代码片段：\nfunc chan1() { ch := make(chan int) ch \u0026lt;- 10 fmt.Println(\u0026#34;发送成功\u0026#34;) // fatal error: all goroutines are asleep - deadlock! }上面这段代码能够通过编译，但是执行的时候会出现以下错误：\nfatal error: all goroutines are asleep - deadlock!deadlock 表示程序中的 goroutine 都被挂起导致程序死锁。导致死锁的原因在于：\nch := make(chan int) 创建的是无缓冲的通道，无缓冲的通道只有在有接收方能够接收值的时候才能发送成功，否则会一直处于等待发送的阶段。同理如果对一个无缓冲通道执行接收操作时，没有任何向通道中发送值的操作那么也会导致接收操作阻塞。简单理解就是：无缓冲的通道必须有至少一个接收方才能发送成功\n上面的代码会阻塞在 ch \u0026lt;- 10 这一行代码形成死锁，解决这个问题其中一种可行的方法是创建一个 goroutine 去接收值，例如：\nfunc chan2() { value := 10 ch := make(chan int) go func(chan int) { value := \u0026lt;-ch fmt.Printf(\u0026#34;接收成功,value=%d \\n\u0026#34;, value) }(ch) ch \u0026lt;- value fmt.Printf(\u0026#34;发送成功,value=%d \\n\u0026#34;, value) }首先无缓冲通道 ch 上的发送操作会阻塞，直到另一个 goroutine 在该通道上执行接收操作，这时数字10才能发送成功，两个 goroutine 将继续执行。相反，如果接收操作先执行，接收方所在的 goroutine 将阻塞，直到 main goroutine 中向该通道发送数字10。\n使用无缓冲通道进行通信将导致发送和接收的 goroutine 同步化。因此无缓冲通道也被称为 同步通道。\n有缓冲的通道# 还有另外一种解决上面死锁问题的方法是：使用有缓冲区的通道。可以在使用 make 函数初始化通道时为其指定通道的容量，例如：\nfunc main() { ch := make(chan int, 1) // 创建一个容量为1的有缓冲区通道 ch \u0026lt;- 10 fmt.Println(\u0026#34;发送成功\u0026#34;) }只要通道的容量大于零，那么该通道就属于有缓冲的通道，通道的容量表示通道中最大能存放的元素数量。当通道内已有元素数达到最大容量后，再向通道执行发送操作就会阻塞，除非有从通道执行接收操作。可以使用内置的 len 函数获取通道内元素的数量，使用 cap 函数获取通道的容量但很少会这么做。\n多返回值模式# 当向通道中发送完数据时可以通过 close 函数来关闭通道。当一个通道被关闭后，再往该通道发送值会引发panic，从该通道取值的操作会先取完通道中的值。通道内的值被接收完后再对通道执行接收操作得到的值会一直都是对应元素类型的零值。那如何判断一个通道是否被关闭呢？\n对一个通道执行接收操作时支持使用如下多返回值模式：\nvalue, ok := \u0026lt;- ch其中\nvalue ：从通道中取出的值，如果通道被关闭则返回对应类型的零值 ok ：通道关闭时返回 false，否则返回 true 循环从通道ch中接收所有值，直到通道被关闭后退出。\nfunc chan4() { ch := make(chan int, 10) for i := 0; i \u0026lt; 5; i++ { wg.Add(1) ch \u0026lt;- i } close(ch) go func(chan int) { // 循环接收值，直到通道被关闭后退出 for { v, ok := \u0026lt;-ch if !ok { break } else { wg.Done() fmt.Printf(\u0026#34;v=%v ok=%v \\n\u0026#34;, v, ok) } } }(ch) wg.Wait() }for range接收值# 通常会选择使用 for range 循环从通道中接收值，当通道被关闭后会在通道内的所有值被接收完毕后会自动退出循环。上面示例使用 for range 改写后会很简洁。\nfunc chan5() { ch := make(chan int, 10) for i := 0; i \u0026lt; 5; i++ { wg.Add(1) ch \u0026lt;- i } close(ch) go func() { for v := range ch { fmt.Println(v) wg.Done() } }() wg.Wait() }注意：目前Go语言中并没有提供一个不对通道进行读取操作就能判断通道是否被关闭的方法。不能简单的通过 len(ch) 操作来判断通道是否被关闭。\n单向通道# 某些场景下可能会将通道作为参数在多个任务函数间进行传递，通常会选择在不同的任务函数中对通道的使用进行限制，比如限制通道在某个函数中只能执行发送或只能执行接收操作。比如：现在有 Producer 和 Consumer 两个函数，其中 Producer 函数会返回一个通道，并且会持续将符合条件的数据发送至该通道，并在发送完成后将该通道关闭。而 Consumer 函数的任务是从通道中接收值进行计算，这两个函数之间通过 Processer 函数返回的通道进行通信。示例代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; ) // Producer 返回一个通道 // 并持续将符合条件的数据发送至返回的通道中 // 数据发送完成后会将返回的通道关闭 func Producer() chan int { ch := make(chan int, 2) // 创建一个新的goroutine执行发送数据的任务 go func() { for i := 0; i \u0026lt; 10; i++ { if i%2 == 1 { ch \u0026lt;- i } } close(ch) // 任务完成后关闭通道 }() return ch } // Consumer 从通道中接收数据进行计算 func Consumer(ch chan int) int { sum := 0 for v := range ch { fmt.Println(v) sum += v } return sum } func main() { ch := Producer() res := Consumer(ch) fmt.Println(res) // 25 }上面的示例代码中可以看出正常情况下 Consumer 函数中只会对通道进行接收操作，但这不代表不可以在 Consumer 函数中对通道进行发送操作。作为 Producer 函数的提供者在返回通道的时候可能只希望调用方拿到返回的通道后只能对其进行接收操作。但是没有办法阻止在 Consumer 函数中对通道进行发送操作。比如：\nfunc Producer2() chan int { ch := make(chan int, 2) // 创建一个新的goroutine执行发送数据的任务 go func() { for i := 0; i \u0026lt; 10; i++ { if i%2 == 1 { ch \u0026lt;- i } } close(ch) // 任务完成后关闭通道 }() return ch } // Consumer 从通道中接收数据进行计算同时可以向通道中写值 func Consumer2(ch chan int) int { sum := 0 ch \u0026lt;- 100 for v := range ch { sum += v } return sum }Go语言中提供了单向通道来处理这种需要限制通道只能进行某种操作的情况。\n\u0026lt;- chan int // 只接收通道，只能接收不能发送 chan \u0026lt;- int // 只发送通道，只能发送不能接收其中，箭头 \u0026lt;- 和关键字 chan 的相对位置表明了当前通道允许的操作，这种限制将在编译阶段进行检测。另外对一个只接收通道执行 close 也是不允许的，因为默认通道的关闭操作应该由发送方来完成。\n使用单向通道将上面的示例代码进行如下改造。\n// Producer3 返回一个接收通道 func Producer3() \u0026lt;-chan int { ch := make(chan int, 2) go func() { for i := 0; i \u0026lt; 10; i++ { if i%2 == 1 { ch \u0026lt;- i } } close(ch) }() return ch } // Consumer3 参数为接收通道 func Consumer3(ch \u0026lt;-chan int) int { sum := 0 for v := range ch { sum += v } return sum }Producer3 函数返回的是一个只接收通道，这就从代码层面限制了该函数返回的通道只能进行接收操作，保证了数据安全。并且返回限制操作的单向通道也会让代码语义更清晰、更易读。\n在函数传参及任何赋值操作中全向通道（正常通道）可以转换为单向通道，但是无法反向转换。\n// channel类型转换 func convertChannel() { // 双向通道 var ch chan int = make(chan int) // 单向写 var sendCh chan\u0026lt;- int = make(chan\u0026lt;- int) // 单向读 var recvCh \u0026lt;-chan int = make(\u0026lt;-chan int) // 双向channel 可以 隐式转换为 任意一种单向channel sendCh = ch recvCh = ch // 单向 channel 不能转换为 双向 channel //\tch = recvCh // cannot use recvCh (variable of type \u0026lt;-chan int) as chan int value in assignment //\tch = sendCh // cannot use sendCh (variable of type chan\u0026lt;- int) as chan int value in assignment fmt.Printf(\u0026#34;sendCh:%T,recvTh:%T\u0026#34;, sendCh, recvCh) }总结# 表格中总结了对不同状态下的通道执行相应操作的结果。\n注意：对已经关闭的通道再执行 close 也会引发 panic。\nselect 多路复用# 某些场景下可能需要同时从多个通道接收数据。通道在接收数据时，如果没有数据可以被接收那么当前 goroutine 将会发生阻塞。可能会写出如下代码尝试使用遍历的方式来实现从多个通道中接收值：\nfor{ // 尝试从ch1接收值 data, ok := \u0026lt;-ch1 // 尝试从ch2接收值 data, ok := \u0026lt;-ch2 … }这种方式虽然可以实现从多个通道接收值的需求，但是程序的运行性能比较差。Go 语言内置了select关键字，使用它可以同时响应多个通道的操作。\nselect 的使用方式类似于 switch 语句，它也有一系列 case 分支和一个默认的分支。每个 case 分支会对应一个通道的通信（接收或发送）过程。select 会一直等待，直到其中的某个 case 的通信操作完成时，就会执行该 case 分支对应的语句。格式如下：\nselect { case \u0026lt;-ch1: //... case data := \u0026lt;-ch2: //... case ch3 \u0026lt;- 10: //... default: //默认操作 }select 语句具有以下特点：\n可处理一个或多个 channel 的发送/接收操作 如果多个 case 同时满足，select 会随机选择一个执行 对于没有 case 的 select 会一直阻塞，可用于阻塞 main 函数，防止退出 下面示例代码能够在终端打印出10以内的奇数，借助这个代码片段来看一下 select 的具体使用。\npackage main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int, 1) for i := 1; i \u0026lt;= 10; i++ { select { case x := \u0026lt;-ch: fmt.Println(x) case ch \u0026lt;- i: } } }上面的代码输出内容如下。\n1 3 5 7 9示例中的代码首先是创建了一个缓冲区大小为1的通道 ch，在进入 for 循环后，此时 i = 1，select 语句中包含两个 case 分支，此时由于通道中没有值可以接收，所以x := \u0026lt;-c 这个 case 分支不满足，而ch \u0026lt;- i这个分支可以执行，会把1发送到通道中，结束本次 for 循环；第二次 for 循环时，i = 2，由于通道缓冲区已满，所以ch \u0026lt;- i这个分支不满足，而x := \u0026lt;-ch这个分支可以执行，从通道接收值1并赋值给变量 x ，所以会在终端打印出 1；后续的 for 循环同理会依次打印出3、5、7、9。\n通道误用示例# 接下来，我们将展示两个因误用通道导致程序出现 bug 的代码片段，希望能够加深读者对通道操作的印象。\n示例1# 各位读者可以查看以下示例代码，尝试找出其中存在的问题。\n// demo1 通道误用导致的bug func demo1() { wg := sync.WaitGroup{} ch := make(chan int, 10) for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } close(ch) wg.Add(3) for j := 0; j \u0026lt; 3; j++ { go func() { for { task := \u0026lt;-ch // 这里假设对接收的数据执行某些操作 fmt.Println(task) } wg.Done() }() } wg.Wait() }将上述代码编译执行后，匿名函数所在的 goroutine 并不会按照预期在通道被关闭后退出。因为task := \u0026lt;- ch的接收操作在通道被关闭后会一直接收到零值，而不会退出。此处的接收操作应该使用task, ok := \u0026lt;- ch，通过判断布尔值ok为假时退出；或者使用select 来处理通道。\n示例2# 各位读者阅读下方代码片段，尝试找出其中存在的问题。\n// demo2 通道误用导致的bug func demo2() { ch := make(chan string) go func() { // 这里假设执行一些耗时的操作 time.Sleep(3 * time.Second) ch \u0026lt;- \u0026#34;job result\u0026#34; }() select { case result := \u0026lt;-ch: fmt.Println(result) case \u0026lt;-time.After(time.Second): // 较小的超时时间 return } }上述代码片段可能导致 goroutine 泄露（goroutine 并未按预期退出并销毁）。由于 select 命中了超时逻辑，导致通道没有消费者（无接收操作），而其定义的通道为无缓冲通道，因此 goroutine 中的ch \u0026lt;- \u0026quot;job result\u0026quot;操作会一直阻塞，最终导致 goroutine 泄露。\n"},{"id":53,"href":"/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/","title":"Csp并发模型","section":"所有文章","content":"并发模型# 业界将如何实现并发编程总结归纳为各式各样的并发模型，常见的并发模型有以下几种：\n线程\u0026amp;锁模型 Actor模型 CSP模型 Fork\u0026amp;Join模型 Go语言中的并发程序主要是通过基于 CSP（communicating sequential processes） 的 goroutine 和 channel来实现，当然也支持使用传统的多线程共享内存的并发方式。\n"},{"id":54,"href":"/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/goroutine/","title":"Goroutine","section":"所有文章","content":"并发编程在当前软件领域是一个非常重要的概念，随着CPU等硬件的发展，都希望让程序运行的更快。Go语言在语言层面天生支持并发（基于 goroutine 的高并发），充分利用现代CPU的多核优势，这也是Go语言能够大范围流行的一个很重要的原因。\n概念了解# 串行/并发/并行# 串行：按照一定顺序先后执行\n并发：同一时间段内执行多个任务，逻辑上的同时发生。一个处理器（在不同时刻或者说在同一时间间隔内）\u0026ldquo;同时\u0026quot;处理多个任务。宏观上是并发的，微观上是按排队等待、唤醒、执行的步骤序列执行\n并行：物理上的同时发生。多核处理器或多个处理器（在同一时刻）同时处理多个任务。并行性允许多个程序同一时刻可在不同 CPU 上同时执行\n进程/线程/协程# 进程（process）：程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位\n线程（thread）：操作系统基于进程开启的轻量级进程，是操作系统调度执行的最小单位\n协程（coroutine）：非操作系统提供而是由用户自行创建和控制的 用户态线程，比线程更轻量级\n阻塞/非阻塞# 阻塞：阻塞是进程(也可以是线程、协程)的状态之一（新建、就绪、运行、阻塞、终止). 指的是当数据未准备就绪，这个进程(线程、协程)一直等待，这就是阻塞\n非阻塞： 当数据为准备就绪，该进程(线程、协程)不等待可以继续执行，这就是非阻塞\n同步/异步# 同步： 发起一个调用时，在没有得到结果之前，这个调用就不返回。调用过程一直在等待。这是同步\n异步：发起调用后就立刻返回，这次调用过程就结束了，等到有结果了被调用方主动通知调用者结果。这是异步\ngoroutine# goroutine 是 Go 语言支持并发的核心，一个 goroutine 会以一个很小的栈开始其生命周期，一般只需要 2KB 。与操作系统线程区别在于：操作系统线程由系统内核进行调度， goroutine 是由Go运行时（runtime）负责调度。Go运行时会智能地将 m个 goroutine 合理地分配给 n 个操作系统线程，实现类似 m:n 的调度机制，不再需要Go开发者自行在代码层面维护一个线程池。\ngoroutine 是 Go 程序中最基本的并发执行单元。每一个 Go 程序都至少包含一个 goroutine（main goroutine），Go程序启动时它会自动创建。Go语言编程中不需要去自己写进程、线程、协程，当需要让某个任务并发执行的时候，只需要把这个任务包装成一个函数，开启一个 goroutine 去执行这个函数就可以了。\ngo关键字# Go语言中只需要在函数或方法调用前加上go关键字就可以创建一个 goroutine ，让该函数或方法在新创建的 goroutine 中执行。\ngo test() // 创建一个新的 goroutine 运行函数test匿名函数也支持使用 go 关键字创建 goroutine 执行。\ngo func(){ // ... }()一个 goroutine 必定对应一个函数/方法，可以创建多个 goroutine 去执行相同的函数/方法。\n启动单个goroutine# 先看一个在 main 函数中执行普通函数调用的示例：\nfunc main() { func() { fmt.Println(\u0026#34;hello\u0026#34;) }() fmt.Println(\u0026#34;end...\u0026#34;) }输出：\nhello end...代码会顺序打印 hello 和 end... 是串行的。接下来在匿名函数前加上关键字 go，启动一个 goroutine 去执行这个函数：\nfunc main() { go func() { fmt.Println(\u0026#34;hello\u0026#34;) }() fmt.Println(\u0026#34;end...\u0026#34;) // 这里只会输出end... }输出：\nend...这一次的执行结果只在终端打印了 end... 并没有打印 hello，原因在于：\nGo程序启动时会为 main 函数创建一个默认的 goroutine 。上面代码中在 main 函数中使用 go 关键字创建了另外一个 goroutine 去执行匿名函数，而此时 main goroutine 还在继续往下执行，程序中此时存在两个并发执行的 goroutine 。当 main 函数结束时整个程序也就结束了，同时 main goroutine 也结束了，所有由 main goroutine 创建的 goroutine 也会一同退出。也就是说 main 函数退出太快，另外一个 goroutine 中的函数还未执行完程序就退出了，导致未打印出“hello”。其实跟C#中主线程退出导致所有的子线程都会退出一个道理。\n使用 time.Sleeep 让 main goroutine 等待一下：\nfunc main() { go func() { fmt.Println(\u0026#34;hello\u0026#34;) }() fmt.Println(\u0026#34;end...\u0026#34;) // 先输出:end... 再输出:hello time.Sleep(time.Second) }重新编译后再次执行，程序会在终端输出如下结果，并且会短暂停顿一下。\nend... hello这里 end... 会首先被输出的原因在于：程序中创建 goroutine 执行函数需要一定的开销，而此时 main 函数所在的 goroutine 是继续执行的，所以会先输出 end...。\n上面代码中使用 time.Sleep 让 main goroutine 等待匿名函数执行结束是不优雅也是不准确的，Go 语言中 sync 包提供了一些常用的并发原语。当并不关心并发操作结果或者有其它方式收集并发操作的结果时，WaitGroup 是实现等待一组并发操作完成的好方法。简单试一下：\nfunc main() { wg.Add(1) // 启动一个goroutine登记+1 go func() { defer wg.Done() // goroutine结束登记-1 fmt.Println(\u0026#34;hello\u0026#34;) }() fmt.Println(\u0026#34;end...\u0026#34;) wg.Wait() // 等待所有线程执行完,先输出:end... 再输出:hello }将代码编译后执行，得到的输出结果和之前一致，但是这一次程序不再会有多余的停顿， 匿名函数的 goroutine 执行完毕后程序直接退出。\n启动多个goroutine# package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var wg sync.WaitGroup func printHello(i int) { defer wg.Done() fmt.Println(\u0026#34;hello\u0026#34;, i) } func main() { for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go printHello(i) } wg.Wait() }多次执行上面的代码会发现每次终端上打印数字的顺序都不一致。因为10个 goroutine 是并发执行的，而 goroutine 的调度是随机的。\n再来看个问题，将 printHello() 修改为匿名函数实现：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var wg sync.WaitGroup func printHello(i int) { defer wg.Done() // goroutine结束就登记-1 fmt.Println(\u0026#34;hello:\u0026#34;, i) } // 使用匿名函数发现多次输出同一个值 func closure2() { for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go func() { defer wg.Done() // 这里匿名函数的i是由外层循环提供的其实就是一个闭包 fmt.Println(\u0026#34;hello:\u0026#34;, i) }() } wg.Wait() } func main() { closure2() }多次执行上面的代码会发现每次终端上可能存在多次输出同一个值的问题，问题在于：匿名函数这里形成了一个闭包\ngo func() { defer wg.Done() // 这里匿名函数的i是由外层循环提供的其实就是一个闭包 fmt.Println(\u0026#34;hello:\u0026#34;, i) }()解决办法也很简单：修改一下将参数 i 传入匿名函数中使用新变量接收：\nfunc closure3() { for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go func(i int) { defer wg.Done() fmt.Println(\u0026#34;hello:\u0026#34;, i) }(i) } wg.Wait() }"},{"id":55,"href":"/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/gpm%E5%8E%9F%E7%90%86%E4%B8%8E%E8%B0%83%E5%BA%A6/","title":"Gpm原理与调度","section":"所有文章","content":"动态栈# 操作系统的线程一般都有固定的栈内存（通常为 2MB ）,而 Go 语言中的 goroutine 非常轻量级，一个 goroutine 的初始栈空间很小（一般为 2KB ），所以在 Go 语言中一次创建数万个 goroutine 也是可能的。并且 goroutine 的栈不是固定的，可以根据需要动态地增大或缩小， Go 的 runtime 会自动为 goroutine 分配合适的栈空间。\ngoroutine调度# 操作系统的线程会被操作系统内核调度时会挂起当前执行的线程并将它的寄存器内容保存到内存中，选出下一次要执行的线程并从内存中恢复该线程的寄存器信息，然后恢复执行该线程的现场并开始执行线程。从一个线程切换到另一个线程需要完整的上下文切换。因为可能需要多次内存访问，索引这个切换上下文的操作开销较大，会增加运行的cpu周期。\n区别于操作系统内核调度操作系统线程，goroutine 的调度是Go语言运行时（runtime）层面的实现，是完全由 Go 语言本身实现的一套调度系统——go scheduler。它的作用是按照一定的规则将所有的 goroutine 调度到操作系统线程上执行。\n在经历数个版本的迭代之后，目前 Go 语言的调度器采用的是 GPM 调度模型。\n其中：\nG：表示 goroutine，每执行一次go f()就创建一个 G，包含要执行的函数和上下文信息。 全局队列（Global Queue）：存放等待运行的 G。 P：表示 goroutine 执行所需的资源，最多有 GOMAXPROCS 个。 P 的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G 时，G 优先加入到 P 的本地队列，如果本地队列满了会批量移动部分 G 到全局队列。 M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，当 P 的本地队列为空时，M 也会尝试从全局队列或其他 P 的本地队列获取 G。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和操作系统调度器是通过 M 结合起来的，每个 M 都代表了1个内核线程，操作系统调度器负责把内核线程分配到 CPU 的核上执行。 单从线程调度讲，Go语言相比起其他语言的优势在于OS线程是由OS内核来调度的， goroutine 则是由Go运行时（runtime）自己的调度器调度的，完全是在用户态下完成的， 不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放，都是在用户态维护着一块大的内存池， 不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。 另一方面充分利用了多核的硬件资源，近似的把若干goroutine均分在物理线程上， 再加上本身 goroutine 的超轻量级，以上种种特性保证了 goroutine 调度方面的性能。\nGOMAXPROCS# Go运行时的调度器使用 GOMAXPROCS 参数来确定需要使用多少个 OS 线程来同时执行 Go 代码。默认值是机器上的 CPU 核心数。例如在一个 8 核心的机器上，GOMAXPROCS 默认为 8。Go语言中可以通过 runtime.GOMAXPROCS 函数设置当前程序并发时占用的 CPU逻辑核心数。（Go1.5版本之前，默认使用的是单核心执行。Go1.5 版本之后，默认使用全部的CPU 逻辑核心数）\n"},{"id":56,"href":"/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/","title":"原子操作","section":"所有文章","content":"原子操作# 针对整数数据类型（int32、uint32、int64、uint64）我们还可以使用原子操作来保证并发安全，通常直接使用原子操作比使用锁操作效率更高。Go语言中原子操作由内置的标准库sync/atomic提供。\natomic包# 方法 解释 func LoadInt32(addr *int32) (val int32) func LoadInt64(addr *int64) (val int64) func LoadUint32(addr *uint32) (val uint32) func LoadUint64(addr *uint64) (val uint64) func LoadUintptr(addr *uintptr) (val uintptr) func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer) 读取操作 func StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) 写入操作 func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) 修改操作 func SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) 交换操作 func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) 比较并交换操作 示例# 我们填写一个示例来比较下互斥锁和原子操作的性能。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) type Counter interface { Inc() Load() int64 } // 普通版 type CommonCounter struct { counter int64 } func (c CommonCounter) Inc() { c.counter++ } func (c CommonCounter) Load() int64 { return c.counter } // 互斥锁版 type MutexCounter struct { counter int64 lock sync.Mutex } func (m *MutexCounter) Inc() { m.lock.Lock() defer m.lock.Unlock() m.counter++ } func (m *MutexCounter) Load() int64 { m.lock.Lock() defer m.lock.Unlock() return m.counter } // 原子操作版 type AtomicCounter struct { counter int64 } func (a *AtomicCounter) Inc() { atomic.AddInt64(\u0026amp;a.counter, 1) } func (a *AtomicCounter) Load() int64 { return atomic.LoadInt64(\u0026amp;a.counter) } func test(c Counter) { var wg sync.WaitGroup start := time.Now() for i := 0; i \u0026lt; 1000; i++ { wg.Add(1) go func() { c.Inc() wg.Done() }() } wg.Wait() end := time.Now() fmt.Println(c.Load(), end.Sub(start)) } func main() { c1 := CommonCounter{} // 非并发安全 test(c1) c2 := MutexCounter{} // 使用互斥锁实现并发安全 test(\u0026amp;c2) c3 := AtomicCounter{} // 并发安全且比互斥锁效率更高 test(\u0026amp;c3) }atomic包提供了底层的原子级内存操作，对于同步算法的实现很有用。这些函数必须谨慎地保证正确使用。除了某些特殊的底层应用，使用通道或者 sync 包的函数/类型实现同步更好。\n"},{"id":57,"href":"/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E5%92%8C%E9%94%81/","title":"并发安全和锁","section":"所有文章","content":"并发安全和锁# 有时候我们的代码中可能会存在多个 goroutine 同时操作一个资源（临界区）的情况，这种情况下就会发生竞态问题（数据竞态）。这就好比现实生活中十字路口被各个方向的汽车竞争，还有火车上的卫生间被车厢里的人竞争。\n我们用下面的代码演示一个数据竞争的示例。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var ( x int64 wg sync.WaitGroup // 等待组 ) // add 对全局变量x执行5000次加1操作 func add() { for i := 0; i \u0026lt; 5000; i++ { x = x + 1 } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) }我们将上面的代码编译后执行，不出意外每次执行都会输出诸如9537、5865、6527等不同的结果。这是为什么呢？\n在上面的示例代码片中，我们开启了两个 goroutine 分别执行 add 函数，这两个 goroutine 在访问和修改全局的x变量时就会存在数据竞争，某个 goroutine 中对全局变量x的修改可能会覆盖掉另一个 goroutine 中的操作，所以导致最后的结果与预期不符。\n互斥锁# 互斥锁是一种常用的控制共享资源访问的方法，它能够保证同一时间只有一个 goroutine 可以访问共享资源。Go 语言中使用sync包中提供的Mutex类型来实现互斥锁。\nsync.Mutex提供了两个方法供我们使用。\n方法名 功能 func (m *Mutex) Lock() 获取互斥锁 func (m *Mutex) Unlock() 释放互斥锁 我们在下面的示例代码中使用互斥锁限制每次只有一个 goroutine 才能修改全局变量x，从而修复上面代码中的问题。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // sync.Mutex var ( x int64 wg sync.WaitGroup // 等待组 m sync.Mutex // 互斥锁 ) // add 对全局变量x执行5000次加1操作 func add() { for i := 0; i \u0026lt; 5000; i++ { m.Lock() // 修改x前加锁 x = x + 1 m.Unlock() // 改完解锁 } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) }将上面的代码编译后多次执行，每一次都会得到预期中的结果——10000。\n使用互斥锁能够保证同一时间有且只有一个 goroutine 进入临界区，其他的 goroutine 则在等待锁；当互斥锁释放后，等待的 goroutine 才可以获取锁进入临界区，多个 goroutine 同时等待一个锁时，唤醒的策略是随机的。\n读写互斥锁# 互斥锁是完全互斥的，但是实际上有很多场景是读多写少的，当我们并发的去读取一个资源而不涉及资源修改的时候是没有必要加互斥锁的，这种场景下使用读写锁是更好的一种选择。读写锁在 Go 语言中使用sync包中的RWMutex类型。\nsync.RWMutex提供了以下5个方法。\n方法名 功能 func (rw *RWMutex) Lock() 获取写锁 func (rw *RWMutex) Unlock() 释放写锁 func (rw *RWMutex) RLock() 获取读锁 func (rw *RWMutex) RUnlock() 释放读锁 func (rw *RWMutex) RLocker() Locker 返回一个实现Locker接口的读写锁 读写锁分为两种：读锁和写锁。当一个 goroutine 获取到读锁之后，其他的 goroutine 如果是获取读锁会继续获得锁，如果是获取写锁就会等待；而当一个 goroutine 获取写锁之后，其他的 goroutine 无论是获取读锁还是写锁都会等待。\n下面我们使用代码构造一个读多写少的场景，然后分别使用互斥锁和读写锁查看它们的性能差异。\nvar ( x int64 wg sync.WaitGroup mutex sync.Mutex rwMutex sync.RWMutex ) // writeWithLock 使用互斥锁的写操作 func writeWithLock() { mutex.Lock() // 加互斥锁 x = x + 1 time.Sleep(10 * time.Millisecond) // 假设读操作耗时10毫秒 mutex.Unlock() // 解互斥锁 wg.Done() } // readWithLock 使用互斥锁的读操作 func readWithLock() { mutex.Lock() // 加互斥锁 time.Sleep(time.Millisecond) // 假设读操作耗时1毫秒 mutex.Unlock() // 释放互斥锁 wg.Done() } // writeWithLock 使用读写互斥锁的写操作 func writeWithRWLock() { rwMutex.Lock() // 加写锁 x = x + 1 time.Sleep(10 * time.Millisecond) // 假设读操作耗时10毫秒 rwMutex.Unlock() // 释放写锁 wg.Done() } // readWithRWLock 使用读写互斥锁的读操作 func readWithRWLock() { rwMutex.RLock() // 加读锁 time.Sleep(time.Millisecond) // 假设读操作耗时1毫秒 rwMutex.RUnlock() // 释放读锁 wg.Done() } func do(wf, rf func(), wc, rc int) { start := time.Now() // wc个并发写操作 for i := 0; i \u0026lt; wc; i++ { wg.Add(1) go wf() } // rc个并发读操作 for i := 0; i \u0026lt; rc; i++ { wg.Add(1) go rf() } wg.Wait() cost := time.Since(start) fmt.Printf(\u0026#34;x:%v cost:%v\\n\u0026#34;, x, cost) }我们假设每一次读操作都会耗时1ms，而每一次写操作会耗时10ms，我们分别测试使用互斥锁和读写互斥锁执行10次并发写和1000次并发读的耗时数据。\n// 使用互斥锁，10并发写，1000并发读 do(writeWithLock, readWithLock, 10, 1000) // x:10 cost:1.466500951s // 使用读写互斥锁，10并发写，1000并发读 do(writeWithRWLock, readWithRWLock, 10, 1000) // x:10 cost:117.207592ms从最终的执行结果可以看出，使用读写互斥锁在读多写少的场景下能够极大地提高程序的性能。不过需要注意的是如果一个程序中的读操作和写操作数量级差别不大，那么读写互斥锁的优势就发挥不出来。\nsync.WaitGroup# 在代码中生硬的使用time.Sleep肯定是不合适的，Go语言中可以使用sync.WaitGroup来实现并发任务的同步。 sync.WaitGroup有以下几个方法：\n方法名 功能 func (wg * WaitGroup) Add(delta int) 计数器+delta (wg *WaitGroup) Done() 计数器-1 (wg *WaitGroup) Wait() 阻塞直到计数器变为0 sync.WaitGroup内部维护着一个计数器，计数器的值可以增加和减少。例如当我们启动了 N 个并发任务时，就将计数器值增加N。每个任务完成时通过调用 Done 方法将计数器减1。通过调用 Wait 来等待并发任务执行完，当计数器值为 0 时，表示所有并发任务已经完成。\n我们利用sync.WaitGroup将上面的代码优化一下：\nvar wg sync.WaitGroup func hello() { defer wg.Done() fmt.Println(\u0026#34;Hello Goroutine!\u0026#34;) } func main() { wg.Add(1) go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(\u0026#34;main goroutine done!\u0026#34;) wg.Wait() }需要注意sync.WaitGroup是一个结构体，进行参数传递的时候要传递指针。\nsync.Once# 在某些场景下我们需要确保某些操作即使在高并发的场景下也只会被执行一次，例如只加载一次配置文件等。\nGo语言中的sync包中提供了一个针对只执行一次场景的解决方案——sync.Once，sync.Once只有一个Do方法，其签名如下：\nfunc (o *Once) Do(f func())**注意：**如果要执行的函数f需要传递参数就需要搭配闭包来使用。\n加载配置文件示例# 延迟一个开销很大的初始化操作到真正用到它的时候再执行是一个很好的实践。因为预先初始化一个变量（比如在init函数中完成初始化）会增加程序的启动耗时，而且有可能实际执行过程中这个变量没有用上，那么这个初始化操作就不是必须要做的。我们来看一个例子：\nvar icons map[string]image.Image func loadIcons() { icons = map[string]image.Image{ \u0026#34;left\u0026#34;: loadIcon(\u0026#34;left.png\u0026#34;), \u0026#34;up\u0026#34;: loadIcon(\u0026#34;up.png\u0026#34;), \u0026#34;right\u0026#34;: loadIcon(\u0026#34;right.png\u0026#34;), \u0026#34;down\u0026#34;: loadIcon(\u0026#34;down.png\u0026#34;), } } // Icon 被多个goroutine调用时不是并发安全的 func Icon(name string) image.Image { if icons == nil { loadIcons() } return icons[name] }多个 goroutine 并发调用Icon函数时不是并发安全的，现代的编译器和CPU可能会在保证每个 goroutine 都满足串行一致的基础上自由地重排访问内存的顺序。loadIcons函数可能会被重排为以下结果：\nfunc loadIcons() { icons = make(map[string]image.Image) icons[\u0026#34;left\u0026#34;] = loadIcon(\u0026#34;left.png\u0026#34;) icons[\u0026#34;up\u0026#34;] = loadIcon(\u0026#34;up.png\u0026#34;) icons[\u0026#34;right\u0026#34;] = loadIcon(\u0026#34;right.png\u0026#34;) icons[\u0026#34;down\u0026#34;] = loadIcon(\u0026#34;down.png\u0026#34;) }在这种情况下就会出现即使判断了icons不是nil也不意味着变量初始化完成了。考虑到这种情况，我们能想到的办法就是添加互斥锁，保证初始化icons的时候不会被其他的 goroutine 操作，但是这样做又会引发性能问题。\n使用sync.Once改造的示例代码如下：\nvar icons map[string]image.Image var loadIconsOnce sync.Once func loadIcons() { icons = map[string]image.Image{ \u0026#34;left\u0026#34;: loadIcon(\u0026#34;left.png\u0026#34;), \u0026#34;up\u0026#34;: loadIcon(\u0026#34;up.png\u0026#34;), \u0026#34;right\u0026#34;: loadIcon(\u0026#34;right.png\u0026#34;), \u0026#34;down\u0026#34;: loadIcon(\u0026#34;down.png\u0026#34;), } } // Icon 是并发安全的 func Icon(name string) image.Image { loadIconsOnce.Do(loadIcons) return icons[name] }并发安全的单例模式# 下面是借助sync.Once实现的并发安全的单例模式：\npackage singleton import ( \u0026#34;sync\u0026#34; ) type singleton struct {} var instance *singleton var once sync.Once func GetInstance() *singleton { once.Do(func() { instance = \u0026amp;singleton{} }) return instance }sync.Once其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证初始化操作的时候是并发安全的并且初始化操作也不会被执行多次。\nsync.Map# Go 语言中内置的 map 不是并发安全的，请看下面这段示例代码。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) var m = make(map[string]int) func get(key string) int { return m[key] } func set(key string, value int) { m[key] = value } func main() { wg := sync.WaitGroup{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(n) set(key, n) fmt.Printf(\u0026#34;k=:%v,v:=%v\\n\u0026#34;, key, get(key)) wg.Done() }(i) } wg.Wait() }将上面的代码编译后执行，会报出fatal error: concurrent map writes错误。我们不能在多个 goroutine 中并发对内置的 map 进行读写操作，否则会存在数据竞争问题。\n像这种场景下就需要为 map 加锁来保证并发的安全性了，Go语言的sync包中提供了一个开箱即用的并发安全版 map——sync.Map。开箱即用表示其不用像内置的 map 一样使用 make 函数初始化就能直接使用。同时sync.Map内置了诸如Store、Load、LoadOrStore、Delete、Range等操作方法。\n方法名 功能 func (m *Map) Store(key, value interface{}) 存储key-value数据 func (m *Map) Load(key interface{}) (value interface{}, ok bool) 查询key对应的value func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) 查询或存储key对应的value func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) 查询并删除key func (m *Map) Delete(key interface{}) 删除key func (m *Map) Range(f func(key, value interface{}) bool) 对map中的每个key-value依次调用f 下面的代码示例演示了并发读写sync.Map。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) // 并发安全的map var m = sync.Map{} func main() { wg := sync.WaitGroup{} // 对m执行20个并发的读写操作 for i := 0; i \u0026lt; 20; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(n) m.Store(key, n) // 存储key-value value, _ := m.Load(key) // 根据key取值 fmt.Printf(\u0026#34;k=:%v,v:=%v\\n\u0026#34;, key, value) wg.Done() }(i) } wg.Wait() }# "},{"id":58,"href":"/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/flag/","title":"Flag","section":"所有文章","content":"Go语言内置的flag包实现了命令行参数的解析，使得开发命令行工具更为简单。\nos.Args# 如果只是简单的想要获取命令行参数，可以像下面的代码示例一样使用 os.Args 来获取命令行参数。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) // 最简单的获取命令行参数 func getOsArgs() { // os.Args是一个[]string if len(os.Args) \u0026gt; 0 { for index, arg := range os.Args { fmt.Printf(\u0026#34;args[%d]=%v\\n\u0026#34;, index, arg) } } }PS D:\\GoProject\\src\u0026gt; go run .\\flagTest.go \u0026#34;a\u0026#34; \u0026#34;s\u0026#34; \u0026#34;1\u0026#34; args[0]=C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\go-build752076497\\b001\\exe\\flagTest.exe args[1]=a args[2]=s args[3]=1os.Args 是一个存储命令行参数的字符串切片，第一个元素是执行文件的名称。\nflag包使用# 介绍 flag 包的常用函数和基本用法，更详细的内容请查看官方文档。\n导入flag包# import flagflag参数类型# flag 包支持的命令行参数类型有bool、int、int64、uint、uint64、float float64、string、duration。\nflag参数 有效值 字符串flag 合法字符串 整数flag 1234、0664、0x1234等类型，也可以是负数。 浮点数flag 合法浮点数 bool类型flag 1, 0, t, f, T, F, true, false, TRUE, FALSE, True, False。 时间段flag 任何合法的时间段字符串。如”300ms”、”-1.5h”。 合法的单位有”ns”、”us” /“µs”、”ms”、”s”、”m”、”h”。 定义命令行flag参数# 有以下两种常用的定义命令行 flag 参数的方法。\nflag.Type()# 基本格式：flag.Type(flag名, 默认值, 帮助信息)*Type\n例如：要定义姓名、年龄、婚否三个命令行参数可以按如下方式定义：\nname := flag.String(\u0026#34;name\u0026#34;, \u0026#34;张三\u0026#34;, \u0026#34;姓名\u0026#34;) age := flag.Int(\u0026#34;age\u0026#34;, 18, \u0026#34;年龄\u0026#34;) married := flag.Bool(\u0026#34;m\u0026#34;, false, \u0026#34;婚否\u0026#34;) delay := flag.Duration(\u0026#34;d\u0026#34;, 0, \u0026#34;时间间隔\u0026#34;)需要注意：此时name、age、married、delay均为对应类型的指针。\nflag.TypeVar()# 基本格式： flag.TypeVar(Type指针, flag名, 默认值, 帮助信息)\n例如要定义姓名、年龄、婚否三个命令行参数，可以按如下方式定义：\nvar name string var age int var married bool var delay time.Duration flag.StringVar(\u0026amp;name, \u0026#34;name\u0026#34;, \u0026#34;张三\u0026#34;, \u0026#34;姓名\u0026#34;) flag.IntVar(\u0026amp;age, \u0026#34;age\u0026#34;, 18, \u0026#34;年龄\u0026#34;) flag.BoolVar(\u0026amp;married, \u0026#34;m\u0026#34;, false, \u0026#34;婚否\u0026#34;) flag.DurationVar(\u0026amp;delay, \u0026#34;d\u0026#34;, 0, \u0026#34;时间间隔\u0026#34;)解析命令行参数# 通过以上两种方法定义好命令行flag参数后，需要通过调用flag.Parse()来对命令行参数进行解析\n支持的命令行参数格式有以下几种：\n-flag xxx （使用空格，一个-符号） --flag xxx （使用空格，两个-符号） -flag=xxx （使用等号，一个-符号） --flag=xxx （使用等号，两个-符号） 其中，布尔类型的参数必须使用等号的方式指定。\nFlag 解析在第一个非flag参数（单个”-“不是flag参数）之前停止，或者在终止符”–“之后停止。\nflag其他函数# flag.Args() // 返回命令行参数后的其他参数，以[]string类型 flag.NArg() // 返回命令行参数后的其他参数个数 flag.NFlag() // 返回使用的命令行参数个数使用示例# 命令行参数使用提示：\nPS D:\\GoProject\\src\u0026gt; go run .\\flagTest.go -help Usage of C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\go-build3280475971\\b001\\exe\\flagTest.exe: -age int 年龄 (default 18) -d duration 时间间隔 -m 婚否 -name string 姓名 (default \u0026#34;张三\u0026#34;)正常使用命令行flag参数：\nPS D:\\GoProject\\src\u0026gt; go run .\\flagTest.go -name=wpl -age=18 -m=false --d=1h wpl 18 false 1h0m0s [] 0 4 使用非flag命令行参数：\nPS D:\\GoProject\\src\u0026gt; go run .\\flagTest.go a b c 张三 18 false 0s [a b c] 3 0 "},{"id":59,"href":"/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/fmt/","title":"Fmt","section":"所有文章","content":"fmt 包实现了类似C#语言 Console.Writeline 和 Console.ReadLine 的格式化I/O。主要分为输出内容和获取输入两部分。\n输出# 标准库 fmt 提供了以下几种输出相关函数。\nPrint# Print 系列函数会将内容输出到系统的标准输出，区别在于Print函数直接输出内容，Printf函数支持格式化输出字符串，Println 函数会在输出内容的结尾添加一个换行符。\nfunc Print(a ...interface{}) (n int, err error) func Printf(format string, a ...interface{}) (n int, err error) func Println(a ...interface{}) (n int, err error)示例：\nfunc fmtPrint() { fmt.Print(\u0026#34;在终端打印该信息\u0026#34;) name := \u0026#34;wangpengliang\u0026#34; fmt.Printf(\u0026#34;我是：%s\\n\u0026#34;, name) fmt.Println(\u0026#34;在终端打印单独一行显示\u0026#34;) }输出：\n在终端打印该信息我是：wangpengliang 在终端打印单独一行显示Fprint# Fprint 系列函数会将内容输出到一个 io.Writer 接口类型的变量 w 中，通常用这个函数往文件中写入内容。\nfunc Fprint(w io.Writer, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error)示例：\nfunc fmtFprint() { // 向标准输出写入内容 fmt.Fprintln(os.Stdout, \u0026#34;向标准输出写入内容\u0026#34;) fileObj, err := os.OpenFile(\u0026#34;./fprintTest.txt\u0026#34;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644) if err != nil { fmt.Println(\u0026#34;打开文件出错，err:\u0026#34;, err) return } name := \u0026#34;wangpengliang\u0026#34; // 向打开的文件句柄中写入内容 fmt.Fprintf(fileObj, \u0026#34;往文件中写入信息：%s\u0026#34;, name) }注意：只要满足 io.Writer 接口的类型都支持写入。\nSprint# Sprint系列函数会把传入的数据生成并返回一个字符串。\nfunc Sprint(a ...interface{}) string func Sprintf(format string, a ...interface{}) string func Sprintln(a ...interface{}) string示例：\nfunc fmtSprint() { s := \u0026#34;wangpengliang\u0026#34; s1 := fmt.Sprint(s) s2 := fmt.Sprintf(\u0026#34;name:%s,age:%d\u0026#34;, \u0026#34;wangpengliang\u0026#34;, 18) fmt.Println(s1, s2) }Errorf# Errorf 函数根据 format 参数生成格式化字符串并返回一个包含该字符串的错误。\nfunc Errorf(format string, a ...interface{}) error通常使用这种方式来自定义错误类型，例如：\nerr := fmt.Errorf(\u0026#34;这是一个错误\u0026#34;)Go1.13 版本为 fmt.Errorf 函数新加了一个%w占位符用来生成一个可以包裹 Error 的 Wrapping Error 。\nfunc errorof() { e := errors.New(\u0026#34;原始错误e\u0026#34;) w := fmt.Errorf(\u0026#34;Wrap了一个错误%w\u0026#34;, e) fmt.Println(w) }格式化占位符# *printf 系列函数都支持 format 格式化参数，这里按照占位符将被替换的变量类型划分，方便查询和记忆。\n%v，原样输出 %T，打印类型 %t，bool类型 %s，字符串 %f，浮点 %d，10进制的整数 %b，2进制的整数 %o，8进制 %x，%X，16进制 %x：0-9，a-f %X：0-9，A-F %c，打印字符 %p，打印内存地址通用占位符# 占位符 说明 %v 值的默认格式表示 %+v 类似%v，但输出结构体时会添加字段名 %#v 值的Go语法表示 %T 打印值的类型 %% 百分号 示例：\nfunc generalPlaceholder() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, 100) // %v：默认格式输出 fmt.Printf(\u0026#34;%v\\n\u0026#34;, false) // %v：默认格式输出 o := struct{ name string }{\u0026#34;wangpengliang\u0026#34;} fmt.Printf(\u0026#34;%v\\n\u0026#34;, o) fmt.Printf(\u0026#34;%+v\\n\u0026#34;, o) // %+v：类似%v，但输出结构体时会添加字段名 fmt.Printf(\u0026#34;%#v\\n\u0026#34;, o) // %#v：值的Go语法表示 fmt.Printf(\u0026#34;%T\\n\u0026#34;, o) // %T：打印值的类型 fmt.Printf(\u0026#34;100%%\\n\u0026#34;) // %%：百分号 }输出：\n100 false {wangpengliang} {name:wangpengliang} struct { name string }{name:\u0026#34;wangpengliang\u0026#34;} struct { name string } 100%布尔型# 占位符 说明 %t true或false 整型# 占位符 说明 %b 表示为二进制 %c 该值对应的unicode码值 %d 表示为十进制 %o 表示为八进制 %x 表示为十六进制，使用a-f %X 表示为十六进制，使用A-F %U 表示为Unicode格式：U+1234，等价于”U+%04X” %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 示例：\nfunc intPlaceholderTest() { n := 65 fmt.Printf(\u0026#34;%b\\n\u0026#34;, n) // %b：二进制输出 fmt.Printf(\u0026#34;%c\\n\u0026#34;, n) // %c：输出对应的unicode编码 fmt.Printf(\u0026#34;%d\\n\u0026#34;, n) // %d:十进制输出 fmt.Printf(\u0026#34;%o\\n\u0026#34;, n) // %o:八进制输出 fmt.Printf(\u0026#34;%x\\n\u0026#34;, n) // %x:十六进制输出,使用a-f fmt.Printf(\u0026#34;%X\\n\u0026#34;, n) // %X:十六进制输出，使用A-F }输出：\n1000001 A 65 101 41 41浮点数与复数# 占位符 说明 %b 无小数部分、二进制指数的科学计数法，如-123456p-78 %e 科学计数法，如-1234.456e+78 %E 科学计数法，如-1234.456E+78 %f 有小数部分但无指数部分，如123.456 %F 等价于%f %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） %G 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） 示例：\nfunc floatPlaceholder() { f := 12.34 fmt.Printf(\u0026#34;%b\\n\u0026#34;, f) // %b：无小数部分、二进制指数的科学计数法 fmt.Printf(\u0026#34;%e\\n\u0026#34;, f) // %e: 科学计数法,如-1234.456e+78 fmt.Printf(\u0026#34;%E\\n\u0026#34;, f) // %E: 科学计数法,如-1234.456E+78 fmt.Printf(\u0026#34;%f\\n\u0026#34;, f) // %f: 有小数部分但无指数部分，如123.456 fmt.Printf(\u0026#34;%g\\n\u0026#34;, f) // %g: 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） fmt.Printf(\u0026#34;%G\\n\u0026#34;, f) // %G: 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） }输出：\n6946802425218990p-49 1.234000e+01 1.234000E+01 12.340000 12.34 12.34字符串和[]byte# 占位符 说明 %s 直接输出字符串或者[]byte %q 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 %x 每个字节用两字符十六进制数表示（使用a-f) %X 每个字节用两字符十六进制数表示（使用A-F） 示例：\nfunc stringPlaceholder() { s := \u0026#34;wangpengliang\u0026#34; fmt.Printf(\u0026#34;%s\\n\u0026#34;, s) // %s：直接输出字符串或者[]byte fmt.Printf(\u0026#34;%q\\n\u0026#34;, s) // %q: 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 fmt.Printf(\u0026#34;%x\\n\u0026#34;, s) // %x: 每个字节用两字符十六进制数表示（使用a-f) fmt.Printf(\u0026#34;%X\\n\u0026#34;, s) // %X: 每个字节用两字符十六进制数表示（使用A-F) }输出：\nwangpengliang \u0026#34;wangpengliang\u0026#34; 77616e6770656e676c69616e67 77616E6770656E676C69616E67指针# 占位符 说明 %p 表示为十六进制，并加上前导的0x 示例代码如下：\nfunc pointerPlaceholder() { a := 10 fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;a) fmt.Printf(\u0026#34;%#p\\n\u0026#34;, \u0026amp;a) }输出结果如下：\n0xc000012088 c000012088宽度标识符# 宽度通过一个紧跟在百分号后面的十进制数指定，如果未指定宽度，则表示值时除必需之外不作填充。精度通过（可选的）宽度后跟点号后跟的十进制数指定。如果未指定精度，会使用默认精度；如果点号后没有跟数字，表示精度为0。举例如下：\n占位符 说明 %f 默认宽度，默认精度 %9f 宽度9，默认精度 %.2f 默认宽度，精度2 %9.2f 宽度9，精度2 %9.f 宽度9，精度0 示例：\nfunc breadth() { n := 12.34 fmt.Printf(\u0026#34;%f\\n\u0026#34;, n) fmt.Printf(\u0026#34;%9f\\n\u0026#34;, n) fmt.Printf(\u0026#34;%.2f\\n\u0026#34;, n) fmt.Printf(\u0026#34;%9.2f\\n\u0026#34;, n) fmt.Printf(\u0026#34;%9.f\\n\u0026#34;, n) }输出：\n12.340000 12.340000 12.34 12.34 12其他flag# 占位符 说明 ’+’ 总是输出数值的正负号；对%q（%+q）会生成全部是ASCII字符的输出（通过转义） ’ ‘ 对数值，正数前加空格而负数前加负号；对字符串采用%x或%X时（% x或% X）会给各打印的字节之间加空格 ’-’ 在输出右边填充空白而不是默认的左边（即从默认的右对齐切换为左对齐） ’#’ 八进制数前加0（%#o），十六进制数前加0x（%#x）或0X（%#X），指针去掉前面的0x（%#p）对%q（%#q），对%U（%#U）会输出空格和单引号括起来的go字面值 ‘0’ 使用0而不是空格填充，对于数值类型会把填充的0放在正负号后面 示例：\nfunc otherPlaceholder() { s := \u0026#34;wangpengliang\u0026#34; fmt.Printf(\u0026#34;%s\\n\u0026#34;, s) fmt.Printf(\u0026#34;%5s\\n\u0026#34;, s) fmt.Printf(\u0026#34;%-5s\\n\u0026#34;, s) fmt.Printf(\u0026#34;%5.7s\\n\u0026#34;, s) fmt.Printf(\u0026#34;%-5.7s\\n\u0026#34;, s) fmt.Printf(\u0026#34;%5.2s\\n\u0026#34;, s) fmt.Printf(\u0026#34;%05s\\n\u0026#34;, s) }输出：\nwangpengliang wangpengliang wangpengliang wangpen wangpen wa wangpengliang获取输入# Go语言fmt包下有fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，可以在程序运行过程中从标准输入获取用户的输入。\nfmt.Scan# 函数签名如下：\nfunc Scan(a ...interface{}) (n int, err error) Scan从标准输入扫描文本，读取由空白符分隔的值保存到传递给本函数的参数中，换行符视为空白符 本函数返回成功扫描的数据个数和遇到的任何错误。如果读取的数据个数比提供的参数少，会返回一个错误报告原因 示例：\nfunc fmtScan() { fmt.Println(\u0026#34;please input you name\u0026#34;) var input string fmt.Scanln(\u0026amp;input) //读取键盘输入，通过操作地址赋值给input.阻塞式 fmt.Println(\u0026#34;you name is：\u0026#34; + input) fmt.Println(\u0026#34;please input you name,age,sex\u0026#34;) var ( name string age int sex bool ) fmt.Scan(\u0026amp;name, \u0026amp;age, \u0026amp;sex) fmt.Printf(\u0026#34;扫描结果 name:%s age:%d sex:%t \\n\u0026#34;, name, age, sex) }please input you name wangpengliang you name is：wangpengliang please input you name,age,sex wangpengliang 18 true 扫描结果 name:wangpengliang age:18 sex:truefmt.Scan 从标准输入中扫描用户输入的数据，将以空白符分隔的数据分别存入指定的参数。\nfmt.Scanf# 函数签名如下：\nfunc Scanf(format string, a ...interface{}) (n int, err error) Scanf从标准输入扫描文本，根据 format 参数指定的格式去读取由空白符分隔的值保存到传递给本函数的参数中 本函数返回成功扫描的数据个数和遇到的任何错误 示例：\nfunc fmtScanf() { var ( name string age int sex bool ) fmt.Scanf(\u0026#34;1:%s 2:%d 3:%t\u0026#34;, \u0026amp;name, \u0026amp;age, \u0026amp;sex) fmt.Printf(\u0026#34;扫描结果 name:%s age:%d sex:%t \\n\u0026#34;, name, age, sex) }将上面的代码编译后在终端执行，在终端按照指定的格式依次输入1:wpl 2:18 3:true。\nPS D:\\GoProject\\src\\golang.basic\u0026gt; go run .\\fmtTest.go 1:wpl 2:18 3:true 扫描结果 name:wpl age:18 sex:true fmt.Scanf 不同于 fmt.Scan 简单的以空格作为输入数据的分隔符，fmt.Scanf 为输入数据指定了具体的输入内容格式，只有按照格式输入数据才会被扫描并存入对应变量。\nfmt.Scanln# 函数签名如下：\nfunc Scanln(a ...interface{}) (n int, err error) Scanln类似Scan，它在遇到换行时才停止扫描。最后一个数据后面必须有换行或者到达结束位置 本函数返回成功扫描的数据个数和遇到的任何错误 示例：\nfunc fmtScanlnfTest() { var ( name string age int sex bool ) fmt.Scanln(\u0026amp;name, \u0026amp;age, \u0026amp;sex) fmt.Printf(\u0026#34;扫描结果 name:%s age:%d sex:%t \\n\u0026#34;, name, age, sex) }将上面的代码编译后在终端执行，在终端依次输入1、2和false使用空格分隔。\nPS D:\\GoProject\\src\\golang.basic\u0026gt; go run .\\fmtTest.go 1 2 false 扫描结果 name:1 age:2 sex:falsefmt.Scanln 遇到回车就结束扫描了，这个比较常用。\nbufio.NewReader# 有时候需要完整获取输入的内容，而输入的内容可能包含空格，这种情况下可以使用 bufio 包来实现。比如：\nfunc bufioTest() { reader := bufio.NewReader(os.Stdin) // 从标准输入生成读对象 fmt.Print(\u0026#34;请输入内容：\u0026#34;) text, _ := reader.ReadString(\u0026#39;\\n\u0026#39;) // 读到换行 text = strings.TrimSpace(text) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, text) }请输入内容：1 2 3 43 435 \u0026#34;1 2 3 43 435\u0026#34;Fscan 系列# 这几个函数功能分别类似于 fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，只不过它们不是从标准输入中读取数据而是从 io.Reader 中读取数据。\nfunc Fscan(r io.Reader, a ...interface{}) (n int, err error) func Fscanln(r io.Reader, a ...interface{}) (n int, err error) func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error)Sscan 系列# 这几个函数功能分别类似于 fmt.Scan 、 fmt.Scanf 、fmt.Scanln 三个函数，只不过它们不是从标准输入中读取数据而是从指定字符串中读取数据。\nfunc Sscan(str string, a ...interface{}) (n int, err error) func Sscanln(str string, a ...interface{}) (n int, err error) func Sscanf(str string, format string, a ...interface{}) (n int, err error)"},{"id":60,"href":"/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/log/","title":"Log","section":"所有文章","content":"Go语言内置的 log 包实现了简单的日志服务。\n"},{"id":61,"href":"/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/time/","title":"Time","section":"所有文章","content":"学习Go语言内置的 time 包的基本用法，time 包提供了时间的显示和计算用的函数。日历计算采用公历。\n时间可分为时间点与时间段，Go 提供了以下两种基础类型\n时间点 Time 时间段 Duration 除此之外也提供了以下类型，做一些特定的业务\n时区 Location Ticker 定时器 Timer 时间点# 一般使用的所有与时间相关的业务都是基于点而延伸的，两点组成一个时间段，大多数应用也都是围绕这些点与面去做逻辑处理。\n初始化# go 针对不同的参数类型提供了以下初始化的方式\n// func Now() Time fmt.Println(time.Now()) // func Parse(layout, value string) (Time, error) time.Parse(\u0026#34;2016-01-02 15:04:05\u0026#34;, \u0026#34;2018-04-23 12:24:51\u0026#34;) // func ParseInLocation(layout, value string, loc *Location) (Time, error) (layout已带时区时可直接用Parse) time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2017-05-11 14:06:06\u0026#34;, time.Local) // func Unix(sec int64, nsec int64) Time time.Unix(1e9, 0) // func Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time time.Date(2018, 1, 2, 15, 30, 10, 0, time.Local) // func (t Time) In(loc *Location) Time 当前时间对应指定时区的时间 loc, _ := time.LoadLocation(\u0026#34;America/Los_Angeles\u0026#34;) fmt.Println(time.Now().In(loc)) // func (t Time) Local() Time获取到时间点之后为了满足业务和设计，需要转换成需要的格式，也就是所谓的时间格式化。\n格式化# to string# 格式化为字符串我们需要使用 time.Format 方法来转换成我们想要的格式\nfmt.Println(time.Now().Format(\u0026quot;2006-01-02 15:04:05\u0026quot;)) // 2018-04-24 10:11:20 fmt.Println(time.Now().Format(time.UnixDate)) // Tue Apr 24 09:59:02 CST 2018 Format 函数中可以指定你想使用的格式，同时 time 包中也给了一些我们常用的格式\nconst ( ANSIC = \u0026#34;Mon Jan _2 15:04:05 2006\u0026#34; UnixDate = \u0026#34;Mon Jan _2 15:04:05 MST 2006\u0026#34; RubyDate = \u0026#34;Mon Jan 02 15:04:05 -0700 2006\u0026#34; RFC822 = \u0026#34;02 Jan 06 15:04 MST\u0026#34; RFC822Z = \u0026#34;02 Jan 06 15:04 -0700\u0026#34; // RFC822 with numeric zone RFC850 = \u0026#34;Monday, 02-Jan-06 15:04:05 MST\u0026#34; RFC1123 = \u0026#34;Mon, 02 Jan 2006 15:04:05 MST\u0026#34; RFC1123Z = \u0026#34;Mon, 02 Jan 2006 15:04:05 -0700\u0026#34; // RFC1123 with numeric zone RFC3339 = \u0026#34;2006-01-02T15:04:05Z07:00\u0026#34; RFC3339Nano = \u0026#34;2006-01-02T15:04:05.999999999Z07:00\u0026#34; Kitchen = \u0026#34;3:04PM\u0026#34; // Handy time stamps. Stamp = \u0026#34;Jan _2 15:04:05\u0026#34; StampMilli = \u0026#34;Jan _2 15:04:05.000\u0026#34; StampMicro = \u0026#34;Jan _2 15:04:05.000000\u0026#34; StampNano = \u0026#34;Jan _2 15:04:05.000000000\u0026#34; ) 注意: galang 中指定的特定时间格式为 \u0026ldquo;2006-01-02 15:04:05 -0700 MST\u0026rdquo;， 为了记忆方便，按照美式时间格式 月日时分秒年 外加时区 排列起来依次是 01/02 03:04:05PM ‘06 -0700，刚开始使用时需要注意。\nto time stamp# ​ func (t Time) Unix() int64 ​ func (t Time) UnixNano() int64\nfmt.Println(time.Now().Unix()) // 获取指定日期的时间戳 dt, _ := time.Parse(\u0026quot;2016-01-02 15:04:05\u0026quot;, \u0026quot;2018-04-23 12:24:51\u0026quot;) fmt.Println(dt.Unix()) fmt.Println(time.Date(2018, 1,2,15,30,10,0, time.Local).Unix()) 其他# time 包还提供了一些常用的方法，基本覆盖了大多数业务，从方法名就能知道代表的含义就不一一说明了。\nfunc (t Time) Date() (year int, month Month, day int) func (t Time) Clock() (hour, min, sec int) func (t Time) Year() int func (t Time) Month() Month func (t Time) Day() int func (t Time) Hour() int func (t Time) Minute() int func (t Time) Second() int func (t Time) Nanosecond() int func (t Time) YearDay() int func (t Time) Weekday() Weekday func (t Time) ISOWeek() (year, week int) func (t Time) IsZero() bool func (t Time) Local() Time func (t Time) Location() *Location func (t Time) Zone() (name string, offset int) func (t Time) Unix() int64 时间类型# time.Time 类型表示时间。可以通过 time.Now() 函数获取当前的时间对象，然后获取时间对象的年月日时分秒等信息。\n示例代码如下：\nfunc getTimeNow() { now := time.Now() //获取当前时间 fmt.Printf(\u0026#34;current time:%v\\n\u0026#34;, now) year := now.Year() //年 month := now.Month() //月 day := now.Day() //日 hour := now.Hour() //小时 minute := now.Minute() //分钟 second := now.Second() //秒 fmt.Printf(\u0026#34;%d-%02d-%02d %02d:%02d:%02d\\n\u0026#34;, year, month, day, hour, minute, second) }时间戳# 时间戳是自 1970年1月1日（08:00:00GMT）至当前时间的总毫秒数。也被称为 Unix时间戳。\n示例代码如下：\n// 获取时间戳 func getUnix() { // 获取时间戳 timestamp1 := time.Now().Unix() //时间戳 timestamp2 := time.Now().UnixNano() //纳秒时间戳 fmt.Printf(\u0026#34;current timestamp1:%v\\n\u0026#34;, timestamp1) fmt.Printf(\u0026#34;current timestamp2:%v\\n\u0026#34;, timestamp2) }使用 time.Unix() 函数可以将时间戳转为时间格式。\nfunc unixConverTime() { // 将时间戳转换为时间格式 timestamp := time.Now().Unix() //时间戳 fmt.Printf(\u0026#34;current timestamp1:%v\\n\u0026#34;, timestamp) timeObj := time.Unix(timestamp, 0) //将时间戳转为时间格式 fmt.Println(timeObj) year := timeObj.Year() //年 month := timeObj.Month() //月 day := timeObj.Day() //日 hour := timeObj.Hour() //小时 minute := timeObj.Minute() //分钟 second := timeObj.Second() //秒 fmt.Printf(\u0026#34;%d-%02d-%02d %02d:%02d:%02d\\n\u0026#34;, year, month, day, hour, minute, second) }时间间隔# time.Duration 是 time 包定义的一个类型，它代表两个时间点之间经过的时间，以纳秒为单位。time.Duration 表示一段时间间隔，可表示的最长时间段大约290年。\ntime 包中定义的时间间隔类型的常量如下：\nconst ( Nanosecond Duration = 1 Microsecond = 1000 * Nanosecond Millisecond = 1000 * Microsecond Second = 1000 * Millisecond Minute = 60 * Second Hour = 60 * Minute )例如：time.Duration 表示1纳秒，time.Second 表示1秒。\n时间操作# Add# 求时间+n后的时间：\nfunc (t Time) Add(d Duration) Time示例代码如下：\nfunc timeAdd() { now := time.Now() value := now.Add(time.Hour) // 当前时间加1小时后的时间 fmt.Println(value) }Sub# 求两个时间之间的差值：\nfunc (t Time) Sub(u Time) Duration示例代码如下：\nfunc timeSub() { now := time.Now() value := now.Sub(now.Add(time.Hour)) fmt.Println(value) }返回一个时间段 t-u。如果结果超出了 Duration 可以表示的最大值/最小值，将返回最大值/最小值。要获取时间点 t-d（d为Duration），可以使用 t.Add(-d)。\nEqual# func (t Time) Equal(u Time) bool判断两个时间是否相同，会考虑时区的影响，因此不同时区标准的时间也可以正确比较。本方法和用 t==u 不同，这种方法还会比较地点和时区信息。\nBefore# func (t Time) Before(u Time) bool如果t代表的时间点在u之前，返回真；否则返回假。\nAfter# func (t Time) After(u Time) bool如果t代表的时间点在u之后，返回真；否则返回假。\n定时器\n使用time.Tick(时间间隔)来设置定时器，定时器的本质上是一个通道（channel）。\nfunc tickDemo() { ticker := time.Tick(time.Second) //定义一个1秒间隔的定时器 for i := range ticker { fmt.Println(i)//每秒都会执行的任务 } }时间格式化# 时间类型有一个自带的方法Format进行格式化，需要注意的是Go语言中格式化时间模板不是常见的Y-m-d H:M:S而是使用Go的诞生时间2006年1月2号15点04分（记忆口诀为2006 1 2 3 4）。也许这就是技术人员的浪漫吧。\n补充：如果想格式化为12小时方式，需指定PM。\nfunc formatDemo() { now := time.Now() // 格式化的模板为Go的出生时间2006年1月2号15点04分 Mon Jan // 24小时制 fmt.Println(now.Format(\u0026#34;2006-01-02 15:04:05.000 Mon Jan\u0026#34;)) // 12小时制 fmt.Println(now.Format(\u0026#34;2006-01-02 03:04:05.000 PM Mon Jan\u0026#34;)) fmt.Println(now.Format(\u0026#34;2006/01/02 15:04\u0026#34;)) fmt.Println(now.Format(\u0026#34;15:04 2006/01/02\u0026#34;)) fmt.Println(now.Format(\u0026#34;2006/01/02\u0026#34;)) }解析字符串格式的时间# now := time.Now() fmt.Println(now) // 加载时区 loc, err := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) if err != nil { fmt.Println(err) return } // 按照指定时区和指定格式解析字符串时间 timeObj, err := time.ParseInLocation(\u0026#34;2006/01/02 15:04:05\u0026#34;, \u0026#34;2019/08/04 14:15:20\u0026#34;, loc) if err != nil { fmt.Println(err) return } fmt.Println(timeObj) fmt.Println(timeObj.Sub(now))练习题：\n"},{"id":62,"href":"/docs/kubernetes/kubernetes%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"Kubernetes基础知识","section":"所有文章","content":"服务器演变过程# 了解K8S之前，首先需要了解服务器的演变过程：\n物理机时代 虚拟机时代 容器化时代 物理机时代# 缺点：\n部署慢 ：每台服务器都要安装操作系统、相关应用程序所需要的环境，各种配置 成本高：物理服务器的价格十分昂贵 资源浪费：硬件资源不能充分利用 扩展和迁移成本高：扩展和迁移需要重新配置一模一样的环境 虚拟机时代# 虚拟机时代解决了物理机时代的缺点，虚拟机时代的优点是：\n易部署：每台物理机可部署多台虚拟机，还可以通过模板，部署快，成本低 资源池：开出来的虚拟机可作为资源池备用，充分压榨服务器性能 资源隔离：每个虚拟机都有独立分配的内存磁盘等硬件资源，虚拟机之间不会互相影响 易扩展：随时都能在一个物理机上创建或销毁虚拟机 缺点：每台虚拟机都需要安装操作系统\n容器化时代# 容器化时代解决了虚拟机时代的缺点，在继承了虚拟机时代优点的基础上，还有以下优势：\n更高效的利用硬件资源：所有容器共享主机操作系统内核，不需要安装操作系统 一致的运行环境：相同的镜像产生相同的行为 更小：较虚拟机而言，容器镜像更小，因为不需要打包操作系统 更快：容器能达到秒级启动，其本质是主机上的一个进程 Kubernetes 简介# Kubernetes 是谷歌开源的容器集群管理系统，用于管理容器化工作负载和服务。是 Google 多年大规模容器管理技术 Borg 的开源版本，主要功能包括：\n基于容器的应用部署、维护和滚动升级 负载均衡和服务发现 跨机器和跨地区的集群调度 自动伸缩 无状态服务和有状态服务 广泛的 Volume 支持 插件机制保证扩展性 Kubernetes 发展非常迅速，目前已成为容器编排领域的领导者。\n参考文档： https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\nKubernetes 相关组件# Kubernetes 主要由以下几个核心组件组成：\netcd：保存整个集群的状态 apiserver：提供资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制 controller manager：负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler：负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上 kubelet：负责维护容器的生命周期，同时也负责 Volume（CVI）和网络 （CNI） 的管理 Container runtime：负责镜像管理以及 Pod 和容器的真正运行（CRI） kube-proxy：负责为 Service 提供 Cluster 内部的服务发现和负载均衡 除了核心组件，还有一些推荐的附加组件：\nkube-dns：负责为整个集群提供 DNS 服务 Ingress Controller：为服务提供外网入口 Heapster：提供资源监控 Dashboard：提供 GUI Federation：提供跨可用区的集群 Fluentd-elasticsearch：提供集群日志采集、存储与查询 Etcd# Etcd 是 CoreOS 基于 Raft 开发的分布式 key-value 存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等）。项目地址：https://github.com/etcd-io/etcd\n主要功能：\n基本的 key-value 存储 监听机制 key 的过期及续约机制，用于监控和服务发现 原子CAS 和 CAD，用于分布式锁和 leader 选举 Kube-apiserver# kube-apiserver 是 Kubernetes 最重要的核心组件之一。\n主要功能：\n提供集群管理的 REST API 接口，包括认证授权、数据校验以及集群状态变更等 提供其他模块之间的数据交互和通信的枢纽（其他模块通过 API Server 查询或修改数据，只有 API Server 才直接操作 etcd） Controller-manager# Controller Manager 由 kube-controller-manager 和 cloud-controller-manager 组成，是 Kubernetes 的大脑。通过 apiserver 监控整个集群的状态，并确保集群处于预期的工作状态。\nkube-controller-manager 由一系列的控制器组成：\nReplication Controller Node Controller CronJob Controller Daemon Controller Deployment Controller Endpoint Controller Garbage Collector Namespace Controller Job Controller Pod AutoScaler RelicaSet Service Controller ServiceAccount Controller StatefulSet Controller Volume Controller Resource quota Controller cloud-controller-manager\n在 Kubernetes 启用 Cloud Provider 时才需要，用来配合云服务提供商的控制，也包括一系列的控制器，如：\nNode Controller Route Controller Service Controller Scheduler# kube-scheduler 负责分配调度 Pod 到集群内的节点上，它监听 kube-apiserver，查询还未分配 Node 的 Pod，然后根据调度策略为这些 Pod 分配节点（更新 Pod的 NodeName 字段）。\n调度器需要充分考虑诸多的因素：\n公平调度 资源高效利用 Qos affinity 和 anti-affinity 数据本地化（data locality） 内部负载干扰（inter-workload interference） deadlines Kubelet# 每个节点上都运行一个 kubelet 服务进程，默认监听 10250 端口，接收并执行 master 发来的指令，管理 Pod 及 Pod 中的容器。每个 kubelet 进程会在 API Server 上注册节点自身信息，定期向 master 节点汇报节点的资源使用情况，并通过 cAdvisor 监控节点和容器的资源。\nContainer runtime# 容器运行时（Container Runtime）是 Kubernetes 最重要的组件之一，负责真正管理镜像和容器的生命周期。Kubelet 通过 Container Runtime Interface (CRI) 与容器运行时交互，以管理镜像和容器。\nKube-proxy# 每台机器上都运行一个 kube-proxy 服务，用于监听 API server 中 service 和 endpoint 的变化情况，并通过 iptables 等来为服务配置负载均衡（仅支持 TCP 和 UDP）。\nkube-proxy 可以直接运行在物理机上，也可以以 static pod 或者 daemonset 的方式运行。\nkube-proxy 当前支持以下几种实现：\nuserspace：最早的负载均衡方案：在用户空间监听一个端口，所有服务通过 iptables 转发到这个端口，然后在其内部负载均衡到实际的 Pod。该方式最主要的问题是：效率低，有明显的性能瓶颈 iptables：目前推荐的方案：完全以 iptables 规则的方式来实现 service 负载均衡。该方式最主要的问题是：在服务多的时候产生太多的 iptables 规则，非增量式更新会引入一定的延时，大规模情况下有明显的性能问题 ipvs：为解决 iptables 模式的性能问题，v1.8 新增了 ipvs 模式，采用增量式更新，并可以保证 service 更新期间连接保持不断开 winuserspace：同 userspace，但仅工作在 windows 上 Kubernetes 架构# Kubernetes 借鉴了 Borg 的设计理念，比如Pod、Service、Labels等。整体架构跟 Borg 非常像，如下图所示：\n在 K8S 中，由 Master 控制节点和 Worker 节点共同构成一个集群。\nMaster# Etcd：用于保存集群中的相关数据 Api Server：集群统一入口，以 restful 风格操作，同时交给 etcd 存储（是唯一能访问etcd的组件）提供认证、授权、访问控制、API注册和发现等机制，可以通过 kubectl 命令行工具，dashboard 可视化面板，或者sdk 等方式访问 Scheduler：节点的调度，选择 node 节点进行应用部署 Controller Manager：处理集群中常规后台任务，一个资源对应一个控制器，同时监控集群状态，确保实际状态和最终状态一致 Worker# kubelet：相当于 Master 派到 node 节点代表，管理本机容器，上报数据给 API Server Container Runtime：容器运行时，K8S支持多个容器运行环境：Docker、Containerd、CRI-O、Rktlet 以及任何实现 Kubernetes CRI (容器运行环境接口) 的软件 kube-proxy：实现服务（Service）抽象组件，屏蔽 PodIP 的变化和负载均衡 镜像库在 Kubernetes 中也起到一个很重要的角色，Kubernetes 需要从镜像库中拉取镜像基于这个镜像的容器才能成功启动。常用的镜像库有 dockerhub、阿里云镜像库、Harbor等\nKubernetes 核心概念# Pod# Pod 是最小调度单元 Pod 包含一个或多个容器（Container） Pod 内的容器共享存储及网络，可通过 localhost 通信 Pod 本意是豌豆荚的意思，此处指 K8S 中资源调度的最小单位，豌豆荚里面的小豆子就像是 Container，豌豆荚本身就像是一个 Pod。\nDeployment# Deployment 是在 Pod 抽象上更为上层的一个抽象，它可以定义一组 Pod 的副本数目、以及这个 Pod 的版本。一般用 Deployment 这个抽象来做应用的真正管理，Pod 是组成 Deployment 最小的单元。\n定义一组 Pod 的副本数量，版本等 通过控制器维护 Pod 的数目 自动恢复失败的 Pod 通过控制器以指定的策略控制版本 Service# Pod 是不稳定的，IP 会变化，所以需要一层抽象来屏蔽这种变化，这层抽象叫做 Service\n提供访问一个或者多个 Pod 实例稳定的访问地址 支持多种访问方式 ClusterIP（对集群内部访问）、NodePort（对集群外部访问）、LoadBalancer（集群外部负载均衡） Volume# Volume 就是存储卷。在 Pod 中可以声明卷来问访问文件系统，同时 Volume 也是一个抽象层，其具体的后端存储可以是本地存储、NFS 网络存储、云存储（阿里云盘、AWS云盘、Google云盘等）、分布式存储（比如 ceph、GlusterFS ）\n声明在 Pod 中容器可以访问的文件系统 可以被挂载在 Pod 中一个或多个容器的指定路径下 支持多种后端存储 Namespace# Namespace（命令空间）是用来做资源的逻辑隔离的，比如 Pod、Deployment、Service 都属于资源，不同Namespace 下资源可以重名。同一 Namespace 下资源名必须唯一。\n一个集群内部的逻辑隔离机制（鉴权、资源等） 每个资源都属于一个 Namespace 同一个 Namespace 中资源命名唯一 不同 Namespace 中资源可重名 "},{"id":63,"href":"/docs/kubernetes/kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","title":"Kubernetes集群安装","section":"所有文章","content":"集群安装方式# minikube K8S 集群模拟器，只有一个节点的集群，只为测试用，master 和 worker 都在一起 直接用云平台 Kubernetes 可视化搭建，只需简单几步就可以创建好一个集群 优点：安装简单，生态齐全，负载均衡器、存储等都给你配套好，简单操作就搞定 裸机安装（Bare Metal） 至少需要两台机器（主节点、工作节点各一台），需要自己安装 Kubernetes 组件，配置会稍微麻烦点。 可以到各云厂商按时租用服务器，费用低，用完就销毁 缺点：配置麻烦，缺少生态支持，例如负载均衡器、云存储 安装 Kubernetes 集群# 服务器环境# 这里选择裸机安装，三台服务器配置如下且均已安装 Docker：\nIP 主机名称 描述 192.168.110.20 master 主节点 192.168.110.232 node1 工作节点1 192.168.110.233 node2 工作节点2 通用节点配置# 分别设置对应主机名# hostnamectl set-hostname master hostnamectl set-hostname node1 hostnamectl set-hostname node2关闭 selinux# setenforce 0 sed -i --follow-symlinks \u0026#39;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#39; /etc/sysconfig/selinux关闭 swap# cat /etc/fstab # # /etc/fstab # Created by anaconda on Tue Aug 9 14:09:10 2022 # # Accessible filesystems, by reference, are maintained under \u0026#39;/dev/disk\u0026#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=6228c8d0-3efa-4ac0-a147-a3ee8dc90897 /boot xfs defaults 0 0 #/dev/mapper/centos-swap swap swap defaults 0 0 # 注释掉最后一行修改 hosts# vim /etc/hosts 192.168.110.20 master 192.168.110.232 node1 192.168.110.233 node2关闭防火墙# systemctl stop firewalld systemctl disable firewalld添加安装源# # 添加 k8s 安装源 cat \u0026lt;\u0026lt;EOF \u0026gt; kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF mv kubernetes.repo /etc/yum.repos.d/ # 添加 Docker 安装源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo安装所需组件# yum install -y kubelet-1.22.4 kubectl-1.22.4 kubeadm-1.22.4 docker-ce设置开机启动# systemctl enable kubelet systemctl start kubelet systemctl enable docker systemctl start docker修改 Docker 配置# # kubernetes 官方推荐 docker 等使用 systemd 作为 cgroupdriver，否则 kubelet 启动不了 cat \u0026lt;\u0026lt;EOF \u0026gt; daemon.json { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://ud6340vz.mirror.aliyuncs.com\u0026#34;] } EOF mv daemon.json /etc/docker/ # 重启生效 systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker主节点配置# 使用 kubeadm 初始化集群（仅在主节点跑）\n# 初始化集群控制台 Control plane kubeadm init --image-repository=registry.aliyuncs.com/google_containers # 失败了可以用 kubeadm reset 重置集群创建成功后，保存命令\nkubeadm join 192.168.110.20:6443 --token yeaovk.aiaf64mm7phk62jy \\ --discovery-token-ca-cert-hash sha256:7c3a7118b7a0b8f1b997d00531fcf304be457f89ec8ea2e6dcd91710f0752ed5 # 忘记了重新获取：kubeadm token create --print-join-command复制授权文件，以便 kubectl 可以有权限访问集群。如果其他节点需要访问集群，需要从主节点复制这个文件过去其他节点。\nmkdir -p $HOME/.kube\rcp -i /etc/kubernetes/admin.conf $HOME/.kube/config\rchown $(id -u):$(id -g) $HOME/.kube/config\r# 在其他机器上创建 ~/.kube/config 文件也能通过 kubectl 访问到集群 有兴趣了解 kubeadm init 具体做了什么的，可以 查看文档\n工作节点配置# 把工作节点加入集群（只在工作节点跑）\nkubeadm join 192.168.110.20:6443 --token yeaovk.aiaf64mm7phk62jy \\ --discovery-token-ca-cert-hash sha256:7c3a7118b7a0b8f1b997d00531fcf304be457f89ec8ea2e6dcd91710f0752ed5安装网络插件，否则 node 是 NotReady 状态（主节点跑）\n# 很有可能国内网络访问不到这个资源，你可以网上找找国内的源安装 flannel kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml这里选择直接下载一份 kube-flannel.yml 的源码，源码参考 下载文件后，在文件所在目录执行\nkubectl apply -f kube-flannel.yml 查看节点，要在主节点查看（其他节点有安装 kubectl 也可以查看）\n[root@master k8s]# kubectl get nodes NAME STATUS ROLES AGE VERSION master Ready control-plane,master 27m v1.22.4 node1 Ready \u0026lt;none\u0026gt; 16m v1.22.4 node2 Ready \u0026lt;none\u0026gt; 11m v1.22.4"},{"id":64,"href":"/docs/linux/centos7%E5%8D%87%E7%BA%A7gcc%E7%89%88%E6%9C%AC/","title":"Centos7升级gcc版本","section":"所有文章","content":"Centos 7 默认 gcc 版本为4.8，有时需要更高版本的，这里以升级至8.3.1版本为例，分别执行下面三条命令即可，无需手动下载源码编译。\n1、安装centos-release-scl\nsudo yum install centos-release-scl2、安装devtoolset，注意：如果想安装7.* 版本的，就改成devtoolset-7-gcc，以此类推\nsudo yum install devtoolset-8-gcc*3、激活对应的devtoolset，可以一次安装多个版本的devtoolset，需要的时候用下面这条命令切换到对应的版本\nscl enable devtoolset-8 bash搞定，查看一下gcc版本\ngcc -v[root@wangpengliang ~]# gcc -v Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/opt/rh/devtoolset-8/root/usr/libexec/gcc/x86_64-redhat-linux/8/lto-wrapp erTarget: x86_64-redhat-linux Configured with: ../configure --enable-bootstrap --enable-languages=c,c++,fortran,lto --prefi x=/opt/rh/devtoolset-8/root/usr --mandir=/opt/rh/devtoolset-8/root/usr/share/man --infodir=/opt/rh/devtoolset-8/root/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-gcc-major-version-only --with-linker-hash-style=gnu --with-default-libstdcxx-abi=gcc4-compatible --enable-plugin --enable-initfini-array --with-isl=/builddir/build/BUILD/gcc-8.3.1-20190311/obj-x86_64-redhat-linux/isl-install --disable-libmpx --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linuxThread model: posix gcc version 8.3.1 20190311 (Red Hat 8.3.1-3) (GCC) [root@wangpengliang ~]#显示为 gcc version 8.3.1 20190311 (Red Hat 8.3.1-3) (GCC)\n补充：这条激活命令只对本次会话有效，重启会话后还是会变回原来的4.8.5版本，要想随意切换可按如下操作。\n首先，安装的 devtoolset 是在 /opt/rh 目录下的\n[root@wangpengliang rh]# ls devtoolset-8 devtoolset-9 [root@wangpengliang rh]#每个版本的目录下面都有个 enable 文件，如果需要启用某个版本，只需要执行\nsource ./enable所以要想切换到某个版本，只需要执行\nsource /opt/rh/devtoolset-8/enable可以将对应版本的切换命令写个shell文件放在配了环境变量的目录下，需要时随时切换，或者开机自启\n4、直接替换旧的gcc 旧的gcc是运行的 /usr/bin/gcc ，所以将该目录下的gcc/g++替换为刚安装的新版本gcc软连接，免得每次 enable mv /usr/bin/gcc /usr/bin/gcc-4.8.5 ln -s /opt/rh/devtoolset-8/root/bin/gcc /usr/bin/gcc mv /usr/bin/g++ /usr/bin/g++-4.8.5 ln -s /opt/rh/devtoolset-8/root/bin/g++ /usr/bin/g++ gcc --version g++ --version"},{"id":65,"href":"/docs/linux/centos%E5%AE%89%E8%A3%85hexo/","title":"Centos安装 Hexo","section":"所有文章","content":"Nodejs 安装# 下载# wget https://nodejs.org/dist/v16.14.0/node-v16.14.0-linux-x64.tar.gz tar -xvf node-v16.14.0-linux-x64.tar.gz # 将文件解压到当前目录配置环境变量# ln -s /hexo/node-v16.14.0-linux-x64/bin/node /usr/local/bin/node ln -s /hexo/node-v16.14.0-linux-x64/bin/npm /usr/local/bin/npm ln -s /hexo/node-v16.14.0-linux-x64/lib/node_modules/hexo-cli/bin/hexo /usr/local/bin/hexo ln -s /projects/hexo/node-v16.14.0-linux-x64/bin/cnpm /usr/local/bin/cnpm # cnpm需要单独安装Hexo 安装# 创建工作目录# mkdir hexo cd hexo初始化 Hexo# # 安装Git(已安装可跳过) yum install git-core # 安装 Hexo npm install -g hexo-cli # 初始化 Hexo hexo initPm2# 参考：https://www.jianshu.com/p/a256ca175c64\n环境变量配置# ln -s /hexo/node-v16.14.0-linux-x64/bin/pm2 /usr/local/bin/pm2hexo_run.js# const { exec } = require(\u0026#39;child_process\u0026#39;) exec(\u0026#39;hexo server\u0026#39;,(error, stdout, stderr) =\u0026gt; { if(error){ console.log(\u0026#39;exec error: ${error}\u0026#39;) return } console.log(\u0026#39;stdout: ${stdout}\u0026#39;); console.log(\u0026#39;stderr: ${stderr}\u0026#39;); })常用命令# pm2 start hexo_run.js #启动 pm2 list #查看pm2管理的所有服务 pm2 stop all #停止pm2列表的所有服务 pm2 stop 0 #停止进程为0的进程 pm2 reload all #重新载入列表所有进程 pm2 reload 0 #重载列表中进程为0的进程 pm2 restart all #重启列表中所有的进程 pm2 restart 0 #重启列表中进程为0的进程 pm2 delete 0 #删除列表中进程为0的进程 pm2 delete all #删除列表中所有的进程"},{"id":66,"href":"/docs/linux/centos%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/","title":"Centos网络配置","section":"所有文章","content":"网络模式# VMnet0（桥接模式） VMnet1（仅主机模式） VMnet8（NAT模式） NAT-VMnet8# NAT(地址转换)-VMnet8：虚拟机要联网得先通过宿主机才能和外面进行通信。\nNAT 模式下的虚拟系统的 TCP/IP 配置信息是由 VMnet8(NAT) 虚拟网络的 DHCP 服务器提供的，无法进行手工修改，因此虚拟系统也就无法和本局域网中的其他真实主机进行通讯。使得虚拟局域网内的虚拟机在对外访问时，使用的则是宿主机的IP地址，这样从外部网络来看只能看到宿主机，完全看不到新建的虚拟局域网。就是虚拟系统会通过宿主机的网络来访问外网，而这里的宿主机相当于有两个网卡，一个是真实网卡，一个是虚拟网卡，真实网卡相当于链接了现实世界的真实路由器，而宿主机的虚拟网卡，相当于连接了一个可以认为是虚拟交换机。\n虚拟机可以上网可以ping通主机，但是主机ping不通虚拟机\nBridged-VMnet0# Bridged(桥接)-VMnet0：虚拟机和宿主机在网络上就是平级的关系，相当于连接在同一交换机上。\n需要手工为虚拟系统配置IP地址、子网掩码，而且还要和宿主机器处于同一网段，这样虚拟机才能和宿主机器进行通信，实现通过局域网的网关或路由器访问互联网。使用 Bridged 模式的虚拟系统和宿主机器的关系，就像连接在同一个Hub上的两台电脑。相当于在一个局域网内创立了一个单独的主机，他可以访问这个局域网内的所有的主机，但是需要手动配置IP地址，子网掩码，并且需要和真实主机在同一网段（nat是两个网段）。\n这个模式里，虚拟机和宿主机可以互相ping通\n查看IP及网卡信息# ip addr\n编辑网卡信息# vi /etc/sysconfig/network-scripts/ifcfg-ens33TYPE=Ethernet BOOTPROTO=static #修改成static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=eno16777736 UUID=bf5337ab-c044-4af7-9143-12da0d493b89 DEVICE=eno16777736 ONBOOT=yes #修改成yes PEERDNS=yes PEERROUTES=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPADDR=192.168.31.32 # 自定义虚拟机的ip地址（主机是192.168.31.31），必须与主机在同一网段 NETMASK=255.255.255.0 # 设置子网掩码，跟宿主一样 GATEWAY=192.168.31.1 # 默认网关，跟宿主一样 DNS1=192.168.31.1 # DNS，跟宿主一样重启 network# service network restart"},{"id":67,"href":"/docs/linux/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Linux常用命令","section":"所有文章","content":"系统级别# 描述 示例 备注 显示机器的处理器架构 arch 显示机器的处理器架构 uname -m 显示正在使用的内核版本 uname -r 显示硬件系统部件 - (SMBIOS / DMI) dmidecode -q 罗列一个磁盘的架构特性 hdparm -i /dev/hda 在磁盘上执行测试性读取操作 hdparm -tT /dev/sda 显示CPU info的信息 cat /proc/cpuinfo 显示中断 cat /proc/interrupts 校验内存使用 cat /proc/meminfo 显示哪些swap被使用 cat /proc/swaps 显示内核的版本 cat /proc/version 显示网络适配器及统计 cat /proc/net/dev 显示已加载的文件系统 cat /proc/mounts 罗列 PCI 设备 lspci -tv 显示 USB 设备 lsusb -tv 显示系统日期 date 显示2007年的日历表 cal 2007 设置日期和时间 - 月日时分年.秒 date 041217002007.00 将时间修改保存到 BIOS clock -w 关闭系统 shutdown -h now 关闭系统 telinit 0 取消按预定时间关闭系统 shutdown -c 重启 shutdown -r now 重启 reboot 注销 logout 目录相关# 描述 示例 备注 进入指定目录 cd /home 返回上一级目录 cd .. 返回上两级目录 cd ../.. 进入个人主目录 cd 进入上次操作所在目录 cd - 显示当前工作路径 pwd 查看目录中的文件 ls 查看目录中的文件 ls -F 显示文件和目录的详细信息 ls -l 显示隐藏文件 ls -a 显示包含数字的文件名和目录名 ls *[0-9]* 显示文件和目录由根目录开始的树形结构 tree yum install tree -y 创建目录 mkdir dir 创建多个目录 mkdir dir1 dir2 创建目录树 mkdir -p /tmp/dir1/dir2 删除文件 rm -f file1 删除目录 rmdir dir1 删除目录并同时删除内容 rm -rf dir1 同时删除多个目录及内容 rm -rf dir1 dir2 重命名/移动 目录 mv dir1 new_dir 复制文件 cp file1 file2 复制目录下的所有文件到当前工作目录 cp dir/* . 复制目录到当前工作目录 cp -a /tmp/dir1. 复制目录 cp -a dir1 dir2 创建一个指向文件或目录的软链接 ln -s file1 lnk1 创建一个指向文件或目录的物理链接 ln file1 lnk1 修改一个文件或目录的时间戳 - (YYMMDDhhmm) touch -t 0712250000 file1 网络相关# 描述 示例 备注 查看本机IP及网卡信息 ip addr 重启网络 service network restart 防火墙添加端口例外 firewall-cmd --add-port=8080/tcp --permanent 重新加载防火墙 firewall-cmd --reload 启动防火墙，也可以使用 service firewalld start systemctl start firewalld.service 停止防火墙，也可以使用 service firewalld stop systemctl stop firewalld.service 启用防火墙 systemctl enable firewalld.service 重启防火墙 service firewalld restart 查看端口列表，也可以使用 firewall-cmd --list-all firewall-cmd --permanent --list-port 查看防火墙状态 firewall-cmd --state "},{"id":68,"href":"/docs/linux/linux%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E/","title":"Linux目录说明","section":"所有文章","content":" 目录 描述 /boot 该目录默认下存放的是Linux的启动文件和内核 /bin Binary的缩写，该目录中存放Linux的常用命令 /sbin Supaer User；该目录用来存放系统管理员使用的管理程序 /var 该目录存放那些经常被修改的文件，包括各种日志、数据文件 /etc 该目录存放系统管理时要用到的各种配置文件和子目录，例如网络配置文件、文件系统、系统配置文件、设备配置信息、设置用户信息等 /dev d是Device的缩写；该目录包含了Linux系统中使用的所有外部设备，它实际上是访问这些外部设备的端口，访问这些外部设备与访问一个文件或一个目录没有区别 /mnt 临时将别的文件系统挂在该目录下 /root 如果你是以超级用户的身份登录的，这个就是超级用户的主目录 /home 如果建立一个名为“xx”的用户，那么在/home目录下就有一个对应的“/home/xx”路径，用来存放该用户的主目录 /usr 用户的应用程序和文件几乎都存放在该目录下 /lib 该目录用来存放系统动态链接共享库，几乎所有的应用程序都会用到该目录下的共享库 /opt 第三方软件在安装时默认会找这个目录,所以你没有安装此类软件时它是空的,但如果你一旦把它删除了,以后在安装此类软件时就有可能碰到麻烦 /tmp 用来存放不同程序执行时产生的临时文件，该目录会被系统自动清理干净 /lost＋found 该目录在大多数情况下都是空的。但当突然停电、或者非正常关机后，有些文件就临时存放在此 /proc 可以在该目录下获取系统信息，这些信息是在内存中由系统自己产生的，该目录的内容不在硬盘上而在内存里 "},{"id":69,"href":"/docs/linux/vmware%E5%AE%89%E8%A3%85centos/","title":"Vmware安装 Centos","section":"所有文章","content":"软件准备# 软件：VMware 操作系统：CentOS7 虚拟机准备# 打开 VMware 选择新建虚拟机\n典型安装与自定义安装\n典型安装：VMware 会将主流的配置应用在虚拟机的操作系统上，对于新手来很友好 自定义安装：自定义安装可以针对性的把一些资源加强，把不需要的资源移除。避免资源浪费 这里选择典型安装\n选择稍后安装操作系统\n选择操作系统为Linux\n输入虚机名称和存储位置\n设置虚机磁盘大小\n自定义硬件\n根据自己电脑实际情况分配\n内存：2G 处理器数量：2 / 内核数量：2 网络适配器：NAT 模式 移除打印机和声卡 Centos安装# 在创建好的虚机上右键设置\n开启虚拟机\n安装操作系统 开启虚拟机后会出现以下界面:\nInstall CentOS 7 安装CentOS 7 Test this media \u0026amp; install CentOS 7 测试安装文件并安装CentOS 7 Troubleshooting 修复故障 选择第一项，安装CentOS 7，回车进入下面的界面\n选择安装过程中使用的语言\n安装位置及分区设置；这里分区使用自动配置\n软件选择：最小安装\n网络和主机名：设置主机名称开启网络连接\n开始安装\n设置Root密码并创建新的用户admin\n等待安装完成重启系统即可。\n"},{"id":70,"href":"/docs/microservice/1.1%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/","title":"1.1微服务入门之项目搭建","section":"所有文章","content":"前言# 此系列旨在复习微服务的相关知识，示例代码中不会出现聚合、聚合根、服务拆分等相关概念（不会涉及到领域驱动相关知识），只使用最简单的.Net Core Web程序，主要关注点在于：\n如何使用 Docker 部署 .NetCore 应用 应用程序的 DockerFile 编写 服务注册和服务发现是什么？解决了什么问题？ 网关用来做什么？服务治理相关（熔断/限流/降级/链路追踪/缓存\u0026hellip;） 微服务概念# 关于微服务的概念解释网上有很多，每个人的理解都不同。至于为什么要使用微服务？微服务的优缺点等相关问题每个人理解不同。个人理解：微服务是一种系统架构模式，和语言无关，框架无关，工具无关，服务器环境无关，微服务目的是：将传统单体系统按照业务拆分成多个职责单一、且可独立运行的服务。至于服务如何拆分，没有明确的定义。采用微服务优点是：每个服务的职责单一且可独立部署、不同服务间采用轻量级的通信协议作为通信原则，松耦合。这样不同服务就可以使用不同的技术栈（优势语言），缺点的话是：微服务架构避免不了会引入更多技术栈、中间件等等增加系统复杂度。（微服务不是银弹，要根据实际业务体量考虑是否使用，否则只会徒增不必要的麻烦）\n项目结构搭建# Order.Api：订单服务 Web.Client：测试使用的客户端 创建项目时启用Docker支持，或者之后添加也可以。添加基础代码，简单的返回服务名称、当前时间、服务IP、端口：\nusing Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Configuration; using System; namespace Order.Api.Controller { [Route(\u0026#34;[Controller]\u0026#34;)] [ApiController] public class OrdersController : ControllerBase { [HttpGet] public IActionResult Index() { string result = $\u0026#34;订单服务：{DateTime.Now:yyyy-MM-dd HH:mm:ss},-{Request.HttpContext.Connection.LocalIpAddress}:{Request.HttpContext.Connection.LocalPort}\u0026#34;; return Ok(result); } } }容器化部署# 代码就写这么简单，下面使用Docker来部署订单服务。这里先了解一下如果启用了Docker支持，VS默认生成的 Dockerfile 文件如下：\n#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging. FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base WORKDIR /app EXPOSE 80 FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build WORKDIR /src COPY [\u0026#34;Order.Api/Order.Api.csproj\u0026#34;, \u0026#34;Order.Api/\u0026#34;] RUN dotnet restore \u0026#34;Order.Api/Order.Api.csproj\u0026#34; COPY . . WORKDIR \u0026#34;/src/Order.Api\u0026#34; RUN dotnet build \u0026#34;Order.Api.csproj\u0026#34; -c Release -o /app/build FROM build AS publish RUN dotnet publish \u0026#34;Order.Api.csproj\u0026#34; -c Release -o /app/publish FROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;Order.Api.dll\u0026#34;]关于Dockerfile 各个命令的作用这里不再解释，可以参考 【Dockerfile】。这里的 Dockerfile 文件不能直接使用，因为我采用的方式是：将发布后的应用部署到 Centos =\u0026gt; docker build镜像=\u0026gt;运行容器。跳过了这里的 dotnet restore 和 dotnet publish。修改后的 Dockerfile如下：\n# See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging. # 指定基础镜像 FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base # 设置工作目录,如不存在会被创建 WORKDIR /app # Copy release文件夹内容到工作目录app COPY . /app # 运行.dll ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;Order.Api.dll\u0026#34;]将发布后的包扔到虚机指定目录中：\n# 进入目录 [root@centos-01 ~]# cd /usr/dotnetcore_src/order.api.release/ # 查看本地镜像列表 [root@centos-01 order.api.release]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 16ff5dcb1c6d 2 hours ago 206MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 6d3756023f75 25 hours ago 210MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 3f41b63e8f79 25 hours ago 210MB mcr.microsoft.com/dotnet/sdk 5.0 da19c23a5531 2 days ago 631MB mcr.microsoft.com/dotnet/aspnet 5.0 a2be3e478ffa 2 days ago 205MB consul latest b74a0a01afc4 2 weeks ago 116MB rabbitmq management 0bfe221339ae 7 weeks ago 253MB mongo latest aad77ae58e0c 7 weeks ago 682MB redis latest 08502081bff6 2 months ago 105MB portainer/portainer latest 580c0e4e98b0 6 months ago 79.1MB elasticsearch 7.1.1 b0e9f9f047e6 2 years ago 894MB # build镜像 [root@centos-01 order.api.release]# docker build -t order.api . Sending build context to Docker daemon 1.184MB Step 1/4 : FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base ---\u0026gt; a2be3e478ffa Step 2/4 : WORKDIR /app ---\u0026gt; Using cache ---\u0026gt; 9f551bd1698a Step 3/4 : COPY . /app ---\u0026gt; 04334af56137 Step 4/4 : ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;Order.Api.dll\u0026#34;] ---\u0026gt; Running in 44daedf04664 Removing intermediate container 44daedf04664 ---\u0026gt; 58968d65acff Successfully built 58968d65acff Successfully tagged order.api:latest # 查看最新本地镜像列表发现 order.api 镜像 [root@centos-01 order.api.release]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE order.api latest 58968d65acff About a minute ago 206MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 16ff5dcb1c6d 2 hours ago 206MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 6d3756023f75 25 hours ago 210MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 3f41b63e8f79 25 hours ago 210MB mcr.microsoft.com/dotnet/sdk 5.0 da19c23a5531 2 days ago 631MB mcr.microsoft.com/dotnet/aspnet 5.0 a2be3e478ffa 2 days ago 205MB consul latest b74a0a01afc4 2 weeks ago 116MB rabbitmq management 0bfe221339ae 7 weeks ago 253MB mongo latest aad77ae58e0c 7 weeks ago 682MB redis latest 08502081bff6 2 months ago 105MB portainer/portainer latest 580c0e4e98b0 6 months ago 79.1MB elasticsearch 7.1.1 b0e9f9f047e6 2 years ago 894MB [root@centos-01 order.api.release]# 有了镜像之后就可以基于镜像创建容器:\n[root@centos-01 order.api.release]# docker run -d --name order.api -p 80:80 order.api eaa1d05afe39ccdc6a07347df78c994f57c654267db1e40b64d21e030b565903容器启动成功后，在宿主机上输入IP地址加端口测试访问：\n至此订单服务就部署完毕。下面使用 Web.Client 客户端测试，这里的客户端是泛指，实际可能是各种业务系统、手机端、小程序等等。\n客户端调用# 这里使用 RestSharp作为Http请求客户端，Nuget 搜索 【RestSharp】 安装即可。\n核心代码如下：\nIServiceHelper.cs：\npublic interface IServiceHelper { Task\u0026lt;string\u0026gt; GetOrder(); }ServiceHelper.cs：\npublic class ServiceHelper : IServiceHelper { public async Task\u0026lt;string\u0026gt; GetOrder() { // 订单服务地址 string serviceUrl = \u0026#34;http://192.168.31.191:80\u0026#34;; var Client = new RestClient(serviceUrl); var request = new RestRequest(\u0026#34;/orders\u0026#34;, Method.GET); var response = await Client.ExecuteAsync(request); return response.Content; } }Startup.cs：\npublic void ConfigureServices(IServiceCollection services) { services.AddControllersWithViews(); // 注入IServiceHelper services.AddSingleton\u0026lt;IServiceHelper, ServiceHelper\u0026gt;(); }HomeController.cs：\npublic class HomeController : Controller { private readonly ILogger\u0026lt;HomeController\u0026gt; logger; private readonly IServiceHelper serviceHelper; public HomeController(ILogger\u0026lt;HomeController\u0026gt; logger, IServiceHelper serviceHelper) { this.logger = logger; this.serviceHelper = serviceHelper; } public async Task\u0026lt;IActionResult\u0026gt; IndexAsync() { ViewBag.OrderData = await serviceHelper.GetOrder(); return View(); } public IActionResult Privacy() { return View(); } [ResponseCache(Duration = 0, Location = ResponseCacheLocation.None, NoStore = true)] public IActionResult Error() { return View(new ErrorViewModel { RequestId = Activity.Current?.Id ?? HttpContext.TraceIdentifier }); } }Index.cshtml：\n@{ ViewData[\u0026#34;Title\u0026#34;] = \u0026#34;Home Page\u0026#34;; } \u0026lt;div class=\u0026#34;text-center\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;display-4\u0026#34;\u0026gt;Welcome\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; @ViewBag.OrderData \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt;启动项目浏览器访问：\n到这里服务已经独立部署运行，客户端也可以正常调用了。但是思考一个问题：如果这个服务挂掉了怎么办？微服务中非常重要的原则就是\u0026quot;高可用\u0026quot;，以上的做法明显不能满足。要解决这个问题一般都会采用集群方式。\n简单服务集群# 既然单个服务实例有挂掉的风险，那么部署多个服务实例试试，只要不同时挂掉就可以保证正常访问。下面使用Docker运行多个服务实例：\n[root@centos-01 ~]# docker run -d --name order.api -p 80:80 order.api c4a974a607b54377115a32a4227fa0f9d2ca4332405875b3763cca2696932c1c [root@centos-01 ~]# docker run -d --name order.api1 -p 81:80 order.api 992f0b2975f60320ba92c2e79b33ae066c17b3b26f54e74b96ad7677d54042d7 [root@centos-01 ~]# docker run -d --name order.api2 -p 82:80 order.api dca6a0cd36a4bca3111b5694f34c8f8ffbcc81d6dbbadb45a2d3209afa7b0595现在订单服务增加到三个服务实例，分别映射到80/81/82端口。需要修改一下客户端代码：\npublic async Task\u0026lt;string\u0026gt; GetOrder() { // 服务实例集合 string[] serviceUrls = { \u0026#34;http://192.168.31.191:80\u0026#34;, \u0026#34;http://192.168.31.191:81\u0026#34;, \u0026#34;http://192.168.31.191:82\u0026#34; }; // 每次随机访问一个服务实例 var client = new RestClient(serviceUrls[new Random().Next(0, 3)]); var request = new RestRequest(\u0026#34;/orders\u0026#34;, Method.GET); var response = await client.ExecuteAsync(request); return response.Content; } 这里拿到服务地址可以自己做复杂的负载均衡策略，比如轮询，随机，权重等或者使用nginx都可以。这不是重点，所以这里只是简单随机访问一个服务实例\n这里已经做到了将请求随机分配到一个服务实例，但这种做法依旧存在问题：\n如果随机访问到的实例刚好挂掉，依然无法正常访问 如果到某个地址的请求连续多次失败，应该移除这个地址保证其他请求不会再访问到 实际应用中，上层的业务系统可能非常多，为了保证可用性，每个业务系统都需要考虑服务实例运行状态吗？而且实际应用中服务实例的数量或者地址大多数时候是不固定的，比如：流量高峰期，增加服务实例，这时候每个业务系统再去配置文件里配置地址？高峰期过了又去把配置删掉？显然是不现实的。服务必须要做到可灵活伸缩 要做到可灵活伸缩就引入了另一个名词：服务注册与发现。\n"},{"id":71,"href":"/docs/microservice/1.2%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/","title":"1.2微服务入门之服务注册与发现","section":"所有文章","content":"前言# 上一篇说到要做到服务的灵活伸缩需要有一种机制来实现，这个机制就是服务注册与发现。这并不是必须的，如果服务实例很少并且很稳定，就没有必要使用。\n概念# 服务注册：简单理解就是有一个注册中心，每个服务实例启动时都去注册中心注册，告诉注册中心地址，端口等信息。同样删除时，也需要去注册中心删除，注册中心负责维护这些服务实例的信息 服务发现：既然注册中心维护了各个服务实例的信息，那么客户端通过注册中心就很容易能发现服务的变化。有了服务注册与发现，客户端就不用再去配置各个服务实例的地址，改为从注册中心统一获取 健康检查：注册中心要保证每个地址的可用状态，挂掉的实例不应该被客户端获取到，所以需要：健康检查。每个服务都需要提供一个用于健康检查的接口，这个接口不具备任何业务功能。服务注册时把这个接口的地址也告诉注册中心，注册中心会定时调用这个接口来检测服务是否正常，如果不正常，则将它移除，这样来保证了服务的可用性 常见注册中心有 Consul、ZooKeeper、etcd、Eureka。\nConsul# Consul官网：https://www.consul.io，主要功能有服务注册与发现、健康检查、K-V存储、多数据中心等，这里不做详细介绍。\n安装：直接在官网下载解压即可 运行：在 consul.exe 目录下打开命令行执行 consul.exe agent -dev 浏览器访问：http://localhost:8500 这里选择使用Docker来部署Consul：\ndocker pull consul docker run -d -p 8500:8500 --restart=always --name=consul consul:latest agent -server -bootstrap -ui -node=1 -client=\u0026#39;0.0.0.0\u0026#39; agent： 表示启动 Agent 进程 server：表示启动 Consul Server 模式 client：表示启动 Consul Cilent 模式 bootstrap：表示这个节点是 Server-Leader ，每个数据中心只能运行一台服务器。技术角度上来看 Leader 是通过 Raft 算法选举的，但是集群第一次启动时需要一个引导 Leader，在引导群集后，建议不要使用此标志 ui：表示启动 Web UI 管理器，默认开放端口 8500，所以上面使用 Docker 命令把 8500 端口对外开放 node：节点的名称，集群中必须是唯一的，默认是该节点的主机名 client：Consul服务监听地址，这提供HTTP、DNS、RPC等服务，默认是 127.0.0.1 所以不对外提供服务，如果要对外提供服务改成 0.0.0.0 join：表示加入到某一个集群中。 如：-json=192.168.0.11 这里看到Consul已经成功运行。\n服务注册# 订单服务项目使用Nuget 安装 Consul，然后添加相关代码：\nConsulHelper.cs：\npublic static class ConsulHelper { /// \u0026lt;summary\u0026gt; /// 服务注册 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;app\u0026#34;\u0026gt;The application.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;configuration\u0026#34;\u0026gt;The configuration.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;lifetime\u0026#34;\u0026gt;The lifetime.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public static IApplicationBuilder RegisterConsul(this IApplicationBuilder app , IConfiguration configuration , IHostApplicationLifetime lifetime) { var consulClient = new ConsulClient(c =\u0026gt; { c.Address = new Uri(configuration[\u0026#34;ConsulSetting:ConsulAddress\u0026#34;]); }); var registration = new AgentServiceRegistration() { // 服务实例唯一标识 ID = Guid.NewGuid().ToString(), // 服务名称 Name = configuration[\u0026#34;ConsulSetting:ServiceName\u0026#34;], // 服务IP地址 Address = configuration[\u0026#34;ConsulSetting:ServiceIP\u0026#34;], // 服务端口：因为要运行多个实例，端口不能在appsettings.json里配置而是在docker容器运行时传入 Port = int.Parse(configuration[\u0026#34;ConsulSetting:ServicePort\u0026#34;]), Check = new AgentServiceCheck() { // 服务启动多久后注册 DeregisterCriticalServiceAfter = TimeSpan.FromSeconds(3), // 健康检查时间间隔 Interval = TimeSpan.FromSeconds(10), // 健康检查地址 HTTP = $\u0026#34;http://{configuration[\u0026#34;ConsulSetting:ServiceIP\u0026#34;]}:{configuration[\u0026#34;ConsulSetting:ServicePort\u0026#34;]}{configuration[\u0026#34;ConsulSetting:ServiceHealthCheck\u0026#34;]}\u0026#34;, // 超时时间 Timeout = TimeSpan.FromSeconds(5) } }; // 服务注册 consulClient.Agent.ServiceRegister(registration).Wait(); // 应用程序终止时，取消注册 lifetime.ApplicationStopping.Register(() =\u0026gt; { consulClient.Agent.ServiceDeregister(registration.ID).Wait(); }); return app; } }appsettings.json：\n{ \u0026#34;Logging\u0026#34;: { \u0026#34;LogLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Information\u0026#34;, \u0026#34;Microsoft\u0026#34;: \u0026#34;Warning\u0026#34;, \u0026#34;Microsoft.Hosting.Lifetime\u0026#34;: \u0026#34;Information\u0026#34; } }, \u0026#34;AllowedHosts\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;ConsulSetting\u0026#34;: { \u0026#34;ServiceName\u0026#34;: \u0026#34;order.service\u0026#34;, \u0026#34;ServiceIP\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;ServiceHealthCheck\u0026#34;: \u0026#34;/healthcheck\u0026#34;, \u0026#34;ConsulAddress\u0026#34;: \u0026#34;http://192.168.31.191:8500\u0026#34; } } 注意：这里没有配置ServicePort，所以如果本地直接运行项目会报错\nStartup.cs：\npublic void Configure(IApplicationBuilder app, IWebHostEnvironment env, IHostApplicationLifetime lifetime) { if (env.IsDevelopment()) { } else { } app.UseStaticFiles(); app.UseRouting(); app.UseEndpoints(endpoints =\u0026gt; { endpoints.MapControllers(); }); // 启用服务注册 app.RegisterConsul(Configuration, lifetime); }OrdersController.cs：\n[Route(\u0026#34;[Controller]\u0026#34;)] [ApiController] public class OrdersController : ControllerBase { private readonly IConfiguration configuration; public OrdersController(IConfiguration configuration) { this.configuration = configuration; } [HttpGet] public IActionResult Index() { string result = $\u0026#34;订单服务：{DateTime.Now:yyyy-MM-dd HH:mm:ss},-{Request.HttpContext.Connection.LocalIpAddress}:{configuration[\u0026#34;ConsulSetting:ServicePort\u0026#34;]}\u0026#34;; return Ok(result); } }HealthCheckController.cs：\n[Route(\u0026#34;[controller]\u0026#34;)] [ApiController] public class HealthCheckController : ControllerBase { /// \u0026lt;summary\u0026gt; /// 健康检查接口 /// \u0026lt;/summary\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; [HttpGet] public IActionResult Get() { return Ok(\u0026#34;Pong.\u0026#34;); } }至此就完成了服务注册、取消注册、健康检查的代码编写，下面重新 build 镜像（过程略过）运行新的容器：\n[root@centos-01 order.api.release]# docker run -d --name order.api -p 80:80 order.api --ConsulSetting:ServicePort=\u0026#34;80\u0026#34; 89acc7d7035f2041a91bc1e1299464a5460290dd66b12161ee4e994d5548def2 [root@centos-01 order.api.release]# docker run -d --name order.api1 -p 81:80 order.api --ConsulSetting:ServicePort=\u0026#34;81\u0026#34; 223be73a41e501e168fdc44459cd6f5851d565e60817dbd0047dff7718394e22 [root@centos-01 order.api.release]# docker run -d --name order.api2 -p 82:80 order.api --ConsulSetting:ServicePort=\u0026#34;82\u0026#34; 至此，3个服务实例都已运行，并且成功注册到 Consul。测试一下服务停止会不会从Consul移除：\n[root@centos-01 order.api.release]# docker stop order.api\n这里需要注意：程序发生异常，健康检查不能正确响应的话，Consul也会移除。至此注册、发现、健康检查功能都完成了，下一步考虑客户端如何拿到这些服务实例的地址。\n客户端# 上面已经成功将服务注册到 Consul中，接下来就该客户端通过 Consul 去做服务发现了。客户端项目同样使用Nuget 安装 Consul，然后调整相关代码：\nServiceHelper.cs：\nusing Consul; using Microsoft.Extensions.Configuration; using RestSharp; using System; using System.Collections.Concurrent; using System.Linq; using System.Threading.Tasks; namespace Web.Client { public interface IServiceHelper { Task\u0026lt;string\u0026gt; GetOrder(); } public class ServiceHelper : IServiceHelper { private readonly IConfiguration configuration; public ServiceHelper(IConfiguration configuration) { this.configuration = configuration; } public async Task\u0026lt;string\u0026gt; GetOrder() { var consulClient = new ConsulClient(c =\u0026gt; { c.Address = new Uri(configuration[\u0026#34;ConsulSetting:ConsulAddress\u0026#34;]); }); // 获取健康的服务 var services = consulClient.Health.Service(\u0026#34;order.service\u0026#34;, null, true, null).Result.Response; // 获取订单服务地址列表 string[] serviceUrls = services.Select(p =\u0026gt; $\u0026#34;http://{p.Service.Address + \u0026#34;:\u0026#34; + p.Service.Port}\u0026#34;).ToArray(); if (!serviceUrls.Any()) { return await Task.FromResult(\u0026#34;【订单服务】服务列表为空\u0026#34;); } // 每次随机访问一个服务实例 var client = new RestClient(serviceUrls[new Random().Next(0, serviceUrls.Length)]); var request = new RestRequest(\u0026#34;/orders\u0026#34;, Method.GET); var response = await client.ExecuteAsync(request); return response.Content; } } }appsettings.json：\n{ \u0026#34;Logging\u0026#34;: { \u0026#34;LogLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Information\u0026#34;, \u0026#34;Microsoft\u0026#34;: \u0026#34;Warning\u0026#34;, \u0026#34;Microsoft.Hosting.Lifetime\u0026#34;: \u0026#34;Information\u0026#34; } }, \u0026#34;AllowedHosts\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;ConsulSetting\u0026#34;: { \u0026#34;ConsulAddress\u0026#34;: \u0026#34;http://192.168.31.191:8500\u0026#34; } }以上代码就完成了对服务列表的获取，浏览器访问测试一下：\n这时候如果停止其中一个服务实例，Consul中也会同步下线，客户端也就访问不到了，但是只要三个实例活着一个就可以正常访问。虽然这里解决了服务发现的问题，但是新的问题又来了：客户端每次调用服务都需要先去Consul中获取服务地址，不仅浪费资源还增加了请求的响应时间。如何保证不要每次请求都需要去Consul 获取地址的同时又可以拿到可用的地址列表呢？Consul 提供的解决方案是：Blocking Queries （阻塞的请求）。详情见官网：Blocking Queries 。\nBlocking Queries# 简单来说就是当客户端请求 Consul 获取地址列表时，需要携带一个版本号信息，Consul 会比较这个客户端版本号是否和 Consul 服务端的版本号一致，如果一致，则 Consul 会阻塞这个请求，直到 Consul 中的服务列表发生变化，或者到达阻塞时间上限；如果版本号不一致，则立即返回。这个阻塞时间默认是5分钟，支持自定义。如果启动一个线程专门去做这件事，就不会影响每次的用户请求了。这样既保证了客户端服务列表的准确性，又节约了客户端请求服务列表的次数。\n调整代码：\nIServiceHelper.cs 增加获取服务列表的接口方法：\nusing Consul; using Microsoft.Extensions.Configuration; using RestSharp; using System; using System.Collections.Concurrent; using System.Linq; using System.Threading.Tasks; namespace Web.Client { public interface IServiceHelper { Task\u0026lt;string\u0026gt; GetOrder(); void GetServices(); } public class ServiceHelper : IServiceHelper { private readonly IConfiguration configuration; private readonly ConsulClient consulClient; private ConcurrentBag\u0026lt;string\u0026gt; orderServiceUrls; public ServiceHelper(IConfiguration configuration) { this.configuration = configuration; this.consulClient = new ConsulClient(c =\u0026gt; { c.Address = new Uri(configuration[\u0026#34;ConsulSetting:ConsulAddress\u0026#34;]); }); } public async Task\u0026lt;string\u0026gt; GetOrder() { if (orderServiceUrls == null) return await Task.FromResult(\u0026#34;【订单服务】初始化服务列表...\u0026#34;); var client = new RestClient(orderServiceUrls.ElementAt(new Random().Next(0, orderServiceUrls.Count()))); var request = new RestRequest(\u0026#34;/orders\u0026#34;, Method.GET); var response = await client.ExecuteAsync(request); return response.Content; } public void GetServices() { var serviceNames = new string[] { \u0026#34;order.service\u0026#34; }; Array.ForEach(serviceNames, p =\u0026gt; { Task.Run(() =\u0026gt; { // WaitTime默认为5分钟 var queryOptions = new QueryOptions { WaitTime = TimeSpan.FromMinutes(10) }; while (true) { GetServices(queryOptions, p); } }); }); } private void GetServices(QueryOptions queryOptions, string serviceName) { var res = consulClient.Health.Service(serviceName, null, true, queryOptions).Result; // 打印服务列表的响应时间等信息 Console.WriteLine($\u0026#34;{DateTime.Now}获取{serviceName}：queryOptions.WaitIndex：{queryOptions.WaitIndex} LastIndex：{res.LastIndex}\u0026#34;); // 版本号不一致 说明服务列表发生变化 if (queryOptions.WaitIndex != res.LastIndex) { queryOptions.WaitIndex = res.LastIndex; //服务地址列表 var serviceUrls = res.Response.Select(p =\u0026gt; $\u0026#34;http://{p.Service.Address + \u0026#34;:\u0026#34; + p.Service.Port}\u0026#34;).ToArray(); if (serviceName == \u0026#34;order.service\u0026#34;) orderServiceUrls = new ConcurrentBag\u0026lt;string\u0026gt;(serviceUrls); } } } }\n至此不需要每次都先请求服务列表，如果服务列表没有更新的话，获取列表的请求会一直阻塞直到设置的10分钟。这时候又发现新的问题：\n每个客户端系统都去维护服务地址是否合理 服务的IP端口直接暴露给所有客户端是否安全 该模式下怎么做到客户端的统一管理 "},{"id":72,"href":"/docs/microservice/1.3%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E7%BD%91%E5%85%B3/","title":"1.3微服务入门之网关","section":"所有文章","content":"前言# 上一篇使用 Consul 完成了服务的注册与发现，实际中光有服务注册与发现往往是不够的，需要一个统一的入口来连接客户端与服务。\nOcelot# 官网：https://ocelot.readthedocs.io ，Ocelot 正是为.Net微服务体系提供一个统一的入口点，称为：Gateway（网关）。\n首先创建一个空的 asp.net core web 项目：\n注意：ocelot.json 是Ocelot的配置文件，设置生成时需要复制到输出目录。ocelot.json 文件名不是固定的可以自己定义\n使用 NuGet 安装 Ocelot，简单修改几处默认代码：\nProgram.cs：\npublic class Program { public static void Main(string[] args) { CreateHostBuilder(args).Build().Run(); } public static IHostBuilder CreateHostBuilder(string[] args) =\u0026gt; Host.CreateDefaultBuilder(args) .ConfigureAppConfiguration((hostingContext, config) =\u0026gt; { config.AddJsonFile(\u0026#34;ocelot.json\u0026#34;, optional: false, reloadOnChange: true); }) .ConfigureWebHostDefaults(webBuilder =\u0026gt; { webBuilder.UseStartup\u0026lt;Startup\u0026gt;(); }); }Startup.cs：\npublic void ConfigureServices(IServiceCollection services) { // 添加ocelot服务 services.AddOcelot(); } // This method gets called by the runtime. Use this method to configure the HTTP request pipeline. public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { // 启用Ocelot中间件 app.UseOcelot().Wait(); }ocelot.json：\n{ \u0026#34;Routes\u0026#34;: [ { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;DownstreamHostAndPorts\u0026#34;: [ { \u0026#34;Host\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;Port\u0026#34;: 80 }, { \u0026#34;Host\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;Port\u0026#34;: 81 }, { \u0026#34;Host\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;Port\u0026#34;: 82 } ], \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;Get\u0026#34; ], \u0026#34;LoadBalancerOptions\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;RoundRobin\u0026#34; //负载均衡，轮询机制 LeastConnection/RoundRobin/NoLoadBalancer/CookieStickySessions } } ], \u0026#34;GlobalConfiguration\u0026#34;: { \u0026#34;BaseUrl\u0026#34;: \u0026#34;http://localhost:5000\u0026#34; } }这里将服务实例的地址写在配置文件中。\nRoutes 节点用来配置路由：\nDownstream 代表下游，也就是服务实例 Upstream 代表上游，也就是客户端。这里路径比较简单，只有 /orders 路径中如果有不固定参数则使用 {} 匹配。 这里配置的意思是：客户端访问网关的 /orders，网关会转发给服务实例的 /orders 。注意：上游的路径不一定要和下游一致，比如上游路径可以配置成 /api/orders。\nLoadBalancerOptions 节点用来配置负载均衡，Ocelot 内置了 LeastConnection 、RoundRobin 、NoLoadBalancer 、CookieStickySessions 4种负载均衡策略：\nLeastConnection 最少连接，跟踪哪些服务正在处理请求，并把新请求发送到现有请求最少的服务上。该算法状态不在整个Ocelot集群中分布 RoundRobin 轮询可用的服务并发送请求。 该算法状态不在整个Ocelot集群中分布 NoLoadBalancer 不负载均衡，从配置或服务发现提供程序中取第一个可用的下游服务 CookieStickySessions 使用cookie关联所有相关的请求到制定的服务 BaseUrl 节点用来配置 Ocelot 网关将要运行的地址。\n浏览器访问：\n客户端# 上面实现通过 Ocelot 网关访问服务实例，调整客户端代码：这里选择直接新建 GatewayServiceHelper：\nusing RestSharp; using System; using System.Threading.Tasks; namespace Web.Client { /// \u0026lt;summary\u0026gt; /// 通过OcelotGateway调用服务 /// \u0026lt;/summary\u0026gt; public class GatewayServiceHelper : IServiceHelper { public async Task\u0026lt;string\u0026gt; GetOrder() { var client = new RestClient(\u0026#34;http://localhost:5000\u0026#34;); var request = new RestRequest(\u0026#34;/orders\u0026#34;, Method.GET); var response = await client.ExecuteAsync(request); return response.Content; } public void GetServices() { throw new NotImplementedException(); } } }Startup.cs：修改注入类型\nservices.AddSingleton\u0026lt;IServiceHelper, GatewayServiceHelper\u0026gt;();下面获取服务地址的代码也不需要了\n// 程序启动时获取服务列表 serviceHelper.GetServices();经过以上调整现在客户端对服务的调用都通过网关进行中转，客户端不再关心服务实例的地址，只需要知道网关地址就可以。另外服务端也避免了服务地址直接暴露给客户端。这样做对客户端，服务都非常友好。但是又出现了一个新的问题：目前服务地址写在 ocelot.json 配置文件中，一旦服务变化，需要人为的修改配置文件，这又显得不太合理。这里比较常用的方案是：结合Consul来实现服务发现。\n服务发现# NuGet 安装Ocelot.Provider.Consul后，修改Startup.cs：\npublic void ConfigureServices(IServiceCollection services) { // 添加Ocelot服务并添加Consul支持 services.AddOcelot().AddConsul(); }修改ocelot.json配置：\n{ \u0026#34;Routes\u0026#34;: [ { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;Get\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;order.service\u0026#34;, \u0026#34;LoadBalancerOptions\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;RoundRobin\u0026#34; } } ], \u0026#34;GlobalConfiguration\u0026#34;: { \u0026#34;BaseUrl\u0026#34;: \u0026#34;http://localhost:5000\u0026#34;, \u0026#34;ServiceDiscoveryProvider\u0026#34;: { \u0026#34;Scheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;Port\u0026#34;: 8500, \u0026#34;Type\u0026#34;: \u0026#34;Consul\u0026#34; } } }这个配置很好理解，就是把 DownstreamHostAndPorts 节点去掉然后增加了 ServiceDiscoveryProvider 服务发现相关配置。\n注意，Ocelot 除了支持 Consul 服务发现以外，还有 Eureka 也可以，Eureka 也是一个类似的注册中心\n浏览器测试：\n至此就实现了服务注册与发现和api网关的基本功能。接下来就要提到：服务治理。\n服务治理# 服务治理没有非常明确的定义。它的作用简单来说，就是帮我们更好的管理服务，提升服务的可用性。缓存、限流、熔断、链路追踪等等都属于常用的服务治理手段。之前讲的负载均衡，服务发现也可以算是服务治理。\n缓存# 在 Ocelot 中启用缓存，需要NuGet 安装Ocelot.Cache.CacheManager，修改Startup.cs 中的 ConfigureServices() 方法：\npublic void ConfigureServices(IServiceCollection services) { services.AddOcelot() .AddConsul() .AddCacheManager(p =\u0026gt; { p.WithDictionaryHandle(); }); }修改 ocelot.json 配置文件：\n{ \u0026#34;Routes\u0026#34;: [ { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;Get\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;order.service\u0026#34;, \u0026#34;LoadBalancerOptions\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;RoundRobin\u0026#34; }, // 缓存 \u0026#34;FileCacheOptions\u0026#34;: { \u0026#34;TtlSeconds\u0026#34;: 5, \u0026#34;Region\u0026#34;: \u0026#34;regionname\u0026#34; } } ], \u0026#34;GlobalConfiguration\u0026#34;: { \u0026#34;BaseUrl\u0026#34;: \u0026#34;http://localhost:5000\u0026#34;, \u0026#34;ServiceDiscoveryProvider\u0026#34;: { \u0026#34;Scheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;Port\u0026#34;: 8500, \u0026#34;Type\u0026#34;: \u0026#34;Consul\u0026#34; } } }在 Routes 路由配置中增加 FileCacheOptions：\nTtlSeconds 缓存的过期时间 Region 缓冲区名称，目前用不到 代码修改完编译重启一下网关项目，然后打开浏览器测试会发现5秒之内的请求都是同样的缓存数据。Ocelot也支持自定义缓存。\n限流# 限流就是限制客户端一定时间内的请求次数。\n修改 ocelot.json 配置文件：\n{ \u0026#34;Routes\u0026#34;: [ { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;Get\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;order.service\u0026#34;, \u0026#34;LoadBalancerOptions\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;RoundRobin\u0026#34; }, // 缓存 \u0026#34;FileCacheOptions\u0026#34;: { \u0026#34;TtlSeconds\u0026#34;: 5, \u0026#34;Region\u0026#34;: \u0026#34;regionname\u0026#34; }, // 限流 \u0026#34;RateLimitOptions\u0026#34;: { \u0026#34;ClientWhitelist\u0026#34;: [ \u0026#34;SuperClient\u0026#34; ], \u0026#34;EnableRateLimiting\u0026#34;: true, \u0026#34;Period\u0026#34;: \u0026#34;2s\u0026#34;, \u0026#34;PeriodTimespan\u0026#34;: 2, \u0026#34;Limit\u0026#34;: 1 } } ], \u0026#34;GlobalConfiguration\u0026#34;: { \u0026#34;BaseUrl\u0026#34;: \u0026#34;http://localhost:5000\u0026#34;, \u0026#34;ServiceDiscoveryProvider\u0026#34;: { \u0026#34;Scheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;Port\u0026#34;: 8500, \u0026#34;Type\u0026#34;: \u0026#34;Consul\u0026#34; }, \u0026#34;RateLimitOptions\u0026#34;: { \u0026#34;DisableRateLimitHeaders\u0026#34;: false, \u0026#34;QuotaExceededMessage\u0026#34;: \u0026#34;too many requests...\u0026#34;, \u0026#34;HttpStatusCode\u0026#34;: 999, \u0026#34;ClientIdHeader\u0026#34;: \u0026#34;Test\u0026#34; } } }在 Routes 路由配置中增加 RateLimitOptions ：\nClientWhitelist 客户端白名单（白名单中的客户端不受限流影响） EnableRateLimiting 是否限流 Period 限流的单位时间，例如1s、5m、1h、1d等 PeriodTimespan 客户端达到请求上限多少秒后可以重试 Limit 客户端在定义的时间内可以发出的最大请求数 在 GlobalConfiguration 配置中也增加 RateLimitOptions：\nDisableRateLimitHeaders 是否禁用 X-Rate-Limit 和 Retry-After 标头（请求达到上限时response header中的限制数和多少秒后能重试） QuotaExceededMessage ：请求达到上限时返回给客户端的消息 HttpStatusCode ：请求达到上限时返回给客户端的 HTTP状态码 ClientIdHeader 可以允许自定义用于标识客户端的标头。默认情况下为 ClientId 代码修改完编译重启一下网关项目，然后打开浏览器测试会发现限制已经生效。\n超时/熔断# 超时：网关请求服务时可容忍的最长响应时间 熔断：当请求某个服务的异常次数达到一定量时，网关在一定时间内就不再对这个服务发起请求直接熔断 在 Ocelot 中启用超时/熔断，需要 NuGet 安装Ocelot.Provider.Polly，修改Startup.cs 中的 ConfigureServices() 方法：\npublic void ConfigureServices(IServiceCollection services) { services.AddOcelot() .AddConsul() .AddCacheManager(p =\u0026gt; { p.WithDictionaryHandle(); }).AddPolly(); }修改 ocelot.json 配置文件：\n{ \u0026#34;Routes\u0026#34;: [ { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/orders\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;Get\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;order.service\u0026#34;, \u0026#34;LoadBalancerOptions\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;RoundRobin\u0026#34; }, // 缓存 \u0026#34;FileCacheOptions\u0026#34;: { \u0026#34;TtlSeconds\u0026#34;: 5, \u0026#34;Region\u0026#34;: \u0026#34;regionname\u0026#34; }, // 限流 \u0026#34;RateLimitOptions\u0026#34;: { \u0026#34;ClientWhitelist\u0026#34;: [ \u0026#34;SuperClient\u0026#34; ], \u0026#34;EnableRateLimiting\u0026#34;: true, \u0026#34;Period\u0026#34;: \u0026#34;2s\u0026#34;, \u0026#34;PeriodTimespan\u0026#34;: 2, \u0026#34;Limit\u0026#34;: 1 }, // 超时熔断 \u0026#34;QoSOptions\u0026#34;: { \u0026#34;ExceptionsAllowedBeforeBreaking\u0026#34;: 3, \u0026#34;DurationOfBreak\u0026#34;: 10000, \u0026#34;TimeoutValue\u0026#34;: 5000 } } ], \u0026#34;GlobalConfiguration\u0026#34;: { \u0026#34;BaseUrl\u0026#34;: \u0026#34;http://localhost:5000\u0026#34;, \u0026#34;ServiceDiscoveryProvider\u0026#34;: { \u0026#34;Scheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;192.168.201.191\u0026#34;, \u0026#34;Port\u0026#34;: 8500, \u0026#34;Type\u0026#34;: \u0026#34;Consul\u0026#34; }, \u0026#34;RateLimitOptions\u0026#34;: { \u0026#34;DisableRateLimitHeaders\u0026#34;: false, \u0026#34;QuotaExceededMessage\u0026#34;: \u0026#34;too many requests...\u0026#34;, \u0026#34;HttpStatusCode\u0026#34;: 999, \u0026#34;ClientIdHeader\u0026#34;: \u0026#34;Test\u0026#34; } } } ExceptionsAllowedBeforeBreaking 发生错误的次数 DurationOfBreak 熔断时间 TimeoutValue 超时时间 以上配置意思是当请求服务发生3次错误时，就熔断10秒，期间客户端的请求直接返回错误，10秒后恢复。\n"},{"id":73,"href":"/docs/microservice/1.4%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E4%BA%8B%E4%BB%B6%E6%80%BB%E7%BA%BF/","title":"1.4微服务入门之事件总线","section":"所有文章","content":"前言# 上一篇中已经完成了 Ocelot + Consul 的搭建，这篇简单说一下事件总线（EventBus)。\n事件总线# 什么是事件总线？\n事件总线是对观察者（发布-订阅）模式的一种实现。它是一种集中式事件处理机制，允许不同的组件之间进行彼此通信而又不需要相互依赖，达到解耦的目的\n为什么要使用事件总线？\n以当前项目举例，假设有一个订单服务，一个产品服务。客户端有一个下单功能，下单时调用订单服务的下单接口，下单接口需要调用产品服务的减库存接口，这涉及到服务与服务之间的调用。服务之间调用可以选择 RestAPI 或者效率更高的 gRPC。可能这两者各有各的使用场景，但是它们都存在服务之间的耦合问题，或者难以做到异步调用 假设下单调用订单服务，订单服务需要调用产品服务，产品服务又要调用物流服务，物流服务再去调用xx服务等等，如果每个服务处理时间需要2s，不使用异步处理的话，响应时间可想而知。如果使用EventBus的话，那么订单服务只需要向EventBus发一个“下单事件”就可以了。产品服务会订阅“下单事件”，当产品服务收到下单事件时，自己去减库存。这样就避免了两个服务之间直接调用的耦合性，并且真正做到了异步调用 既然涉及到多个服务之间的异步调用，那么就不得不提分布式事务。分布式事务并不是微服务独有的问题，而是所有的分布式系统都会存在的问题。关于分布式事务，可以查一下 “CAP原则” 和 “BASE理论” 了解更多。如今分布式系统更多时候会追求事务的最终一致性。\n下面使用开源框架 CAP来演示 EventBus 的基本使用。之所以使用 CAP 是因为它既能解决分布式系统的最终一致性，同时又是一个 EventBus，它具备EventBus 的所有功能。点击了解更多。\nCAP# 目前 CAP 支持使用 RabbitMQ ，Kafka，Azure Service Bus 等进行底层之间的消息发送，不需要具备这些消息队列的使用经验就可以轻松的集成到项目中。CAP 目前支持使用 Sql Server，MySql，PostgreSql，MongoDB 数据库的项目。这里选择：消息组件使用 RabbitMq，数据库存储使用 SqlServer。\nNuget 安装 :\nMicrosoft.EntityFrameworkCore Microsoft.EntityFrameworkCore.Tools Microsoft.EntityFrameworkCore.SqlServer DotNetCore.CAP DotNetCore.CAP.RabbitMQ DotNetCore.CAP.SqlServerProduct.Api# 新增 Product.Api 作为产品服务，代码结构与 Order.Api 结构类似：\nProductsController.cs# 增加减库存接口：\nusing DotNetCore.CAP; using Microsoft.AspNetCore.Mvc; using Microsoft.EntityFrameworkCore; using Microsoft.Extensions.Configuration; using Newtonsoft.Json; using Product.Api.Models; using System; using System.Threading.Tasks; namespace Product.Api.Controller { [Route(\u0026#34;[Controller]\u0026#34;)] [ApiController] public class ProductsController : ControllerBase { private readonly IConfiguration configuration; private readonly ICapPublisher capBus; private readonly ProductContext context; public ProductsController(IConfiguration configuration, ICapPublisher capBus, ProductContext context) { this.configuration = configuration; this.capBus = capBus; this.context = context; } [HttpGet] public IActionResult Index() { string result = $\u0026#34;产品服务：{DateTime.Now:yyyy-MM-dd HH:mm:ss},-{Request.HttpContext.Connection.LocalIpAddress}:{configuration[\u0026#34;ConsulSetting:ServicePort\u0026#34;]}\u0026#34;; return Ok(result); } /// \u0026lt;summary\u0026gt; /// 减库存 订阅下单事件 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;message\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; [NonAction] [CapSubscribe(\u0026#34;order.services.createorder\u0026#34;)] public async Task ReduceStock(CreateOrderMessageDto message) { Console.WriteLine(\u0026#34;message:\u0026#34; + JsonConvert.SerializeObject(message)); var product = await context.Products.FirstOrDefaultAsync(p =\u0026gt; p.ID == message.ProductID); product.Stock -= message.Count; await context.SaveChangesAsync(); } } }CreateOrderMessageDto.cs# namespace Product.Api.Models { /// \u0026lt;summary\u0026gt; /// 下单事件消息 /// \u0026lt;/summary\u0026gt; public class CreateOrderMessageDto { /// \u0026lt;summary\u0026gt; /// 产品ID /// \u0026lt;/summary\u0026gt; public int ProductID { get; set; } /// \u0026lt;summary\u0026gt; /// 购买数量 /// \u0026lt;/summary\u0026gt; public int Count { get; set; } } }Product.cs# using System.ComponentModel.DataAnnotations; using System.ComponentModel.DataAnnotations.Schema; namespace Product.Api.Models { public class Product { [Key] public int ID { get; set; } /// \u0026lt;summary\u0026gt; /// 产品名称 /// \u0026lt;/summary\u0026gt; [Required] [Column(TypeName = \u0026#34;VARCHAR(16)\u0026#34;)] public string Name { get; set; } /// \u0026lt;summary\u0026gt; /// 库存 /// \u0026lt;/summary\u0026gt; [Required] public int Stock { get; set; } } }ProductContext.cs# using Microsoft.EntityFrameworkCore; namespace Product.Api { public class ProductContext : DbContext { public ProductContext(DbContextOptions\u0026lt;ProductContext\u0026gt; options) : base(options) { } public DbSet\u0026lt;Models.Product\u0026gt; Products { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { //初始化种子数据 modelBuilder.Entity\u0026lt;Models.Product\u0026gt;().HasData(new Models.Product { ID = 1, Name = \u0026#34;ThinkPad\u0026#34;, Stock = 100 }, new Models.Product { ID = 2, Name = \u0026#34;Mac\u0026#34;, Stock = 100 }); } } }appsettings.json# { \u0026#34;Logging\u0026#34;: { \u0026#34;LogLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Information\u0026#34;, \u0026#34;Microsoft\u0026#34;: \u0026#34;Warning\u0026#34;, \u0026#34;Microsoft.Hosting.Lifetime\u0026#34;: \u0026#34;Information\u0026#34; } }, \u0026#34;AllowedHosts\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;ConsulSetting\u0026#34;: { \u0026#34;ServiceName\u0026#34;: \u0026#34;product.service\u0026#34;, \u0026#34;ServiceIP\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;ServiceHealthCheck\u0026#34;: \u0026#34;/healthcheck\u0026#34;, \u0026#34;ConsulAddress\u0026#34;: \u0026#34;http://192.168.31.191:8500\u0026#34; }, \u0026#34;ConnectionString\u0026#34;: \u0026#34;Server=192.168.31.210;Database=Microservice.Sample.Product;user id=sa;password=wpl19950815;MultipleActiveResultSets=true\u0026#34; }Startup.cs# public void ConfigureServices(IServiceCollection services) { services.AddControllers(); services.AddDbContext\u0026lt;ProductContext\u0026gt;(opt =\u0026gt; opt.UseSqlServer(Configuration[\u0026#34;ConnectionString\u0026#34;])); services.AddCap(x =\u0026gt; { x.UseEntityFramework\u0026lt;ProductContext\u0026gt;().UseRabbitMQ(option =\u0026gt; { option.HostName = \u0026#34;192.168.31.191\u0026#34;; option.UserName = \u0026#34;guest\u0026#34;; option.Password = \u0026#34;guest\u0026#34;; }); }); }Order.Api# OrdersController.cs# 增加下单接口：\nusing DotNetCore.CAP; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Configuration; using Order.Api.Models; using System; using System.Threading.Tasks; namespace Order.Api.Controller { [Route(\u0026#34;[Controller]\u0026#34;)] [ApiController] public class OrdersController : ControllerBase { private readonly IConfiguration configuration; private readonly ICapPublisher capBus; private readonly OrderContext context; public OrdersController(IConfiguration configuration, ICapPublisher capBus, OrderContext context) { this.configuration = configuration; this.capBus = capBus; this.context = context; } [HttpGet] public IActionResult Index() { string result = $\u0026#34;订单服务：{DateTime.Now:yyyy-MM-dd HH:mm:ss},-{Request.HttpContext.Connection.LocalIpAddress}:{configuration[\u0026#34;ConsulSetting:ServicePort\u0026#34;]}\u0026#34;; return Ok(result); } /// \u0026lt;summary\u0026gt; /// 创建订单 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;order\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; [Route(\u0026#34;Create\u0026#34;)] [HttpPost] public async Task\u0026lt;IActionResult\u0026gt; CreateOrder(Models.Order order) { using (var trans = context.Database.BeginTransaction(capBus, autoCommit: true)) { order.CreateTime = DateTime.Now; context.Orders.Add(order); var result = await context.SaveChangesAsync() \u0026gt; 0; if (result) { // 发布下单事件 await capBus.PublishAsync(\u0026#34;order.services.createorder\u0026#34;, new CreateOrderMessageDto() { Count = order.Count, ProductID = order.ProductID }); return Ok(); } return BadRequest(); } } } }CreateOrderMessageDto.cs# namespace Order.Api.Models { /// \u0026lt;summary\u0026gt; /// 下单事件消息 /// \u0026lt;/summary\u0026gt; public class CreateOrderMessageDto { /// \u0026lt;summary\u0026gt; /// 产品ID /// \u0026lt;/summary\u0026gt; public int ProductID { get; set; } /// \u0026lt;summary\u0026gt; /// 购买数量 /// \u0026lt;/summary\u0026gt; public int Count { get; set; } } }Order.cs# using System; using System.ComponentModel.DataAnnotations; namespace Order.Api.Models { public class Order { [Key] public int ID { get; set; } /// \u0026lt;summary\u0026gt; /// 下单时间 /// \u0026lt;/summary\u0026gt; [Required] public DateTime CreateTime { get; set; } /// \u0026lt;summary\u0026gt; /// 产品ID /// \u0026lt;/summary\u0026gt; [Required] public int ProductID { get; set; } /// \u0026lt;summary\u0026gt; /// 购买数量 /// \u0026lt;/summary\u0026gt; [Required] public int Count { get; set; } } }OrderContext.cs# using Microsoft.EntityFrameworkCore; namespace Order.Api { public class OrderContext : DbContext { public OrderContext(DbContextOptions\u0026lt;OrderContext\u0026gt; options) : base(options) { } public DbSet\u0026lt;Models.Order\u0026gt; Orders { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { } } }appsettings.json# { \u0026#34;Logging\u0026#34;: { \u0026#34;LogLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Information\u0026#34;, \u0026#34;Microsoft\u0026#34;: \u0026#34;Warning\u0026#34;, \u0026#34;Microsoft.Hosting.Lifetime\u0026#34;: \u0026#34;Information\u0026#34; } }, \u0026#34;AllowedHosts\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;ConsulSetting\u0026#34;: { \u0026#34;ServiceName\u0026#34;: \u0026#34;order.service\u0026#34;, \u0026#34;ServiceIP\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;ServiceHealthCheck\u0026#34;: \u0026#34;/healthcheck\u0026#34;, \u0026#34;ConsulAddress\u0026#34;: \u0026#34;http://192.168.31.191:8500\u0026#34; }, \u0026#34;ConnectionString\u0026#34;: \u0026#34;Server=192.168.31.210;Database=Microservice.Sample.Order;user id=sa;password=wpl19950815;MultipleActiveResultSets=true\u0026#34; }Startup.cs# public void ConfigureServices(IServiceCollection services) { services.AddControllers(); services.AddDbContext\u0026lt;OrderContext\u0026gt;(opt =\u0026gt; opt.UseSqlServer(Configuration[\u0026#34;ConnectionString\u0026#34;])); services.AddCap(x =\u0026gt; { x.UseEntityFramework\u0026lt;OrderContext\u0026gt;().UseRabbitMQ(option =\u0026gt; { option.HostName = \u0026#34;192.168.31.191\u0026#34;; option.UserName = \u0026#34;guest\u0026#34;; option.Password = \u0026#34;guest\u0026#34;; }); }); }\n以上就是产品服务的新增以及订单服务的部分代码调整，功能很简单：各自添加自己的数据库表，订单服务增加下单接口，下单接口会发出“下单事件”。产品服务增加减库存接口，减库存接口会订阅“下单事件”。然后客户端调用下单接口下单时，产品服务会减去相应的库存。关于EF数据库迁移之类的基本使用不做介绍。\n重新构建镜像# [root@centos-01 dotnetcore_src]# cd order.api.release/ [root@centos-01 order.api.release]# docker build -t order.api . Sending build context to Docker daemon 16.05MB Step 1/4 : FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base ---\u0026gt; a2be3e478ffa Step 2/4 : WORKDIR /app ---\u0026gt; Using cache ---\u0026gt; 9f551bd1698a Step 3/4 : COPY . /app ---\u0026gt; e19ab440e8a5 Step 4/4 : ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;Order.Api.dll\u0026#34;] ---\u0026gt; Running in 3d1e4110f02e Removing intermediate container 3d1e4110f02e ---\u0026gt; 06322a6c6e83 Successfully built 06322a6c6e83 Successfully tagged order.api:latest [root@centos-01 order.api.release]# cd ../product.api.release/ [root@centos-01 product.api.release]# docker build -t product.api . Sending build context to Docker daemon 16.38MB Step 1/4 : FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base ---\u0026gt; a2be3e478ffa Step 2/4 : WORKDIR /app ---\u0026gt; Using cache ---\u0026gt; 9f551bd1698a Step 3/4 : COPY . /app ---\u0026gt; 6f6d08e02d78 Step 4/4 : ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;Product.Api.dll\u0026#34;] ---\u0026gt; Running in 7616a505741e Removing intermediate container 7616a505741e ---\u0026gt; 6be08521c6fe Successfully built 6be08521c6fe Successfully tagged product.api:latest运行订单服务，产品服务：\ndocker run -d --name order.api -p 80:80 order.api --ConsulSetting:ServicePort=\u0026#34;80\u0026#34; docker run -d --name order.api1 -p 81:80 order.api --ConsulSetting:ServicePort=\u0026#34;81\u0026#34; docker run -d --name order.api2 -p 82:80 order.api --ConsulSetting:ServicePort=\u0026#34;82\u0026#34; docker run -d --name product.api -p 85:80 product.api --ConsulSetting:ServicePort=\u0026#34;85\u0026#34; docker run -d --name product.api1 -p 86:80 product.api --ConsulSetting:ServicePort=\u0026#34;86\u0026#34; docker run -d --name product.api2 -p 87:80 product.api --ConsulSetting:ServicePort=\u0026#34;87\u0026#34;\nocelot.json 增加路由配置：\n{ \u0026#34;Routes\u0026#34;: [ { // 路由规则匹配 \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/orders/{url}\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/orders/{url}\u0026#34;, // 增加Post请求 \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;Get\u0026#34;, \u0026#34;Post\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;order.service\u0026#34;, \u0026#34;LoadBalancerOptions\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;RoundRobin\u0026#34; }, // 缓存 \u0026#34;FileCacheOptions\u0026#34;: { \u0026#34;TtlSeconds\u0026#34;: 5, \u0026#34;Region\u0026#34;: \u0026#34;regionname\u0026#34; }, // 限流 \u0026#34;RateLimitOptions\u0026#34;: { \u0026#34;ClientWhitelist\u0026#34;: [ \u0026#34;SuperClient\u0026#34; ], \u0026#34;EnableRateLimiting\u0026#34;: true, \u0026#34;Period\u0026#34;: \u0026#34;2s\u0026#34;, \u0026#34;PeriodTimespan\u0026#34;: 2, \u0026#34;Limit\u0026#34;: 1 }, // 超时熔断 \u0026#34;QoSOptions\u0026#34;: { \u0026#34;ExceptionsAllowedBeforeBreaking\u0026#34;: 3, \u0026#34;DurationOfBreak\u0026#34;: 10000, \u0026#34;TimeoutValue\u0026#34;: 5000 } }, { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/products\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/products\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;Get\u0026#34; ], \u0026#34;ServiceName\u0026#34;: \u0026#34;product.service\u0026#34;, \u0026#34;LoadBalancerOptions\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;RoundRobin\u0026#34; }, // 缓存 \u0026#34;FileCacheOptions\u0026#34;: { \u0026#34;TtlSeconds\u0026#34;: 5, \u0026#34;Region\u0026#34;: \u0026#34;regionname\u0026#34; }, // 限流 \u0026#34;RateLimitOptions\u0026#34;: { \u0026#34;ClientWhitelist\u0026#34;: [ \u0026#34;SuperClient\u0026#34; ], \u0026#34;EnableRateLimiting\u0026#34;: true, \u0026#34;Period\u0026#34;: \u0026#34;2s\u0026#34;, \u0026#34;PeriodTimespan\u0026#34;: 2, \u0026#34;Limit\u0026#34;: 1 }, // 超时熔断 \u0026#34;QoSOptions\u0026#34;: { \u0026#34;ExceptionsAllowedBeforeBreaking\u0026#34;: 3, \u0026#34;DurationOfBreak\u0026#34;: 10000, \u0026#34;TimeoutValue\u0026#34;: 5000 } } ], \u0026#34;GlobalConfiguration\u0026#34;: { \u0026#34;BaseUrl\u0026#34;: \u0026#34;http://localhost:5000\u0026#34;, \u0026#34;ServiceDiscoveryProvider\u0026#34;: { \u0026#34;Scheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;192.168.31.191\u0026#34;, \u0026#34;Port\u0026#34;: 8500, \u0026#34;Type\u0026#34;: \u0026#34;Consul\u0026#34; }, \u0026#34;RateLimitOptions\u0026#34;: { \u0026#34;DisableRateLimitHeaders\u0026#34;: false, \u0026#34;QuotaExceededMessage\u0026#34;: \u0026#34;too many requests...\u0026#34;, \u0026#34;HttpStatusCode\u0026#34;: 999, \u0026#34;ClientIdHeader\u0026#34;: \u0026#34;Test\u0026#34; } } }至此整个环境就有点复杂了。要确保 SqlServer，RabbitMQ，Consul，服务实例、Gateway都正常运行：\ncap.published 表和 cap.received 表由 CAP 自动生成，内部使用本地消息表+MQ来实现异步确保。\n测试# 使用Postman作为客户端调用下单接口（5000是Ocelot网关端口）：\n订单库： 产品库： 至此虽然功能很简单，但是实现了服务的解耦，异步调用，和最终一致性。要注意的是：\n这里的事务是指：订单持久化到数据库/和下单事件保存到 cap.published表（保存到 cap.published 表理论上代表消息正常发送到MQ），要么一同成功，要么一同失败。如果这个事务成功，那么就可以认为这个业务流程是成功的 产品服务的减库存是否成功那是产品服务的事，理论上也应该是成功的。因为消息已经确保发到了MQ，产品服务必然会收到消息。CAP也提供了失败重试，和失败回调机制，要理解 “CAP 是基于MQ加本地消息表来实现异步确保” 如果下单成功但是库存不足导致减库存失败了怎么办，是否需要回滚订单表的数据？如果产生这种想法，说明还没有真正理解最终一致性的思想。首先下单前肯定会检查一下库存数量，既然允许下单那么必然是库存充足的。（高并发下保证不超卖是另一个问题这里不考虑）如果非要数据回滚也是能实现的，CAP的 ICapPublisher.Publish 方法提供一个callbackName 参数，当减库存时，可以触发这个回调。其本质也是通过发布订阅完成，但不推荐 CAP无法保证消息不重复，实际使用中需要自己考虑一下实现消息的重复过滤和幂等 "},{"id":74,"href":"/docs/microservice/1.5%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8Bdockercompose/","title":"1.5微服务入门之 Docker Compose","section":"所有文章","content":"前言# 上一篇中使用 CAP 完成了一个简单的 Eventbus，实现了服务之间的解耦和异步调用，并且做到数据的最终一致性。搞到这里系统环境已经比较复杂了，想把整个系统运行起来会非常繁琐：要运行 Consul、订单服务、产品服务、网关、鉴权中心、RabbitMQ，本篇将使用 Docker Compose 来解决以上问题，仅需一个简单的命令，即可启动整个环境。\nDocker Compose# 什么是Docker Compose？\nCompose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务\n简单来理解，Compose类似一个批量工具，可以执行一组命令，支持批量构建镜像，批量启动容器，批量删除容器等等功能。Windows的 Docker Desktop 中已经包括了 Compose，Linux下 Compose 则需要单独安装。关于 Compose 更多信息参考 【Docker三剑客之DockerCompose】。\nyml file# yml 文件是使用 Compose 必不可少的，在编写 yml 文件之前需要准备Dockerfile。之前的章节中，网关服务不是在 Docker 中运行的，现在全部放到Docker中。确保解决方案中每个项目都添加Docker支持。\n# See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging. # 基于 `mcr.microsoft.com/dotnet/aspnet:5.0 AS base` 来构建镜像 FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base # 设置工作目录,如不存在会被创建 WORKDIR /app # Copy release文件夹内容到工作目录app COPY . /app # 运行.dll ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;Ocelot.Geteway.dll\u0026#34;]新建 docker-compose.yml 文件，以下是 docker-compose.yml文件内容：\nversion: \u0026#39;3.4\u0026#39; services: apigateway: image: gateway build: context: . dockerfile: ./gateway.release/Dockerfile ports: - \u0026#39;8080:8080\u0026#39; environment: - ASPNETCORE_URLS=http://+:8080 networks: - my-testnet depends_on: - orderapi1 - orderapi2 - orderapi3 - productapi1 - productapi2 - productapi3 orderapi1: image: order.api build: context: . dockerfile: ./order.api.release/Dockerfile ports: - 80:80 environment: - ASPNETCORE_URLS=http://+:80 - ConsulSetting:ServiceIP=80 - ConsulSetting:ServicePort=80 networks: - my-testnet depends_on: - consul - rabbitmq orderapi2: image: order.api ports: - \u0026#39;81:80\u0026#39; environment: - ASPNETCORE_URLS=http://+:81 - ConsulSetting:ServiceIP=orderapi2 - ConsulSetting:ServicePort=81 networks: - my-testnet depends_on: - orderapi1 orderapi3: image: order.api ports: - \u0026#39;82:80\u0026#39; environment: - ASPNETCORE_URLS=http://+:82 - ConsulSetting:ServiceIP=orderapi3 - ConsulSetting:ServicePort=82 networks: - my-testnet depends_on: - orderapi1 productapi1: image: product.api build: context: . dockerfile: ./product.api.release/Dockerfile ports: - \u0026#39;85:80\u0026#39; environment: - ASPNETCORE_URLS=http://+:85 - ConsulSetting:ServiceIP=productapi1 - ConsulSetting:ServicePort=85 networks: - my-testnet depends_on: - consul - rabbitmq productapi2: image: product.api ports: - \u0026#39;86:80\u0026#39; environment: - ASPNETCORE_URLS=http://+:86 - ConsulSetting:ServiceIP=productapi2 - ConsulSetting:ServicePort=86 networks: - my-testnet depends_on: - productapi1 productapi3: image: product.api ports: - \u0026#39;87:80\u0026#39; environment: - ASPNETCORE_URLS=http://+:87 - ConsulSetting:ServiceIP=productapi3 - ConsulSetting:ServicePort=87 networks: - my-testnet depends_on: - productapi1 consul: image: consul container_name: consul ports: - \u0026#39;8500:8500\u0026#39; networks: - my-testnet rabbitmq: image: rabbitmq:3.9.5-management container_name: rabbitmq ports: - 15672:15672 - 5672:5672 networks: - my-testnet networks: my-testnet: driver: bridge以上 yml 文件定义了网关服务、订单服务、产品服务、Consul，rabbitMQ 9个服务（容器），和一个容器网络 my-testnet。这里 product.api和 order.api 是基于同样的镜像各运行了3个容器，真实开发中他们应该分布在多个docker主机中。将 yml文件扔到虚机目录中（这里为了快速测试，真实不会这么搞）。\n容器网络# 之前容器之间通讯是通过容器的IP访问，虽然是可以访问但不友好。更好的方式是：自定义一个bridge网络，将所有服务（容器）加入这个网络中，那么容器之间就可以直接通过服务名称通信了。（这里暂时没这么做）bridge 模式只是docker网络模式中的一种，更多信息参考：【Docker高级网络配置#容器跨网桥通信】。\n构建与启动# 完成以上操作后，进入虚机目录执行docker-compose up -d\n[root@centos-01 dotnetcore_src]# docker-compose up -d Creating rabbitmq ... Creating consul ... Creating rabbitmq Creating rabbitmq ... done Creating dotnetcoresrc_productapi1_1 ... Creating dotnetcoresrc_orderapi1_1 ... Creating dotnetcoresrc_productapi1_1 Creating dotnetcoresrc_orderapi1_1 ... done Creating dotnetcoresrc_productapi1_1 ... done Creating dotnetcoresrc_orderapi2_1 ... Creating dotnetcoresrc_productapi3_1 ... Creating dotnetcoresrc_orderapi3_1 Creating dotnetcoresrc_productapi2_1 ... Creating dotnetcoresrc_productapi3_1 Creating dotnetcoresrc_orderapi2_1 Creating dotnetcoresrc_orderapi3_1 ... done Creating dotnetcoresrc_apigateway_1 ... Creating dotnetcoresrc_apigateway_1 ... done [root@centos-01 dotnetcore_src]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 82e1221c03b5 gateway \u0026#34;dotnet Ocelot.Gatew…\u0026#34; 6 seconds ago Up 5 seconds 0.0.0.0:8080-\u0026gt;8080/tcp, :::8080-\u0026gt;8080/tcp dotnetcoresrc_apigateway_1 90a760680cba product.api \u0026#34;dotnet Product.Api.…\u0026#34; 7 seconds ago Up 6 seconds 0.0.0.0:86-\u0026gt;80/tcp, :::86-\u0026gt;80/tcp dotnetcoresrc_productapi2_1 352c6bce65e6 product.api \u0026#34;dotnet Product.Api.…\u0026#34; 7 seconds ago Up 6 seconds 0.0.0.0:87-\u0026gt;80/tcp, :::87-\u0026gt;80/tcp dotnetcoresrc_productapi3_1 eafce74e7582 order.api \u0026#34;dotnet Order.Api.dll\u0026#34; 7 seconds ago Up 6 seconds 0.0.0.0:81-\u0026gt;80/tcp, :::81-\u0026gt;80/tcp dotnetcoresrc_orderapi2_1 6b9c45e89c55 order.api \u0026#34;dotnet Order.Api.dll\u0026#34; 7 seconds ago Up 6 seconds 0.0.0.0:82-\u0026gt;80/tcp, :::82-\u0026gt;80/tcp dotnetcoresrc_orderapi3_1 2acb5ed6125e order.api \u0026#34;dotnet Order.Api.dll\u0026#34; 8 seconds ago Up 7 seconds 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp dotnetcoresrc_orderapi1_1 e9c6a88e6a72 product.api \u0026#34;dotnet Product.Api.…\u0026#34; 8 seconds ago Up 7 seconds 0.0.0.0:85-\u0026gt;80/tcp, :::85-\u0026gt;80/tcp dotnetcoresrc_productapi1_1 84b03969229f consul \u0026#34;docker-entrypoint.s…\u0026#34; 9 seconds ago Up 8 seconds 8300-8302/tcp, 8301-8302/udp, 8600/tcp, 8600/udp, 0.0.0.0:8500-\u0026gt;8500/tcp, :::8500-\u0026gt;8500/tcp consul aff9066b3ff0 rabbitmq:3.9.5-management \u0026#34;docker-entrypoint.s…\u0026#34; 9 seconds ago Up 8 seconds 4369/tcp, 5671/tcp, 0.0.0.0:5672-\u0026gt;5672/tcp, :::5672-\u0026gt;5672/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672-\u0026gt;15672/tcp, :::15672-\u0026gt;15672/tcp rabbitmq [root@centos-01 dotnetcore_src]# 浏览器访问网关测试：\nPostman调用下单接口： 查看数据库： 至此就完成了使用 docker-compose 一键启动整个环境，想要摧毁这个环境也很简单，只需要一句 docker-compose down。\n"},{"id":75,"href":"/docs/microservice/consul%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0/","title":"Consul服务注册发现","section":"所有文章","content":"官网地址：https://www.consul.io\n简介# Consul 是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件，由 HashiCorp 公司用 Go 语言开发, 基于 Mozilla Public License 2.0 的协议进行开源。 Consul 支持 健康检查，并允许 HTTP 、GRPC 和 DNS 协议调用 API 存储键值对。 一致性协议采用 Raft 算法,用来保证服务的高可用。使用 GOSSIP 协议管理成员和广播消息，并且支持 ACL 访问控制。\nConsul 包含多个组件，但作为整体来看的话主要功能是：为基础设施提供服务发现和服务配置的工具，主要提供以下关键特性：\n服务发现：Consul 的客户端用于注册服务，其他的客户端可以通过 Consul 来中找到这个注册的服务（使用 DNS 或 HTTP） 健康检查：Consul 客户端可以提供任意数量的健康检查，要么与给定的服务相关联（“网络服务器是否返回 200 OK”），要么与本地节点（“内存利用率是否低于 90%”）相关联。可以通过这个信息来监控集群健康状况，并且服务发现组件可以使用它来避免将请求路由到不健康的主机上 KV 存储：应用程序可以将 Consul 的分层键/值存储用于多种目的，包括动态配置、功能标记、协调、领导选举等。简单的 HTTP API 使其易于使用 安全服务通信：Consul 可以为服务生成和分发 TLS 证书，以建立相互的 TLS 连接。 意图 可用于定义允许哪些服务进行通信。可以通过实时更改意图轻松管理服务分段，而不是使用复杂的网络拓扑和静态防火墙规则 多数据中心：Consul 支持开箱即用的多个数据中心。这意味着 Consul 的用户不必担心构建额外的抽象层以扩展到多个区域 Consul Agent# 每个为 Consul 提供服务的节点都会运行一个 Consul Agent，启动 Consul 必须运行 Agent（可以选择运行为 Server 或 Client 模式。每个数据中心至少要有一台 Server，一个 Client是一个非常轻量级的进程，用于注册服务，运行健康检查和转发对 Server 的查询） 这个 Agent 功能主要在于：\n负责对节点上的服务以及节点本身进行健康检查 Agent 会与一台或多台 Consul Server 保持通信（Consul Server 用于存储和复制数据） Server 会自己选举一个 Leader。虽然 Consul 可以在一台服务器上运行，但建议使用 3 到 5 台以达到高可用。建议为每个数据中心启用 Consul Server 集群 Server 维护一个目录，这个目录保存着所有 Agent 提交的信息，包括哪些服务可用、哪些节点运行哪些服务、运行状况信息等。可以在此处找到 Agent 和目录的交互方式 当需要查找 Consul 中注册的服务或者各节点的基础设施组件时可以查询任何 Consul Server 或者 任何 Consul 代理。代理自动将查询转发到 Server。\n每个数据中心都运行一个 Consul 服务器集群。当进行跨数据中心的服务发现或配置请求时，本地 Consul Server 将请求转发到远程数据中心并返回结果。\nConsul 对比# 针对服务注册发现有很多中间件都可以做，比如 zookeeper 、Etcd 、doozerd 、eureka，Consul 相比于这些软件优势在于：\n使用 Raft 算法来保证一致性：Raft 比复杂的 Paxos 算法更直接。（zookeeper 采用的是 Paxos, etcd 使用的则是 Raft） 支持多数据中心：内外网服务采用不同端口进行监听，多数据中心集群可以避免单数据中心的单点故障。（zookeeper 和 etcd 不支持多数据中心） 支持健康检查： etcd 不支持此功能 支持 HTTP/DNS /GPRS 协议接口： zookeeper 集成比较复杂，etcd 只支持 http 协议 官方提供 WEB 管理界面，etcd 无此功能 综合比较，Consul 作为服务注册和配置管理的新星，还是比较值得关注和研究的。官网：Consul Vs Other Software 。\nConsul 架构# 上图是官网给出的 Consul 架构图，简单了解一下这张图。首先可以看到有两个数据中心，分别标注为 \u0026ldquo;DATACENTER1\u0026quot;和 \u0026ldquo;DATACENTER2\u0026rdquo;。Consul对多个数据中心有天然非常好的支持，并推荐这么做。\n每个数据中心内都混合着 Client 和 Server。推荐是3到5台 Server。这是在权衡故障场景下可用性和性能之间取得平衡给出的建议（随着机器的增加，共识的速度会逐渐变慢）。但Client 的数量没有限制的可以轻松地扩展到数千或数万。\n所有在数据中心的代理都会参与一个Gossip协议。这代表有一个 Gossip 池，其中保存着这个数据中心的所有 Agent。这么做目的在于：\n客户端不需要配置 Server地址，发现工作是自动完成的 检测代理故障的工作不放在单个Server上而是分布式的，使得故障检测的扩展性比原生的心跳方案要强得多。同时还为节点提供了故障检测，如果代理无法到达，那么该节点可能已经发生了故障 它被用作消息层，当发生重要事件（如Leader 选举）时进行通知 每个数据中心的 Server 都会参与共同选举出一个 Leader，如果一个 Server 被选中为 Leader 那它会有额外的职责：Leader负责处理所有查询和事务。事务也会复制到所有参与选举的 Server。由于这个要求，当 None-Leader Server 收到RPC请求时，会将其转发给集群Leader。\nThe server agents also operate as part of a WAN gossip pool. This pool is different from the LAN pool as it is optimized for the higher latency of the internet and is expected to contain only other Consul server agents. The purpose of this pool is to allow datacenters to discover each other in a low-touch manner. Bringing a new datacenter online is as easy as joining the existing WAN gossip pool. Because the servers are all operating in this pool, it also enables cross-datacenter requests. When a server receives a request for a different datacenter, it forwards it to a random server in the correct datacenter. That server may then forward to the local leader.\nThis results in a very low coupling between datacenters, but because of failure detection, connection caching and multiplexing, cross-datacenter requests are relatively fast and reliable.\nIn general, data is not replicated between different Consul datacenters. When a request is made for a resource in another datacenter, the local Consul servers forward an RPC request to the remote Consul servers for that resource and return the results. If the remote datacenter is not available, then those resources will also not be available, but that won\u0026rsquo;t otherwise affect the local datacenter. There are some special situations where a limited subset of data can be replicated, such as with Consul\u0026rsquo;s built-in ACL replication capability, or external tools like consul-replicate.\nIn some places, client agents may cache data from the servers to make it available locally for performance and reliability. Examples include Connect certificates and intentions which allow the client agent to make local decisions about inbound connection requests without a round trip to the servers. Some API endpoints also support optional result caching. This helps reliability because the local agent can continue to respond to some queries like service-discovery or Connect authorization from cache even if the connection to the servers is disrupted or the servers are temporarily unavailable.\nConsul 安装# 安装 Consul 没什么难度。具体参考官网：Consul 安装 ，这里只记录如何使用 Docker 安装 Consul。\n准备 Consul 镜像：\ndocker pull consul # 默认拉取latest docker pull consul:1.6.1 # 拉取指定版本验证安装：\n[root@centos-01 ~]# docker exec -it consul /bin/sh / # consul Usage: consul [--version] [--help] \u0026lt;command\u0026gt; [\u0026lt;args\u0026gt;] Available commands are: acl Interact with Consul\u0026#39;s ACLs agent Runs a Consul agent catalog Interact with the catalog config Interact with Consul\u0026#39;s Centralized Configurations connect Interact with Consul Connect debug Records a debugging archive for operators event Fire a new event exec Executes a command on Consul nodes force-leave Forces a member of the cluster to enter the \u0026#34;left\u0026#34; state info Provides debugging information for operators. intention Interact with Connect service intentions join Tell Consul agent to join cluster keygen Generates a new encryption key keyring Manages gossip layer encryption keys kv Interact with the key-value store leave Gracefully leaves the Consul cluster and shuts down lock Execute a command holding a lock login Login to Consul using an auth method logout Destroy a Consul token created with login maint Controls node or service maintenance mode members Lists the members of a Consul cluster monitor Stream logs from a Consul agent operator Provides cluster-level tools for Consul operatorsConsul Server# [root@centos-01 coresrc]# docker run -d --name=consul_server -p 8500:8500 consul agent -server -bootstrap -ui -node=1 -client=\u0026#39;0.0.0.0\u0026#39; 355be46f502ca9f9e1498022e4c86fabf96c9e72b161cf4c71deff9c2012338b agent：启动 agent 进程（前面提过启动 Consul 必须运行 agent） -server：以 Server 模式启动 bootstrap：表示这个节点是 Server-Leader ，上面说过正常情况下 Leader 是通过 Raft 算法选举出来的，但是集群第一次启动时需要一个引导 Leader，在引导群集后，就不要使用此标志了 node：节点名称（集群中必须是唯一的，默认是该节点的主机名） -client：Consul 服务监听地址（这个地址提供 HTTP、DNS、RPC 等服务，默认是 127.0.0.1 不对外提供服务，需要对外提供服务改成 0.0.0.0） 其它参数：\n-bootstrap-expect ：在一个数据中心中期望提供的 Server 节点数量，当该值提供的时候，Consul一直等到达到指定 Sever 数目的时候才会引导整个集群，该标记不能和 bootstrap 共用 -bind：该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是 0.0.0.0 ui：启动 Web UI 管理器（默认开放端口 8500） -rejoin：使 Consul 忽略先前的离开，在再次启动后仍旧尝试加入集群中 -config-dir：配置文件目录，里面所有以.json结尾的文件都会被加载 查看集群信息：\n[root@centos-01 ~]# docker exec -it consul consul members Node Address Status Type Build Protocol DC Segment 1 172.17.0.2:8301 alive server 1.10.2 2 dc1 \u0026lt;all\u0026gt;Consul Server 集群# 加入两个 Server 模式的 Consul 到集群中。Server 模式在集群中建议是 3个以上，这样更好的避免因为 Server 的宕机导致整个集群挂掉的风险，做到高可用。\ndocker run -d --name=consul_server2 consul agent -server -bootstrap -node=2 -client=\u0026#39;0.0.0.0\u0026#39; -join=172.17.0.2 docker run -d --name=consul_server3 consul agent -server -bootstrap -node=3 -client=\u0026#39;0.0.0.0\u0026#39; -join=172.17.0.2查看集群信息：\n[root@centos-01 ~]# docker exec -it consul_server consul members Node Address Status Type Build Protocol DC Segment 1 172.17.0.2:8301 alive server 1.10.2 2 dc1 \u0026lt;all\u0026gt; 2 172.17.0.3:8301 alive server 1.10.2 2 dc1 \u0026lt;all\u0026gt; 3 172.17.0.4:8301 alive server 1.10.2 2 dc1 \u0026lt;all\u0026gt;Consul Client 加入集群# Client 在 Consul 集群中起到了代理 Server 的作用，Client 模式不持久化数据。一般情况每台应用服务器都会安装一个 Client ，这样可以减轻跨服务器访问带来性能损耗。也可以减轻 Server 的请求压力。\n加入两个 Client 模式的 Consul：\ndocker run -d --name=consul_client1 consul agent -client -node=4 -join=172.17.0.2 -client=\u0026#39;0.0.0.0\u0026#39; docker run -d --name=consul_client2 consul agent -client -node=5 -join=172.17.0.2 -client=\u0026#39;0.0.0.0\u0026#39;查看集群信息：\n[root@centos-01 ~]# docker exec -it consul_server consul members Node Address Status Type Build Protocol DC Segment 1 172.17.0.2:8301 alive server 1.10.2 2 dc1 \u0026lt;all\u0026gt; 2 172.17.0.3:8301 alive server 1.10.2 2 dc1 \u0026lt;all\u0026gt; 3 172.17.0.4:8301 alive server 1.10.2 2 dc1 \u0026lt;all\u0026gt; 53c94791711e 172.17.0.5:8301 alive client 1.10.2 2 dc1 \u0026lt;default\u0026gt; fa871a7045ec 172.17.0.6:8301 alive client 1.10.2 2 dc1 \u0026lt;default\u0026gt;Consul 对外接口# http://localhost:8500/v1/status/leader: 显示当前集群的Leader http://localhost:8500/v1/agent/members： 查看集群成员的详细信息 http://localhost:8500/v1/status/peers：显示集群中的Server成员 http://localhost:8500/v1/catalog/services： 显示所有服务 http://localhost:8500/v1/catalog/nodes：显示集群节点的详细信息 参考：# https://www.consul.io/docs/install https://www.bookstack.cn/read/consul-guide/06_setup_cluster.md https://cloud.tencent.com/developer/article/1416526 https://www.jianshu.com/p/b12037fa3249 https://blog.csdn.net/liuzhuchen/article/details/81913562 http://www.liangxiansen.cn/2017/04/06/consul/#%E4%BD%BF%E7%94%A8consul "},{"id":76,"href":"/docs/prometheus/1.1prometheus%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%AE%89%E8%A3%85/","title":"1.1 Prometheus简介及安装","section":"所有文章","content":"简介# Prometheus 是一个开源的完整监控解决方案，基于中央化的规则计算、统一分析和告警的新模型。 相比于传统监控系统具有以下优点：\n易于管理# Prometheus 核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。\nPrometheus 基于 Pull 模型的架构方式，可以在任何地方（本地电脑，开发环境，测试环境）搭建监控系统。对于一些复杂的情况，还可以使用服务发现( Service Discovery )的能力动态管理监控目标。\n监控服务内部状态# Pometheus 鼓励用户监控服务的内部状态，基于 Prometheus 丰富的 Client 库，可以轻松的在应用程序中添加对 Prometheus 的支持，从而可以获取服务和应用内部真正的运行状态。\n强大的数据模型# 所有采集的监控数据均以指标 metric 的形式保存在内置的时间序列数据库当中( TSDB )。所有样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签。如下所示：\nhttp_request_status{code=\u0026#39;200\u0026#39;,content_path=\u0026#39;/api/path\u0026#39;, environment=\u0026#39;produment\u0026#39;} =\u0026gt; [value1@timestamp1,value2@timestamp2...] http_request_status{code=\u0026#39;200\u0026#39;,content_path=\u0026#39;/api/path2\u0026#39;, environment=\u0026#39;produment\u0026#39;} =\u0026gt; [value1@timestamp1,value2@timestamp2...]每一条时间序列由指标名称( Metrics Name )以及一组标签( Labels )唯一标识。每条时间序列按照时间的先后顺序存储一系列的样本值。\n表示维度的标签可能来源于监控对象的状态，比如 code=404 或者 content_path=/api/path 。也可能来源于的环境定义，比如 environment=produment 。基于这些 Labels 可以方便地对监控数据进行聚合，过滤，裁剪。\nPromQL 查询# Prometheus 内置了一个强大的数据查询语言 PromQL 。 通过 PromQL 可以实现对监控数据的查询、聚合。同时PromQL 也被应用于数据可视化(如Grafana)以及告警当中。\n通过 PromQL 可以轻松回答类似于以下问题：\n过去一段时间中95%应用延迟时间的分布范围？ 预测在4小时后，磁盘空间占用大致会是什么情况？ CPU占用率前5位的服务有哪些？(过滤) 高效# 对于监控系统而言，大量的监控任务必然导致有大量的数据产生。而 Prometheus 可以高效地处理这些数据，对于单个 Prometheus Server 实例而言它可以处理：\n数以百万的监控指标 每秒处理数十万的数据点 可扩展# Prometheus 非常简单，因此可以在每个数据中心、每个团队运行独立的 Prometheus Sevrer。Prometheus 对于联邦集群的支持，可以让多个 Prometheus 实例产生一个逻辑集群，当单实例 Prometheus Server 处理的任务量过大时，通过使用功能分区( sharding )+联邦集群( federation )对其进行扩展。\n易于集成# 使用 Prometheus 可以快速搭建监控服务，并且可以非常方便地在应用程序中进行集成。目前支持： Java， JMX， Python， Go，Ruby， .Net， Node.js 等语言的客户端SDK，基于这些SDK可以快速让应用程序纳入到 Prometheus 的监控当中，或者开发自己的监控数据收集程序。同时这些客户端收集的监控数据，不仅仅支持Prometheus，还能支持 Graphite 这些其他的监控工具。\nPrometheus还支持与其他的监控系统进行集成：Graphite， Statsd， Collected， Scollector， muini， Nagios 等。\nPrometheus 社区还提供了大量第三方实现的监控数据采集支持：JMX， CloudWatch， EC2， MySQL， PostgresSQL， Haskell， Bash， SNMP， Consul， Haproxy， Mesos， Bind， CouchDB， Django， Memcached， RabbitMQ， Redis， RethinkDB， Rsyslog 等等。\n可视化# Prometheus Server 中自带了一个 Prometheus UI ，通过这个UI可以方便地直接对数据进行查询，并且支持直接以图形化的形式展示数据。同时 Prometheus 还提供了一个独立的基于 Ruby On Rails 的 Dashboard 解决方案Promdash。最新的 Grafana 可视化工具也已经提供了完整的 Prometheus 支持，基于 Grafana 可以创建更加精美的监控图标。基于 Prometheus 提供的API还可以实现自己的监控可视化UI。r\n开放性# 通常来说当需要监控一个应用程序时，一般需要该应用程序提供对相应监控系统协议的支持。因此应用程序会与所选择的监控系统进行绑定。为了减少这种绑定所带来的限制。对于决策者而言要么直接在应用中集成该监控系统的支持，要么就在外部创建单独的服务来适配不同的监控系统。\n而对于 Prometheus 来说，使用 Prometheus 的 client library 的输出格式不止支持 Prometheus 的格式化数据，也可以输出支持其它监控系统的格式化数据，比如Graphite。\n甚至可以在不使用 Prometheus 的情况下，采用Prometheus的 client library 来让应用程序支持监控数据采集\nPrometheus 架构# 这里从 Prometheus 的架构角度了解一下 Prometheus 生态中的各个组件，下图展示 Prometheus 的基本架构：\nPrometheus Server# Prometheus Server 是 Prometheus 组件中的核心部分，负责实现对监控数据的获取，存储以及查询。\nPrometheus Server 可以通过静态配置管理监控目标，也可以配合使用 Service Discovery 的方式动态管理监控目标，并从这些监控目标中获取数据。\nPrometheus Server 需要对采集到的监控数据进行存储，Prometheus Server 本身就是一个时序数据库，将采集到的监控数据按照时间序列的方式存储在本地磁盘当中。\nPrometheus Server 对外提供了自定义的 PromQL 语言，实现对数据的查询以及分析。 内置的 Express Browser UI，通过这个UI可以直接通过 PromQL 实现数据的查询以及可视化。\nPrometheus Server 的联邦集群能力可以使其从其他的 Prometheus Server 实例中获取数据，因此在大规模监控的情况下，可以通过联邦集群以及功能分区的方式对 Prometheus Server 进行扩展。\nExporters# Exporter 将监控数据采集的端点通过HTTP服务的形式暴露给 Prometheus Server，Prometheus Server 通过访问该Exporter 提供的 Endpoint 端点，即可获取到需要采集的监控数据。\n一般可以将 Exporter 分为两类：\n直接采集：这一类 Exporter 直接内置了对 Prometheus 监控的支持，比如 cAdvisor，Kubernetes，Etcd，Gokit等，都直接内置了用于向 Prometheus 暴露监控数据的端点 间接采集：原有监控目标并不直接支持 Prometheus，需要通过 Prometheus 提供的 Client Library 编写该监控目标的监控采集程序。例如： Mysql Exporter，JMX Exporter，Consul Exporter 等 AlertManager# 在 Prometheus Server 中支持基于 PromQL 创建告警规则，如果满足 PromQL 定义的规则，则会产生一条告警，而告警的后续处理流程则由 AlertManager 进行管理。在 AlertManager 中可以与邮件，Slack等等内置的通知方式进行集成，也可以通过 Webhook 自定义告警处理方式。AlertManager 是 Prometheus 体系中的告警处理中心。\nPushGateway# 由于 Prometheus 数据采集基于 Pull 模型进行设计，因此在网络环境的配置上必须要让 Prometheus Server 能够直接与 Exporter 进行通信。 当这种网络需求无法直接满足时，就可以利用 PushGateway 来进行中转。通过 PushGateway 将内部网络的监控数据主动 Push 到 Gateway 当中。而 Prometheus Server 同样采用 Pull 的方式从 PushGateway 中获取到监控数据。\nPrometheus 安装# Prometheus 基于 Golang 编写，编译后的软件包，不依赖于任何的第三方依赖。用户只需要下载对应平台的二进制包，解压并且添加基本的配置即可正常启动 Prometheus Server。\n二进制包安装# 对于非 Docker 用户，可以从 https://prometheus.io/download/ 找到最新版本的 Prometheus Sevrer 软件包：\ncurl -LO https://github.com/prometheus/prometheus/releases/download/v2.36.2/prometheus-2.36.2.linux-amd64.tar.gz解压，并将 Prometheus 相关的命令，添加到系统环境变量路径即可：\ntar -xzf prometheus-2.36.2.linux-amd64.tar.gz cd prometheus-2.36.2.linux-amd64解压后当前目录会包含默认的 Prometheus 配置文件 promethes.yml\n# my global config\rglobal:\rscrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\revaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\r# scrape_timeout is set to the global default (10s).\r# Alertmanager configuration\ralerting:\ralertmanagers:\r- static_configs:\r- targets:\r# - alertmanager:9093\r# Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;.\rrule_files:\r# - \u0026#34;first_rules.yml\u0026#34;\r# - \u0026#34;second_rules.yml\u0026#34;\r# A scrape configuration containing exactly one endpoint to scrape:\r# Here it\u0026#39;s Prometheus itself.\rscrape_configs:\r# The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config.\r- job_name: \u0026#39;prometheus\u0026#39;\r# metrics_path defaults to \u0026#39;/metrics\u0026#39;\r# scheme defaults to \u0026#39;http\u0026#39;.\rstatic_configs:\r- targets: [\u0026#39;localhost:9090\u0026#39;]Promtheus 作为一个时间序列数据库，其采集的数据会以文件的形似存储在本地中，默认的存储路径为 data/，因此需要先手动创建该目录：\nmkdir -p data也可以通过参数 --storage.tsdb.path=\u0026quot;data/\u0026quot; 修改本地数据存储的路径。\n启动 Prometheus 服务，其会默认加载当前路径下的 prometheus.yaml 文件：\n./prometheus正常的情况下，可以看到以下输出内容：\nlevel=info ts=2018-10-23T14:55:14.499484Z caller=main.go:554 msg=\u0026#34;Starting TSDB ...\u0026#34;\rlevel=info ts=2018-10-23T14:55:14.499531Z caller=web.go:397 component=web msg=\u0026#34;Start listening for connections\u0026#34; address=0.0.0.0:9090\rlevel=info ts=2018-10-23T14:55:14.507999Z caller=main.go:564 msg=\u0026#34;TSDB started\u0026#34;\rlevel=info ts=2018-10-23T14:55:14.508068Z caller=main.go:624 msg=\u0026#34;Loading configuration file\u0026#34; filename=prometheus.yml\rlevel=info ts=2018-10-23T14:55:14.509509Z caller=main.go:650 msg=\u0026#34;Completed loading of configuration file\u0026#34; filename=prometheus.yml\rlevel=info ts=2018-10-23T14:55:14.509537Z caller=main.go:523 msg=\u0026#34;Server is ready to receive web requests.\u0026#34;容器安装# 对于 Docker 用户，直接使用 Prometheus 的镜像即可启动Prometheus Server：\n在 etc 下创建目录 prometheus ：\n[root@wangpengliang100ecs ~]# cd /etc/ [root@wangpengliang100ecs etc]# mkdir prometheus设置权限目录：\nchown -R root:root /etc/prometheus手动创建 prometheus.yml配置文件，内容如下：\n# my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;. rule_files: # - \u0026#34;first_rules.yml\u0026#34; # - \u0026#34;second_rules.yml\u0026#34; # A scrape configuration containing exactly one endpoint to scrape: # Here it\u0026#39;s Prometheus itself. scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#39;prometheus\u0026#39; # metrics_path defaults to \u0026#39;/metrics\u0026#39; # scheme defaults to \u0026#39;http\u0026#39;. static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;]启动容器：\ndocker run -d --name prometheus -p 9090:9090 -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus浏览器访问# 启动完成后，可以通过 http://ipaddress:9090 访问 Prometheus 的UI界面：\n"},{"id":77,"href":"/docs/prometheus/1.2exporter%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/","title":"1.2 Exporter数据采集","section":"所有文章","content":"上一节学习了如何部署 Prometheus Server，这节学习如何使用 Exporter 收集主机数据。在 Prometheus 的架构设计中，Prometheus Server 并不直接服务监控特定的目标，其主要任务负责数据的收集，存储并且对外提供数据查询支持。因此为了能够能够监控到某些东西，如主机的CPU使用率，需要使用到 Exporter。Prometheus 周期性的从 Exporter 暴露的 HTTP 服务地址（通常是 /metrics）拉取监控样本数据。\nExporter 是一个相对开放的概念，可以是一个独立运行的程序独立于监控目标，也可以直接内置在监控目标中。只要能够向 Prometheus 提供标准格式的监控样本数据即可\nExporter 概念# 广义上所有可以向 Prometheus 提供监控样本数据的程序都可以被称为一个 Exporter 。Exporter 的一个实例称为Target，Prometheus 通过轮询的方式定期从这些 Target 中获取样本数据。\nExporter 来源# 社区提供# Prometheus 社区提供了丰富的 Exporter 实现，涵盖了从基础设施，中间件以及网络等各个方面的监控功能。这些Exporter 可以实现大部分通用的监控需求。下面表格列举了社区中常用的 Exporter：\n范围 常用Exporter 数据库 MySQL Exporter, Redis Exporter, MongoDB Exporter, MSSQL Exporter等 硬件 Apcupsd Exporter，IoT Edison Exporter， IPMI Exporter, Node Exporter等 消息队列 Beanstalkd Exporter, Kafka Exporter, NSQ Exporter, RabbitMQ Exporter等 存储 Ceph Exporter, Gluster Exporter, HDFS Exporter, ScaleIO Exporter等 HTTP服务 Apache Exporter, HAProxy Exporter, Nginx Exporter等 API服务 AWS ECS Exporter， Docker Cloud Exporter, Docker Hub Exporter, GitHub Exporter等 日志 Fluentd Exporter, Grok Exporter等 监控系统 Collectd Exporter, Graphite Exporter, InfluxDB Exporter, Nagios Exporter, SNMP Exporter等 其它 Blockbox Exporter, JIRA Exporter, Jenkins Exporter， Confluence Exporter等 自定义创建# 除了直接使用社区提供的 Exporter 程序以外，还可以基于 Prometheus 提供的 Client Library 创建自己的 Exporter 程序。目前 Promthues 社区官方提供了对以下编程语言的支持：Go、Java/Scala、Python、Ruby。同时还有第三方实现的如：Bash、C++、Common Lisp、Erlang,、Haskeel、Lua、Node.js、PHP、Rust 等。\nExporter 运行方式# 独立使用# 以 Node Exporter 为例，由于操作系统本身并不直接支持 Prometheus 同时用户也无法通过直接从操作系统层面上提供对 Prometheus 的支持。因此只能通过独立运行一个程序的方式，通过操作系统提供的相关接口，将系统的运行状态数据转换为可供 Prometheus 读取的监控数据。 除了 Node Exporter 以外，比如 MySQL Exporter、Redis Exporter 等都是通过这种方式实现。 在这里 Exporter 程序扮演了中间代理人的角色。\n应用中集成# 为了能够更好的监控系统的内部运行状态，有些开源项目如 Kubernetes，ETCD 等直接在代码中使用了Prometheus 的 Client Library，提供了对 Prometheus 的直接支持。这种方式让应用程序可以直接将内部的运行状态暴露给 Prometheus，适合于需要更多自定义监控指标需求的项目。\nExporter 规范# 所有的 Exporter 程序都需要按照 Prometheus 的规范，返回监控的样本数据。以 Node Exporter 为例，当访问 /metrics 地址时会返回以下内容：\n# HELP node_cpu Seconds the cpus spent in each mode. # TYPE node_cpu counter node_cpu{cpu=\u0026#34;cpu0\u0026#34;,mode=\u0026#34;idle\u0026#34;} 362812.7890625 # HELP node_load1 1m load average. # TYPE node_load1 gauge node_load1 3.0703125这是一种基于文本的格式规范，相比于 Protocol buffer 文本具有更好的可读性，以及跨平台性。\nPrometheus 2.0 之前的版本支持 Protocol buffer 规范，2.0 及之后的版本不再支持 Protocol buffer\nExporter 返回的样本数据，主要由三个部分组成：样本一般由 注释信息（HELP），样本的类型注释信息（TYPE）和 样本组成。Prometheus 会对 Exporter 响应的内容逐行解析：\n如果当前行以 # HELP 开始，Prometheus 将按照以下规则对内容进行解析，得到当前指标名称以及相应的说明信息 # HELP \u0026lt;metrics_name\u0026gt; \u0026lt;doc_string\u0026gt; 如果当前行以 # TYPE 开始，Prometheus 将按照以下规则对内容进行解析，得到当前指标名称以及指标类型 # TYPE \u0026lt;metrics_name\u0026gt; \u0026lt;metrics_type\u0026gt;TYPE 注释行必须出现在指标的第一个样本之前。如果没有明确指标类型需要返回为 untyped 。 除了 # 开头的所有行都会被视为是监控样本数据。 每一行样本需要满足以下格式规范：\nmetric_name [{label_name=\u0026#34;label_value\u0026#34;} ] value [ timestamp ] # 示例 node_cpu_seconds_total{cpu=\u0026#34;1\u0026#34;,mode=\u0026#34;system\u0026#34;} 2.2其中 metric_name 和 label_name 必须遵循 PromQL 的格式规范要求。value 是一个 float 格式的数据，timestamp 类型为 int64（从1970-01-01 00:00:00以来的毫秒数），timestamp 可选，默认为当前时间。具有相同metric_name 的样本必须按照一个组的形式排列，并且每一行必须是唯一的指标名称和标签键值对组合。\n需要注意：对于 istogram 和 summary 类型的样本。按照以下约定返回样本数据：\n类型为 summary 或 histogram 的指标 x，该指标所有样本值的总和需要使用一个单独的 x_sum 指标表示 类型为 summary 或 histogram 的指标 x，该指标所有样本的总数需要使用一个单独的 x_count 指标表示 类型为 summary 的指标 x，其不同分位数 quantile 所代表的样本，需要使用单独的 x{quantile=\u0026quot;y\u0026quot;} 表示 类型 histogram 的指标 x，为了表示其样本的分布情况，每一个分布需要使用 x_bucket{le=\u0026quot;y\u0026quot;} 表示，其中 y 为当前分布的上位数。同时必须包含一个样本 x_bucket{le=\u0026quot;+Inf\u0026quot;} ，并且其样本值必须和 x_count 相同 对于 histogram 和 summary 的样本，必须按照分位数 quantile 和分布le的值的递增顺序排序 以下是类型为 histogram 和 summary 的样本输出示例：\n# A histogram, which has a pretty complex representation in the text format: # HELP http_request_duration_seconds A histogram of the request duration. # TYPE http_request_duration_seconds histogram http_request_duration_seconds_bucket{le=\u0026#34;0.05\u0026#34;} 24054 http_request_duration_seconds_bucket{le=\u0026#34;0.1\u0026#34;} 33444 http_request_duration_seconds_bucket{le=\u0026#34;0.2\u0026#34;} 100392 http_request_duration_seconds_bucket{le=\u0026#34;+Inf\u0026#34;} 144320 http_request_duration_seconds_sum 53423 http_request_duration_seconds_count 144320 # Finally a summary, which has a complex representation, too: # HELP rpc_duration_seconds A summary of the RPC duration in seconds. # TYPE rpc_duration_seconds summary rpc_duration_seconds{quantile=\u0026#34;0.01\u0026#34;} 3102 rpc_duration_seconds{quantile=\u0026#34;0.05\u0026#34;} 3272 rpc_duration_seconds{quantile=\u0026#34;0.5\u0026#34;} 4773 rpc_duration_seconds_sum 1.7560473e+07 rpc_duration_seconds_count 2693对于 Prometheus 还没有提供支持的编程语言，只需要按照以上规范返回响应的文本数据即可。\n指定样本格式# 在 Exporter 响应的 HTTP 头信息中，可以通过 Content-Type 指定特定的规范版本，例如：\nHTTP/1.1 200 OK Content-Encoding: gzip Content-Length: 2906 Content-Type: text/plain; version=0.0.4 Date: Sat, 17 Mar 2018 08:47:06 GMT其中 version 用于指定 Text-based 的格式版本，当没有指定版本的时候，默认使用最新格式规范的版本。同时 HTTP 响应头还需要指定压缩格式为 gzip。\n常用 Exporter# Node Exporter# 为了能够采集到主机的运行指标如：CPU、内存、磁盘等信息，需要在主机上安装一个 Node Exporter 程序，该程序对外暴露了一个用于获取当前监控样本数据的 HTTP 访问地址。这样的程序称为 Exporter，Exporter 的实例称为一个 Target。Prometheus 通过轮询的方式定时从这些 Target 中获取监控数据样本。\n安装# Node Exporter 同样采用 Golang 编写，并且不存在任何的第三方依赖，只需要下载，解压即可运行。可以从 https://prometheus.io/download/ 获取最新的 Node Exporter 版本的二进制包。\n在 usr 目录下创建 exporter 目录：\n[root@wangpengliang101ecs ~]# cd /usr/ [root@wangpengliang101ecs usr]# ls bin etc games include lib lib64 libexec local sbin share src tmp [root@wangpengliang101ecs usr]# mkdir exporter [root@wangpengliang101ecs usr]# cd exporter下载 Node Exporter.tar.gz 并解压到当前目录：\ncurl -LO https://github.com/prometheus/node_exporter/releases/download/v1.3.1/node_exporter-1.3.1.linux-amd64.tar.gz [root@wangpengliang101ecs exporter]# tar -xzf node_exporter-1.3.1.linux-amd64.tar.gz [root@wangpengliang101ecs exporter]# ls node_exporter-1.3.1.linux-amd64 node_exporter-1.3.1.linux-amd64.tar.gz运行 node exporter\n[root@wangpengliang101ecs exporter]# cd node_exporter-1.3.1.linux-amd64/ nohup ./node_exporter \u0026amp; # 后台运行,端口默认9100 这里使用 nohup 后台运行 node_exporter，默认端口为 9100，如果端口有冲突可以通过 --web.listen-address=:xxx 进行修改\n启动成功后，查看端口\n[root@wangpengliang101ecs node_exporter-1.3.1.linux-amd64]# netstat -anplt|grep 9100 tcp6 0 0 :::9100 :::* LISTEN 2443/./node_exporte tcp6 0 0 172.17.135.171:9100 222.174.189.42:52597 ESTABLISHED 2443/./node_exporte监控指标# 访问 http://ipaddress:9100/metrics ，可以看到当前 node exporter 获取到的主机监控数据，如下所示：\n每一个监控指标之前都会有一段类似于如下形式的信息：\n# HELP node_cpu Seconds the cpus spent in each mode. # TYPE node_cpu counter node_cpu{cpu=\u0026#34;cpu0\u0026#34;,mode=\u0026#34;idle\u0026#34;} 362812.7890625 # HELP node_load1 1m load average. # TYPE node_load1 gauge node_load1 3.0703125其中 HELP 用于解释当前指标的含义，TYPE 则说明当前指标的数据类型。在上面的例子中:\nnode_cpu 的注释表明当前指标是 cpu0 上 idle 进程占用CPU的总时间，CPU占用时间是一个只增不减的度量指标，从类型中也可以看出node_cpu的数据类型是计数器(counter)，与该指标的实际含义一致 node_load1 该指标反映了当前主机在最近一分钟以内的负载情况，系统的负载情况会随系统资源的使用而变化，因此 node_load1 反映的是当前状态，数据可能增加也可能减少，从注释中可以看出当前指标类型为仪表盘(gauge)，与指标反映的实际含义一致 除了这些以外，根据物理主机系统的不同，还可能看到如下监控指标：\nnode_boot_time：系统启动时间 node_cpu：系统CPU使用量 nodedisk：磁盘IO nodefilesystem：文件系统用量 node_load1：系统负载 nodememeory：内存使用量 nodenetwork：网络带宽 node_time：当前系统时间 go_*：node exporter中go相关指标 process_*：node exporter自身进程相关运行指标 集成# 为了能够让 Prometheus Server 能够从当前 Node Exporter 获取到监控数据，需要修改 Prometheus 配置文件。编辑 prometheus.yml 在 scrape_configs 节点下添加以下内容:\nscrape_configs: - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] # 采集node exporter监控数据 - job_name: \u0026#39;123.56.222.108\u0026#39; # 这里jobname是自定义的 static_configs: - targets: [\u0026#39;123.56.222.108:9100\u0026#39;]重新启动 Prometheus Server，如果 Prometheus 能够正常从 Node Exporter 获取数据，则会看到以下结果：\nup{instance=\u0026#34;123.56.222.108:9100\u0026#34;, job=\u0026#34;123.56.222.108:9100\u0026#34;} 1 up{instance=\u0026#34;localhost:9090\u0026#34;, job=\u0026#34;prometheus\u0026#34;} 1 其中“1”表示正常，“0”则为异常。\n自动重启# 添加 node_exporter.service\nvim /etc/systemd/system/node_exporter.service内容如下：\n[Unit] Description=node_exporter Monitoring System Documentation=node_exporter Monitoring System [Service] ExecStart=/projects/node_exporter/node_exporter-1.3.1.linux-amd64/node_exporter --web.listen-address=:6060 # 这里ExecStart地址为node_exporter安装地址 [Install] WantedBy=multi-user.target设置自动重启\nsystemctl daemon-reload systemctl start node_exporter.service systemctl status node_exporter.service systemctl enable node_exporter.serviceCadvisor Exporter# 安装镜像\ndocker pull google/cadvisor:latest运行容器\ndocker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:rw \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --volume=/dev/disk/:/dev/disk:ro \\ --publish=8080:8080 \\ --detach=true \\ --name=cadvisor \\ --privileged=true \\ google/cadvisor:latest开放端口\nfirewall-cmd --add-port=8080/tcp --permanent firewall-cmd --reload任务和实例# 上面通过在 prometheus.yml 配置文件中，添加如下配置让 Prometheus 可以从 Node Exporter 暴露的服务中获取监控指标数据。\n- job_name: \u0026#39;123.56.222.108\u0026#39; static_configs: - targets: [\u0026#39;123.56.222.108:9100\u0026#39;]当需要采集不同的监控指标(例如：主机、MySQL、Nginx)时，只需要运行相应的监控采集程序，并且让 Prometheus Server 知道这些 Exporter 实例的访问地址。在 Prometheus 中，每一个暴露监控样本数据的HTTP服务称为一个实例。例如在当前主机上运行的 Node Exporter 可以被称为一个实例( Instance )。\n而一组用于相同采集目的的实例，或者同一个采集进程的多个副本则通过一个一个任务(Job)进行管理。\n* job: node\r* instance 2: 1.2.3.4:9100\r* instance 4: 5.6.7.8:9100当前在每一个 Job 中主要使用了静态配置( static_configs )的方式定义监控目标。除了静态配置每一个Job的采集Instance地址以外，Prometheus 还支持与 DNS、Consul、E2C、Kubernetes 等进行集成实现自动发现Instance实例，并从这些 Instance上获取监控数据。\n除了通过使用“up”表达式查询当前所有Instance的状态以外，还可以通过Prometheus UI中的Targets页面查看当前所有的监控采集任务，以及各个任务下所有实例的状态：\n所以这里配置文件 scrape_configs 内容可以调整为：\nscrape_configs:\r# The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config.\r- job_name: \u0026#39;prometheus\u0026#39;\r# metrics_path defaults to \u0026#39;/metrics\u0026#39;\r# scheme defaults to \u0026#39;http\u0026#39;.\rstatic_configs:\r- targets: [\u0026#39;localhost:9090\u0026#39;,\u0026#39;123.56.222.108:9100\u0026#39;]\n"},{"id":78,"href":"/docs/prometheus/1.3promql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/","title":"1.3 Prom Ql查询语言","section":"所有文章","content":"Prometheus 官方文档地址\n监控样本# 通过 Node Exporter 暴露的 HTTP 服务，Prometheus 可以采集到当前主机所有监控指标的样本数据。比如：\n# HELP node_cpu_guest_seconds_total Seconds the CPUs spent in guests (VMs) for each mode. # TYPE node_cpu_guest_seconds_total counter node_cpu_guest_seconds_total{cpu=\u0026#34;0\u0026#34;,mode=\u0026#34;nice\u0026#34;} 0 node_cpu_guest_seconds_total{cpu=\u0026#34;0\u0026#34;,mode=\u0026#34;user\u0026#34;} 0 node_cpu_guest_seconds_total{cpu=\u0026#34;1\u0026#34;,mode=\u0026#34;nice\u0026#34;} 0 node_cpu_guest_seconds_total{cpu=\u0026#34;1\u0026#34;,mode=\u0026#34;user\u0026#34;} 0 # HELP node_cpu_seconds_total Seconds the CPUs spent in each mode. # TYPE node_cpu_seconds_total counter node_cpu_seconds_total{cpu=\u0026#34;0\u0026#34;,mode=\u0026#34;idle\u0026#34;} 996.7 node_cpu_seconds_total{cpu=\u0026#34;0\u0026#34;,mode=\u0026#34;iowait\u0026#34;} 0.52其中非 # 开头的每一行表示当前 Node Exporter 采集到的一个监控样本：\nnode_cpu_seconds_total ：表示当前指标名称 大括号中的标签：表示当前样本的一些特征和维度 浮点数：表示该监控样本的具体值 时间序列（time-series）# Prometheus 会将所有采集到的样本数据以时间序列（time-series）的方式保存在内存数据库中，定时保存到硬盘上。\ntime-series 是按照时间戳和值的序列顺序存放的，称之为向量(vector)\n每条 time-series 通过指标名称(metrics name)和一组标签集(labelset)命名。其中每一个点称为一个样本(sample)。样本由以下三部分组成：\n指标（metric）：metric name 和描述当前样本特征的 labelsets 时间戳（timestamp）：一个精确到毫秒的时间戳 样本值（value）： 一个 float64 的浮点型数据表示当前样本的值 \u0026lt;--------------- metric ---------------------\u0026gt;\u0026lt;-timestamp -\u0026gt;\u0026lt;-value-\u0026gt; http_request_total{status=\u0026#34;200\u0026#34;, method=\u0026#34;GET\u0026#34;}@1434417560938 =\u0026gt; 94355 http_request_total{status=\u0026#34;200\u0026#34;, method=\u0026#34;GET\u0026#34;}@1434417561287 =\u0026gt; 94334 http_request_total{status=\u0026#34;404\u0026#34;, method=\u0026#34;GET\u0026#34;}@1434417560938 =\u0026gt; 38473 http_request_total{status=\u0026#34;404\u0026#34;, method=\u0026#34;GET\u0026#34;}@1434417561287 =\u0026gt; 38544 http_request_total{status=\u0026#34;200\u0026#34;, method=\u0026#34;POST\u0026#34;}@1434417560938 =\u0026gt; 4748 http_request_total{status=\u0026#34;200\u0026#34;, method=\u0026#34;POST\u0026#34;}@1434417561287 =\u0026gt; 4785指标（metric）# 指标（Metric）通过如下格式表示：\n\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...} 指标名称(metric name)：表示被监控样本的含义。比如：http_request_total 表示当前系统接收到的HTTP请求总量。指标名称只能由ASCII字符、数字、下划线以及冒号组成并必须符合正则表达式 [a-zA-Z_:][a-zA-Z0-9_:]* 标签(label)：反映当前样本的特征维度，通过这些维度 Prometheus 可以对样本数据进行过滤，聚合等。标签的名称只能由ASCII字符、数字以及下划线组成并满足正则表达式 [a-zA-Z_][a-zA-Z0-9_]* 其中以 __ 作为前缀的标签是系统保留的关键字，只能在系统内部使用。标签的值可以包含任何 Unicode 编码的字符。\n在 Prometheus 的底层实现中指标名称实际上是以 __name__=\u0026lt;metric name\u0026gt; 的形式保存在数据库中的，因此以下两种方式均表示的同一条 time-series：\napi_http_requests_total{method=\u0026#34;POST\u0026#34;, handler=\u0026#34;/messages\u0026#34;} 等同于： {__name__=\u0026#34;api_http_requests_total\u0026#34;，method=\u0026#34;POST\u0026#34;, handler=\u0026#34;/messages\u0026#34;} 在 Prometheus 源码中也可以指标(Metric)对应的数据结构，如下所示：\ntype Metric LabelSet type LabelSet map[LabelName]LabelValue type LabelName string type LabelValue stringMetric 类型# 为了能够理解和区分不同监控指标之间的差异，Prometheus 定义了4中不同的指标类型（metric type）：\nCounter（计数器） Gauge（仪表盘） Histogram（直方图） Summary（摘要） Exporter Node 返回的样本数据中，其注释中也包含了该样本的类型。例如：\n# HELP node_cpu_seconds_total Seconds the CPUs spent in each mode. # TYPE node_cpu_seconds_total counter node_cpu_seconds_total{cpu=\u0026#34;0\u0026#34;,mode=\u0026#34;idle\u0026#34;} 996.7Counter-\u0026gt;只增不减# Counter 类型的指标工作方式和计数器一样，只增不减（除非系统发生重置）。如 http_requests_total ，node_cpu 都是 Counter 类型的监控指标。 一般在定义 Counter 类型指标的名称时推荐使用 _total 作为后缀。\n示例：通过 rate() 函数获取HTTP请求量的增长率：\nrate(http_requests_total[5m])查询当前系统中，访问量前10的 HTTP 地址：\ntopk(10, http_requests_total)Gauge-\u0026gt;可增可减# Gauge 类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）都是 Gauge 类型的监控指标。\n通过 Gauge 指标，可以直接查看系统的当前状态。对于 Gauge 类型的监控指标，通过 PromQL 内置函数 delta() 可以获取样本在一段时间的变化情况。例如，计算CPU温度在两个小时内的差异：\ndelta(cpu_temp_celsius{host=\u0026#34;zeus\u0026#34;}[2h])还可以使用 deriv() 计算样本的线性回归模型，甚至直接使用 predict_linear() 对数据的变化趋势进行预测。例如：预测系统磁盘空间在4个小时之后的剩余情况：\npredict_linear(node_filesystem_free{job=\u0026#34;node\u0026#34;}[1h], 4 * 3600)Histogram/Summary# Histogram 和 Summary 主要用于统计和分析样本的分布情况。\n大多数情况下人们都倾向于使用某些量化指标的平均值，例如CPU的平均使用率、页面的平均响应时间。这种方式的问题很明显，以系统API调用的平均响应时间为例：如果大多数API请求都维持在100ms 的响应时间范围内，而个别请求的响应时间需要 5s，那么就会导致某些WEB页面的响应时间落到中位数的情况，这种现象被称为长尾问题\n为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如：统计延迟在 010ms 之间的请求数有多少而 1020ms 之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram 和Summary 都是为了能够解决这样问题的存在，通过 Histogram 和 Summary 类型的监控指标，可以快速了解监控样本的分布情况。\n例如：指标 prometheus_tsdb_wal_fsync_duration_seconds 的指标类型为 Summary。 它记录了 Prometheus Server 中 wal_fsync 处理的处理时间，通过访问 Prometheus Server 的 /metrics 地址，可以获取到以下监控样本数据：\n# HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of WAL fsync.\r# TYPE prometheus_tsdb_wal_fsync_duration_seconds summary\rprometheus_tsdb_wal_fsync_duration_seconds{quantile=\u0026#34;0.5\u0026#34;} 0.012352463\rprometheus_tsdb_wal_fsync_duration_seconds{quantile=\u0026#34;0.9\u0026#34;} 0.014458005\rprometheus_tsdb_wal_fsync_duration_seconds{quantile=\u0026#34;0.99\u0026#34;} 0.017316173\rprometheus_tsdb_wal_fsync_duration_seconds_sum 2.888716127000002\rprometheus_tsdb_wal_fsync_duration_seconds_count 216从上面的样本中可以得知当前 Prometheus Server 进行 wal_fsync 操作的总次数为216次，耗时 2.888716127000002s。其中中位数（quantile=0.5）的耗时为 0.012352463，9分位数（quantile=0.9）的耗时为 0.014458005s。\n在 Prometheus Server 自身返回的样本数据中，还能找到类型为 Histogram 的监控指标prometheus_tsdb_compaction_chunk_range_bucket。\n# HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction\r# TYPE prometheus_tsdb_compaction_chunk_range histogram\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;100\u0026#34;} 0\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;400\u0026#34;} 0\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;1600\u0026#34;} 0\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;6400\u0026#34;} 0\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;25600\u0026#34;} 0\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;102400\u0026#34;} 0\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;409600\u0026#34;} 0\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;1.6384e+06\u0026#34;} 260\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;6.5536e+06\u0026#34;} 780\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;2.62144e+07\u0026#34;} 780\rprometheus_tsdb_compaction_chunk_range_bucket{le=\u0026#34;+Inf\u0026#34;} 780\rprometheus_tsdb_compaction_chunk_range_sum 1.1540798e+09\rprometheus_tsdb_compaction_chunk_range_count 780对比 Summary 类型的指标：\n相似之处在于： Histogram 类型的样本同样会反应当前指标的记录的总数(以 _count 作为后缀)以及其值的总量（以 _sum 作为后缀） 不同在于： Histogram 指标直接反应了在不同区间内样本的个数，区间通过标签 len 进行定义 对于 Histogram 的指标，还可以通过 histogram_quantile() 函数计算出其值的分位数。不同在于:\nHistogram 通过 histogram_quantile 函数是在服务器端计算的分位数（会消耗更多的资源） Sumamry 的分位数则是直接在客户端计算完成（在通过 PromQL 进行查询时有更好的性能表现） 选择这两种方式时应该按照自己的实际场景进行选择\nPromQL# Prometheus 通过指标名称（metrics name）以及对应的一组标签（labelset）来定义一条时间序列。指标名称反映了监控样本的基本标识，而 label 则在这个基本特征上为采集到的数\t过滤，聚合，统计从而产生新的计算后的一条时间序列。\nPromQL 是 Prometheus 内置的数据查询语言，其提供对时间序列数据丰富的查询，聚合以及逻辑运算能力的支持\n查询时间序列# 当 Prometheus 通过 Exporter Node 采集到相应的监控指标样本数据后，可以通过 PromQL 对监控样本数据进行查询。比如：直接使用监控指标名称查询\nprometheus_http_requests_total # 等同于： prometheus_http_requests_total{}该表达式返回指标名称为 http_requests_total 的所有时间序列：\nprometheus_http_requests_total{code=\u0026#34;200\u0026#34;, handler=\u0026#34;/-/ready\u0026#34;, instance=\u0026#34;localhost:9090\u0026#34;, job=\u0026#34;prometheus\u0026#34;} prometheus_http_requests_total{code=\u0026#34;200\u0026#34;, handler=\u0026#34;/api/v1/label/:name/values\u0026#34;, instance=\u0026#34;localhost:9090\u0026#34;, job=\u0026#34;prometheus\u0026#34;}标签过滤# PromQL 支持根据时间序列的标签匹配模式来对时间序列进行过滤，目前主要支持两种匹配模式：\n完全匹配 =：使用 label=value 选择标签满足表达式定义的时间序列 正则匹配 != ：使用 label!=value 根据标签匹配排除时间序列 比如：\nprometheus_http_requests_total{instance=\u0026#34;localhost:9090\u0026#34;} prometheus_http_requests_total{instance!=\u0026#34;localhost:9090\u0026#34;}除了使用完全匹配的方式对时间序列进行过滤以外，PromQL 还可以支持使用正则表达式作为匹配条件，多个表达式之间使用 | 进行分离：PromQL 支持使用 =~ 和 !~ 两种正则匹配模式：\n使用 label=~regx 表示选择那些标签符合正则表达式定义的时间序列 反之使用 label!~regx 进行排除 比如，如果想查询多个环节下的时间序列序列可以使用如下表达式：\nprometheus_http_requests_total{environment=~\u0026#34;staging|testing|development\u0026#34;,method!=\u0026#34;GET\u0026#34;}范围查询# 直接通过类似于 PromQL 表达式 process_http_request_total 查询时间序列时，返回值中只会包含该时间序列中最新的一个样本值，这样的返回结果为 瞬时向量。相应的表达式称为 瞬时向量表达式。\n如果需要过去一段时间范围内的样本数据时，则需要使用 区间向量表达式。区间向量表达式和瞬时向量表达式差异在于：在区间向量表达式中需要定义时间选择的范围，时间范围通过时间范围选择器 [] 进行定义。例如，通过以下表达式可以选择最近5分钟内的所有样本数据：\nhttp_request_total{}[5m]该表达式将会返回查询到的时间序列中最近5分钟的所有样本数据：\nprometheus_http_requests_total{code=\u0026#34;200\u0026#34;, handler=\u0026#34;/-/ready\u0026#34;, instance=\u0026#34;localhost:9090\u0026#34;, job=\u0026#34;prometheus\u0026#34;} 10 @1657164241.316 10 @1657164256.319 10 @1657164271.319 10 @1657164286.316 prometheus_http_requests_total{code=\u0026#34;200\u0026#34;, handler=\u0026#34;/api/v1/label/:name/values\u0026#34;, instance=\u0026#34;localhost:9090\u0026#34;, job=\u0026#34;prometheus\u0026#34;} 10 @1657164241.316 10 @1657164256.319 10 @1657164271.319 10 @1657164286.316 11 @1657164301.316通过区间向量表达式查询到的结果称为 区间向量。\n除了使用 m 表示分钟以外，PromQL 的时间范围选择器支持其它时间单位：\ns - 秒 m - 分钟 h - 小时 d - 天 w - 周 y - 年 时间位移# 在瞬时向量表达式或者区间向量表达式中，都是以当前时间为基准：\nhttp_request_total{} # 瞬时向量表达式，选择当前最新的数据 http_request_total{}[5m] # 区间向量表达式，选择以当前时间为基准，5分钟内的数据如果想查询5分钟前的瞬时样本数据，或昨天一天区间内的样本数据可以使用位移操作，位移操作的关键字为 offset。可以使用 offset 执行时间位移操作：\nhttp_request_total{} offset 5m http_request_total{}[1d] offset 1d聚合操作# 一般如果描述样本特征的标签(label)在并非唯一的情况下，通过 PromQL 查询数据，会返回多条满足这些特征维度的时间序列。PromQL 提供的聚合操作可以用来对这些时间序列进行处理，形成一条新的时间序列：\n# 查询系统所有http请求的总量 sum(http_request_total) # 按照mode计算主机CPU的平均使用时间 avg(node_cpu) by (mode) # 按照主机查询各个主机的CPU使用率 sum(sum(irate(node_cpu{mode!=\u0026#39;idle\u0026#39;}[5m])) / sum(irate(node_cpu[5m]))) by (instance)操作符# 数学运算# 例如：通过指标 node_memory_free_bytes_total 获取到当前主机可用的内存空间大小，样本单位为 Bytes。如果要求使用 MB 作为单位响应数据，只需要将查询到的时间序列的样本值进行单位换算即可：\nnode_memory_free_bytes_total / (1024 * 1024) 瞬时向量与标量之间进行数学运算时：数学运算符会依次作用于瞬时向量中的每一个样本值，从而得到一组新的时间序列\n瞬时向量与瞬时向量之间进行数学运算时，过程会相对复杂一点。 例如，如果想根据 node_disk_bytes_written 和 node_disk_bytes_read 获取主机磁盘IO的总量，可以使用如下表达式：\nnode_disk_bytes_written + node_disk_bytes_read工作原理是：依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行运算，如果没找到匹配元素，则直接丢弃。同时新的时间序列将不会包含指标名称。 该表达式返回结果的示例如下所示：\n{device=\u0026#34;sda\u0026#34;,instance=\u0026#34;localhost:9100\u0026#34;,job=\u0026#34;node_exporter\u0026#34;}=\u0026gt;1634967552@1518146427.807 + 864551424@1518146427.807 {device=\u0026#34;sdb\u0026#34;,instance=\u0026#34;localhost:9100\u0026#34;,job=\u0026#34;node_exporter\u0026#34;}=\u0026gt;0@1518146427.807 + 1744384@1518146427.807PromQL 支持的数学运算符如下所示：\n+ (加法) - (减法) * (乘法) / (除法) % (求余) ^ (幂运算) 布尔运算# 在 PromQL 通过标签匹配模式，可以根据时间序列的特征维度对其进行查询。而布尔运算则支持根据时间序列中样本的值，对时间序列进行过滤。\n例如：通过数学运算符可以计算出当前所有主机节点的内存使用率：\n(node_memory_bytes_total - node_memory_free_bytes_total) / node_memory_bytes_total而如果只想知道当前内存使用率超过95%的主机通过使用布尔运算符可以方便的获取到该结果：\n(node_memory_bytes_total - node_memory_free_bytes_total) / node_memory_bytes_total \u0026gt; 0.95瞬时向量与标量进行布尔运算时：PromQL 依次比较向量中的所有时间序列样本的值，如果比较结果为 true 则保留，反之丢弃。\n瞬时向量与瞬时向量直接进行布尔运算时：同样遵循默认的匹配模式：依次找到与左边向量元素匹配（标签完全一致）的\b右边向量元素进行相应的操作，如果没找到匹配元素，则直接丢弃。\n目前，Prometheus支持以下布尔运算符如下：\n== (相等) != (不相等) \u0026gt; (大于) \u0026lt; (小于) \u0026gt;= (大于等于) \u0026lt;= (小于等于) bool 修饰符# 布尔运算符的默认行为是对时序数据进行过滤。而在其它的情况下可能需要的是真正的布尔结果。例如，只需要知道当前模块的 HTTP 请求量是否 \u0026gt;=1000，如果大于等于1000则返回1（true）否则返回0（false）。这时可以使用 bool 修饰符改变布尔运算的默认行为。 例如：\nhttp_requests_total \u0026gt; bool 1000使用 bool 修改符后，布尔运算不会对时间序列进行过滤，而是直接依次瞬时向量中的各个样本数据与标量的比较结果0或者1，从而形成一条新的时间序列。\nhttp_requests_total{code=\u0026#34;200\u0026#34;,handler=\u0026#34;query\u0026#34;,instance=\u0026#34;localhost:9090\u0026#34;,job=\u0026#34;prometheus\u0026#34;,method=\u0026#34;get\u0026#34;} 1\rhttp_requests_total{code=\u0026#34;200\u0026#34;,handler=\u0026#34;query_range\u0026#34;,instance=\u0026#34;localhost:9090\u0026#34;,job=\u0026#34;prometheus\u0026#34;,method=\u0026#34;get\u0026#34;} 0同时需要注意的是，如果是在两个标量之间使用布尔运算，则必须使用 bool 修饰符\n2 == bool 2 # 结果为1集合运算符# 使用瞬时向量表达式能够获取到一个包含多个时间序列的集合，称为瞬时向量。 通过集合运算，可以在两个瞬时向量之间进行相应的集合操作。目前 Prometheus 支持以下集合运算符：\nand (并且) or (或者) unless (排除) vector1 and vector2 产生一个由 vector1 的元素组成的新的向量。该向量包含 vector1 中完全匹配 vector2 中的元素组成\nvector1 or vector2 产生一个新的向量，该向量包含 vector1 中所有的样本数据，以及 vector2 中没有与 vector1 匹配到的样本数据\nvector1 unless vector2 产生一个新的向量，新向量中的元素由 vector1 中没有与 vector2 匹配的元素组成\n操作符优先级# 对于复杂类型的表达式，需要了解运算操作的运行优先级，PromQL 操作符中优先级由高到低依次为：\n^ *, /, % +, - ==, !=, \u0026lt;=, \u0026lt;, \u0026gt;=, \u0026gt; and, unless or 匹配模式# 向量与向量之间进行运算操作时会基于默认的匹配规则：依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行运算，如果没找到匹配元素，则直接丢弃。\n在 PromQL 中有两种典型的匹配模式：一对一（one-to-one）,多对一（many-to-one）或一对多（one-to-many）。\n一对一匹配# 一对一匹配模式会从操作符两边表达式获取的瞬时向量依次比较并找到唯一匹配(标签完全一致)的样本值。默认情况下，使用表达式：\nvector1 \u0026lt;operator\u0026gt; vector2在操作符两边表达式标签不一致的情况下，可以使用 on(label list) 或者 ignoring(label list）修改便签的匹配行为。使用 ignoreing 可以在匹配时忽略某些标签。而 on 则用于将匹配行为限定在某些标签之内。\n\u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; ignoring(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt;\r\u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; on(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt;例如当存在样本：\nmethod_code:http_errors:rate5m{method=\u0026#34;get\u0026#34;, code=\u0026#34;500\u0026#34;} 24\rmethod_code:http_errors:rate5m{method=\u0026#34;get\u0026#34;, code=\u0026#34;404\u0026#34;} 30\rmethod_code:http_errors:rate5m{method=\u0026#34;put\u0026#34;, code=\u0026#34;501\u0026#34;} 3\rmethod_code:http_errors:rate5m{method=\u0026#34;post\u0026#34;, code=\u0026#34;500\u0026#34;} 6\rmethod_code:http_errors:rate5m{method=\u0026#34;post\u0026#34;, code=\u0026#34;404\u0026#34;} 21\rmethod:http_requests:rate5m{method=\u0026#34;get\u0026#34;} 600\rmethod:http_requests:rate5m{method=\u0026#34;del\u0026#34;} 34\rmethod:http_requests:rate5m{method=\u0026#34;post\u0026#34;} 120使用 PromQL 表达式：\nmethod_code:http_errors:rate5m{code=\u0026#34;500\u0026#34;} / ignoring(code) method:http_requests:rate5m该表达式会返回在过去5分钟内，HTTP请求状态码为500的在所有请求中的比例。如果没有使用 ignoring(code)，操作符两边表达式返回的瞬时向量中将找不到任何一个标签完全相同的匹配项。\n因此结果如下：\n{method=\u0026#34;get\u0026#34;} 0.04 // 24 / 600\r{method=\u0026#34;post\u0026#34;} 0.05 // 6 / 120同时由于method为put和del的样本找不到匹配项，因此不会出现在结果当中。\n多对一和一对多# 多对一和一对多两种匹配模式指的是“一”侧的每一个向量元素可以与\u0026quot;多\u0026quot;侧的多个元素匹配的情况。在这种情况下，必须使用 group 修饰符：group_left 或者 group_right 来确定哪一个向量具有更高的基数（充当“多”的角色）。\n\u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; ignoring(\u0026lt;label list\u0026gt;) group_left(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt;\r\u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; ignoring(\u0026lt;label list\u0026gt;) group_right(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt;\r\u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; on(\u0026lt;label list\u0026gt;) group_left(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt;\r\u0026lt;vector expr\u0026gt; \u0026lt;bin-op\u0026gt; on(\u0026lt;label list\u0026gt;) group_right(\u0026lt;label list\u0026gt;) \u0026lt;vector expr\u0026gt;多对一和一对多两种模式一定是出现在操作符两侧表达式返回的向量标签不一致的情况。因此需要使用 ignoring 和 on 修饰符来排除或者限定匹配的标签列表。\n例如表达式：\nmethod_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m该表达式中，左向量 method_code:http_errors:rate5m 包含两个标签method和code。而右向量method:http_requests:rate5m 中只包含一个标签 method，因此匹配时需要使用 ignoring 限定匹配的标签为code。 在限定匹配标签后，右向量中的元素可能匹配到多个左向量中的元素 因此该表达式的匹配模式为多对一，需要使用 group 修饰符 group_left 指定左向量具有更好的基数。\n最终运算结果如下：\n{method=\u0026#34;get\u0026#34;, code=\u0026#34;500\u0026#34;} 0.04 // 24 / 600\r{method=\u0026#34;get\u0026#34;, code=\u0026#34;404\u0026#34;} 0.05 // 30 / 600\r{method=\u0026#34;post\u0026#34;, code=\u0026#34;500\u0026#34;} 0.05 // 6 / 120\r{method=\u0026#34;post\u0026#34;, code=\u0026#34;404\u0026#34;} 0.175 // 21 / 120 注意：group 修饰符只能在比较和数学运算符中使用。在逻辑运算 and, unless 和 or 才注意操作中默认与右向量中的所有元素进行匹配。\n聚合操作# Prometheus 还提供了下列内置的聚合操作符，这些操作符作用域瞬时向量。用于将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列。\nsum (求和) min (最小值) max (最大值) avg (平均值) stddev (标准差) stdvar (标准差异) count (计数) count_values (对value进行计数) bottomk (后n条时序) topk (前n条时序) quantile (分布统计) 使用聚合操作的语法如下：\n\u0026lt;aggr-op\u0026gt;([parameter,] \u0026lt;vector expression\u0026gt;) [without|by (\u0026lt;label list\u0026gt;)]其中只有 count_values、quantile、topk、bottomk 支持参数(parameter)。\nwithout/by# without ：用于从计算结果中移除列举的标签而保留其它标签 by ：正好相反，结果向量中只保留列出的标签，其余标签则移除 通过 without 和 by 可以按照样本的问题对数据进行聚合。\n例如：\nsum(http_requests_total) without (instance) 等价于： sum(http_requests_total) by (code,handler,job,method)如果只需要计算整个应用的HTTP请求总量，可以直接使用表达式：\nsum(http_requests_total)count_values# count_values 用于时间序列中每一个样本值出现的次数。count_values 会为每一个唯一的样本值输出一个时间序列，并且每一个时间序列包含一个额外的标签。\n例如：\ncount_values(\u0026#34;count\u0026#34;, http_requests_total)topk/boottomk# topk 和 bottomk 则用于对样本值进行排序，返回当前样本值前n位，或者后n位的时间序列。\n例如：获取HTTP请求数前5位的时序样本数据，可以使用表达式：\ntopk(5, http_requests_total)quantile# quantile 用于计算当前样本数据值的分布情况 quantile(φ, express) 其中 0 ≤ φ ≤ 1。\n例如：当φ为0.5时，即表示找到当前样本数据中的中位数：\nquantile(0.5, http_requests_total)常见内置函数# 内置函数相关参考\n"},{"id":79,"href":"/docs/prometheus/1.4alertmanager%E5%91%8A%E8%AD%A6%E5%A4%84%E7%90%86/","title":"1.4 Alertmanager告警处理","section":"所有文章","content":"告警简介# 告警能力在 Prometheus 的架构中被划分为两个部分：\n在 Prometheus Server 中定义告警规则以及产生告警\nAlertmanager 组件用于处理由 Prometheus 产生的告警\nAlertmanager 是 Prometheus 体系中告警的统一处理中心。Alertmanager 提供了多种内置第三方告警通知方式，同时还提供对 Webhook 通知的支持，通过 Webhook 可以完成对告警更多个性化的扩展。\nPrometheus会周期性的对告警规则进行计算，如果满足告警触发条件就会向 Alertmanager 发送告警信息\n告警规则主要由以下几部分组成：\n告警名称：需要为告警规则命名，对于命名而言，需要能够直接表达出该告警的主要内容 告警规则：告警规则主要由 PromQL 进行定义，其实际意义是当表达式（PromQL）查询结果持续多长时间（During）后触发告警 在 Prometheus 中，还可以通过Group（告警组）对一组相关的告警进行统一定义。这些定义通过 YAML 文件统一管理。\nAlertmanager 作为一个独立的组件，负责接收并处理来自 Prometheus Server (也可以是其它的客户端程序)的告警信息。Alertmanager 可以对这些告警信息进行进一步的处理，比如当接收到大量重复告警时能够消除重复的告警信息，同时对告警信息进行分组并且路由到正确的通知方，Prometheus 内置了对邮件，Slack 等多种通知方式的支持，同时还支持与 Webhook 的集成，以支持更多定制化的场景。\n例如，目前 Alertmanager 还不支持钉钉，可以通过 Webhook 与钉钉机器人进行集成，从而通过钉钉接收告警信息。同时 AlertManager 还提供了静默和告警抑制机制来对告警通知行为进行优化。\nAlertmanager 特性# Alertmanager 除了提供基本的告警通知能力以外，还主要提供了如：分组、抑制以及静默等告警特性：\n分组# 分组机制可以将详细的告警信息合并成一个通知。在某些情况下，比如由于系统宕机导致大量的告警被同时触发，在这种情况下分组机制可以将这些被触发的告警合并为一个告警通知，避免一次性接受大量的告警通知，而无法对问题进行快速定位。\n例如，当集群中有数百个正在运行的服务实例，并且为每一个实例设置了告警规则。假如此时发生了网络故障，可能导致大量的服务实例无法连接到数据库，结果就会有数百个告警被发送到 Alertmanager。\n而作为用户，可能只希望能够在一个通知中就能查看哪些服务实例收到影响。这时可以按照服务所在集群或者告警名称对告警进行分组，而将这些告警内聚在一起成为一个通知。\n告警分组，告警时间，以及告警的接受方式可以通过 Alertmanager 的配置文件进行配置。\n抑制# 抑制是指当某一告警发出后，可以停止重复发送由此告警引发的其它告警的机制。\n例如，当集群不可访问时触发了一次告警，通过配置 Alertmanager 可以忽略与该集群有关的其它所有告警。这样可以避免接收到大量与实际问题无关的告警通知。\n抑制机制同样通过 Alertmanager 的配置文件进行设置。\n静默# 静默提供了一个简单的机制可以快速根据标签对告警进行静默处理。如果接收到的告警符合静默的配置，Alertmanager 则不会发送告警通知。\n静默设置需要在 Alertmanager 的 Werb 页面上进行设置。\n自定义告警规则# 告警规则允许基于 PromQL 表达式定义告警触发条件，Prometheus 后端对这些触发规则进行周期性计算，当满足触发条件后则会触发告警通知。默认情况下可以通过 Prometheus 的 Web 界面查看这些告警规则以及告警的触发状态。当 Promthues 与 Alertmanager 关联之后，可以将告警发送到外部服务如 Alertmanager 中并通过 Alertmanager 可以对这些告警进行进一步的处理。\n定义告警规则# 一条典型的告警规则如下所示：\ngroups:\r- name: example\rrules:\r- alert: HighErrorRate\rexpr: job:request_latency_seconds:mean5m{job=\u0026#34;myjob\u0026#34;} \u0026gt; 0.5\rfor: 10m\rlabels:\rseverity: page\rannotations:\rsummary: High request latency\rdescription: description info在告警规则文件中，可以将一组相关的规则设置定义在一个 group下。在每一个 group 中可以定义多个告警规则(rule)。一条告警规则主要由以下几部分组成：\nalert：告警规则的名称 expr：基于 PromQL 表达式告警触发条件，用于计算是否有时间序列满足该条件 for ：评估等待时间，可选参数。用于表示只有当触发条件持续一段时间后才发送告警。在等待期间新产生告警的状态为 pending labels：自定义标签，允许用户指定要附加到告警上的一组附加标签 annotations：用于指定一组附加信息，比如用于描述告警详细信息的文字等，annotations 的内容在告警产生时会一同作为参数发送到 Alertmanager 为了能够让 Prometheus 启用定义的告警规则，需要在 Prometheus 全局配置文件中通过 rule_files 指定一组告警规则文件的访问路径，Prometheus 启动后会自动扫描这些路径下规则文件中定义的内容，并且根据这些规则计算是否向外部发送通知。\nrule_files: [ - \u0026lt;filepath_glob\u0026gt; ... ] # 示例 rule_files: - \u0026#34;/etc/prometheus/rules.yml\u0026#34;默认情况下 Prometheus 会每分钟对这些告警规则进行计算，如果想定义自己的告警计算周期，可以通过evaluation_interval 来覆盖默认的计算周期：\nglobal: [ evaluation_interval: \u0026lt;duration\u0026gt; | default = 1m ]模板化# 一般来说，在告警规则文件的 annotations 中使用 summary 描述告警的概要信息，description 用于描述告警的详细信息。同时 Alertmanager 的UI也会根据这两个标签值显示告警信息。为了让告警信息具有更好的可读性，Prometheus 支持模板化 label 和 annotations 的中标签的值。\n通过 $labels.\u0026lt;labelname\u0026gt; 变量可以访问当前告警实例中指定标签的值。$value 则可以获取当前 PromQL 表达式计算的样本值。\n# To insert a firing element\u0026#39;s label values: {{ $labels.\u0026lt;labelname\u0026gt; }} # To insert the numeric expression value of the firing element: {{ $value }}例如，可以通过模板化优化 summary 以及 description 的内容的可读性：\ngroups: - name: example rules: # Alert for any instance that is unreachable for \u0026gt;5 minutes. - alert: InstanceDown expr: up == 0 for: 5m labels: severity: page annotations: summary: \u0026#34;Instance {{ $labels.instance }} down\u0026#34; description: \u0026#34;{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.\u0026#34; # Alert for any instance that has a median request latency \u0026gt;1s. - alert: APIHighRequestLatency expr: api_http_request_latencies_second{quantile=\u0026#34;0.5\u0026#34;} \u0026gt; 1 for: 10m annotations: summary: \u0026#34;High request latency on {{ $labels.instance }}\u0026#34; description: \u0026#34;{{ $labels.instance }} has a median request latency above 1s (current value: {{ $value }}s)\u0026#34;实践# 在目录 /etc/prometheus/ 下创建 rules.yml 文件，内容如下：\ngroups: - name: 主机监控 rules: - alert: HostOutOfMemory # 下面为了测试内存使用率高于1%告警 expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 \u0026lt; 99 for: 10s labels: severity: warning annotations: summary: Host out of memory (instance {{ $labels.instance }}) description: \u0026#34;Node memory is filling up (\u0026lt; 10% left)\\n VALUE = {{ $value }}\\n LABELS = {{ $labels }}\u0026#34;调整 prometheus.yml ：\nrule_files: - \u0026#34;/etc/prometheus/rules.yml\u0026#34;重新启动 Prometheus 容器，将 rules.yml 也挂载到容器内：\ndocker run -d --name prometheus -p 9090:9090 -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml -v /etc/prometheus/rules.yml:/etc/prometheus/rules.yml prom/prometheus查看告警状态# 如下所示，可以通过 Prometheus WEB界面中的 Alerts 菜单查看当前 Prometheus 下的所有告警规则，以及其当前所处的活动状态。\n这里可以看到规则已经生效，同时对于已经 pending 或者 firing 的告警，Prometheus也会将它们存储到时间序列 ALERTS{} 中。\nAlertmanager 部署# 上面看到配置的规则已经生效并且产生了告警，下面开始集成 Alertmanager 实现后续对告警信息的处理，Alertmanager 和 Prometheus Server 一样均采用 Golang 实现，并且没有第三方依赖。一般可以通过以下几种方式来部署 ：\n二进制包 容器部署 源码方式安装 二进制包部署# Alertmanager 最新版本的下载地址可以从 Prometheus 官方网站 https://prometheus.io/download/ 获取\ncurl -LO https://github.com/prometheus/alertmanager/releases/download/v$VERSION/alertmanager-$VERSION.darwin-amd64.tar.gz tar xvf alertmanager-$VERSION.darwin-amd64.tar.gzAlertmanager 解压后会包含一个默认的 alertmanager.yml 配置文件，内容如下所示：\nglobal:\rresolve_timeout: 5m\rroute:\rgroup_by: [\u0026#39;alertname\u0026#39;]\rgroup_wait: 10s\rgroup_interval: 10s\rrepeat_interval: 1h\rreceiver: \u0026#39;web.hook\u0026#39;\rreceivers:\r- name: \u0026#39;web.hook\u0026#39;\rwebhook_configs:\r- url: \u0026#39;http://127.0.0.1:5001/\u0026#39;\rinhibit_rules:\r- source_match:\rseverity: \u0026#39;critical\u0026#39;\rtarget_match:\rseverity: \u0026#39;warning\u0026#39;\requal: [\u0026#39;alertname\u0026#39;, \u0026#39;dev\u0026#39;, \u0026#39;instance\u0026#39;]容器部署# 在 etc 目录下新建 alertmanager 目录：\n[root@wangpengliang100ecs ~]# cd /etc/ [root@wangpengliang100ecs etc]# mkdir alertmanager在 etc/alertmanager 目录下新建 alertmanager.yml：\nglobal: resolve_timeout: 5m route: group_by: [\u0026#39;alertname\u0026#39;] group_wait: 10s group_interval: 10s repeat_interval: 30h receiver: \u0026#39;web.hook\u0026#39; receivers: - name: \u0026#39;web.hook\u0026#39; webhook_configs: - url: \u0026#39;http://127.0.0.1:5001/\u0026#39; inhibit_rules: - source_match: severity: \u0026#39;critical\u0026#39; target_match: severity: \u0026#39;warning\u0026#39; equal: [\u0026#39;alertname\u0026#39;, \u0026#39;dev\u0026#39;, \u0026#39;instance\u0026#39;]启动 alertmanager 容器：\ndocker run -d --name alertmanager -p 9093:9093 -v /etc/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml prom/alertmanager:v0.23.0访问 http://ipaddress:9093 在浏览器中查看：\nAlert 菜单下可以查看 Alertmanager 接收到的告警内容。Silences 菜单下则可以通过UI创建静默规则，Status菜单可以看到当前系统的运行状态以及配置信息。\nAlertmanager 集成# Alertmanager 部署完成后，需要在 Prometheus 中设置 Alertmanager 相关的信息\n调整 prometheus.yml ：\nalerting: alertmanagers: - static_configs: - targets: - 47.93.56.197:9093重新启动 prometheus:\n[root@wangpengliang100ecs etc]# docker restart prometheus\n集成163邮箱# 上面看到 Prometheus 的告警信息已经推送到了 Alertmanager，下面将告警信息发送到邮箱。这里使用163邮箱进行测试，需要在邮箱中开启 POP3/SMTP服务，具体方法自行百度。\n调整 alertmanager.yml：\n# 全局配置,包括报警解决后的超时时间、SMTP 相关配置、各种渠道通知的 API 地址等等。 global: # 告警超时时间 resolve_timeout: 5m # 发送者邮箱地址 smtp_from: \u0026#39;15101587969@163.com\u0026#39; # 邮箱smtp服务器地址及端口 smtp_smarthost: \u0026#39;smtp.163.com:465\u0026#39; # 因为阿里云默认封了25端口,所以选择465端口 # 发送者邮箱账号 smtp_auth_username: \u0026#39;15101587969@163.com\u0026#39; # 发送者邮箱密码，这里填入邮箱开启SMTP中获取的授权码 smtp_auth_password: \u0026#39;xxxxxx\u0026#39; # 是否使用tls smtp_require_tls: false # 路由配置,设置报警的分发策略，它是一个树状结构，按照深度优先从左向右的顺序进行匹配。 route: # 用于将传入警报分组在一起的标签。 # 基于告警中包含的标签，如果满足group_by中定义标签名称，那么这些告警将会合并为一个通知发送给接收器。 group_by: [\u0026#39;alertname\u0026#39;] # 发送通知的初始等待时间 group_wait: 30s # 在发送有关新警报的通知之前需要等待多长时间 group_interval: 30s # 如果已发送通知，则在再次发送通知之前要等待多长时间，通常约3小时或更长时间 repeat_interval: 30s # 接受者名称 receiver: \u0026#39;163.email\u0026#39; # 配置告警消息接受者信息，例如常用的 email、wechat、slack、webhook 等消息通知方式 receivers: - name: \u0026#39;163.email\u0026#39; email_configs: # 配置接受邮箱地址 - to : \u0026#39;15101587969@163.com\u0026#39;重启 alertmanager 容器：\n[root@wangpengliang100ecs etc]# docker restart alertmanager\n配置邮件模板# 上面看到已经成功接收到了邮件，但是格式比较乱，可以使用邮件模板，Alertmanager 带有默认模板，可以自定义模板内容，Alertmanager 的通知模板基于 Go 模板系统，具体支持哪些变量请参照 官网说明。\n在 etc/alertmanager 目录下新建 email.tmpl 文件：\n{{ define \u0026#34;email.html\u0026#34; }} {{ range .Alerts }} 告警程序: prometheus_alert \u0026lt;br\u0026gt; 告警类型: {{ .Labels.alertname }} \u0026lt;br\u0026gt; 故障主机: {{ .Labels.instance }} \u0026lt;br\u0026gt; 告警主题: {{ .Annotations.summary }} \u0026lt;br\u0026gt; 告警详情: {{ .Annotations.description }} \u0026lt;br\u0026gt; {{ end }} {{ end }}调整 alertmanager.yml 添加模板扫描，及邮件使用模板\ntemplates: - \u0026#39;templates/*.tmpl receivers: - name: \u0026#39;163.email\u0026#39; email_configs: # 配置接受邮箱地址 - to : \u0026#39;15101587969@163.com\u0026#39; html: \u0026#39;{{ template \u0026#34;email.html\u0026#34; . }}\u0026#39; # 邮件主题信息 headers: {Subject: \u0026#34;[WARN] 报警邮件 {{ .CommonLabels.instance }} {{ .CommonAnnotations.summary }}\u0026#34;} 重启容器并映射邮件模板文件到容器内：\ndocker run -d --name alertmanager -p 9093:9093 -v /etc/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml -v /etc/alertmanager/email.tmpl:/etc/alertmanager/templates/email.tmpl prom/alertmanager:v0.23.0查看邮件：\nAlertmanager 配置# 在 Alertmanager 中通过路由(Route)来定义告警的处理方式。路由是一个基于标签匹配的树状匹配结构。根据接收到告警的标签匹配相应的处理方式。\nAlertmanager 主要负责对 Prometheus 产生的告警进行统一处理，因此在 Alertmanager 配置中一般会包含以下几个主要部分：\n全局配置（global）：用于定义一些全局的公共参数，如全局的SMTP配置，Slack配置等内容； 模板（templates）：用于定义告警通知时的模板，如HTML模板，邮件模板等； 告警路由（route）：根据标签匹配，确定当前告警应该如何处理； 接收人（receivers）：接收人是一个抽象的概念，它可以是一个邮箱也可以是微信，Slack或者Webhook等，接收人一般配合告警路由使用； 抑制规则（inhibit_rules）：合理设置抑制规则可以减少垃圾告警的产生 完整配置格式如下：\nglobal:\r[ resolve_timeout: \u0026lt;duration\u0026gt; | default = 5m ]\r[ smtp_from: \u0026lt;tmpl_string\u0026gt; ] [ smtp_smarthost: \u0026lt;string\u0026gt; ] [ smtp_hello: \u0026lt;string\u0026gt; | default = \u0026#34;localhost\u0026#34; ]\r[ smtp_auth_username: \u0026lt;string\u0026gt; ]\r[ smtp_auth_password: \u0026lt;secret\u0026gt; ]\r[ smtp_auth_identity: \u0026lt;string\u0026gt; ]\r[ smtp_auth_secret: \u0026lt;secret\u0026gt; ]\r[ smtp_require_tls: \u0026lt;bool\u0026gt; | default = true ]\r[ slack_api_url: \u0026lt;secret\u0026gt; ]\r[ victorops_api_key: \u0026lt;secret\u0026gt; ]\r[ victorops_api_url: \u0026lt;string\u0026gt; | default = \u0026#34;https://alert.victorops.com/integrations/generic/20131114/alert/\u0026#34; ]\r[ pagerduty_url: \u0026lt;string\u0026gt; | default = \u0026#34;https://events.pagerduty.com/v2/enqueue\u0026#34; ]\r[ opsgenie_api_key: \u0026lt;secret\u0026gt; ]\r[ opsgenie_api_url: \u0026lt;string\u0026gt; | default = \u0026#34;https://api.opsgenie.com/\u0026#34; ]\r[ hipchat_api_url: \u0026lt;string\u0026gt; | default = \u0026#34;https://api.hipchat.com/\u0026#34; ]\r[ hipchat_auth_token: \u0026lt;secret\u0026gt; ]\r[ wechat_api_url: \u0026lt;string\u0026gt; | default = \u0026#34;https://qyapi.weixin.qq.com/cgi-bin/\u0026#34; ]\r[ wechat_api_secret: \u0026lt;secret\u0026gt; ]\r[ wechat_api_corp_id: \u0026lt;string\u0026gt; ]\r[ http_config: \u0026lt;http_config\u0026gt; ]\rtemplates:\r[ - \u0026lt;filepath\u0026gt; ... ]\rroute: \u0026lt;route\u0026gt;\rreceivers:\r- \u0026lt;receiver\u0026gt; ...\rinhibit_rules:\r[ - \u0026lt;inhibit_rule\u0026gt; ... ]在全局配置中需要注意的是 resolve_timeout，该参数定义了当 Alertmanager 持续多长时间未接收到告警后标记告警状态为 resolved（已解决）。该参数的定义可能会影响到告警恢复通知的接收时间，可根据自己的实际场景进行定义，其默认值为5分钟。\n"},{"id":80,"href":"/docs/prometheus/1.5grafana%E7%9B%91%E6%8E%A7%E5%8F%AF%E8%A7%86%E5%8C%96/","title":"1.5 Grafana监控可视化","section":"所有文章","content":"关于 Grafana 更多资料参考\nGrafana 安装# 这里采用 Dokcer 安装 Grafana，如果防火墙处于开启状态需要开放对应端口。\ndocker run -d -p 3000:3000 --user root --name=grafana -v /home/grafana:/var/lib/grafana grafana/grafana:7.3.6Grafana 登录# 访问：http://ipaddress:3000，默认账号/密码：admin/admin\n添加数据源# 登陆成功后，点击 \u0026ldquo;datasources\u0026rdquo; 按钮，跳转到添加数据源页面，Type 选择 Prometheus 配置如下：\nName: 数据源名称\nURL: Prometheus 地址\nAccess: Server(Default)\n其余默认，点击 \u0026ldquo;Save \u0026amp; Test\u0026rdquo;，如下所示：\n导入 Dashboard# 从 Grafana 官网下载相关 dashboaed 到本地，如：https://grafana.com/dashboards/405\nGrafana首页 =\u0026gt; 左上角图标 =\u0026gt; Dashboard =\u0026gt; Import\n上传已下载至本地的 json 文件或者直接使用 dashboard id，更多 Dashboard 参考，数据源选择之前添加的数据源，点击导入按钮。\n查看 Dashboard# Grafana首页 =\u0026gt; 左上角图标 =\u0026gt; Dashboard =\u0026gt; Home，双击查看创建的 Dashboard 如下：\n"},{"id":81,"href":"/docs/rabbitmq/1.1rabbitmq%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%AE%89%E8%A3%85/","title":"1.1 Rabbit Mq概念及安装","section":"所有文章","content":"消息(Message )是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。\n消息队列（Message Queue）是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从MQ中取消息而不管是谁发布的。发布者和使用者都不用知道对方的存在。\n消息队列应用场景# 消息队列是一种应用间的异步协作机制，以常见的订单系统为例，用户点击【下单】按钮之后的业务逻辑可能包括：扣减库存、生成相应单据、发红包、发短信通知。在业务发展初期这些逻辑可能放在一起同步执行，随着业务的发展订单量增长，需要提升系统服务的性能，这时可以将一些不需要立即生效的操作拆分出来异步执行，比如发放红包、发短信通知等。这种场景下就可以用 MQ，在下单的主流程（比如扣减库存、生成相应单据）完成之后发送一条消息到MQ让主流程快速完结，而由另外的单独线程拉取 MQ 的消息（或者由 MQ 推送消息），当发现 MQ 中有发红包或发短信之类的消息时，执行相应的业务逻辑。以上是用于业务解耦的情况，其它常见场景包括最终一致性、广播、错峰流控等。\nFeatures# RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。\nAMQP(Advanced Message)\n高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。\n可靠性(Reliability)\nRabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。\n灵活的路由(Flexible Routing)\n在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange绑定在一起，也通过插件机制实现自己的 Exchange。\n消息集群(Clustering)\n多个RabbitMQ服务器可以组成一个集群,形成一个逻辑 Broker。\n高可用(Highly Available Queues)\n队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。\n可靠性(Reliability)\nRabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等。\n多语言客户端(Many Clients)\nRabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby 等。\n管理界面(Management UI)\nRabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息Broker的许多方面。\n跟踪机制(Tracing)\n如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。\n插件机制(Plugin System)\nRabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。\n概念模型# 消息模型# 所有 MQ 产品从模型抽象上来说都是一样的过程：消费者（consumer）订阅某个队列。生产者（producer）创建消息，然后发布到队列（queue）中，最后将消息发送到监听的消费者。\nRabbitMQ 基本概念# 上面只是最简单抽象的描述，具体到 RabbitMQ则有更详细的概念需要解释。上面介绍过 RabbitMQ 是 AMQP协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念。\n名词解释# Message\n消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。\nPublisher\n消息的生产者，也是一个向交换器发布消息的客户端应用程序。\nExchange\n交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。\nBinding\n绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，可以将交换器理解成一个由绑定构成的路由表。\nQueue\n消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。\nConnection\n网络连接，比如一个TCP连接。\nChannel\n信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。\nConsumer\n消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。\nVirtual Host\n虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 /。\nBroker\n表示消息队列服务器实体。\n消息路由\nAMQP中增加了Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而Binding决定交换器的消息应该发送到哪个队列。\nRabbitMQ安装# Windows# 安装Erlang# 因为RabbitMQ是用Erlang语言编写的，所以要安装RabbitMQ先要安装Erlang\n下载地址: http://www.erlang.org/downloads 根据需要选择版本 下载完成后直接安装，一路next（路径自行选择） 命令行输入：erl，提示版本信息: Eshell V10.6 (abort with ^G), 说明Erlang安装成功 安装RabbitMQ# 下载地址: https://www.rabbitmq.com/install-windows.html 根据需要选择版本(注意：RabbitMQ和Erlang版本可能存在不匹配情况) 下载完成后直接安装，一路next（路径自行选择） 环境变量配置# 新建环境变量ERLANG_HOME，路径为Erlang安装路径 新建环境变量RABBITMQ_SERVER，路径为RabbitMQ安装路径 在Path中添加ERLANG_HOME和RABBITMQ_SERVER Management Plugin可视化插件# 进入到RabbitMQ安装目录, D:\\RabbitMQ\\rabbitmq_server-3.8.2\\sbin 运行命令：rabbitmq-plugins.bat enable rabbitmq_management 浏览器访问：http://localhost:15672/ 用户名/密码均为: guest Centos# 采用的虚拟机系统为Centos7，采用的安装方式是yum安装，为了简单，直接使用官方提供的 erlang 和 RabbitMQ-server 的自动安装脚本(官方安装文档)，逐行执行下边的代码就可以安装完成 erlang 和 RabbitMQ。\n安装socat# yum install socat\n安装erlang# curl -s https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh | sudo bash yum -y install erlang安装rabbitMQ-server# curl -s https://packagecloud.io/install/repositories/rabbitmq/rabbitmq-server/script.rpm.sh | sudo bash yum -y install rabbitmq-server启动rabbitMQ服务# systemctl start rabbitmq-server添加Web管理插件# rabbitmq-plugins enable rabbitmq_management开放端口# firewall-cmd --zone=public --add-port=5672/tcp --permanent firewall-cmd --zone=public --add-port=15672/tcp --permanent重新加载防火墙# firewall-cmd --reload\n访问Web界面# 默认账号密码都是 guest ，但是如果使用 guest 登录，会出现报错如下：\n原因是 RabbitMQ3.3 以后，guest 账号只能在本机登录。创建其他登录账号然后重启 RabbitMQ 即可。\n创建用户# 如果是登录虚机中的RabbitMq无法使用guest账户,需要创建其他登录账户\n创建用户名admin，密码admin的用户\nrabbitmqctl add_user admin admin设置admin为超级管理员\nrabbitmqctl set_user_tags admin administrator授权远程访问（也可以登录后可视化配置）\nrabbitmqctl set_permissions -p / admin \u0026#34;.\u0026#34; \u0026#34;.\u0026#34; \u0026#34;.*\u0026#34;创建完成后重启RabbitMQ\nsystemctl restart rabbitmq-server`"},{"id":82,"href":"/docs/rabbitmq/1.2%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/","title":"1.2工作模式介绍","section":"所有文章","content":"使用C#连接rabbitMq测试各工作模式区别\nC#创建RabbitMq连接\nnamespace RabbitMQPublisher { using System; using RabbitMQ.Client; public static class BasePublisher { public static ConnectionFactory CreateRabbitMqConnection() { // RabbitMQ连接工厂 return new ConnectionFactory() { HostName = \u0026#34;localhost\u0026#34;, // 用户名 UserName = \u0026#34;guest\u0026#34;, // 密码 Password = \u0026#34;guest\u0026#34;, // 网络故障自动恢复连接 AutomaticRecoveryEnabled = true, // 心跳处理 RequestedHeartbeat = new TimeSpan(5000) }; } } }工作模式# Rabbitmq的几种工作模式，具体可参考官网给出的Demo：https://www.rabbitmq.com/getstarted.html， RPC 模式类似常用的请求-响应模式，这里不过多解释，感兴趣可以参考官网文档：https://www.rabbitmq.com/tutorials/tutorial-six-dotnet.html。 这里只学习其中的1-5种，也可以分类成两种：不使用交换机和使用交换机。\n其实还是使用了交换机的，简单队列和work模式是绑定到了默认的 AMQP default。只不过没有显式声明和绑定而已\n简单队列# “ P”是生产者，“ C”是消费者。中间的框是一个队列-RabbitMQ代表保留的消息缓冲区，这个模式很简单，其实就是只有一个消费者，简单的保证操作的顺序性\nnamespace RabbitMQPublisher { using RabbitMQ.Client; using System; using System.Text; /// \u0026lt;summary\u0026gt; /// 点对点:最简单的工作模式 /// \u0026lt;/summary\u0026gt; internal static class PointToPointPublisher { readonly static string queueName = \u0026#34;test.pointToPoint.queue\u0026#34;; private static void Main(string[] args) { while (true) { Console.WriteLine(\u0026#34;消息发布者:模式{点对点}=\u0026gt;输入消息内容\u0026#34;); string message = Console.ReadLine(); if (!string.IsNullOrEmpty(message)) { // RabbitMQ连接工厂 ConnectionFactory factory = BasePublisher.CreateRabbitMqConnection(); // 建立连接 using IConnection connection = factory.CreateConnection(); // 创建信道 using IModel channel = connection.CreateModel(); // 声明队列 channel.QueueDeclare(queueName, false, false, false, null); // 消息发送 channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queueName, basicProperties: null, body: Encoding.UTF8.GetBytes(message)); } } } } }默认的传统队列是：发布者发布消息，只有一个消费者消费。但是如果消费者多开默认采用轮询(均摊)机制。\n均摊消费，如果每个消费者速度不一样的情况下，均摊消费是不公平的，应该是能者多劳\nWorker# Worker模式是一对多的模式，但是这个一对多并不是像发布订阅那种，而是将消息顺序传输给每个接收者。其实就是简单队列模式下的消费者多开\nExchangesType# Exchange分发消息时根据类型的不同分发策略有区别：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型。\nFanout# 发布订阅模式(fanout)，消息发送到Exchange，所有订阅了当前Exchange的Queue都可以收到消息。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上。每个发到 fanout 类型交换器的消息都会分发到所有绑定的队列上去。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的\n生产者\nnamespace RabbitMQPublisher { using EasyNetQ; using RabbitMQ.Client; using System; using System.Text; /// \u0026lt;summary\u0026gt; /// 发布订阅模式(fanout),消息会发送到exchange,所有订阅了exchange的queue都可以收到消息 /// type=fanout：routingKey不会生效 /// \u0026lt;/summary\u0026gt; internal static class FanoutPublisher { private static void Main(string[] args) { while (true) { Console.WriteLine(\u0026#34;消息发布者:模式{fanout}=\u0026gt;输入消息内容\u0026#34;); string message = Console.ReadLine(); if (!string.IsNullOrEmpty(message)) { // RabbitMQ连接工厂 ConnectionFactory factory = BasePublisher.CreateRabbitMqConnection(); // 建立连接 using IConnection connection = factory.CreateConnection(); // 创建信道 using IModel channel = connection.CreateModel(); // 声明交换机 string exchangeName = $\u0026#34;test.exchange.fanout\u0026#34;; channel.ExchangeDeclare(exchange: exchangeName, type: \u0026#34;fanout\u0026#34;); // 声明队列 string queue1 = \u0026#34;test.fanout.queue1\u0026#34;; channel.QueueDeclare(queue1, false, false, false, null); string queue2 = \u0026#34;test.fanout.queue2\u0026#34;; channel.QueueDeclare(queue2, false, false, false, null); // 将队列与交换机进行绑定 channel.QueueBind(queue: queue1, exchange: exchangeName, routingKey: \u0026#34;fanout\u0026#34;); channel.QueueBind(queue: queue2, exchange: exchangeName, routingKey: \u0026#34;\u0026#34;); channel.BasicPublish(exchange: exchangeName, routingKey: \u0026#34;\u0026#34;, basicProperties: null, body: Encoding.UTF8.GetBytes(message)); } } } } }\n这里虽然绑定 q1 时指定了 routingkey=\u0026quot;fanout\u0026quot; 但是q1/q2 都正常收到了消息，证实上面说的“fanout 交换器不处理路由键”。\n消费者\nnamespace RabbitMQConsumer { using RabbitMQ.Client; using RabbitMQ.Client.Events; using System; using System.Text; internal static class FanoutConsumer { private static void Main(string[] args) { Console.WriteLine(\u0026#34;input queueName...\u0026#34;); var input = Console.ReadLine(); ConnectionFactory factory = BaseConsumer.CreateRabbitMqConnection(); using IConnection connection = factory.CreateConnection(); using IModel channel = connection.CreateModel(); EventingBasicConsumer consumer = new(channel); channel.BasicQos(0, 1, false); switch (input) { case \u0026#34;1\u0026#34;: channel.BasicConsume(queue: \u0026#34;test.fanout.queue1\u0026#34;, autoAck: false, consumer: consumer); // 绑定消息接收后的事件委托 consumer.Received += (model, message) =\u0026gt; { Console.WriteLine($\u0026#34;Message:{Encoding.UTF8.GetString(message.Body.ToArray())}\u0026#34;); channel.BasicAck( deliveryTag: message.DeliveryTag, // 是否一次性确认多条数据 multiple: false); }; Console.ReadLine(); break; case \u0026#34;2\u0026#34;: channel.BasicConsume(queue: \u0026#34;test.fanout.queue2\u0026#34;, autoAck: false, consumer: consumer); // 绑定消息接收后的事件委托 consumer.Received += (model, message) =\u0026gt; { Console.WriteLine($\u0026#34;Message:{Encoding.UTF8.GetString(message.Body.ToArray())}\u0026#34;); channel.BasicAck( deliveryTag: message.DeliveryTag, // 是否一次性确认多条数据 multiple: false); }; Console.ReadLine(); break; } } } }Direct# direct跟fanout的区别在于多了routekey，消息发送到Exchange，所有订阅了当前Exchange并且routingKey完全匹配的Queue才可以收到消息。消息中的路由键（routing key）如果和 Binding 中的 binding key 一致，交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。\nnamespace RabbitMQPublisher { using System; using System.Text; using RabbitMQ.Client; /// \u0026lt;summary\u0026gt; /// 路由模式(direct),消息会发送到exchange /// 所有订阅了当前Exchange并且routingKey完全匹配的Queue都可以收到消息 /// \u0026lt;/summary\u0026gt; static class DirectPublisher { static void Main(string[] args) { while (true) { Console.WriteLine(\u0026#34;消息发布者:模式{direct}=\u0026gt;输入消息内容\u0026#34;); string message = Console.ReadLine(); if (!string.IsNullOrEmpty(message)) { ConnectionFactory factory = BasePublisher.CreateRabbitMqConnection(); using var connection = factory.CreateConnection(); using var channel = connection.CreateModel(); // 声明交换机 string exchangeName = $\u0026#34;test.exchange.direct\u0026#34;; channel.ExchangeDeclare(exchange: exchangeName, type: \u0026#34;direct\u0026#34;); // 声明队列 string queue1 = \u0026#34;test.direct.queue1\u0026#34;; channel.QueueDeclare(queue1, false, false, false, null); string queue2 = \u0026#34;test.direct.queue2\u0026#34;; channel.QueueDeclare(queue2, false, false, false, null); //将队列与交换机进行绑定 channel.QueueBind(queue: queue1, exchange: exchangeName, routingKey: \u0026#34;fanout\u0026#34;); channel.QueueBind(queue: queue2, exchange: exchangeName, routingKey: \u0026#34;\u0026#34;); // 只有queue1可以收到消息,因为queue2的routingKey不匹配 channel.BasicPublish(exchange: exchangeName, routingKey: \u0026#34;fanout\u0026#34;, basicProperties: null, body: Encoding.UTF8.GetBytes(message)); } } } } }Topic# topic符模式与路由模式一致，只不过通配符模式中的路由可以声明为模糊查询，RabbitMQ拥有两个通配符；topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号 # 和符号 *。# 匹配0个或多个单词，* 匹配一个单词\n#：匹配0-n个字符语句 *：匹配一个字符语句 注意：RabbitMQ中通配符并不像正则中的单个字符，而是一个以“.”分割的字符串，如 ”topic1.*“匹配的规则以topic1开始并且\u0026quot;.\u0026ldquo;后只有一段语句的路由。例：\u0026ldquo;topic1.aaa\u0026rdquo;，\u0026ldquo;topic1.bb\u0026rdquo;\nnamespace RabbitMQPublisher { using System; using System.Text; using RabbitMQ.Client; /// \u0026lt;summary\u0026gt; /// 路由模式(topic),消息会发送到exchange /// topic与direct模式区别在于routingKey可以声明为模糊查询，RabbitMQ拥有两个通配符 /// #：匹配0-n个字符语句 /// *：匹配一个字符语句 /// \u0026lt;/summary\u0026gt; static class TopicPublisher { static void Main(string[] args) { while (true) { Console.WriteLine(\u0026#34;消息发布者:模式{topic}=\u0026gt;输入消息内容\u0026#34;); string message = Console.ReadLine(); if (!string.IsNullOrEmpty(message)) { ConnectionFactory factory = BasePublisher.CreateRabbitMqConnection(); using var connection = factory.CreateConnection(); using var channel = connection.CreateModel(); // 声明交换机 string exchangeName = $\u0026#34;test.exchange.topic\u0026#34;; channel.ExchangeDeclare(exchange: exchangeName, type: \u0026#34;topic\u0026#34;); // 声明队列 string queue1 = \u0026#34;test.topic.queue1\u0026#34;; channel.QueueDeclare(queue1, false, false, false, null); string queue2 = \u0026#34;test.topic.queue2\u0026#34;; channel.QueueDeclare(queue2, false, false, false, null); //将队列与交换机进行绑定 channel.QueueBind(queue: queue1, exchange: exchangeName, routingKey: \u0026#34;topic.*\u0026#34;); channel.QueueBind(queue: queue2, exchange: exchangeName, routingKey: \u0026#34;topic.#\u0026#34;); #if debug // queue1和queue2都可以收到消息 channel.BasicPublish( exchange: exchangeName, routingKey: \u0026#34;topic.test\u0026#34;, basicProperties: null, body: Encoding.UTF8.GetBytes(message)); #endif // 只有queue2可以收到消息,因为.#可以匹配一个或者多个字符语句而.*只能匹配单个 channel.BasicPublish( exchange: exchangeName, routingKey: \u0026#34;topic.test.test\u0026#34;, basicProperties: null, body: Encoding.UTF8.GetBytes(message)); } } } } }发布,路由,通配符这三种模式可以算为一种模式，区别仅仅是交互机类型不同.发送者将消息发送发送到交换机，接收者创建各自的消息队列绑定到交换机。\nMandatory参数# 注意：channel.BasicPublish()，mandatory 参数指定交换器无法根据自身类型和路由键找到一个符合条件的队列时的处理方式。\ntrue：RabbitMQ会调用Basic.Return命令将消息返回给生产者 false：RabbitMQ会把消息直接丢弃 internal static class PointToPointPublisher { readonly static string queueName = \u0026#34;test.pointToPoint.queue\u0026#34;; private static void Main(string[] args) { while (true) { Console.WriteLine(\u0026#34;消息发布者:模式{点对点}=\u0026gt;输入消息内容\u0026#34;); string message = Console.ReadLine(); if (!string.IsNullOrEmpty(message)) { // RabbitMQ连接工厂 ConnectionFactory factory = BasePublisher.CreateRabbitMqConnection(); // 建立连接 using IConnection connection = factory.CreateConnection(); // 创建信道 using IModel channel = connection.CreateModel(); #if mandatory // 声明队列 channel.QueueDeclare(queueName, false, false, false, null); #endif // 消息发送 channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queueName, basicProperties: null, body: Encoding.UTF8.GetBytes(message)); } } } }这里发送消息时rabbitMq 中并没有名称为 test.pointToPoint.queue 的队列，这里没有设置 mandatory 参数所以消息会默认被丢弃，可以使用BasicReturn 来获取没有正常发送到队列中的消息。\n// 消息发送 channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queueName, basicProperties: null, body: Encoding.UTF8.GetBytes(message), mandatory: true); // 获取没有正常发送到队列中的消息 channel.BasicReturn += (sender, message) =\u0026gt; { Console.WriteLine(Encoding.UTF8.GetString(message.Body.ToArray())); };Exchange：AMQP default# Default exchange：\nThe default exchange is implicitly bound to every queue, with a routing key equal to the queue name. It is not possible to explicitly bind to, or unbind from the default exchange. It also cannot be deleted.\n译：默认交换器隐式地绑定到每个队列，其路由键等于队列名。 不可能显式地绑定到默认交换，或从默认交换取消绑定。 也不能删除。\n这里是说每个 queue 都会默认绑定到这个AMQP default 这个交换器，不能显式手动绑定也不能解绑或者删除。\n// 消息发送 channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: \u0026#34;test.pointToPoint.queue\u0026#34;, basicProperties: null, body: Encoding.UTF8.GetBytes(message));这里发布消息时没有指定 exchange，队列名称就是routingKey。\nQos机制# 当生产者将消息发布到rabbitmq之后，如果在未配置 QOS 的情况下，rabbitmq尽可能快速地发送队列中的所有消息到消费者端，如果消息比较多，消费者来不及处理，就会缓存这些消息，当消息堆积过多，可能导致服务器内存不足而影响其他进程，rabbitmq的QOS可以很好的解决这类问题，QOS 就是限制消费者一次性从rabbitmq中获取消息的个数，而不是获取所有消息。比如设置rabbitmq的QOS为10，也就是 prefetch=10 ，就是说哪怕rabbitmq中有100条消息，消费者也只是一次性获取10条，然后消费者消费这10条消息，剩下的交给其他消费者，当10条消息中的 unacked 个数少于prefetch * 消费者数目时，会继续从rabbitmq获取消息，如果在工作模式中，不使用QOS，你会发现所有的消息都被一个消费者消费了。\n"},{"id":83,"href":"/docs/rabbitmq/1.3%E6%B6%88%E6%81%AF%E7%A1%AE%E8%AE%A4%E5%8F%8A%E6%8C%81%E4%B9%85%E5%8C%96/","title":"1.3消息确认及持久化","section":"所有文章","content":"学习rabbitMq中的消息确认和持久化机制\n生产端消息确认# tx机制# tx机制叫做事务机制，RabbitMQ中有三个与tx机制的方法：txSelect()、txCommit()、txRollback()\nchannel.txSelect()： 用于将当前channel设置成transaction模式 channel.txCommit() ：提交事务 channel.txRollback() ：回滚事务 使用 tx 机制，首先要通过txSelect 方法开启事务，然后发布消息给 broker 服务器，如果 txCommit 提交成功，则说明消息成功被 broker 接收；如果在txCommit 执行之前 broker 异常崩溃或者由于其他原因抛出异常，这个时候可以捕获异常，通过 txRollback 回滚事务。\n/// \u0026lt;summary\u0026gt; /// 生产端消息确认(tx事务机制) /// \u0026lt;/summary\u0026gt; [TestMethod] public void PublisherTest_Transaction() { channel.QueueDeclare(queue: queueName, durable: false, exclusive: false, autoDelete: false, arguments: null); string message = \u0026#34;hello world\u0026#34;; byte[] messageBody = Encoding.UTF8.GetBytes(message); try { // 开启tx事务机制 channel.TxSelect(); // 消息发送 channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queueName, basicProperties: null, body: messageBody); // 事务提交 channel.TxCommit(); } catch (Exception ex) { // 事务回滚 channel.TxRollback(); Assert.Fail(ex.Message); } }Confirm模式# C#的RabbitMQ API中，有三个与Confirm相关的方法：ConfirmSelect()、WaitForConfirms()、WaitForConfirmOrDie\nchannel.ConfirmSelect() ：表示开启Confirm模式 channel.WaitForConfirms() ：等待所有消息确认，如果所有的消息都被服务端成功接收返回true，只要有一条没有被成功接收就返回false channel.WaitForConfirmsOrDie()和WaitForConfirms作用类型，也是等待所有消息确认。区别在于该方法没有返回值(Void)，如果有任意一条消息没有被成功接收，该方法会立即抛出OperationInterrupedException类型异常 /// \u0026lt;summary\u0026gt; /// 生产端消息确认(Confirm模式) /// \u0026lt;/summary\u0026gt; [TestMethod] public void PublisherTest_Confirm() { channel.QueueDeclare(queue: queueName, durable: false, exclusive: false, autoDelete: false, arguments: null); string message = \u0026#34;hello world\u0026#34;; byte[] messageBody = Encoding.UTF8.GetBytes(message); // 开启Confirm模式 channel.ConfirmSelect(); // 消息发送 channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queueName, basicProperties: null, body: messageBody); // WaitForConfirms确认消息(可以同时确认多条消息)是否发送成功 if (channel.WaitForConfirms()) { Console.WriteLine($\u0026#34;Message发送成功\u0026#34;); } else { Assert.Fail(); } }消费端消息确认# 自动确认# 当RabbbitMQ将消息发送给消费者后，消费者接收到消息后，不等待消息处理结束，立即自动回送一个确认回执。自动确认的用法十分简单，设置消费方法的参数 autoAck 为 true 即可\nEventingBasicConsumer consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u0026gt; { string message = Encoding.UTF8.GetString(ea.Body.ToArray()); }; channel.BasicConsume(queue: \u0026#34;hello\u0026#34;, autoAck: true, consumer: consumer);可能存在的问题：\n丢失数据：Broker会在接收到确认回执时删除消息，如果消费者接收到消息并返回了确认回执，然后这个消费者在处理消息时挂了，那么这条消息就再也找不回来了 只要队列不空，RabbitMQ会源源不断的把消息推送给客户端，而不管客户端能否消费的完，如果其中一个消费端消费的较慢,会极大的浪费性能 手动确认(BasicAck)# 消费从队列中获取消息后，服务器会将该消息处于不可用状态，等待消费者反馈。Resume方法的参数autoAck设置为false，然后在消费端使用代码 channel.BasicAck()/BasicReject()等方法来确认和拒绝消息即可实现手动确认\nEventingBasicConsumer consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u0026gt; { string message = Encoding.wUTF8.GetString(ea.Body.ToArray()); // 手动ack channel.BasicAck( deliveryTag: ea.DeliveryTag, multiple: false); }; channel.BasicConsume(queue: \u0026#34;hello\u0026#34;, autoAck: false, consumer: consumer);改为手动确认方式只需改两处\n开启监听时将 autoAck 参数改为 false 消息消费成功后返回确认 这段代码中，先处理消息，成功后再做 ack响应，失败就不做 ack响应，这样消息会储存在MQ的Unacked消息里，不会丢失，看起来没啥问题，但是如果其中一条消息在处理时抛出了异常，将导致后续所有消息都会无法消费。\n消息拒绝# BasicNack()# 与BasicReject()不同的是同时支持多个消息，可以nack 该消费者先前接收未ack 的所有消息\nEventingBasicConsumer consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u0026gt; { string message = Encoding.UTF8.GetString(ea.Body.ToArray()); try { /* 消费到某条消息时出错 * 导致Broker无法拿到正常回执信息引发后续消息都无法被正常消费 * 如果MQ没得到ack响应，这些消息会堆积在Unacked消息里,不会丢弃,直至客户端断开重连时，才变回ready * 如果Consumer客户端不断开连接，这些Unacked消息，永远不会变回ready状态 * Unacked消息多了,占用内存越来越大,就会异常 */ MessageConsumer(ea); channel.BasicAck( deliveryTag: ea.DeliveryTag, multiple: false); } catch (Exception ex) { // 出错了，发nack，并通知MQ把消息塞回的队列头部（不是尾部） channel.BasicNack( deliveryTag: ea.DeliveryTag, multiple: false, requeue: true); } }; channel.BasicConsume(queue: \u0026#34;hello\u0026#34;, autoAck: false, consumer: consumer);这里将代码调整为消费正常就 ack，不正常就nack，并等下一次重新消费。看起来没问题，但是如果某条消息在消费时又抛出异常，该消息将会被Nack机制重新扔回 队列头部，下一步又消费这条会出异常的消息，又出错，塞回队列……进入死循环，所以要谨慎使用Nack机制。这里可以在catch中记录错误日志依旧使用ack确认消费。\nBasicReject()# 消费端告诉服务器这个消息拒绝接收，不处理，可以设置是否放回到队列中还是丢掉(只能一次拒绝一个消息)\nMessagePublisher(\u0026#34;hello\u0026#34;, $\u0026#34;1\u0026#34;); MessagePublisher(\u0026#34;hello\u0026#34;, $\u0026#34;2\u0026#34;); MessagePublisher(\u0026#34;hello\u0026#34;, $\u0026#34;3\u0026#34;); channel.QueueDeclare( queue: \u0026#34;hello\u0026#34;, durable: false, exclusive: false, autoDelete: false, arguments: null); EventingBasicConsumer consumer = new EventingBasicConsumer(channel); channel.BasicQos(0, 1, false); consumer.Received += (model, ea) =\u0026gt; { string message = Encoding.UTF8.GetString(ea.Body.ToArray()); if (message == \u0026#34;2\u0026#34;) { Console.WriteLine($\u0026#34;Message：{message}\u0026#34;); channel.BasicAck( deliveryTag: ea.DeliveryTag, multiple: false); } else { Console.WriteLine($\u0026#34;拒绝处理\u0026#34;); /* BasicReject用于拒绝消息 requeue参数指定了拒绝后是否重新放回queue 一次只能拒绝一条消息 设置为true: 消息会被重新仍回queue中 设置为false:消息将被丢弃 */ channel.BasicReject( deliveryTag: ea.DeliveryTag, requeue: true); } }; channel.BasicConsume(queue: \u0026#34;hello\u0026#34;, autoAck: false, consumer: consumer);BasicRecover()# 路由不成功的消息可以使用recovery重新发送到队列中,参数是是否requeue，true则重新入队列，并且尽可能的将之前recover的消息投递给其他消费者消费，而不是自己再次消费。false则消息会重新被投递给自己\n消息持久化 Persistent# 参数 重启RabbitMQ exchange.durable=fasle/queue.durable=false exchange/queue将会被丢弃 exchange.durable=fasle exchange将会被丢弃 queue.durable=fasle queue将会被丢弃 exchange.durable=fasle/queue.durable=true exchange将会被丢弃,queue虽然会存在,但队列内消息会全部丢失 exchange.durable=true/queue.durable=true exchange/queue会存在,但队列内消息会全部丢失 exchange.durable=true\u0026amp;\u0026amp;queue.durable=true/消息发布时(persistent=true) 消息真正的持久化 for (int i = 0; i \u0026lt; 100; i++) { byte[] messageBody = Encoding.UTF8.GetBytes(i.ToString()); // 设置消息持久化 var props = channel.CreateBasicProperties(); props.Persistent = true; // 消息发送 channel.BasicPublish( exchange: \u0026#34;TestExchange\u0026#34;, routingKey: \u0026#34;\u0026#34;, basicProperties: props, body: messageBody); }消息优先级 Priority# queue是先进先出的，即先发送的消息先被消费。但是在具体业务中可能会遇到要提前处理某些消息的需求，如一个常见的需求：普通客户的消息按先进先出的顺序处理，vip客户的消息要提前处理。消息实现优先级控制的实现方式是：首先在声明queue是设置队列的x-max-priority属性，然后在publish消息时，设置消息的优先级等级即可\n/// \u0026lt;summary\u0026gt; /// 消息优先级 /// \u0026lt;/summary\u0026gt; [TestMethod] public void PublisherTest_Priority() { channel.QueueDeclare(queue: queueName, durable: false, exclusive: false, autoDelete: false, arguments: new Dictionary\u0026lt;string, object\u0026gt;() { // 队列优先级最高为10，不加x-max-priority的话，消息发布时设置了消息的优先级也不会生效 {\u0026#34;x-max-priority\u0026#34;,10 } }); // 测试数据 string[] msgs = { \u0026#34;vip1\u0026#34;, \u0026#34;hello1\u0026#34;, \u0026#34;hello2\u0026#34;, \u0026#34;hello3\u0026#34;, \u0026#34;vip5\u0026#34; }; // 设置消息优先级 IBasicProperties props = channel.CreateBasicProperties(); foreach (string msg in msgs) { // vip开头的消息，优先级设置为9,其他消息优先级为1 if (msg.StartsWith(\u0026#34;vip\u0026#34;)) props.Priority = 9; else props.Priority = 1; channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queueName, basicProperties: props, body: Encoding.UTF8.GetBytes(msg)); } Assert.IsTrue(true); }"},{"id":84,"href":"/docs/rabbitmq/1.4%E4%B8%A4%E7%A7%8D%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F%E5%92%8Cqos%E7%9A%84%E5%AE%9E%E7%8E%B0/","title":"1.4两种消费模式和 Qos的实现","section":"所有文章","content":"学习rabbitMq的消费模式\n消费模式# EventingBasicConsumer# EventingBasicConsumer 是发布/订阅模式的消费者，即只要订阅的 queue 中有了新消息，Broker就会立即把消息推送给消费者，这种模式可以保证消息及时地被消费者接收到。EventingBasicConsumer 是长连接的，只需要创建一个 Connection ,然后在 Connection 的基础上创建通道 channel，消息的发送都是通过 channel 来执行的，这样可以减少 Connection 的创建，比较节省资源。之前一直使用的就是 EventingBasicConsumer 不再赘述。\nBasicGet# EventingBasicConsumer 可以让消费者最及时地获取到消息，使用 EventingBasicConsumer 模式时消费者在被动的接收消息，即消息是推送过来的，Broker是主动的一方，如果想让消费者作为主动的一方什么时候想要消息了，就自己发送一个请求去找Broker可以使用Get方式。Get方式是短连接的，消费者每次想要消息的时候，首先建立一个connection，发送一次请求，Broker接收到请求后，响应一条消息给消费者，然后断开连接。RabbitMQ中Get方式和HTTP的请求响应流程基本一样，Get方式的实时性比较差，也比较耗费资源。\nBasicGetResult result = channel.BasicGet(queue: \u0026#34;test\u0026#34;, autoAck: true); Assert.IsNotNull(result.Body.ToArray()); Console.WriteLine($\u0026#34;接收到消息{Encoding.UTF8.GetString(result.Body.ToArray())}\u0026#34;); // 打印exchange和routingKey Console.WriteLine($\u0026#34;exchange：{result.Exchange},routingKey:{result.RoutingKey}\u0026#34;);QueueBaicConsumer# 用法和Get方式类似，QueueBaicConsumer在官方API中标记已过时，不再介绍。\nBasicQos# 当消息有十万，百万条时，一股脑把消息发送给消费者，可能会造成消费者内存爆满 当消息处理比较慢的时，单一的消费者处理这些消息可能很长时间，自然想到再添加一个消费者加快消息的处理速度，但是这些消息都被原来的消费者接收了，状态为Unacked，所以这些消息不会再发送给新添加的消费者 RabbitMQ提供的Qos(服务质量)可以完美解决上边的问题，使用Qos时，Broke不会再把消息全部发送给消费者，可以设置每次传输给消费者的消息条数n，消费者把这n条消息处理完成后，再获取n条数据进行处理，这样就不用担心消息丢失、服务端内存爆满的问题，因为没有发送的消息状态都是Ready，所以新增一个消费者时，消息也可以立即发送给新增的消费者。\n使用Qos的方式十分简单,在消费端调用channel.BasicQos()方法即可。\nchannel.BasicQos(prefetchSize: 0, prefetchCount: 2, global: false);"},{"id":85,"href":"/docs/rabbitmq/1.5channel%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95/","title":"1.5 Channel常见方法","section":"所有文章","content":"记录rabbitMq中Channel常见的方法\nchannel.exchangeDeclare()# type：direct、fanout、topic durable：(true、false) true：服务器重启会保留下来Exchange。警告：仅设置此选项，不代表消息持久化。即不保证重启后消息还在。 原文：true if we are declaring a durable exchange (the exchange will survive a server restart\nautoDelete：(true、false) true：当已经没有消费者时，服务器是否可以删除该Exchange 原文：true if the server should delete the exchange when it is no longer in use\n/** * Declare an exchange. * @see com.rabbitmq.client.AMQP.Exchange.Declare * @see com.rabbitmq.client.AMQP.Exchange.DeclareOk * @param exchange the name of the exchange * @param type the exchange type * @param durable true if we are declaring a durable exchange (the exchange will survive a server restart) * @param autoDelete true if the server should delete the exchange when it is no longer in use * @param arguments other properties (construction arguments) for the exchange * @return a declaration-confirm method to indicate the exchange was successfully declared * @throws java.io.IOException if an error is encountered */ Exchange.DeclareOk exchangeDeclare(String exchange, String type, boolean durable, boolean autoDelete, Map\u0026lt;String, Object\u0026gt; arguments) throws IOException;chanel.basicQos()# prefetchSize：0 prefetchCount：会告诉RabbitMQ不要同时给一个消费者推送多于N个消息，即一旦有N个消息还没有ack，则该consumer将block掉，直到有消息ack global：true\\false 是否将上面设置应用于channel，简单点说，就是上面限制是channel级别的还是consumer级别 备注：据说prefetchSize 和global这两项，rabbitmq没有实现，暂且不研究\n/** * Request specific \u0026#34;quality of service\u0026#34; settings. * * These settings impose limits on the amount of data the server * will deliver to consumers before requiring acknowledgements. * Thus they provide a means of consumer-initiated flow control. * @see com.rabbitmq.client.AMQP.Basic.Qos * @param prefetchSize maximum amount of content (measured in * octets) that the server will deliver, 0 if unlimited * @param prefetchCount maximum number of messages that the server * will deliver, 0 if unlimited * @param global true if the settings should be applied to the * entire channel rather than each consumer * @throws java.io.IOException if an error is encountered */ void basicQos(int prefetchSize, int prefetchCount, boolean global) throws IOException;channel.basicPublish()# routingKey：路由键，#匹配0个或多个单词，*匹配一个单词，在topic exchange做消息转发用 mandatory：true：如果exchange根据自身类型和消息routeKey无法找到一个符合条件的queue，那么会调用basic.return方法将消息返还给生产者。false：出现上述情形broker会直接将消息扔掉 immediate：true：如果exchange在将消息route到queue(s)时发现对应的queue上没有消费者，那么这条消息不会放入队列中。当与消息routeKey关联的所有queue(一个或多个)都没有消费者时，该消息会通过basic.return方法返还给生产者。 BasicProperties ：需要注意的是BasicProperties.deliveryMode，0:不持久化 1：持久化 这里指的是消息的持久化，配合channel(durable=true),queue(durable)可以实现，即使服务器宕机，消息仍然保留 简单来说：mandatory标志告诉服务器至少将该消息route到一个队列中，否则将消息返还给生产者；immediate标志告诉服务器如果该消息关联的queue上有消费者，则马上将消息投递给它，如果所有queue都没有消费者，直接把消息返还给生产者，不用将消息入队列等待消费者了\n/** * Publish a message. * * Publishing to a non-existent exchange will result in a channel-level * protocol exception, which closes the channel. * * Invocations of \u0026lt;code\u0026gt;Channel#basicPublish\u0026lt;/code\u0026gt; will eventually block if a * \u0026lt;a href=\u0026#34;http://www.rabbitmq.com/alarms.html\u0026#34;\u0026gt;resource-driven alarm\u0026lt;/a\u0026gt; is in effect. * * @see com.rabbitmq.client.AMQP.Basic.Publish * @see \u0026lt;a href=\u0026#34;http://www.rabbitmq.com/alarms.html\u0026#34;\u0026gt;Resource-driven alarms\u0026lt;/a\u0026gt;. * @param exchange the exchange to publish the message to * @param routingKey the routing key * @param mandatory true if the \u0026#39;mandatory\u0026#39; flag is to be set * @param immediate true if the \u0026#39;immediate\u0026#39; flag is to be * set. Note that the RabbitMQ server does not support this flag. * @param props other properties for the message - routing headers etc * @param body the message body * @throws java.io.IOException if an error is encountered */ void basicPublish(String exchange, String routingKey, boolean mandatory, boolean immediate, BasicProperties props, byte[] body) throws IOException;channel.basicAck()# deliveryTag：该消息的index multiple：是否批量；true:将一次性ack所有小于deliveryTag的消息 /** * Acknowledge one or several received * messages. Supply the deliveryTag from the {@link com.rabbitmq.client.AMQP.Basic.GetOk} * or {@link com.rabbitmq.client.AMQP.Basic.Deliver} method * containing the received message being acknowledged. * @see com.rabbitmq.client.AMQP.Basic.Ack * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver} * @param multiple true to acknowledge all messages up to and * including the supplied delivery tag; false to acknowledge just * the supplied delivery tag. * @throws java.io.IOException if an error is encountered */ void basicAck(long deliveryTag, boolean multiple) throws IOException;channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, true)# deliveryTag：该消息的index multiple：是否批量.true:将一次性拒绝所有小于deliveryTag的消息 requeue：被拒绝的是否重新入队列 /** * Reject one or several received messages. * * Supply the \u0026lt;code\u0026gt;deliveryTag\u0026lt;/code\u0026gt; from the {@link com.rabbitmq.client.AMQP.Basic.GetOk} * or {@link com.rabbitmq.client.AMQP.Basic.GetOk} method containing the message to be rejected. * @see com.rabbitmq.client.AMQP.Basic.Nack * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver} * @param multiple true to reject all messages up to and including * the supplied delivery tag; false to reject just the supplied * delivery tag. * @param requeue true if the rejected message(s) should be requeued rather * than discarded/dead-lettered * @throws java.io.IOException if an error is encountered */ void basicNack(long deliveryTag, boolean multiple, boolean requeue) throws IOException;channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false)# deliveryTag：该消息的index requeue：被拒绝的是否重新入队列 channel.basicNack 与 channel.basicReject 的区别在于basicNack可以拒绝多条消息，而basicReject一次只能拒绝一条消息\n/** * Reject a message. Supply the deliveryTag from the {@link com.rabbitmq.client.AMQP.Basic.GetOk} * or {@link com.rabbitmq.client.AMQP.Basic.Deliver} method * containing the received message being rejected. * @see com.rabbitmq.client.AMQP.Basic.Reject * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver} * @param requeue true if the rejected message should be requeued rather than discarded/dead-lettered * @throws java.io.IOException if an error is encountered */ void basicReject(long deliveryTag, boolean requeue) throws IOException;channel.basicConsume(queueName, true, consumer)# autoAck：是否自动ack，如果不自动ack，需要使用channel.ack、channel.nack、channel.basicReject 进行消息应答 /** * Start a non-nolocal, non-exclusive consumer, with * a server-generated consumerTag. * @param queue the name of the queue * @param autoAck true if the server should consider messages * acknowledged once delivered; false if the server should expect * explicit acknowledgements * @param callback an interface to the consumer object * @return the consumerTag generated by the server * @throws java.io.IOException if an error is encountered * @see com.rabbitmq.client.AMQP.Basic.Consume * @see com.rabbitmq.client.AMQP.Basic.ConsumeOk * @see #basicConsume(String, boolean, String, boolean, boolean, Map, Consumer) */ String basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;chanel.exchangeBind()# channel.queueBind(queueName, EXCHANGE_NAME, bindingKey)；用于通过绑定bindingKey将queue到Exchange，之后便可以进行消息接收\n/** * Bind an exchange to an exchange, with no extra arguments. * @see com.rabbitmq.client.AMQP.Exchange.Bind * @see com.rabbitmq.client.AMQP.Exchange.BindOk * @param destination the name of the exchange to which messages flow across the binding * @param source the name of the exchange from which messages flow across the binding * @param routingKey the routine key to use for the binding * @return a binding-confirm method if the binding was successfully created * @throws java.io.IOException if an error is encountered */ Exchange.BindOk exchangeBind(String destination, String source, String routingKey) throws IOException;channel.queueDeclare(queueName, false, false, false, null)# durable：(true、false) true：在服务器重启时，能够存活 exclusive ：是否为当前连接的专用队列，在连接断开后，会自动删除该队列，生产环境中应该很少用到 autodelete：当没有任何消费者使用时，自动删除该队列 this means that the queue will be deleted when there are no more processes consuming messages from it.)\n/** * Declare a queue * @see com.rabbitmq.client.AMQP.Queue.Declare * @see com.rabbitmq.client.AMQP.Queue.DeclareOk * @param queue the name of the queue * @param durable true if we are declaring a durable queue (the queue will survive a server restart) * @param exclusive true if we are declaring an exclusive queue (restricted to this connection) * @param autoDelete true if we are declaring an autodelete queue (server will delete it when no longer in use) * @param arguments other properties (construction arguments) for the queue * @return a declaration-confirm method to indicate the queue was successfully declared * @throws java.io.IOException if an error is encountered */ Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map\u0026lt;String, Object\u0026gt; arguments) throws IOException;arguments中可以设置的常用属性\n参数名 作用 示例 示例描述 Message TTL 设置队列中消息的有效时间 { \u0026ldquo;x-message-ttl\u0026rdquo;,1000*8} 设置队列中的所有消息的有效期为8s Auto expire 一定的时间内队列没有被使用，则自动删除队列 {\u0026ldquo;x-expires\u0026rdquo;,1000*60} 如果60s没有队列被访问，则删除队列 Max length 队列能保存消息的最大条数 {\u0026ldquo;x-max-length\u0026rdquo;,100 } 设置队列最多保存100条消息 Max length bytes 队列中ready类型消息的总字节数 {\u0026ldquo;x-max-length-bytes\u0026rdquo;,1000 } 设置队列中ready类型消息总共不能超过1000字节 Overflow behaviour 当队列消息满了时，再接收消息时的处理方法。有两种处理方案：默认为\u0026quot;drop-head\u0026quot;模式，表示从队列头部丢弃消息；\u0026ldquo;reject-publish\u0026quot;表示不接收后续的消息 {\u0026ldquo;x-overflow\u0026rdquo;,\u0026ldquo;reject-publish\u0026rdquo; } 设置当队列消息满了时,丢弃传来后续消息 Dead letter exchange 用于存储被丢弃的消息的交换机名。Overflow behaviour 的两种处理方案中丢弃的消息都会发送到这个交换机 {\u0026ldquo;x-dead-letter-exchange\u0026rdquo;,\u0026ldquo;beiyongExchange\u0026rdquo; } 设置丢弃的消息发送到名字为beiyongExchange的交换机 Dead letter routing key 被丢弃的消息发送到Dead letter exchange时的使用的routing Key {\u0026ldquo;x-dead-letter-routing-key\u0026rdquo;,\u0026ldquo;deadKey\u0026rdquo; } 设置丢弃的消息发送到beiyongExchange交换机时的RoutingKey值是\u0026quot;deadKey\u0026rdquo; Maximum priority 设置队列中消息优先级的最大等级，在publish消息时可以设置单条消息的优先级等级 {\u0026ldquo;x-max-priority\u0026rdquo;,10 } 设置中消息优先级的最大等级为10 Lazy mode 设置队列的模式，如果设置为Lazy表示队列中消息尽可能存放在磁盘中，以减少内存占用；不设置时消息都存放在队列中，用以尽可能快的处理消息 {\u0026ldquo;x-queue-mode\u0026rdquo;,\u0026ldquo;lazy\u0026rdquo;} 3.6以后版本可用，设置队列中消息尽可能存放在磁盘中，以减少内存占用。在消息拥堵时和消息持久化配置使用可以减少内存占用 "},{"id":86,"href":"/docs/rabbitmq/1.6rabbitmq%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"1.6 Rabbit Mq常用命令","section":"所有文章","content":"记录rabbitMq中常见的命令\n用户角色分类# none# 通常就是普通的生产者和消费者,无法登录控制台,不能访问 management plugin ，通常就是普通的生产者和消费者。\nmanagement# 普通管理者，仅可登陆管理控制台(启用 management plugin 的情况下)，无法看到节点信息，也无法对 policies 进行管理。可以通过 AMQP 做的任何事外加：\n列出自己可以通过AMQP登入的 virtual hosts 查看自己的 virtual hosts 中的 queues, exchanges 和 bindings 查看和关闭自己的 channels 和 connections 查看有关自己的 virtual hosts的全局统计信息，包含其他用户在这些 virtual hosts中的活动 policymaker# 策略制定者，management可以做的任何事外加：\n查看、创建和删除自己的 virtual hosts所属的 policies和 parameters\nmonitoring# 监控者，management可以做的任何事外加：\n列出所有virtual hosts，包括他们不能登录的virtual hosts\n查看其他用户的 connections和 channels\n查看节点级别的数据如 clustering和 memory使用情况\n查看真正的关于所有 virtual hosts的全局的统计信息\n同时可以查看 rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)\nadministrator# 超级管理员，policymaker和monitoring可以做的任何事外加:\n创建和删除virtual hosts\n查看、创建和删除 users\n查看创建和删除 permissions\n关闭其他用户的 connections\nRabbitMQ Control# 使用Web管理界面可以实现RabbitMQ的大部分常用功能，但是有些功能WebUI是做不到的，如：开启/关闭RabbitMQ应用程序和集群的管理等。RabbitMQ Control是RabbitMQ的命令行管理工具，可以调用所有的RabbitMQ内置功能，主命令是 rabbitmqctl。\n创建用户# rabbitmqctl add_user {用户名} {密码}设置权限# rabbitmqctl set_user_tags {用户名} {权限}比如：创建一个超级用户\nrabbitmqctl add_user admin1 admin1 rabbitmqctl set_user_tags admin1 administrator查看用户列表# rabbitmqctl list_users为用户赋权# // 使用户user1具有vhost1这个virtual host中所有资源的配置、写、读权限以便管理其中的资源 rabbitmqctl set_permissions -p vhost1 user1 \u0026#39;.*\u0026#39; \u0026#39;.*\u0026#39; \u0026#39; .*\u0026#39;查看权限# rabbitmqctl list_user_permissions user1 rabbitmqctl list_permissions -p vhost1清除权限# rabbitmqctl clear_permissions [-p VHostPath] User删除用户# rabbitmqctl delete_user Username修改用户密码# rabbitmqctl change_password Username NewpasswordManagement Plugin# 找到安装rabbitMQ的路径，然后切换到sbin的文件夹，管理员运行Shell脚本\nrabbitmq-pluginsenable rabbitmq_managementrabbitmqctl clear_permissions [-p VHostPath] User启动监控管理器# rabbitmq-plugins enable rabbitmq_management关闭监控管理器# rabbitmq-plugins disable rabbitmq_management启动rabbitmq# net start RabbitMQ关闭rabbitmq# net stop RabbitMQ查看所有的队列# rabbitmqctl list_queues清除所有的队列# rabbitmqctl reset查看已有用户及角色# rabbitmqctl list_users新增虚拟主机# rabbitmqctl add_vhost vhost_name将新虚拟主机授权给新用户# rabbitmqctl set_permissions -p vhost_name username \u0026#39;.*\u0026#39; \u0026#39;.*\u0026#39; \u0026#39;.*\u0026#39;设置用户权限# rabbitmqctl set_permissions -p VHostPath username ConfP WriteP ReadP查看(指定hostpath)所有用户的权限信息# rabbitmqctl list_permissions [-p VHostPath]查看指定用户的权限信息# rabbitmqctl list_user_permissions username清除用户的权限信息# rabbitmqctl clear_permissions [-p VHostPath] username"},{"id":87,"href":"/docs/rabbitmq/1.7rabbitmq%E5%B8%B8%E8%A7%81%E7%AD%96%E7%95%A5/","title":"1.7 Rabbit Mq常见策略","section":"所有文章","content":"rabbitMq策略学习\n死信队列# 死信队列：DLX，dead-letter-exchang，利用DLX，当消息在一个队列中变成死信 (dead message) 之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。\n死信判断条件# 消息被拒绝(basic.reject / basic.nack)，并且 requeue = false 消息 TTL 过期 队列达到最大长度 死信处理过程# DLX也是一个正常的Exchange，和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性 当这个队列中有死信时，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去，进而被路由到另一个队列 可以通过监听这个死信队列的消息做相应的处理 死信队列设置# 首先设置死信队列的 exchange 和 queue，然后进行绑定\nstring dlxExchangeName = \u0026#34;test.dlx.exchange\u0026#34;; string dlxQueueName = \u0026#34;test.dlx.queue\u0026#34;; channel.ExchangeDeclare(dlxExchangeName, type: \u0026#34;topic\u0026#34;); channel.QueueDeclare(queue: dlxQueueName, durable: false, exclusive: false, autoDelete: false, arguments: null); // #表示只要有消息到达了死信的exchange,都会路由到这个死信队列 channel.QueueBind(queue: dlxQueueName, exchange: dlxExchangeName, routingKey: \u0026#34;#\u0026#34;);定义业务队列，并设置死信参数\n// 声明队列时添加死信参数 Dictionary\u0026lt;string, object\u0026gt; agruments = new() { { \u0026#34;x-dead-letter-exchange\u0026#34;, dlxExchangeName } }; channel.QueueDeclare(queue: queueName, durable: false, exclusive: false, autoDelete: false, arguments: agruments);Pub 完整代码如下：\n/// \u0026lt;summary\u0026gt; /// Pub:死信队列.DLXs the pub test. /// \u0026lt;/summary\u0026gt; [TestMethod] public void Dlx_PubTest() { string dlxExchangeName = \u0026#34;test.dlx.exchange\u0026#34;; string dlxQueueName = \u0026#34;test.dlx.queue\u0026#34;; channel.ExchangeDeclare(dlxExchangeName, type: \u0026#34;topic\u0026#34;); channel.QueueDeclare(queue: dlxQueueName, durable: false, exclusive: false, autoDelete: false, arguments: null); // # 表示只要有消息到达了死信的exchange,都会路由到这个死信队列 channel.QueueBind(queue: dlxQueueName, exchange: dlxExchangeName, routingKey: \u0026#34;#\u0026#34;); // 声明队列时添加死信参数 Dictionary\u0026lt;string, object\u0026gt; agruments = new() { { \u0026#34;x-dead-letter-exchange\u0026#34;, dlxExchangeName } }; channel.QueueDeclare(queue: queueName, durable: false, exclusive: false, autoDelete: false, arguments: agruments); for (int i = 0; i \u0026lt; 10; i++) { channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queueName, basicProperties: null, body: Encoding.UTF8.GetBytes(i.ToString())); } Assert.IsTrue(true); }\n消费完毕，死信queue加了一条数据。\n实际环境还需要对死信队列进行一个监听和处理，具体的处理逻辑和业务相关，这里只简单演示死信队列是否生效。\n延时队列# 延迟队列就是进入该队列的消息会被延迟消费的队列。而一般的队列，消息一旦入队了之后就会被消费者马上消费\n延迟队列能做什么？延迟队列多用于需要延迟工作的场景。最常见的是以下两种场景：\n延迟消费。比如：用户生成订单之后，需要过一段时间校验订单的支付状态，如果订单仍未支付则需要及时关闭订单 延迟重试。比如消费者从队列里消费消息时失败了，但是想要延迟一段时间后自动重试 实现思路\n实现依赖于RabbitMQ的两个特性\nTime-To-Live Extensions\nRabbitMQ允许我们为消息或者队列设置TTL（time to live），也就是过期时间。TTL表明了一条消息可在队列中存活的最大时间，单位为毫秒。也就是说，当某条消息被设置了TTL或者当某条消息进入了设置了TTL的队列时，这条消息会在经过TTL秒后“死亡”，成为Dead Letter。如果既配置了消息的TTL，又配置了队列的TTL，那么较小的那个值会被取用。更多资料请查阅官方文档。\nDead Letter Exchanges\n被设置了TTL的消息在过期后会成为Dead Letter。\n之前说过在RabbitMQ中，一共有三种消息的“死亡”形式：\n消息被拒绝。通过调用basic.reject或者basic.nack并且设置的requeue参数为false 消息因为设置了TTL而过期 消息进入了一条已经达到最大长度的队列 如果队列设置了Dead Letter Exchange（DLX），那么这些Dead Letter就会被重新publish到Dead Letter Exchange，通过Dead Letter Exchange路由到其他队列。\n延迟消费# 生产者产生的消息首先会进入缓冲队列（图中红色队列）。通过RabbitMQ提供的TTL扩展，这些消息会被设置过期时间，也就是延迟消费的时间。等消息过期之后，这些消息会通过配置好的DLX转发到实际消费队列（图中蓝色队列），以此达到延迟消费的效果。\n延时重试# 消费者发现该消息处理出现了异常，比如是因为网络波动引起的异常。那么如果不等待一段时间，直接就重试的话，很可能会导致在这期间内一直无法成功，造成一定的资源浪费。可以将其先放在缓冲队列中（图中红色队列，可以理解为重试定义的exchange），等消息经过一段的延迟时间后再次进入实际消费队列中（图中蓝色队列），此时由于已经过了“较长”的时间了，异常的一些波动通常已经恢复，这些消息可以被正常消费。\nRabbitMQchannel.basicNack()能够让消息回到队列中，这样可以实现重试。但是无法明确重试次数，如果当前的消息一直重试的话，则后面的消息就会堆积起来，导致后面的消息无法消费。这是一个致命的缺点。因此需要设置重试次数来解决类似问题。\n使用redis或者mongo等第三方存储当前重试次数 在header中添加重试次数,使用channel.basicPublish()方法重新将消息发送后将重试次数加1 可以设置重试次数到达阈值时转发到指定的exchange。\n代码示例：\nhttps://github.com/wangpengliang815/CodeSnippet\n参考：\nhttps://www.rabbitmq.com/ttl.html https://www.cnblogs.com/xishuai/p/spring-boot-rabbitmq-delay-queue.html https://www.cnblogs.com/lori/p/9984760.html https://www.jianshu.com/p/537cb84ba72f https://www.jianshu.com/p/986ee5eb78bc https://www.cnblogs.com/wyy1234/category/1321800.html "},{"id":88,"href":"/docs/rabbitmq/1.8rabbitmq%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","title":"1.8 Rabbit Mq常见问题","section":"所有文章","content":"rabbitMq常见问题记录\n为什么要使用消息队列# 解耦# 传统模式：系统间耦合度强 如系统A直接调用系统B系统C的代码，如果再有系统D接入，则系统A还要修改代码。 中间件模式：系统A将消息写入消息队列，系统B、系统C 订阅消息队列，如果再有系统D介入，直接订阅消息队列即可 系统A不必修改代码。\n异步# 传统模式：一些非必的业务逻辑以同步得方式运行浪费时间。 中间件模式：将消息写入消息队列 一些非必要的业务逻辑以异步得方式运行提高响应速度。\n削峰/限流# 传统模式：并发量大得时候所有请求全部到数据库，造成数据库连接异常。 中间件模式：系统按照数据库能处理得并发量从消息队列中慢慢拉取消息。在生产环境中这种短暂得高峰期积压是允许的。\n消息队列的使用场景# 消息队列常见的使用场景很多，比较核心的有3个：解耦、异步、削峰。\n什么是RabbitMQ# 即一个消息队列，主要是用来实现应用程序的异步和解耦，同时也能起到消息缓冲，消息分发的作用。RabbitMQ使用的是AMQP协议，它是一种二进制协议\nAMQP，即Advanced Message Queuing Protocol(高级消息排队协议),一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。\n为什么使用RabbitMQ# 这里涉及一个消息中间件选型的问题\n特性 ActiveMQ RabbitMQ RocketMQ kafka 开发语言 java erlang java scala 单机吞吐量 万级 万级 10万级 10万级 时效性 ms级 us级 ms级 ms级以内 可用性 高(主从架构) 高(主从架构) 非常高(分布式架构) 非常高(分布式架构) 功能特性 成熟的产品，在很多公司得到应用；有较多的文档；各种协议支持较好 基于erlang开发，所以并发能力很强，性能极其好，延时很低;管理界面较丰富 MQ功能比较完备，扩展性佳 只支持主要的MQ功能，像消息查询，消息回溯等功能没有提供，在大数据领域应用广泛 中小型软件公司，建议选RabbitMQ.一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。正所谓，成也萧何，败也萧何！他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐 大型软件公司，根据具体使用在rocketMq和kafka之间二选一。一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。至于kafka，根据业务场景选择，如果有日志采集功能，肯定首选kafka 具体该选哪个，应该根据实际场景考虑，不能为了用而用\n使用消息队列的缺点# 系统可用性降低：本来其他系统只要运行好好的，那你的系统就是正常的。现在加了消息队列进去，那消息队列挂了，你的系统也就挂了。因此，系统可用性降低 系统复杂性增加：要多考虑很多方面的问题，比如一致性问题、如何保证消息不被重复消费，如何保证保证消息可靠传输。因此，需要考虑的东西更多，系统复杂性增大\n如何实现高可用# 参考：搭建RabbitMQ高可用集群\n重要角色有哪些# 生产者：消费的创建者，负责创建和推送数据到消息服务器 消费者：消息的接收方，用于处理数据和确认消息 代理：指RabbitMQ本身，本身不生产消息，只扮演“快递”的角色\n重要组件有哪些# ConnectionFactory（连接管理器）：应用程序与Rabbit之间建立连接的管理器，程序代码中使用 Channel（信道）：消息推送使用的通道 Exchange（交换器）：用于接收，分配消息 Queue（队列）：用于存储生产者的消息 RoutingKey（路由键）：用于把生产者的数据分配到交换器上 BindingKey（绑定键）：用于把交换器的消息绑定到队列上\nvhost作用# 每个RabbitMQ都能创建多个vhost，称为虚拟主机，每个虚拟主机都是mini版的RabbitMQ，它拥有自己的队列，交换器和绑定，拥有自己的权限机制。\n消息如何发送# 首先客户端必须连接到RabbitMQ服务器才能发布和消费消息，客户端和 rabbit server 之间会创建一个tcp连接，一旦tcp打开并通过了认证（认证就是你发送给rabbit服务器的用户名和密码），你的客户端和 就创建一条 amqp 信道（channel），信道是创建在“真实”tcp上的虚拟连接，amqp命令都是通过信道发送出去的，每个信道都会有唯一的id，不论是发布消息，订阅队列都是通过这个信道完成。\n怎么保证消息可靠性# 从三个角度分析：生产者弄丢数据 消息队列弄丢数据 消费者弄丢数据。\n生产者丢失数据# 提供 Transacton 和 confirm 机制来确保生产者不丢消息。\nTransacton: 发消息前开启事务（channel.txSelect()),然后发送消息，如果发送过程中有什么异常，事务就会回滚（channel,txRollback()),如果发送成功则提交事务（channel.txCommit()).然而缺点是吞吐量下降了。因此生产用confirm模式居多。一但channel 进入confirm 模式，所有该信道上面发送的消息都将会指派一个唯一的ID（从1开始），一但消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID),这就使生产这知道消息已经到达消息队列了。如果RabbitMQ没有处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。\n消息队列丢失数据# 处理消息队列丢失数据的情况，一把是开启持久化磁盘的配置。这个持久话配置可以和 confirm 机制配合使用，你可以在持久化磁盘之后，再给生产这发送一个Ack信号。这样如果持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。\n持久化一般分两步\n将queue 的持久化标识 durable设置为 true,则代表一个持久化队列 发送消息的时候将 deliveryMode=2 这样设置之后，rabbitMQ就算挂掉了，重启后也能恢复数据。\n消费者丢数据# 消费者丢数据一般是因为采用了自动确认消息模式，这种模式下，消费者会自动确认收到信息。这时rabbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息。\n解决方案：采用手动确认消息即可，在处理完消息后才发送 ack\n怎么避免消息丢失# 将数据写到消息队列上，系统B和C还没来得及取消息队列的数据，就挂掉了。如果没有做任何的措施，数据就丢了，这时候就要考虑数据的持久化，磁盘、数据库、Redis等，是同步存储还是异步存储。\n消息持久化成功的条件# 声明队列必须设置持久化 durable设置为 true 消息推送投递模式必须设置持久化， deliveryMode 设置为2（持久） 消息已经到达持久化交换器 消息已经到达持久化队列 持久化有什么缺点# 持久化的缺点就是降低了服务器的吞吐量，因为使用的是磁盘而非内存存储，从而降低了吞吐量。可使用SSD硬盘来缓解吞吐量的问题。\n有几种广播类型# direct（默认）：最基础最简单的模式，发送方把消息发送给订阅方，如果有多个订阅者，默认采用轮询的方式进行消息发送 headers：与 direct类似，只是性能很差，实际开发使用很少 fanout：分发模式，把消费分发给所有订阅者 topic：匹配订阅模式，使用正则匹配到消息队列，能匹配到的都能接收到 延迟消息队列如何实现# 消息过期后进入死信交换器，再由交换器转发到延迟消费队列，实现延迟功能，使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。\n集群有什么用# 高可用：某个服务器出现问题，整个RabbitMQ还可以继续使用 高容量：集群可以承载更多的消息量\n节点的类型有哪些# 磁盘节点：消息会存储到磁盘 内存节点：消息都存储到内存中，重启服务器消息丢失，性能高于磁盘类型\n集群搭建需要注意哪些问题# 各节点之间使用-link 连接，此属性不能忽略 各节点使用的 erlang cookie值必须相同，此值相当于“秘钥”的功能，用于各节点的认证 整个集群必须包含一个磁盘节点 节点拷贝问题# 每个节点是其他节点的完整拷贝吗?为什么 不是，原因有以下两个：\n存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据 性能的考虑：如果每条消息都需要完整拷贝每一个集群节点，那新增节点并没有提升处理消息的能力，最多是保持和单节点相同的性能甚至更糟 集群中唯一磁盘节点崩溃会发生什么情况# 如果唯一磁盘的磁盘节点崩溃，不能进行以下操作：\n不能创建队列 不能创建交换器 不能创建绑定 不能添加用户 不能更改权限 不能添加和删除集群节点 唯一磁盘节点崩溃了，集群是可以保持运行的，但不能更改任何东西。\n集群节点停止顺序# 对集群的停止的顺序是有要求的，应该先关闭内存节点，最后关闭磁盘节点。如果顺序恰好相反的话，可能造成消息的丢失。\nKafka与RabbitMQ# 应用场景方面# RabbitMQ：用于实时的，对可靠性要求较高的消息传递上 kafka：用于处于活跃的流式数据，大数据量的数据处理上\n架构模型方面# producer，broker，consumer RabbitMQ：以broker为中心，有消息的确认机制 kafka：以consumer为中心，无消息的确认机制\n吞吐量方面# RabbitMQ：支持消息的可靠的传递，支持事务，不支持批量操作，基于存储的可靠性的要求存储可以采用内存或硬盘，吞吐量小 kafka：内部采用消息的批量处理，数据的存储和获取是本地磁盘顺序批量操作，消息处理的效率高，吞吐量高\n集群负载均衡方面# RabbitMQ：本身不支持负载均衡，需要loadbalancer的支持 kafka：采用zookeeper对集群中的broker，consumer进行管理，可以注册topic到zookeeper上，通过zookeeper的协调机制，producer保存对应的topic的broker信息，可以随机或者轮询发送到broker上，producer可以基于语义指定分片，消息发送到broker的某个分片上。 kafka通过zk和分区机制实现：zk记录broker信息，生产者可以获取到并通过策略完成负载均衡；通过分区，投递消息到不同分区，消费者通过服务组完成均衡消费\n"},{"id":89,"href":"/docs/rabbitmq/1.9rabbitmq%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88/","title":"1.9 Rabbit Mq集群方案","section":"所有文章","content":"集群方案\n"},{"id":90,"href":"/docs/rabbitmq/%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5rabbitmq/","title":"客户端连接 Rabbit Mq","section":"所有文章","content":"客户端连接RabbitMQ\nRabbitMQ.Client# 基于 RabbitMQ.Client 的封装，在 NuGet 中搜索 RabbitMQ.Client ，直接点击按钮安装即可。\nnamespace CommonLib.RabbitMQ { using global::RabbitMQ.Client; using global::RabbitMQ.Client.Events; using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading; public class QueueOptions { /// \u0026lt;summary\u0026gt; /// 是否持久化 /// \u0026lt;/summary\u0026gt; public bool Durable { get; set; } = true; /// \u0026lt;summary\u0026gt; /// 是否自动删除 /// \u0026lt;/summary\u0026gt; public bool AutoDelete { get; set; } = false; /// \u0026lt;summary\u0026gt; /// 参数 /// \u0026lt;/summary\u0026gt; public IDictionary\u0026lt;string, object\u0026gt; Arguments { get; set; } = new Dictionary\u0026lt;string, object\u0026gt;(); } public class ConsumeQueueOptions : QueueOptions { /// \u0026lt;summary\u0026gt; /// 是否自动提交 /// \u0026lt;/summary\u0026gt; public bool AutoAck { get; set; } = false; /// \u0026lt;summary\u0026gt; /// 每次接收消息条数 /// \u0026lt;/summary\u0026gt; public ushort? FetchCount { get; set; } = 1; } public class ExchangeConsumeQueueOptions : ConsumeQueueOptions { /// \u0026lt;summary\u0026gt; /// 路由值 /// \u0026lt;/summary\u0026gt; public string[] RoutingKeys { get; set; } /// \u0026lt;summary\u0026gt; /// 参数 /// \u0026lt;/summary\u0026gt; public IDictionary\u0026lt;string, object\u0026gt; BindArguments { get; set; } = new Dictionary\u0026lt;string, object\u0026gt;(); } public class ExchangeQueueOptions : QueueOptions { /// \u0026lt;summary\u0026gt; /// 交换机类型 /// \u0026lt;/summary\u0026gt; public string Type { get; set; } /// \u0026lt;summary\u0026gt; /// 队列及路由值 /// \u0026lt;/summary\u0026gt; public List\u0026lt;Tuple\u0026lt;string, string\u0026gt;\u0026gt; QueueAndRoutingKey { get; set; } = new List\u0026lt;Tuple\u0026lt;string, string\u0026gt;\u0026gt;(); /// \u0026lt;summary\u0026gt; /// 参数 /// \u0026lt;/summary\u0026gt; public IDictionary\u0026lt;string, object\u0026gt; BindArguments { get; set; } = new Dictionary\u0026lt;string, object\u0026gt;(); } public static class RabbitMQExchangeType { /// \u0026lt;summary\u0026gt; /// 普通模式 /// \u0026lt;/summary\u0026gt; public const string Common = \u0026#34;\u0026#34;; /// \u0026lt;summary\u0026gt; /// 路由模式 /// \u0026lt;/summary\u0026gt; public const string Direct = \u0026#34;direct\u0026#34;; /// \u0026lt;summary\u0026gt; /// 发布/订阅模式 /// \u0026lt;/summary\u0026gt; public const string Fanout = \u0026#34;fanout\u0026#34;; /// \u0026lt;summary\u0026gt; /// 匹配订阅模式 /// \u0026lt;/summary\u0026gt; public const string Topic = \u0026#34;topic\u0026#34;; } public abstract class RabbitBase : IDisposable { private readonly List\u0026lt;AmqpTcpEndpoint\u0026gt; amqpList; private IConnection connection; protected RabbitBase(params string[] hosts) { if (hosts == null || hosts.Length == 0) { throw new ArgumentException(\u0026#34;invalid hosts！\u0026#34;, nameof(hosts)); } amqpList = new List\u0026lt;AmqpTcpEndpoint\u0026gt;(); amqpList.AddRange(hosts.Select(host =\u0026gt; new AmqpTcpEndpoint(host, Port))); } protected RabbitBase(params (string, int)[] hostAndPorts) { if (hostAndPorts == null || hostAndPorts.Length == 0) { throw new ArgumentException(\u0026#34;invalid hosts！\u0026#34;, nameof(hostAndPorts)); } amqpList = new List\u0026lt;AmqpTcpEndpoint\u0026gt;(); amqpList.AddRange(hostAndPorts.Select(tuple =\u0026gt; new AmqpTcpEndpoint(tuple.Item1, tuple.Item2))); } /// \u0026lt;summary\u0026gt; /// 端口 /// \u0026lt;/summary\u0026gt; public int Port { get; set; } = 5672; /// \u0026lt;summary\u0026gt; /// 账号 /// \u0026lt;/summary\u0026gt; public string UserName { get; set; } = ConnectionFactory.DefaultUser; /// \u0026lt;summary\u0026gt; /// 密码 /// \u0026lt;/summary\u0026gt; public string Password { get; set; } = ConnectionFactory.DefaultPass; /// \u0026lt;summary\u0026gt; /// 虚拟机 /// \u0026lt;/summary\u0026gt; public string VirtualHost { get; set; } = ConnectionFactory.DefaultVHost; public virtual void Dispose() { // connection?.Close(); // connection?.Dispose(); } /// \u0026lt;summary\u0026gt; /// 关闭连接 /// \u0026lt;/summary\u0026gt; public void Close() { connection?.Close(); connection?.Dispose(); } /// \u0026lt;summary\u0026gt; /// 获取rabbitmq的连接 /// \u0026lt;/summary\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; protected IModel GetChannel() { if (connection == null) { lock (this) { if (connection == null) { ConnectionFactory factory = new() { Port = Port, UserName = UserName, VirtualHost = VirtualHost, Password = Password }; // 网络故障自动恢复连接 factory.AutomaticRecoveryEnabled = true; // 心跳处理 factory.RequestedHeartbeat = new TimeSpan(5000); connection = factory.CreateConnection(amqpList); } } } return connection.CreateModel(); } } public class RabbitMQHelper : RabbitBase { public RabbitMQHelper(params string[] hosts) : base(hosts) { } public RabbitMQHelper(params (string, int)[] hostAndPorts) : base(hostAndPorts) { } /// \u0026lt;summary\u0026gt; /// 简单队列消息发布 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;queue\u0026#34;\u0026gt;The queue.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;message\u0026#34;\u0026gt;The message.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;options\u0026#34;\u0026gt;The options.\u0026lt;/param\u0026gt; public void Publish(string queue, string message, QueueOptions options = null) { options ??= new QueueOptions(); IModel channel = GetChannel(); channel.QueueDeclare(queue, options.Durable, false, options.AutoDelete, options.Arguments ?? new Dictionary\u0026lt;string, object\u0026gt;()); byte[] buffer = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: queue, basicProperties: null, body: buffer); channel.Close(); } /// \u0026lt;summary\u0026gt; /// 订阅模式/路由模式/Topic模式 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;exchange\u0026#34;\u0026gt;The exchange.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;routingKey\u0026#34;\u0026gt;The routing key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;message\u0026#34;\u0026gt;The message.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;options\u0026#34;\u0026gt;The options.\u0026lt;/param\u0026gt; public void Publish(string exchange, string routingKey, string message, ExchangeQueueOptions options = null) { options ??= new ExchangeQueueOptions(); IModel channel = GetChannel(); channel.ExchangeDeclare(exchange, string.IsNullOrEmpty(options.Type) ? RabbitMQExchangeType.Fanout : options.Type, options.Durable, options.AutoDelete, options.Arguments ?? new Dictionary\u0026lt;string, object\u0026gt;()); if (options.QueueAndRoutingKey.Count \u0026gt; 0) { foreach (var item in options.QueueAndRoutingKey) { if (!string.IsNullOrEmpty(item.Item1)) { channel.QueueDeclare(item.Item1, options.Durable, false, options.AutoDelete, options.Arguments); channel.QueueBind(item.Item1, exchange, item.Item2 ?? \u0026#34;\u0026#34;, options.BindArguments ?? new Dictionary\u0026lt;string, object\u0026gt;()); } } } byte[] buffer = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange, routingKey, null, buffer); channel.Close(); } public event Action\u0026lt;RecieveResult\u0026gt; Received; /// \u0026lt;summary\u0026gt; /// 构造消费者 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;channel\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;options\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private IBasicConsumer ConsumeInternal(IModel channel, ConsumeQueueOptions options) { EventingBasicConsumer consumer = new(channel); consumer.Received += (sender, e) =\u0026gt; { try { CancellationTokenSource cancellationTokenSource = new(); if (!options.AutoAck) { cancellationTokenSource.Token.Register(() =\u0026gt; { channel.BasicAck(e.DeliveryTag, false); }); } Received?.Invoke(new RecieveResult(e, cancellationTokenSource)); } catch { } }; if (options.FetchCount != null) { channel.BasicQos(0, options.FetchCount.Value, false); } return consumer; } /// \u0026lt;summary\u0026gt; /// 消息监听 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;queue\u0026#34;\u0026gt;The queue.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;options\u0026#34;\u0026gt;The options.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public ListenResult Listen(string queue, ConsumeQueueOptions options = null) { options ??= new ConsumeQueueOptions(); IModel channel = GetChannel(); channel.QueueDeclare(queue, options.Durable, false, options.AutoDelete, options.Arguments ?? new Dictionary\u0026lt;string, object\u0026gt;()); IBasicConsumer consumer = ConsumeInternal(channel, options); channel.BasicConsume(queue, options.AutoAck, consumer); ListenResult result = new(); result.Token.Register(() =\u0026gt; { try { channel.Close(); channel.Dispose(); } catch { } }); return result; } /// \u0026lt;summary\u0026gt; /// 消费消息 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;exchange\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;queue\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;options\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; public ListenResult Listen(string exchange, string queue, ExchangeConsumeQueueOptions options = null) { options ??= new ExchangeConsumeQueueOptions(); IModel channel = GetChannel(); channel.QueueDeclare(queue, options.Durable, false, options.AutoDelete, options.Arguments ?? new Dictionary\u0026lt;string, object\u0026gt;()); if (options.RoutingKeys != null \u0026amp;\u0026amp; !string.IsNullOrEmpty(exchange)) { foreach (string key in options.RoutingKeys) { channel.QueueBind(queue, exchange, key, options.BindArguments); } } IBasicConsumer consumer = ConsumeInternal(channel, options); channel.BasicConsume(queue, options.AutoAck, consumer); ListenResult result = new(); result.Token.Register(() =\u0026gt; { try { channel.Close(); channel.Dispose(); } catch { } }); return result; } public class RecieveResult { private CancellationTokenSource cancellationTokenSource; public RecieveResult(BasicDeliverEventArgs arg, CancellationTokenSource cancellationTokenSource) { Body = Encoding.UTF8.GetString(arg.Body.ToArray()); ConsumerTag = arg.ConsumerTag; DeliveryTag = arg.DeliveryTag; Exchange = arg.Exchange; Redelivered = arg.Redelivered; RoutingKey = arg.RoutingKey; this.cancellationTokenSource = cancellationTokenSource; } /// \u0026lt;summary\u0026gt; /// 消息体 /// \u0026lt;/summary\u0026gt; public string Body { get; private set; } /// \u0026lt;summary\u0026gt; /// 消费者标签 /// \u0026lt;/summary\u0026gt; public string ConsumerTag { get; private set; } /// \u0026lt;summary\u0026gt; /// Ack标签 /// \u0026lt;/summary\u0026gt; public ulong DeliveryTag { get; private set; } /// \u0026lt;summary\u0026gt; /// 交换机 /// \u0026lt;/summary\u0026gt; public string Exchange { get; private set; } /// \u0026lt;summary\u0026gt; /// 是否Ack /// \u0026lt;/summary\u0026gt; public bool Redelivered { get; private set; } /// \u0026lt;summary\u0026gt; /// 路由 /// \u0026lt;/summary\u0026gt; public string RoutingKey { get; private set; } public void Commit() { if (cancellationTokenSource == null || cancellationTokenSource.IsCancellationRequested) return; cancellationTokenSource.Cancel(); cancellationTokenSource.Dispose(); cancellationTokenSource = null; } } public class ListenResult { private readonly CancellationTokenSource cancellationTokenSource; /// \u0026lt;summary\u0026gt; /// CancellationToken /// \u0026lt;/summary\u0026gt; public CancellationToken Token { get { return cancellationTokenSource.Token; } } /// \u0026lt;summary\u0026gt; /// 是否已停止 /// \u0026lt;/summary\u0026gt; public bool Stoped { get { return cancellationTokenSource.IsCancellationRequested; } } public ListenResult() { cancellationTokenSource = new CancellationTokenSource(); } /// \u0026lt;summary\u0026gt; /// 停止监听 /// \u0026lt;/summary\u0026gt; public void Stop() { cancellationTokenSource.Cancel(); } } } }EasyNetQ# 简介# EasyNetQ 是基于官方.NET组件 RabbitMQ.Client 的又一层封装，使用起来更加方便，不用关心具体队列声明，路由声明等细节。EasyNetQ目的是提供一个尽可能简洁适用于RabbitMQ的.NET类库。为了实现这些目标，EasyNetQ强制使用了一些简单的约定。包括如下:\n消息用 .NET 类型 表示 消息通过 .NET类型 路由 这意味着消息必须用 .NET class定义。每一个不同的消息类型必须用一个 class 表示。这个类必须是 public 并带有一个默认构造函数和可以读写的属性。这个类不需要实现任何功能。仅仅做一个简单的数据容器，下面是一个简单的消息：\npublic class MyMessage { public string Content { get; set; } }EasyNetQ通过消息的类型来路由。当发布一个消息，EasyNetQ会检查消息类型， 然后给它一个 基于类型名称、命名空间和程序集的路由键。默认EasyNetQ使用 Newtonsoft.Json 序列化 .NET类型 为 JSON ，这样好处是消息可读性好。\n引用：EasyNetQ是一个在RabbitMQ.Client类库之上提供服务的组件集合。做了这些事情，像序列化、错误处理、线程管理、连接管理等。通过一个Mini-Ioc容器组织在一起。你能很容易用你自己实现去替换这些组件。所以如果你喜欢用XML 序列化而不是用JSON，仅仅需要以一个ISerializer的实现，然后注册到这个容器中。\n这些组件最上层是IAdvancedBus API。这看起来很像AMQP规格。实际也是你能够通过这个API运行很多AMQP方法。这个API对你隐藏了唯一AMQP概念是channels。这是因为channels 是一个复杂的底层概念，不应该被放到AMQP部分规格的第一的位置。 坦白来说，这个API中 ‘Advanced’不是一个非常好的名字。用‘lamqp’可能更好些。\n这个顶层高级API是一系列消息模式：Publish/Subscribe, Request/Response,和 Send/Receive. 这是EasyNetQ坚持的设计思想。这些模式是我们应该实现的。这样有非常小的弹性。要么你接受我的处理方法，或者你就不要去使用。这样做的目的是，不用你和使用者花费精力去重新发明轮子。你不需要每一次去做选择，你只需要简单的去Publish和Subscribe消息。这样设计是未来实现EasyNetQ的核心目标，即尽可能简单的使用RabbitMQ。\n这些模式的后面是这个 IBus API. 再一次看到这个一个简单的名字，它跟消息总线概念有关。IPackagedMessagePatterns可能是一个更好名字。\n80%的用户的工作，在80%的时间都会使用IBus。它不是完备的API，如果这个模式下，你想实现的功能这个IBus没有提供，那么你应该使用IAdvancedBus。这样使用没有问题，EasyNetQ就这这样设计使用的。\n优势# C#中已经提供了RabbitMQ.Client， RabbitMQ. Client 实现了AMQP协议的客户端（RabbitMQ实现了服务器端）。 AMQP是为HTTP协议设计的。它的设计是跨平台的和与语言无关的。它也旨在灵活支持多种基于交换/绑定/队列模型的消息传递模式。\nRabiitMQ Client 非常地灵活，但是伴随着灵活性而来是复杂性。这意味着需要写大量代码。比如：\n实现消息传递模式，例如 Publish/Subscribe或 Request/Response 实现路由策略。需要设计如何绑定 Exchange/Queue 。并且需要设计怎样在生产者和消费者之间进行消息路由 实现消息的序列化/反序列化。 如何转换AMQP的二进制消息为编程语言能理解的格式 为订阅去实现一个消费者线程。将需要有一个专门的消费者循环等待订阅的消息。如何处理多个订阅者，或者瞬间订阅者 实现消费者重新连接。假如连接崩溃了或者RabbitMQ 服务挂了，怎样能检测到并确保所有的订阅都能被重建 懂得和实施服务质量设置。需要什么样的设置来确保一个可靠的客户端 实现一个错误处理策略。假如接受到一个错误的消息，或者发生一个未处理异常被抛出，客户端应该做什么 实现发布者可靠的消息确认。 EasyNetQ目标是在AMQP之上封装所有这些关注点在一个简单好用的类库中。\n安装# 在 NuGet 中搜索 EasyNetQ 直接点击按钮安装即可。EasyNetQ 依赖 RabbitMQ.Client，所以会同时安装两个dll。\n连接# 使用 EasyNetQ 连接 RabbitMQ，是在应用程序启动时创建一个 IBus 对象，并且在应用程序关闭时释放该对象。RabbitMQ 连接是基于 IBus 接口的，当IBus 中的方法被调用，连接才会开启。创建一个 IBus 对象的方法如下：\nvar bus = RabbitHutch.CreateBus(“host=myServer;virtualHost=myVirtualHost;username=mike;password=topsecret”);连接字符串基于 Key/Value 形式，每个Key中间用分号 ; 断开。其中 host 是必须的，其他值采用默认配置。连接中可能用到的 Key 如下：\nhost：host=localhost 或 host =192.168.1.102 或者 host=my.rabbitmq.com ,集群配置的话可以用逗号将服务地址隔开，例如：host=a.com,b.com,c.com virtualHost：虚拟主机，默认 / username：登录名 password：登录密码 requestedHeartbeat：心跳设置，默认10秒 prefetchcount：默认是50 pubisherConfirms：默认 false persistentMessages：消息持久化，默认 true product：产品名 platform：平台 timeout：默认10秒 关闭连接，使用 bus.Dispose();\n日志# EasyNetQ 提供了日志接口 IEasyNetQLogger\npublic interface IEasyNetQLogger { void DebugWrite(string format, params object[] args); void InfoWrite(string format, params object[] args); void ErrorWrite(string format, params object[] args); void ErrorWrite(Exception exception); }内部默认用的是 NullLogger，即什么也不做，不记录日志。在测试的时候也可以用 ConsoleLogger 来显示运行中的各种信息。不过一般在正式使用环境中，可以自定义日志并实现 IEasyNetQLogger接口。然后在 RabbitHutch.CreateBus 的重载方法中注册想用的日志类型。（日志中会记录连接RabbitMQ的过程和队列创建细节等信息）代码如下：\nvar logger = new MyLogger() // 继承自 IEasyNetQLogger var bus = RabbitHutch.CreateBus(“my connection”, x =\u0026gt; x.Register\u0026lt;IEasyNetQLogger\u0026gt;(_ =\u0026gt; logger));发布/订阅# EasyNetQ 支持最简单的消息模式是：发布/订阅。发布消息后任意消费者都可以订阅该消息，并且不需要额外配置。首先：需要先创建一个 IBus 对象，然后创建一个可序列化的 .NET对象。调用 Publish方法即可。\nPub\nservices.AddSingleton(RabbitHutch.CreateBus(redisConnection)); IServiceProvider provider = services.BuildServiceProvider(); mq = provider.GetService\u0026lt;IBus\u0026gt;(); mq.PubSub.Publish(new { message = \u0026#34;hello.world\u0026#34; }); 注意：Publish只顾发送消息到队列，但是不管有没有消费端订阅，所以，发布之后，如果没有消费者，该消息将不会被消费甚至丢失。\nSub\n一个EasyNetQ订阅者订阅一种消息类型（消息类为.NET 类型）。通过调用Subcribe方法一旦对一个类型设置了订阅，一个持久化队列就会在RabbitMQ broker上被创建，这个类型的任何消息都会被发送到这个队列上。\nmq.PubSub.Subscribe\u0026lt;MyMessage\u0026gt;(\u0026#34;\u0026#34;, msg =\u0026gt; { Console.WriteLine(msg.Content); });subscription_id\n相同类型消息、相同订阅id调用Subscribe：EasyNetQ将会在RabbitMQ Broker上为特定的消息类型的和订阅id的组合创建唯一的队列。每一次调用Subscribe方法会创建一个新的队列消费者。如果用相同的消息和订阅id调用Subscribe两次，将会创建两个消费者去消费同一个队列。然后RabbitMQ将会依次连续轮询消息给每一个消费者（均摊机制）。这种可伸缩性和工作分担是非常棒的。比如：一个处理消息的服务已经超负荷工作了。简单的创建一个新的服务实例（在同一个机器上，或者不同的机器上），不用配置任何东西，自动就得到了伸缩性。\n相同类型消息、不同订阅id调用Subscribe：假如相同的消息类型，用不同的订阅id调用了两次Subscribe，将创建两个队列，每一个队列有自己的消费者。每一个消息的副本将会路由到每一个队列，因此不同的消费者都将得到所有消息（这个类型的，Fanout）。适用于几个不同的服务都关心相同类型的消息。\n"},{"id":91,"href":"/docs/redis/1.10redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","title":"1.10 Redis常见问题","section":"所有文章","content":"redis常见问题记录\n什么是Redis？# Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。与传统数据库不同的是 Redis 数据存在内存中，所以读写速度非常快。\nRedis优缺点有哪些？# 优点 缺点 读写性能优异：读 110000次/s，写 81000次/s 缓存和数据库双写一致性问题 支持数据持久化：支持AOF和RDB两种持久化方式 缓存雪崩问题 支持事务：Redis的所有操作都是原子性的，同时还支持对几个操作合并后的原子性执行 缓存击穿问题 支持多种数据结构：除了支持String类型外还支持Hash、Set、Zset、List等数据结构 缓存的并发竞争问题 支持主从复制：主机会自动将数据同步到从机，可以进行读写分离 为什么要用Redis?# 高性能\n假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在数缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可。\n高并发\n直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。\nRedis为什么快?# 完全基于内存：绝大部分请求是纯粹的内存操作非常快速。数据存在内存中类似于 HashMap。查找和操作的时间复杂度都是O(1)。\n采用单线程：避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。\n使用多路 I/O 复用模型，非阻塞 IO。\n传统并发模型：每个 I/O 流(快递)都有一个新的线程管理。多路复用：只有单个线程，通过跟踪每个 I/O 流的状态来管理多个 I/O 流\nRedis有哪些数据类型?# 5种基本数据类型\nString List Set Zset Hash 3种特殊数据类型\nGeospatial 地理位置 Hyperloglog 基数统计 Bitmap位图场景 Redis的应用场景有哪些？# 计数器\n可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。\n缓存\n将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。\n会话缓存\n可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。\n消息队列(发布/订阅功能)\nList 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息实现消息队列(不过最好使用 Kafka、RabbitMQ 等消息中间件）。\n分布式锁实现\n在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。\n其它\nSet 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。\n什么是Redis持久化？# 持久化就是把内存的数据写到磁盘中去，防止服务宕机内存数据丢失。\nRedis 的持久化机制有哪些？# Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制\nRDB：是Redis DataBase缩写快照，Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照周期。\n优点 缺点 只有一个文件 dump.rdb，方便持久化 数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 Redis 发生故障，会发生数据丢失 容灾性好，一个文件可以保存到安全的磁盘 性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能 数据集较大时时，比 AOF 的启动效率更高 AOF（Append-only file)： 是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。\n优点 缺点 数据安全，AOF 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次 aof文件比 rdb文件大，且恢复速度慢 通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题 数据集大的时候，比rdb启动效率低 AOF 机制的 rewrite模式。AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）) 对比\naof文件比rdb更新频率高，优先使用aof还原数据 aof比rdb更安全也更大 rdb性能比aof好 如果两个都配了优先加载aof 如何选择合适的持久化方式?# 一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，应该同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。\n如果非常关心数据， 但仍然可以承受数分钟以内的数据丢失，那么可以只使用RDB持久化。如果只希望数据在服务器运行的时候存在，也可以不使用任何持久化方式。\n过期键的删除策略?# Redis是key-value数据库，可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。\n过期策略通常有以下三种\n定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。\n惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。\n定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。Redis中同时使用了惰性过期和定期过期两种过期策略。\n注意：除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），还可以根据具体的业务需求进行自定义的缓存淘汰策略\nRedis key的过期时间和永久有效怎么设置？# EXPIRE和PERSIST命令\nRedis的内存淘汰策略有哪些?# Redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略；Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。\n全局的键空间选择性移除\nnoeviction：当内存不足以容纳新写入数据时，新写入操作会报错\nallkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）\nallkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key\n设置过期时间的键空间选择性移除\nvolatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key\nvolatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key\nvolatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除\n注意：\nRedis的内存淘汰策略的选取并不会影响过期的key的处理\n内存淘汰策略用于处理内存不足时的需要申请额外空间的数据\n过期策略用于处理过期的缓存数据\nRedis的内存用完了会发生什么？# 如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回）或者可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。\nRedis如何做内存优化？# 可以利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以应该尽可能的将数据模型抽象到一个散列表里面。比如web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而应该把这个用户的所有信息存储到一张散列表里面。\nRedis线程模型？# Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。\n参考：https://www.cnblogs.com/barrywxx/p/8570821.html\n什么是事务？# 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。\nRedis事务的概念?# Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结：Redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。\nRedis事务的三个阶段?# 1）事务开始 MULTI\n2）命令入队\n3）事务执行 EXEC\n事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求将会把请求放入队列中排队。\nRedis事务相关命令?# Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的\nRedis会将一个事务中的所有命令序列化，然后按顺序执行\nRedis不支持回滚，Redis 在事务失败时不进行回滚，而是继续执行余下的命令， 所以 Redis 的内部可以保持简单且快速\n如果在一个事务中的命令出现错误，那么所有的命令都不会执行\n如果在一个事务中出现运行错误，那么正确的命令会被执行\nWATCH命令是一个乐观锁，可以为 Redis 事务提供check-and-set（CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC`命令\nMULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行\nEXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil\n通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出\nUNWATCH命令可以取消Watch对所有key的监控\n事务管理（ACID）概述# 原子性（Atomicity）\n原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生\n一致性（Consistency）\n事务前后数据的完整性必须保持一致\n隔离性（Isolation）\n多个事务并发执行时，一个事务的执行不应影响其他事务的执行\n持久性（Durability）\n持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响\nRedis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有持久性\nRedis事务支持隔离性吗？# Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此Redis 的事务是总是带有隔离性的。\nRedis事务保证原子性吗，支持回滚吗？# Redis中单条命令是原子性执行的，但事务不保证原子性且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。\nRedis事务其他实现？# 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行。其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完 基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐 Redis实现分布式锁# Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。\n当且仅当 key 不存在，将 key 的值设为 value。 若给定的 key 已经存在，则 SETNX 不做任何动作\nSETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写\n返回值：设置成功返回 1 | 设置失败返回 0\n如何解决Redis的并发竞争 Key 问题# 所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和期望的顺序不同，也就导致了结果的不同\n方案一：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）\n方案二：并发量过大的情况下,可以通过消息中间件进行处理,把Redis.Set操作放在队列中使其串行化必须依次执行\n什么是 RedLock# Redis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性：\n安全特性：互斥访问，即永远只有一个 client 能拿到锁 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区 容错性：只要大部分 Redis 节点存活就可以正常提供服务 缓存雪崩# 缓存雪崩是指缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。\n使缓存集中失效的原因：\n1、Redis服务器宕机\n2、对缓存数据设置了相同的过期时间，导致某时间段内缓存集中失效\n解决方案\n1、针对原因1，可以实现Redis的高可用，Redis Cluster 或者 Redis Sentinel(哨兵) 等\n2、针对原因2，设置缓存过期时间时加上一个随机值，避免缓存在同一时间过期\n3、使用双缓存策略，设置两个缓存，原始缓存和备用缓存，原始缓存失效时，访问备用缓存，备用缓存失效时间设置长点\n缓存穿透# 缓存穿透表示查询一个一定不存在的数据，由于没有获取到缓存，所以没写入缓存，导致这个不存在的数据每次都需要去数据库查询，失去了缓存的意义。请求的数据大量的没有获取到缓存，导致走数据库，有可能搞垮数据库，使整个服务瘫痪。\n解决方案\n1、接口层增加校验，如用户鉴权校验，id做基础校验，id\u0026lt;=0的直接拦截\n2、从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击\n3、采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免对底层存储系统的查询压力\n缓存击穿# 缓存击穿表示某个key的缓存非常热门，有很高的并发一直在访问，如果该缓存失效，请求会同时打到数据库，压垮数据库。\n缓存击穿与缓存雪崩的区别是：\n1、缓存击穿针对的是某一热门key缓存\n2、缓存雪崩针对的是大量缓存的集中失效\n解决方案\n1、设置热点数据永远不过期\n2、加互斥锁\n缓存预热# 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。\n解决方案\n1、直接写个缓存刷新页面，上线时手工操作一下\n2、数据量不大，可以在项目启动的时候自动进行加载\n3、定时刷新缓存\n如何保证缓存与数据库双写时的数据一致性？# TODO\nRedis回收进程如何工作的？# 一个客户端运行了新的命令，添加了新的数据 Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收 一个新的命令被执行，等等 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下 Redis回收使用的是什么算法？# LRU算法\n"},{"id":92,"href":"/docs/redis/1.1nosql%E6%A6%82%E8%BF%B0/","title":"1.1 No Sql概述","section":"所有文章","content":"什么是NoSQL# 在现代的计算系统上每天网络上都会产生庞大的数据量。这些数据有很大一部分是由关系数据库管理系统（RDBMS）来处理。 1970年 E.F.Codd\u0026rsquo;s提出的关系模型的论文 \u0026ldquo;A relational model of data for large shared data banks\u0026rdquo;，这使得数据建模和应用程序编程更加简单。\nNoSQL(NoSQL = Not Only SQL )，意即\u0026quot;不仅仅是SQL\u0026quot;\n为什么要使用NoSQL# 传统关系型数据库面对海量数据的存储，以及实现高访问量、高并发读/写，显得力不从心。尤其是当面对超大规模、高并发、高吞吐量的大型动态网站的时候，就会暴露出很多难以克服的问题，影响用户体验。为了满足对海量数据的高速存储需求，实现高并发、高吞吐量，NoSQL 应运而生。NoSQL 的出现可以解决传统关系型数据库所不能解决的问题。\n1) ：NoSQL 解决了高并发读/写问题\nWeb 2.0 动态网站需要根据用户的个性化信息来实时生成动态页面和提供动态信息，而无法使用动态页面的静态化技术，因此数据库的并发负载就会非常高。比如，微博、朋友圈的实时更新，就会出现每秒上万次的读/写需求。关系型数据库在面对每秒上万次的 SQL 查询操作时还能应对自如，但是在面对每秒上万次的 SQL 写操作时就难以胜任了。普通的 BBS 系统网站也存在高并发读/写的需求，比如，实时统计在线人数、记录热门帖子的浏览次数等，当面对这些需求时，传统的关系型数据库就会出现大量问题。\n2) NoSQL 解决了海量数据的高效率存储和访问问题\n面对实时产生的大数据量的存储与查询，关系型数据库是难以应付的，会显得效率非常低。而利用 NoSQL 的高效存储与查询能力，就能解决这个问题。\n3) NoSQL 实现了高可用性及高可扩展性\n在基于 Web 的架构中，关系型数据库难以进行横向扩展。当一个网站系统的用户量和访问量与日俱增的时候，数据库没有办法像 Web 服务器或应用服务器那样通过添加更多的硬件来搭建负载均衡的服务器。对于很多提供 24 小时不间断服务的网站来说，对数据库系统的维护升级和扩展是非常折磨人的一件事，往往需要停机维护和数据迁移。\nNoSQL 数据库特点# NoSQL 数据库具有如下特点\n容易扩展，方便使用。数据之间没有关系 数据模型非常灵活，无须提前为要存储的数据建立字段类型，随时可以存储自定义的数据格式 适合大数据量、高性能的存储 具有高并发读/写、高可用性 在什么应用场景下使用 NoSQL# NoSQL 数据库的应用场景比较广泛\n对于大数据量、高并发的存储系统及相关应用 对于一些数据模型比较简单的相关应用 对数据一致性要求不是很高的业务场景 对于给定 key 来映射一些复杂值的环境 对一些大型系统的日志信息的存储 存储用户信息，如大型电商系统的购物车、会话等 对于多数据源的数据存储 对易变化、热点高频信息、关键字等信息的存储 NoSQL四大分类# 键值(Key-Value)# 键值数据库就像在传统语言中使用的哈希表。可以通过key来添加、查询或者删除数据，鉴于使用主键访问，所以会获得不错的性能及扩展性。\n产品：Riak、Redis、Memcached、Amazon’s Dynamo、Project Voldemort\n适用场景：\n储存用户信息，比如会话、配置文件、参数、购物车等等。这些信息一般都和ID(键)挂钩，这种情景下键值数据库是个很好的选择。\n不适用场景：\n取代通过键查询，而是通过值来查询。Key-Value数据库中根本没有通过值查询的途径\n需要储存数据之间的关系。在Key-Value数据库中不能通过两个或以上的键来关联数据\n事务的支持。在Key-Value数据库中故障产生时不可以进行回滚\n列存储# 列存储数据库将数据储存在列族(column family)中，一个列族存储经常被一起查询的相关数据。举个例子，如果我们有一个Person类，我们通常会一起查询他们的姓名和年龄而不是薪资。这种情况下，姓名和年龄就会被放入一个列族中，而薪资则在另一个列族中。\n产品：Cassandra、HBase\n适用场景\n可以将数据储存在不同的列中，每个应用程序可以将信息写入自己的列族中。\n博客平台。储存每个信息到不同的列族中。举例：标签储存在一个，类别在一个，文章则在另一个。\n不适用场景\n如果需要ACID事务。Vassandra就不支持事务\n原型设计。如果分析Cassandra的数据结构，就会发现结构是基于期望的数据查询方式而定。在模型设计之初，根本不可能去预测它的查询方式，而一旦查询方式改变，就必须重新设计列族。\n文档型# 面向文档数据库会将数据以文档的形式储存。每个文档都是自包含的数据单元，是一系列数据项的集合。每个数据项都有一个名称与对应的值，值既可以是简单的数据类型，如字符串、数字和日期等;也可以是复杂的类型，如有序列表和关联对象。数据存储的最小单位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用XML、JSON或者JSONB等多种形式存储。\n产品：MongoDB、CouchDB、RavenDB\n适用场景\n日志，企业环境下，每个应用程序都有不同的日志信息。Document-Oriented数据库并没有固定的模式，所以可以使用它储存不同的信息\n分析，鉴于它的弱模式结构，不改变模式下就可以储存不同的度量方法及添加新的度量\n不适用场景\n在不同的文档上添加事务。Document-Oriented数据库并不支持文档间的事务，如果对这方面有需求则不应该选用这个解决方案。\n图形(Graph)# 图数据库允许将数据以图的方式储存。实体会被作为顶点，而实体之间的关系则会被作为边。比如我们有三个实体，Steve Jobs、Apple和Next，则会有两个“Founded by”的边将Apple和Next连接到Steve Jobs。\n产品：Neo4J、Infinite Graph、OrientDB\n适用场景\n在一些关系性强的数据中\n推荐引擎。如果将数据以图的形式表现，那么将会非常有益于推荐的制定\n不适用场景\n不适合的数据模型。图数据库的适用范围很小，因为很少有操作涉及到整个图\nNoSQL数据库对比# 分类 Examples举例 典型应用场景 数据模型 优点 缺点 键值（key-value） Key 指向 Value 的键值对，通常用hash table来实现 列存储数据库 Cassandra, HBase, Riak 分布式的文件系统 以列簇式存储，将同一列数据存在一起 查找速度快，可扩展性强，更容易进行分布式扩展 功能相对局限 文档型数据库 CouchDB, MongoDb Web应用（与Key-Value类似，Value是结构化的，不同的是数据库能够了解Value的内容） Key-Value对应的键值对，Value为结构化数据 数据结构要求不严格，表结构可变，不需要像关系型数据库一样需要预先定义表结构 查询性能不高，而且缺乏统一的查询语法。 图形(Graph)数据库 Neo4J, InfoGrid, Infinite Graph 社交网络，推荐系统等。专注于构建关系图谱 图结构 利用图结构相关算法。比如最短路径寻址，N度关系查找等 很多时候需要对整个图做计算才能得出需要的信息，而且这种结构不太好做分布式的集群方案。 "},{"id":93,"href":"/docs/redis/1.2redis%E5%AE%89%E8%A3%85/","title":"1.2 Redis安装","section":"所有文章","content":"下载安装包# Redis（Remote Dictionary Server )，即远程字典服务，是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。\nRedis 是没有 Windows 平台下的官方支持版本的。Redis 官方不建议在 Windows 下使用，所以官网没有 Windows 版本可以下载；可以下载在 github 上的ServiceStack 提供的非官方 Windows 版本的 Redis 但不推荐，因为：\n该版本并不是官方支持的，缺少官方支持在使用上可能会出现很多问题 Redis的最新版本与 Windows 版本不同步，Redis官网版本早于Redis中文网 所以不考虑Windows下版本安装，直接选择Linux下版本安装\nLinux安装程序分为两种\n手动安装 yum安装 如果是手动下载，需要将文件上传到Linux系统中\n解压文件\ntar -xvf Redis-6.2.1.tar.gzRedis是C语言开发，安装Redis需要先将Redis的源码进行编译，编译依赖gcc环境。因此需要安装gcc，安装过程中有提示时，输入Y即可。（make命令必须在Redis解压后的程序目录下执行）\nCentos7安装有默认gcc环境，默认4.8.5版本！编译 Redis-6.x，要求 gcc5.3以上 编译器，否则会遇到大量的错误。主要原因是从 Redis-6.x 开始的多线程代码依赖C标准库中的新增类型 _Atomic 。但注意 gcc 从 4.9 版本才开始正式和完整地支持 stdatomic（gcc-4.8.5 部分支持）。Centos7默认的 gcc 版本为：4.8.5 \u0026lt; 5.3 无法编译\nGcc升级# 参考 ：Centos7升级gcc版本\n查看gcc版本# [root@wangpengliang Redis]# gcc -v编译Redis# 进入 Redis 程序目录\ncd /usr/Redis/Redis-6.2.1Make：下载环境并编译 Redis 程序\n[root@localhost Redis-6.2.1]# make install #将Redis安装在Linux默认位置：/usr/local/bin 或者（推荐） [root@localhost Redis-6.2.1]# make install PREFIX=/usr/Redis/Redis-6.2.1/installpackage　#将Redis安装在指定位置安装完成查看文件列表\n[root@wangpengliang bin]# cd /usr/Redis/Redis-6.2.1/installpackage/bin [root@wangpengliang bin]# ls Redis-benchmark Redis-check-aof Redis-check-rdb Redis-cli Redis-sentinel Redis-server [root@wangpengliang bin]# ll 总用量 21940 -rwxr-xr-x. 1 root root 5675824 4月 18 01:32 Redis-benchmark lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-check-aof -\u0026gt; Redis-server lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-check-rdb -\u0026gt; Redis-server -rwxr-xr-x. 1 root root 5881760 4月 18 01:32 Redis-cli lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-sentinel -\u0026gt; Redis-server -rwxr-xr-x. 1 root root 10904032 4月 18 01:32 Redis-server配置Redis# 复制 Redis 核心配置文件，文件在安装命令目录中（默认位置在 /usr/local/bin ）。我在安装时选择了安装在指定位置（ /usr/Redis/Redis-6.2.1/installpackage ），Redis配置文件需要放在安装目录下。（Redis.conf 配置文件在 Redis 程序目录中）\n# 进入Redis安装目录/bin [root@wangpengliang bin]# cd /usr/Redis/Redis-6.2.1/installpackage/bin # 创建目录conf：用于存放配置文件 [root@wangpengliang bin]# mkdir conf # 查看创建结果 [root@wangpengliang bin]# ll 总用量 21940 drwxr-xr-x. 2 root root 6 4月 18 01:43 conf -rwxr-xr-x. 1 root root 5675824 4月 18 01:32 Redis-benchmark lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-check-aof -\u0026gt; Redis-server lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-check-rdb -\u0026gt; Redis-server -rwxr-xr-x. 1 root root 5881760 4月 18 01:32 Redis-cli lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-sentinel -\u0026gt; Redis-server -rwxr-xr-x. 1 root root 10904032 4月 18 01:32 Redis-server # 复制Redis程序目录中的配置文件放入到Redis安装目录下conf目录中 [root@wangpengliang bin]# cp /usr/Redis/Redis-6.2.1/Redis.conf /usr/Redis/Redis-6.2.1/install package/bin/conf/[root@wangpengliang bin]# ll 总用量 21940 drwxr-xr-x. 2 root root 24 4月 18 01:44 conf -rwxr-xr-x. 1 root root 5675824 4月 18 01:32 Redis-benchmark lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-check-aof -\u0026gt; Redis-server lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-check-rdb -\u0026gt; Redis-server -rwxr-xr-x. 1 root root 5881760 4月 18 01:32 Redis-cli lrwxrwxrwx. 1 root root 12 4月 18 01:32 Redis-sentinel -\u0026gt; Redis-server -rwxr-xr-x. 1 root root 10904032 4月 18 01:32 Redis-server # 进入Redis安装目录下conf目录 [root@wangpengliang bin]# cd conf # 查看配置文件 [root@wangpengliang conf]# ll 总用量 92 -rw-r--r--. 1 root root 92222 4月 18 01:44 Redis.conf启动Redis# 进入 Redis 安装目录 bin 使用命令启动 Redis 服务（测试 Redis 服务会占用一个窗口） # 在Redis安装目录下的bin目录中启动Redis服务并指定配置文件 [root@wangpengliang bin]# ./Redis-server conf/Redis.conf 20335:C 18 Apr 2021 01:51:48.190 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 20335:C 18 Apr 2021 01:51:48.190 # Redis version=6.2.1, bits=64, commit=00000000, modified=0, pid=20335, just started20335:C 18 Apr 2021 01:51:48.190 # Configuration loaded 20335:M 18 Apr 2021 01:51:48.191 * Increased maximum number of open files to 10032 (it was or iginally set to 1024).20335:M 18 Apr 2021 01:51:48.191 * monotonic clock: POSIX clock_gettime _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 6.2.1 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 6379 | `-._ `._ / _.-\u0026#39; | PID: 20335 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | http://Redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 20335:M 18 Apr 2021 01:51:48.193 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.20335:M 18 Apr 2021 01:51:48.193 # Server initialized 20335:M 18 Apr 2021 01:51:48.193 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect.20335:M 18 Apr 2021 01:51:48.193 * Ready to accept connections测试Redis# 新开连接窗口，启动客户端连接 Redis 服务器。\n[root@wangpengliang ~]# cd /usr/Redis/Redis-6.2.1/installpackage/bin # 启动客户端连接服务器并指定端口 [root@wangpengliang bin]# ./Redis-cli -p 6379 # 测试连接 127.0.0.1:6379\u0026gt; ping PONG # 退出Redis 127.0.0.1:6379\u0026gt; exit后台启动Redis# 以上的 Redis 安装和启动可以算是临时服务。当开启服务后，Redis服务窗口是无法再使用的，可以将 Redis 服务设置为后台启动服务，避免 Linux 窗口连接的浪费。\n编辑 Redis 配置文件 Redis.conf 开启 Redis 后台服务（默认是关闭的） Step1：vi /usr/Redis/Redis6.x/bin/conf/Redis.conf　打开编辑(键入命令 :set nu 显示行号)\nStep2：输入i、I、a 等进入编辑模式\nStep3：将daemonize no 改成daemonize yes（表示开启Redis后台服务：约225行）\nStep4：按 esc 退出插入模式，输入:wq 保存退出\n# 启动Redis服务 [root@wangpengliang bin]# ./Redis-server conf/Redis.conf # 此时Redis服务已经作为后台服务启动，不再占用窗口，直接在本窗口启用客户端测试连接 [root@wangpengliang bin]# ./Redis-cli -p 6379 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; exit查看Redis服务进程# # 查看进程服务，过滤只看Redis的 [root@wangpengliang bin]# ps -ef |grep Redis root 20395 1 0 02:07 ? 00:00:00 ./Redis-server 127.0.0.1:6379 root 20410 20345 0 02:10 pts/1 00:00:00 grep --color=auto Redis卸载# 删除 Redis 安装目录和 Redis 解压文件即可。\nRedis6379端口不通解决方法# 背景\nRedis 在虚拟机中安装 使用 RedisClient 在 Windows 主机中连接 虚拟机中查看 Redis 进程和端口，都是存在的；但是IP地址需要设置为 0.0.0.0 而不是 127.0.0.1 ，更改 Redis 使用的配置文件即可。\nbind 127.0.0.1 =\u0026gt; bind 0.0.0.0127.0.0.1只能是本机能使用，如果 Redis 已经启动，需要先停止才能使配置文件生效\n[root@wangpengliang bin]# ./Redis-cli -p 6379 127.0.0.1:6379\u0026gt; SHUTDOWN not connected\u0026gt;重启 Redis\n[root@wangpengliang bin]# ./Redis-server conf/Redis.conf主机中使用 RedisClient 连接\n本机安装的Redis版本为6.x，RedisClient暂不支持\n这里可以使用控制台来测试，只是缺少了可视化的优势，需要自己敲命令\n"},{"id":94,"href":"/docs/redis/1.3redis%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"1.3 Redis基本数据类型","section":"所有文章","content":"Redis基本数据类型\nString字符串# Redis 字符串是字节序列。Redis 字符串是二进制安全的，意味着他们有一个已知的长度没有任何特殊字符终止，所以可以存储任何东西，512M 为上限，主要的还是操作键值对。String的数据结构是简单的 Key-Value模型，Value可以是字符串，也可以是数字。\nset key value# 普通添加\n127.0.0.1:6379 set name wangpengliang OK 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34;setex key seconds value# 添加时设置过期时间\n127.0.0.1:6379 setex name 30 wangpengliang OK 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34;ttl# 检查key还有多少秒过期\n127.0.0.1:6379 setex name 30 wangpengliang OK 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34; # 查看距离过期时间还有多少秒 127.0.0.1:6379 ttl name (integer) 18 127.0.0.1:6379 \u0026gt;setnx key value# 如果key不存在，则创建一个key，如果key存在，则创建失败并返回0；setnx 在分布式锁中经常使用到\n# 设置key=name value=wangpengliang 127.0.0.1:6379 set name wangpengliang OK # 检查是否设置成功 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34; # 使用setnx设置key=name:因为已存在所以创建失败返回0 127.0.0.1:6379 setnx name wangpengliang (integer) 0 # 清空数据库 127.0.0.1:6379 FLUSHDB OK # 重新使用setnx设置key=name:返回1说明创建成功 127.0.0.1:6379 setnx name wangpengliang (integer) 1 # 检查是否设置成功 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34;get key# 获取指定key的value\n127.0.0.1:6379 set name wangpengliang OK 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34;mset/mget# 用于同时设置/获取一个或多个键值对，批量操作。同时设置多个值，如果其中有一个存在，那么就都创建失败；要么一起成功，要么一起失败，这是一个原子性操作\n# 使用mset同时设置多个k-v 127.0.0.1:6379 mset name1 wangpengliang name2 lizimeng name3 shijiangtao OK # 使用met同时读取多个k-v 127.0.0.1:6379 mget name1 name2 name3 1) \u0026#34;wangpengliang\u0026#34; 2) \u0026#34;lizimeng\u0026#34; 3) \u0026#34;shijiangtao\u0026#34;incr# 让当前键值以 1 的数量递增，并返回递增后的值。相当于C#中的 i++\n# 设置key=num value=10 127.0.0.1:6379 set num 10 OK 127.0.0.1:6379 get num \u0026#34;10\u0026#34; # 设置key=num value=value+1 127.0.0.1:6379 incr num (integer) 11incrby# 可以指定参数一次增加的数值，并返回递增后的值。设置步长的方式递增\n# 设置key=num value=10 127.0.0.1:6379 set num 10 OK 127.0.0.1:6379 get num \u0026#34;10\u0026#34; # 设置key=num value=value+2(2是步长) 127.0.0.1:6379 incrby num 2 (integer) 12decr# 让当前键值以 1 的数量递减，并返回递减后的值。相当于C#中的 i--\n# 设置key=num value=10 127.0.0.1:6379 set num 10 OK 127.0.0.1:6379 get num \u0026#34;10\u0026#34; # 设置key=num value=value-1 127.0.0.1:6379 decr num (integer) 9decrby# 可以指定参数一次减少的数值，并返回递减后的值。设置步长的方式递减\n# 设置key=num value=10 OK 127.0.0.1:6379 get num \u0026#34;10\u0026#34; # 设置key=num value=value-2(2是步长) 127.0.0.1:6379 incrby num 2 (integer) 8append# 向键值的末尾追加 value。如果键不存在则将该键的值设置为 value。返回值是追加后字符串的总长度\n127.0.0.1:6379 append name wang (integer) 4 127.0.0.1:6379 get name \u0026#34;wang\u0026#34;127.0.0.1:6379 set name wang OK 127.0.0.1:6379 get name \u0026#34;wang\u0026#34; 127.0.0.1:6379 append name pengliang (integer) 13 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34;strlen# 获取字符串长度\n127.0.0.1:6379 set name wangpengliang OK 127.0.0.1:6379 strlen name (integer) 13getrange# 截取指定索引的字符串，相当于 Substring\n127.0.0.1:6379 set name wangpengliang OK 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34; 127.0.0.1:6379 getrange name 0 3 \u0026#34;wang\u0026#34;setrange# 从指定索引开始替换字符串\n127.0.0.1:6379 set name hello OK 127.0.0.1:6379 get name \u0026#34;hello\u0026#34; 127.0.0.1:6379 setrange name 0 world (integer) 5 127.0.0.1:6379 get name \u0026#34;world\u0026#34;127.0.0.1:6379 set name \u0026#34;hello java\u0026#34; OK 127.0.0.1:6379 get name \u0026#34;hello java\u0026#34; 127.0.0.1:6379 setrange name 6 \u0026#34;csharp\u0026#34; (integer) 12 127.0.0.1:6379 get name \u0026#34;hello csharp\u0026#34;127.0.0.1:6379 set name \u0026#34;hello csharp\u0026#34; OK 127.0.0.1:6379 get name \u0026#34;hello csharp\u0026#34; 127.0.0.1:6379 setrange name 6 \u0026#34;java\u0026#34; (integer) 12 127.0.0.1:6379 get name \u0026#34;hello javarp\u0026#34;注意：命令会确保字符串足够长以便将 value 设置在指定的偏移量上，如果给定 key 原来储存的字符串长度比偏移量小。比如：字符串只有 5 个字符长，但你设置的 offset 是 10 ，那么原字符和偏移量之间的空白将用零字节(zerobytes, \u0026quot;\\x00\u0026quot; )来填充。\ndel# 根据key删除一个或者多个元素\n127.0.0.1:6379 set name wangpengliang OK 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34; 127.0.0.1:6379 del name (integer) 1 127.0.0.1:6379 get name (nil)127.0.0.1:6379 mset k1 wangpengliang k2 lizimeng OK 127.0.0.1:6379 mget k1 k2 1) \u0026#34;wangpengliang\u0026#34; 2) \u0026#34;lizimeng\u0026#34; 127.0.0.1:6379 del k1 k2 (integer) 2 127.0.0.1:6379 mget k1 k2 1) (nil) 2) (nil)对象方式设置# 设置一个user:1对象，值为Json字符串来保存一个对象；set user:1 {name:zhangsan,age:3}\n# 设置key=num value=10 127.0.0.1:6379 set num 10 OK 127.0.0.1:6379 get num \u0026#34;10\u0026#34; # 设置key=num value=value-1 127.0.0.1:6379 decr num (integer) 9127.0.0.1:6379 mset user:1:name wangpengliang user:1:age 25 OK 127.0.0.1:6379 mget user:1:name user:1:age 1) \u0026#34;wangpengliang\u0026#34; 2) \u0026#34;25\u0026#34;getset# 先 get 然后再 set 如果设置的键不存在值 =\u0026gt; 则设置值，并且返回 nil 如果设置的键存在值，则返回该值，并设置新的值\n127.0.0.1:6379 getset name wangpengliang (nil) 127.0.0.1:6379 get name \u0026#34;wangpengliang\u0026#34; 127.0.0.1:6379 getset name lizimeng \u0026#34;wangpengliang\u0026#34; 127.0.0.1:63应用场景# 计数器—点赞,视频播放量,每播放一次就+1 统计多单位的数量 粉丝数 对象缓存存储 Hash散列表# Redis 的哈希是键值对的集合。Redis 的哈希值是字符串字段和字符串值之间的映射，因此它们被用来表示对象，还有用户信息之类的，经常变动的信息。\nhset# 存储一个哈希键值对的集合。格式：hset key field value\n127.0.0.1:6379 hset user name wangpengliang age 25 (integer) 2 127.0.0.1:6379 hget user name \u0026#34;wangpengliang\u0026#34; 127.0.0.1:6379 hget user age \u0026#34;25\u0026#34;hget# 获取一个哈希键的值。格式：hget key field\n127.0.0.1:6379 hset user name wangpengliang age 25 (integer) 2 127.0.0.1:6379 hget user name \u0026#34;wangpengliang\u0026#34;hmset# 存储一个或多个哈希是键值对的集合。格式：hmset key field1 value1 …fieldN keyN\n127.0.0.1:6379 hmset user1 name wangpengliang age 25 address beijing OK 127.0.0.1:6379 hmget user1 name age address 1) \u0026#34;wangpengliang\u0026#34; 2) \u0026#34;25\u0026#34; 3) \u0026#34;beijing\u0026#34;hmget# 获取多个指定的键的值。格式：hmget key field1 … fieldN\n127.0.0.1:6379 hset user name wangpengliang age 25 (integer) 2 127.0.0.1:6379 hget user name \u0026#34;wangpengliang\u0026#34;hexists# 判断哈希表中的字段名是否存在 如果存在返回 1 否则返回 0。格式：hexists key field\n127.0.0.1:6379 hmset user1 name wangpengliang age 25 address beijing OK 127.0.0.1:6379 hmget user1 name age address 1) \u0026#34;wangpengliang\u0026#34; 2) \u0026#34;25\u0026#34; 3) \u0026#34;beijing\u0026#34; 127.0.0.1:6379 hexists user1 name (integer) 1 127.0.0.1:6379 hexists user1 aa (integer) 0hdel# 删除一个或多个字段。格式：hdel key field\n127.0.0.1:6379 hmset user name wangpengliang age 25 OK 127.0.0.1:6379 hmget user name age 1) \u0026#34;wangpengliang\u0026#34; 2) \u0026#34;25\u0026#34; 127.0.0.1:6379 hdel user name (integer) 1 127.0.0.1:6379 hmget user name age 1) (nil) 2) \u0026#34;25\u0026#34;hgetall# 获取一个哈希是键值对的集合。 格式：hgetall key\n127.0.0.1:6379 hmset user name wangpengliang age 25 OK 127.0.0.1:6379 hgetall user 1) \u0026#34;age\u0026#34; 2) \u0026#34;25\u0026#34; 3) \u0026#34;name\u0026#34; 4) \u0026#34;wangpengliang\u0026#34;hvals# 只返回字段值。 格式：hvals key\n127.0.0.1:6379 hmset user name wangpengliang age 25 OK 127.0.0.1:6379 hvals user 1) \u0026#34;25\u0026#34; 2) \u0026#34;wangpengliang\u0026#34;hkeys# 只返回字段名。 格式：hkeys key\n127.0.0.1:6379 hmset user name wangpengliang age 25 OK 127.0.0.1:6379 hkeys user 1) \u0026#34;age\u0026#34; 2) \u0026#34;name\u0026#34;hlen# 返回 key 的 hash 的元素个数\n127.0.0.1:6379 hmset user name wangpengliang age 25 OK 127.0.0.1:6379 hlen user (integer) 2hincrby key field value# 指定增量value\n127.0.0.1:6379 hset test num 10 (integer) 1 127.0.0.1:6379 hget test num \u0026#34;10\u0026#34; 127.0.0.1:6379 hincrby test num 2 (integer) 12hsetnx key field value# 如果该键不存在就创建，如果该键存在就创建失败\n127.0.0.1:6379 hsetnx test num 10 (integer) 1 127.0.0.1:6379 hsetnx test num 20 (integer) 0应用场景# 主要用于存储部分变更数据，比如存储用户信息等等 List链表# Redis 的链表是简单的字符串列表，可以添加元素到 Redis 列表的头部或尾部。 Lpush：表示向链表的左添加，也就是向链表的头添加 Rpush：表示向链表的右添加，也就是向链表的尾添加\nlpush key value# 向链表左侧添加(头插法)\n127.0.0.1:6379 lpush keys one (integer) 1 127.0.0.1:6379 lpush keys two (integer) 2 127.0.0.1:6379 lpush keys three (integer) 3 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;three\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;one\u0026#34;rpush key value# 向链表右侧添加(尾插法)\n127.0.0.1:6379 rpush keys one (integer) 1 127.0.0.1:6379 rpush keys two (integer) 2 127.0.0.1:6379 rpush keys three (integer) 3 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34;lpop key# 从左边移出一个元素\n127.0.0.1:6379 rpush keys one (integer) 1 127.0.0.1:6379 rpush keys two (integer) 2 127.0.0.1:6379 rpush keys three (integer) 3 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; 127.0.0.1:6379 lpop keys \u0026#34;one\u0026#34; 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;two\u0026#34; 2) \u0026#34;three\u0026#34;rpop key# 从右边移出一个元素\n127.0.0.1:6379 rpush keys one (integer) 1 127.0.0.1:6379 rpush keys two (integer) 2 127.0.0.1:6379 rpush keys three (integer) 3 127.0.0.1:6379 rpop keys \u0026#34;three\u0026#34; 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34;lrange key start end# 命令将返回索引从 start 到 stop 之间的所有元素。Redis 的列表起始索引为 0。如果要获取全部的元素：lrange key 0 -1\n127.0.0.1:6379 rpush keys one (integer) 1 127.0.0.1:6379 rpush keys two (integer) 2 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34;llen key# 返回链表中元素的个数 相当于关系型数据库中 select count(*)\n127.0.0.1:6379 rpush keys one (integer) 1 127.0.0.1:6379 rpush keys two (integer) 2 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 127.0.0.1:6379 llen keys (integer) 2lindex key indexnumber# lindex 命令用来返回指定索引的元素，索引从 0 开始，如果是负数表示从右边开始计算的索引，最右边元素的索引是-1。如果要将列表类型当做数组来用，lindex 命令是必不可少的\n127.0.0.1:6379 rpush keys one (integer) 1 127.0.0.1:6379 rpush keys two (integer) 2 127.0.0.1:6379 rpush keys three (integer) 3 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; 127.0.0.1:6379 lindex keys 2 \u0026#34;three\u0026#34;lset key indexnumber value# 它会将索引为 index的元素赋值为 value，原来的值会被覆盖。如果该列表不存在就会报错。所以使用这个命令之前先使用exists判断一下\n127.0.0.1:6379 rpush keys one (integer) 1 127.0.0.1:6379 rpush keys two (integer) 2 127.0.0.1:6379 rpush keys three (integer) 3 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; 127.0.0.1:6379 lset keys 2 twotwo OK 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;twotwo\u0026#34; 127.0.0.1:6379 lset keys 10 twotwo (error) ERR index out of rangelrem key count value# 移除key链表中``count` 个元素的value值，精确匹配，如果链表中有多个重复的值，这里的count指的是可以删除多个相同key的值\n127.0.0.1:6379 rpush keys a (integer) 1 127.0.0.1:6379 rpush keys b (integer) 2 127.0.0.1:6379 rpush keys c (integer) 3 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34; 127.0.0.1:6379 rpush keys d (integer) 4 127.0.0.1:6379 rpush keys a (integer) 5 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34; 4) \u0026#34;d\u0026#34; 5) \u0026#34;a\u0026#34; 127.0.0.1:6379 lrem keys 2 a (integer) 2 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;b\u0026#34; 2) \u0026#34;c\u0026#34; 3) \u0026#34;d\u0026#34;ltrim list startIndex endIndex# 通过下标截取指定的长度，这个时候List已经改变了，只剩下截断的元素\n127.0.0.1:6379 clear 127.0.0.1:6379 rpush keys a (integer) 1 127.0.0.1:6379 rpush keys b (integer) 2 127.0.0.1:6379 rpush keys c (integer) 3 127.0.0.1:6379 rpush keys d (integer) 4 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34; 4) \u0026#34;d\u0026#34; 127.0.0.1:6379 ltrim keys 2 3 OK 127.0.0.1:6379 lrange keys 0 -1 1) \u0026#34;c\u0026#34; 2) \u0026#34;d\u0026#34;rpoplpush source destination# 移除当前的source链表中的最后一个元素，并且将该元素移动到destination链表当中\n127.0.0.1:6379 rpush keys1 a (integer) 1 127.0.0.1:6379 rpush keys1 b (integer) 2 127.0.0.1:6379 rpush keys1 c (integer) 3 127.0.0.1:6379 rpoplpush keys1 keys2 \u0026#34;c\u0026#34; 127.0.0.1:6379 lrange keys1 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 127.0.0.1:6379 lrange keys2 0 -1 1) \u0026#34;c\u0026#34;linsert key BEFORE|AFTER pivot value# 在Key列表的指定元素的前/后面插入元素value\n127.0.0.1:6379 rpush keys1 a (integer) 1 127.0.0.1:6379 rpush keys1 b (integer) 2 127.0.0.1:6379 rpush keys1 c (integer) 3 127.0.0.1:6379 linsert keys1 before b a1 (integer) 4 127.0.0.1:6379 lrange keys 0 -1 (empty array) 127.0.0.1:6379 lrange keys1 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;a1\u0026#34; 3) \u0026#34;b\u0026#34; 4) \u0026#34;c\u0026#34; 127.0.0.1:6379 linsert keys1 after b b1 (integer) 5 127.0.0.1:6379 lrange keys1 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;a1\u0026#34; 3) \u0026#34;b\u0026#34; 4) \u0026#34;b1\u0026#34; 5) \u0026#34;c\u0026#34; List是一个链表，before node after，left ，right都可以插入值 如果key不存在，就创建新的链表 如果key存在就创建新的值 如果移除了所有的值，空链表，也就代表不存在 在两边插入或者改动值，效率最高，中间元素相对来说效率会低一点 应用场景# 消息队列：利用 List 的Push 操作，将任务存在 List 中，然后工作线程再用POP 操作将任务取出进行执行。Redis还提供了操作List中某一段的API，可以直接查询，删除 List 中某一段的元素。 消息排队：消息队列（Lpush、Rpop）、栈（Lpush、Lpop）使用 List 可以构建队列系统，使用 sorted set 甚至可以构建有优先级的队列系统。 Set集合# Redis 的集合是字符串的无序集合。但在Set集合当中，是不允许有重复的。Set是通过hash table实现的，可以进行添加、删除和查找。对集合可以取 并集，交集，差集。\nsadd key value# 添加一个 string 元素到key对应的 set 集合中， 成功返回 1,如果元素已经在集合中返回 0\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys a (integer) 0 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;a\u0026#34; 3) \u0026#34;b\u0026#34;scard key# 返回 set 的元素个数，如果 set 是空或者key不存在返回 0\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;a\u0026#34; 3) \u0026#34;b\u0026#34; 127.0.0.1:6379 scard keys (integer) 3smembers key# 返回 key 对应 set 的所有元素，结果是无序的\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;a\u0026#34; 3) \u0026#34;b\u0026#34;sismember key value# 判断 value 是否在 set 中，存在返回1，0表示不存在或者key不存在\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;a\u0026#34; 3) \u0026#34;b\u0026#34; 127.0.0.1:6379 sismember keys a (integer) 1 127.0.0.1:6379 sismember keys d (integer) 0srem key value# 从 key 对应 set 中移除给定元素，成功返回1，如果 value 在集合中不存在或者key不存在返回 0\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;a\u0026#34; 3) \u0026#34;b\u0026#34; 127.0.0.1:6379 srem keys a (integer) 1 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;b\u0026#34; 127.0.0.1:6379 srem keys g (integer) 0srandmember key nums# 从key集合中随机抽取nums个元素\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 srandmember keys 2 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34;spop key# 随机删除一些key集合中的元素\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 spop keys \u0026#34;a\u0026#34; 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;b\u0026#34;smove source destination member# 将原集合source中的member元素移动到destination集合中\n127.0.0.1:6379 sadd keys a (integer) 1 127.0.0.1:6379 sadd keys b (integer) 1 127.0.0.1:6379 sadd keys c (integer) 1 127.0.0.1:6379 smove keys keys2 a (integer) 1 127.0.0.1:6379 smembers keys 1) \u0026#34;c\u0026#34; 2) \u0026#34;b\u0026#34; 127.0.0.1:6379 smembers keys2 1) \u0026#34;a\u0026#34;sdiff key1 key2# 取出key1中与key2集合的不同元素，差集\n127.0.0.1:6379 sadd keys1 a (integer) 1 127.0.0.1:6379 sadd keys1 b (integer) 1 127.0.0.1:6379 sadd keys1 c (integer) 1 127.0.0.1:6379 sadd keys2 c (integer) 1 127.0.0.1:6379 sadd keys2 g (integer) 1 127.0.0.1:6379 sadd keys2 f (integer) 1 127.0.0.1:6379 sdiff keys1 keys2 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34;sinter key1 key2# 取key1与key2两个集合中相同的元素，交集\n127.0.0.1:6379 sadd keys1 a (integer) 1 127.0.0.1:6379 sadd keys1 b (integer) 1 127.0.0.1:6379 sadd keys1 c (integer) 1 127.0.0.1:6379 sadd keys2 c (integer) 1 127.0.0.1:6379 sadd keys2 g (integer) 1 127.0.0.1:6379 sadd keys2 f (integer) 1 127.0.0.1:6379 sinter keys1 keys2 1) \u0026#34;c\u0026#34;sunion key1 key2# 将key1与key2两个集合中的元素合在一起，并集\n127.0.0.1:6379 sadd keys1 a (integer) 1 127.0.0.1:6379 sadd keys1 b (integer) 1 127.0.0.1:6379 sadd keys1 c (integer) 1 127.0.0.1:6379 sadd keys2 c (integer) 1 127.0.0.1:6379 sadd keys2 g (integer) 1 127.0.0.1:6379 sadd keys2 f (integer) 1 127.0.0.1:6379 sunion keys1 keys2 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34; 3) \u0026#34;g\u0026#34; 4) \u0026#34;b\u0026#34; 5) \u0026#34;f\u0026#34;应用场景# 微博、用户将所有关注的人都放入到一个set集合当中，将它的粉丝也放在一个集合中 共同关注、共同爱好、二度好友、QQ的好友推荐（六度分割理论） SortedSet( 有序集合) zset# Redis 的有序集合类似于 Redis 的集合，字符串不重复的集合；zset是一个有序集合，每一个成员有一个分数与之对应，成员不可以重复，但是分数是可以重复的，zset会自动用分数对成员进行排序。\nzadd key score value# 将一个或多个 value 及其 socre 加入到 set 中\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34;zrange key start end# 0 和-1 表示从索引为 0 的元素到最后一个元素（同 LRANGE 命令相似）\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34;zrange key 0 -1 withscores# 连同 score 一块输出，使用 WITHSCORES 参数\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zadd keys 2 b (integer) 1 127.0.0.1:6379 zadd keys 3 c (integer) 1 127.0.0.1:6379 zrange keys 0 -1 withscores 1) \u0026#34;a\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;b\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;c\u0026#34; 6) \u0026#34;3\u0026#34;zremrangebyscore key start end# 范围删除操作\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zadd keys 2 b (integer) 1 127.0.0.1:6379 zadd keys 3 c (integer) 1 127.0.0.1:6379 zrange keys 0 -1 withscores 1) \u0026#34;a\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;b\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;c\u0026#34; 6) \u0026#34;3\u0026#34; 127.0.0.1:6379 zremrangebyscore keys 0 2 (integer) 2 127.0.0.1:6379 zrange keys 0 -1 withscores 1) \u0026#34;c\u0026#34; 2) \u0026#34;3\u0026#34;zrangebyscore key min max# 升序排序操作，将key按最小值到最大值进行输出\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zadd keys 2 b (integer) 1 127.0.0.1:6379 zadd keys 3 c (integer) 1 127.0.0.1:6379 zrangebyscore keys 1 3 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34;srandmember key nums# 倒序排序操作，将key按照从大到小排序输出\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zadd keys 2 b (integer) 1 127.0.0.1:6379 zadd keys 3 c (integer) 1 127.0.0.1:6379 zrevrangebyscore keys 3 1 1) \u0026#34;c\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;a\u0026#34;zrem key value# 删除指定的元素\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zadd keys 2 b (integer) 1 127.0.0.1:6379 zadd keys 3 c (integer) 1 127.0.0.1:6379 zrem keys b (integer) 1 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34; 127.0.0.1:6379 zrem keys d (integer) 0 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34;zcard key# 获取有序集合中的个数\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zadd keys 2 b (integer) 1 127.0.0.1:6379 zadd keys 3 c (integer) 1 127.0.0.1:6379 zrem keys b (integer) 1 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34; 127.0.0.1:6379 zrem keys d (integer) 0 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34; 127.0.0.1:6379 zcard keys (integer) 2count key min max# 获取指定区间的成员数量\n127.0.0.1:6379 zadd keys 1 a (integer) 1 127.0.0.1:6379 zadd keys 2 b (integer) 1 127.0.0.1:6379 zadd keys 3 c (integer) 1 127.0.0.1:6379 zrem keys b (integer) 1 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34; 127.0.0.1:6379 zrem keys d (integer) 0 127.0.0.1:6379 zrange keys 0 -1 1) \u0026#34;a\u0026#34; 2) \u0026#34;c\u0026#34; 127.0.0.1:6379 zcard keys (integer) 2 127.0.0.1:6379 zcount keys 0 2 (integer) 1应用场景# 存储班级成绩表、工资表排序 参考# Redis中文命令手册\n"},{"id":95,"href":"/docs/redis/1.4redis%E7%89%B9%E6%AE%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"1.4 Redis特殊数据类型","section":"所有文章","content":"redis特殊数据类型\nGeospatial 地理位置# Hyperloglog 基数统计# Bitmap位图# TODO：知道有这个东西，需要用的时候看下文档即可，不做记录。\n"},{"id":96,"href":"/docs/redis/1.5redis%E4%BA%8B%E5%8A%A1%E6%93%8D%E4%BD%9C/","title":"1.5 Redis事务操作","section":"所有文章","content":"事务概念# 一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序的串行化执行而不会被其他命令插入，不许加塞。\n事务作用# 一个队列中，一次性、顺序性、排他性的执行一系列命令。\n事务常用命令# multi# 标记一个事务块的开始\n127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)\u0026gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)\u0026gt; get k1 QUEUED 127.0.0.1:6379(TX)\u0026gt; exec 1) OK 2) OK 3) \u0026#34;v1\u0026#34;discard# 取消事务，放弃执行事务块内的所有命令\n127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)\u0026gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)\u0026gt; discard OK 127.0.0.1:6379\u0026gt; get k1 (nil)exec# 执行所有事务块内的命令\n127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)\u0026gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)\u0026gt; get k1 QUEUED 127.0.0.1:6379(TX)\u0026gt; exec 1) OK 2) OK 3) \u0026#34;v1\u0026#34;事务原子性# Redis单条命令是保证原子性的，但是Redis事务并不能保证原子性。所有的命令在事务中并不会立即执行，只会在执行事务的时候才会执行，所以Redis事务没有事务隔离级别的概念。\n编译时异常\n127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)\u0026gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)\u0026gt; set k3 v3 QUEUED # 随便写的，此时会报错误不存在这个命令；但是并没有说事务停止了 127.0.0.1:6379(TX)\u0026gt; helloworld (error) ERR unknown command `helloworld`, with args beginning with: 127.0.0.1:6379(TX)\u0026gt; set k4 v4\\ QUEUED 127.0.0.1:6379(TX)\u0026gt; exec (error) EXECABORT Transaction discarded because of previous errors. 127.0.0.1:6379\u0026gt; get k1 (nil)结果可知：事务中所有命令都不会被执行\n运行时异常\n127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)\u0026gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)\u0026gt; set k3 v3 QUEUED # k1值是字符串类型所以无法自增，但是并没有提示错误 127.0.0.1:6379(TX)\u0026gt; incr k1 QUEUED 127.0.0.1:6379(TX)\u0026gt; exec 1) OK 2) OK 3) OK 4) (error) ERR value is not an integer or out of range 127.0.0.1:6379\u0026gt; get k1 \u0026#34;v1\u0026#34; 127.0.0.1:6379\u0026gt; get k2 \u0026#34;v2\u0026#34; 127.0.0.1:6379\u0026gt; get k3 \u0026#34;v3\u0026#34;结果可知：出错的命令不会被执行，正常的命令还是会被执行\n基于编译时异常和运行时异常的区别，可以更好的理解为什么说：Redis单条命令是保证原子性的，但是Redis事务是不保证原子性的。\nWatch监控# 乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。\n悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会 block 直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。\n单线程操作# # 余额 127.0.0.1:6379\u0026gt; set money 100 OK # 花出去的钱 127.0.0.1:6379\u0026gt; set out 0 OK # 监视money 127.0.0.1:6379\u0026gt; watch money OK # 启动事务 127.0.0.1:6379\u0026gt; multi OK # 余额-20 127.0.0.1:6379(TX)\u0026gt; DECRby money 20 QUEUED # out+20 127.0.0.1:6379(TX)\u0026gt; INCRBY out 20 QUEUED # 执行事务 127.0.0.1:6379(TX)\u0026gt; EXEC 1) (integer) 80 2) (integer) 20结果正常\n多线程操作# 客户端1\n# 余额 127.0.0.1:6379\u0026gt; set money 100 OK # 花出去的钱 127.0.0.1:6379\u0026gt; set out 0 OK # 监视money 127.0.0.1:6379\u0026gt; watch money OK # 启动事务 127.0.0.1:6379\u0026gt; multi OK # 余额-20 127.0.0.1:6379(TX)\u0026gt; DECRby money 20 QUEUED # out+20 127.0.0.1:6379(TX)\u0026gt; INCRBY out 20 QUEUED 注意：这个时候并没有执行事务\n客户端2\n127.0.0.1:6379\u0026gt; WATCH money OK 127.0.0.1:6379\u0026gt; incrby money 100 (integer) 200回到客户端1\n127.0.0.1:6379(TX)\u0026gt; exec (nil)结果可知：使用watch可以实现乐观锁的功能\nUnWatch# 接着上面的 watch 讲解，先解锁再获取最新的值进行操作。\n# 解锁 127.0.0.1:6379\u0026gt; unwatch OK 127.0.0.1:6379\u0026gt; multi OK 127.0.0.1:6379(TX)\u0026gt; decrby money 20 QUEUED 127.0.0.1:6379(TX)\u0026gt; INCRBY out 20 QUEUED 127.0.0.1:6379(TX)\u0026gt; exec 1) (integer) 180 2) (integer) 20"},{"id":97,"href":"/docs/redis/1.6redis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"1.6 Redis配置文件详解","section":"所有文章","content":"Redis.Config 配置文件# 经常使用的配置使用“# =\u0026gt;”方式写了注释\n# Redis configuration file example. # # Note that in order to read the configuration file, Redis must be # started with the file path as first argument: # # ./redis-server /path/to/redis.conf # Note on units: when memory size is needed, it is possible to specify # it in the usual form of 1k 5GB 4M and so forth: # # =\u0026gt; 单位设置 # 1k =\u0026gt; 1000 bytes # 1kb =\u0026gt; 1024 bytes # 1m =\u0026gt; 1000000 bytes # 1mb =\u0026gt; 1024*1024 bytes # 1g =\u0026gt; 1000000000 bytes # 1gb =\u0026gt; 1024*1024*1024 bytes # # =\u0026gt; Redis单位对大小写不敏感 # units are case insensitive so 1GB 1Gb 1gB are all the same. # =\u0026gt; 包含：可以把多个Redis.conf组合成一个conf ################################## INCLUDES ################################### # Include one or more other config files here. This is useful if you # have a standard template that goes to all Redis servers but also need # to customize a few per-server settings. Include files can include # other files, so use this wisely. # # Note that option \u0026#34;include\u0026#34; won\u0026#39;t be rewritten by command \u0026#34;CONFIG REWRITE\u0026#34; # from admin or Redis Sentinel. Since Redis always uses the last processed # line as value of a configuration directive, you\u0026#39;d better put includes # at the beginning of this file to avoid overwriting config change at runtime. # # If instead you are interested in using includes to override configuration # options, it is better to use include as the last line. # # include /path/to/local.conf # include /path/to/other.conf ################################## MODULES ##################################### # Load modules at startup. If the server is not able to load modules # it will abort. It is possible to use multiple loadmodule directives. # # loadmodule /path/to/my_module.so # loadmodule /path/to/other_module.so # =\u0026gt; 网络配置 ################################## NETWORK ##################################### # By default, if no \u0026#34;bind\u0026#34; configuration directive is specified, Redis listens # for connections from all available network interfaces on the host machine. # It is possible to listen to just one or multiple selected interfaces using # the \u0026#34;bind\u0026#34; configuration directive, followed by one or more IP addresses. # Each address can be prefixed by \u0026#34;-\u0026#34;, which means that redis will not fail to # start if the address is not available. Being not available only refers to # addresses that does not correspond to any network interfece. Addresses that # are already in use will always fail, and unsupported protocols will always BE # silently skipped. # # Examples: # # bind 192.168.1.100 10.0.0.1 # listens on two specific IPv4 addresses # bind 127.0.0.1 ::1 # listens on loopback IPv4 and IPv6 # bind * -::* # like the default, all available interfaces # # ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the # internet, binding to all the interfaces is dangerous and will expose the # instance to everybody on the internet. So by default we uncomment the # following bind directive, that will force Redis to listen only on the # IPv4 and IPv6 (if available) loopback interface addresses (this means Redis # will only be able to accept client connections from the same host that it is # running on). # # IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES # JUST COMMENT OUT THE FOLLOWING LINE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # =\u0026gt; 绑定的IP:127.0.0.1只能是本地使用，如果需要提供给远程访问，需要设置为*统配或者指定IP bind 0.0.0.0 -::1 # Protected mode is a layer of security protection, in order to avoid that # Redis instances left open on the internet are accessed and exploited. # # When protected mode is on and if: # # 1) The server is not binding explicitly to a set of addresses using the # \u0026#34;bind\u0026#34; directive. # 2) No password is configured. # # The server only accepts connections from clients connecting from the # IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain # sockets. # # By default protected mode is enabled. You should disable it only if # you are sure you want clients from other hosts to connect to Redis # even if no authentication is configured, nor a specific set of interfaces # are explicitly listed using the \u0026#34;bind\u0026#34; directive. # =\u0026gt; 是否受保护模式 protected-mode yes # Accept connections on the specified port, default is 6379 (IANA #815344). # If port 0 is specified Redis will not listen on a TCP socket. # =\u0026gt; 端口设置 port 6379 # TCP listen() backlog. # # In high requests-per-second environments you need a high backlog in order # to avoid slow clients connection issues. Note that the Linux kernel # will silently truncate it to the value of /proc/sys/net/core/somaxconn so # make sure to raise both the value of somaxconn and tcp_max_syn_backlog # in order to get the desired effect. tcp-backlog 511 # Unix socket. # # Specify the path for the Unix socket that will be used to listen for # incoming connections. There is no default, so Redis will not listen # on a unix socket when not specified. # # unixsocket /run/redis.sock # unixsocketperm 700 # Close the connection after a client is idle for N seconds (0 to disable) timeout 0 # TCP keepalive. # # If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence # of communication. This is useful for two reasons: # # 1) Detect dead peers. # 2) Force network equipment in the middle to consider the connection to be # alive. # # On Linux, the specified value (in seconds) is the period used to send ACKs. # Note that to close the connection the double of the time is needed. # On other kernels the period depends on the kernel configuration. # # A reasonable value for this option is 300 seconds, which is the new # Redis default starting with Redis 3.2.1. tcp-keepalive 300 ################################# TLS/SSL ##################################### # By default, TLS/SSL is disabled. To enable it, the \u0026#34;tls-port\u0026#34; configuration # directive can be used to define TLS-listening ports. To enable TLS on the # default port, use: # # port 0 # tls-port 6379 # Configure a X.509 certificate and private key to use for authenticating the # server to connected clients, masters or cluster peers. These files should be # PEM formatted. # # tls-cert-file redis.crt # tls-key-file redis.key # Normally Redis uses the same certificate for both server functions (accepting # connections) and client functions (replicating from a master, establishing # cluster bus connections, etc.). # # Sometimes certificates are issued with attributes that designate them as # client-only or server-only certificates. In that case it may be desired to use # different certificates for incoming (server) and outgoing (client) # connections. To do that, use the following directives: # # tls-client-cert-file client.crt # tls-client-key-file client.key # Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange: # # tls-dh-params-file redis.dh # Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL # clients and peers. Redis requires an explicit configuration of at least one # of these, and will not implicitly use the system wide configuration. # # tls-ca-cert-file ca.crt # tls-ca-cert-dir /etc/ssl/certs # By default, clients (including replica servers) on a TLS port are required # to authenticate using valid client side certificates. # # If \u0026#34;no\u0026#34; is specified, client certificates are not required and not accepted. # If \u0026#34;optional\u0026#34; is specified, client certificates are accepted and must be # valid if provided, but are not required. # # tls-auth-clients no # tls-auth-clients optional # By default, a Redis replica does not attempt to establish a TLS connection # with its master. # # Use the following directive to enable TLS on replication links. # # tls-replication yes # By default, the Redis Cluster bus uses a plain TCP connection. To enable # TLS for the bus protocol, use the following directive: # # tls-cluster yes # By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended # that older formally deprecated versions are kept disabled to reduce the attack surface. # You can explicitly specify TLS versions to support. # Allowed values are case insensitive and include \u0026#34;TLSv1\u0026#34;, \u0026#34;TLSv1.1\u0026#34;, \u0026#34;TLSv1.2\u0026#34;, # \u0026#34;TLSv1.3\u0026#34; (OpenSSL \u0026gt;= 1.1.1) or any combination. # To enable only TLSv1.2 and TLSv1.3, use: # # tls-protocols \u0026#34;TLSv1.2 TLSv1.3\u0026#34; # Configure allowed ciphers. See the ciphers(1ssl) manpage for more information # about the syntax of this string. # # Note: this configuration applies only to \u0026lt;= TLSv1.2. # # tls-ciphers DEFAULT:!MEDIUM # Configure allowed TLSv1.3 ciphersuites. See the ciphers(1ssl) manpage for more # information about the syntax of this string, and specifically for TLSv1.3 # ciphersuites. # # tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256 # When choosing a cipher, use the server\u0026#39;s preference instead of the client # preference. By default, the server follows the client\u0026#39;s preference. # # tls-prefer-server-ciphers yes # By default, TLS session caching is enabled to allow faster and less expensive # reconnections by clients that support it. Use the following directive to disable # caching. # # tls-session-caching no # Change the default number of TLS sessions cached. A zero value sets the cache # to unlimited size. The default size is 20480. # # tls-session-cache-size 5000 # Change the default timeout of cached TLS sessions. The default timeout is 300 # seconds. # # tls-session-cache-timeout 60 ################################# GENERAL ##################################### # By default Redis does not run as a daemon. Use \u0026#39;yes\u0026#39; if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. # When Redis is supervised by upstart or systemd, this parameter has no impact. # =\u0026gt; 是否以守护进程的方式运行，默认是no daemonize yes # If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # requires \u0026#34;expect stop\u0026#34; in your upstart job config # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # on startup, and updating Redis status on a regular # basis. # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal \u0026#34;process is ready.\u0026#34; # They do not enable continuous pings back to your supervisor. # # The default is \u0026#34;no\u0026#34;. To run under upstart/systemd, you can simply uncomment # the line below: # # supervised auto # If a pid file is specified, Redis writes it where specified at startup # and removes it at exit. # # When the server runs non daemonized, no pid file is created if none is # specified in the configuration. When the server is daemonized, the pid file # is used even if not specified, defaulting to \u0026#34;/var/run/redis.pid\u0026#34;. # # Creating a pid file is best effort: if Redis is not able to create it # nothing bad happens, the server will start and run normally. # # Note that on modern Linux systems \u0026#34;/run/redis.pid\u0026#34; is more conforming # and should be used instead. # =\u0026gt; 如果以守护进程方式运行，需要指定一个守护进程的文件 pidfile /var/run/redis_6379.pid # Specify the server verbosity level. # This can be one of: # debug (a lot of information, useful for development/testing) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) # =\u0026gt; 设置日志级别 loglevel notice # Specify the log file name. Also the empty string can be used to force # Redis to log on the standard output. Note that if you use standard # output for logging but daemonize, logs will be sent to /dev/null # =\u0026gt; 设置日志的存储位置 logfile \u0026#34;\u0026#34; # To enable logging to the system logger, just set \u0026#39;syslog-enabled\u0026#39; to yes, # and optionally update the other syslog parameters to suit your needs. # syslog-enabled no # Specify the syslog identity. # syslog-ident redis # Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7. # syslog-facility local0 # To disable the built in crash log, which will possibly produce cleaner core # dumps when they are needed, uncomment the following: # # crash-log-enabled no # To disable the fast memory check that\u0026#39;s run as part of the crash log, which # will possibly let redis terminate sooner, uncomment the following: # # crash-memcheck-enabled no # Set the number of databases. The default database is DB 0, you can select # a different one on a per-connection basis using SELECT \u0026lt;dbid\u0026gt; where # dbid is a number between 0 and \u0026#39;databases\u0026#39;-1 # =\u0026gt; 默认数据库数量 databases 16 # By default Redis shows an ASCII art logo only when started to log to the # standard output and if the standard output is a TTY and syslog logging is # disabled. Basically this means that normally a logo is displayed only in # interactive sessions. # # However it is possible to force the pre-4.0 behavior and always show a # ASCII art logo in startup logs by setting the following option to yes. # =\u0026gt; 是否总是显示Logo always-show-logo no # By default, Redis modifies the process title (as seen in \u0026#39;top\u0026#39; and \u0026#39;ps\u0026#39;) to # provide some runtime information. It is possible to disable this and leave # the process name as executed by setting the following to no. set-proc-title yes # When changing the process title, Redis uses the following template to construct # the modified title. # # Template variables are specified in curly brackets. The following variables are # supported: # # {title} Name of process as executed if parent, or type of child process. # {listen-addr} Bind address or \u0026#39;*\u0026#39; followed by TCP or TLS port listening on, or # Unix socket if only that\u0026#39;s available. # {server-mode} Special mode, i.e. \u0026#34;[sentinel]\u0026#34; or \u0026#34;[cluster]\u0026#34;. # {port} TCP port listening on, or 0. # {tls-port} TLS port listening on, or 0. # {unixsocket} Unix domain socket listening on, or \u0026#34;\u0026#34;. # {config-file} Name of configuration file used. # proc-title-template \u0026#34;{title} {listen-addr} {server-mode}\u0026#34; ################################ SNAPSHOTTING ################################ # Save the DB to disk. # # save \u0026lt;seconds\u0026gt; \u0026lt;changes\u0026gt; # # Redis will save the DB if both the given number of seconds and the given # number of write operations against the DB occurred. # # Snapshotting can be completely disabled with a single empty string argument # as in following example: # # save \u0026#34;\u0026#34; # # Unless specified otherwise, by default Redis will save the DB: # * After 3600 seconds (an hour) if at least 1 key changed # * After 300 seconds (5 minutes) if at least 100 keys changed # * After 60 seconds if at least 10000 keys changed # # You can set these explicitly by uncommenting the three following lines. # # =\u0026gt; 快照持久化规则设置 # =\u0026gt; 如果3600秒内，至少一个Key进行了修改，就会进行持久化 # save 3600 1 # save 300 100 # save 60 10000 # By default Redis will stop accepting writes if RDB snapshots are enabled # (at least one save point) and the latest background save failed. # This will make the user aware (in a hard way) that data is not persisting # on disk properly, otherwise chances are that no one will notice and some # disaster will happen. # # If the background saving process will start working again Redis will # automatically allow writes again. # # However if you have setup your proper monitoring of the Redis server # and persistence, you may want to disable this feature so that Redis will # continue to work as usual even if there are problems with disk, # permissions, and so forth. # =\u0026gt; 持久化出错时，是否继续工作 stop-writes-on-bgsave-error yes # Compress string objects using LZF when dump .rdb databases? # By default compression is enabled as it\u0026#39;s almost always a win. # If you want to save some CPU in the saving child set it to \u0026#39;no\u0026#39; but # the dataset will likely be bigger if you have compressible values or keys. # =\u0026gt; 是否压缩rdb文件；压缩是需要耗费一些CPU资源的 rdbcompression yes # Since version 5 of RDB a CRC64 checksum is placed at the end of the file. # This makes the format more resistant to corruption but there is a performance # hit to pay (around 10%) when saving and loading RDB files, so you can disable it # for maximum performances. # # RDB files created with checksum disabled have a checksum of zero that will # tell the loading code to skip the check. # =\u0026gt; 保存rdb文件时，是否校验rdb文件 rdbchecksum yes # Enables or disables full sanitation checks for ziplist and listpack etc when # loading an RDB or RESTORE payload. This reduces the chances of a assertion or # crash later on while processing commands. # Options: # no - Never perform full sanitation # yes - Always perform full sanitation # clients - Perform full sanitation only for user connections. # Excludes: RDB files, RESTORE commands received from the master # connection, and client connections which have the # skip-sanitize-payload ACL flag. # The default should be \u0026#39;clients\u0026#39; but since it currently affects cluster # resharding via MIGRATE, it is temporarily set to \u0026#39;no\u0026#39; by default. # # sanitize-dump-payload no # The filename where to dump the DB dbfilename dump.rdb # Remove RDB files used by replication in instances without persistence # enabled. By default this option is disabled, however there are environments # where for regulations or other security concerns, RDB files persisted on # disk by masters in order to feed replicas, or stored on disk by replicas # in order to load them for the initial synchronization, should be deleted # ASAP. Note that this option ONLY WORKS in instances that have both AOF # and RDB persistence disabled, otherwise is completely ignored. # # An alternative (and sometimes better) way to obtain the same effect is # to use diskless replication on both master and replicas instances. However # in the case of replicas, diskless is not always an option. rdb-del-sync-files no # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the \u0026#39;dbfilename\u0026#39; configuration directive. # # The Append Only File will also be created inside this directory. # # Note that you must specify a directory here, not a file name. # =\u0026gt; rdb文件保存目录 dir ./ ################################# REPLICATION ################################# # Master-Replica replication. Use replicaof to make a Redis instance a copy of # another Redis server. A few things to understand ASAP about Redis replication. # # +------------------+ +---------------+ # | Master | ---\u0026gt; | Replica | # | (receive writes) | | (exact copy) | # +------------------+ +---------------+ # # 1) Redis replication is asynchronous, but you can configure a master to # stop accepting writes if it appears to be not connected with at least # a given number of replicas. # 2) Redis replicas are able to perform a partial resynchronization with the # master if the replication link is lost for a relatively small amount of # time. You may want to configure the replication backlog size (see the next # sections of this file) with a sensible value depending on your needs. # 3) Replication is automatic and does not need user intervention. After a # network partition replicas automatically try to reconnect to masters # and resynchronize with them. # # replicaof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; # If the master is password protected (using the \u0026#34;requirepass\u0026#34; configuration # directive below) it is possible to tell the replica to authenticate before # starting the replication synchronization process, otherwise the master will # refuse the replica request. # # masterauth \u0026lt;master-password\u0026gt; # # However this is not enough if you are using Redis ACLs (for Redis version # 6 or greater), and the default user is not capable of running the PSYNC # command and/or other commands needed for replication. In this case it\u0026#39;s # better to configure a special user to use with replication, and specify the # masteruser configuration as such: # # masteruser \u0026lt;username\u0026gt; # # When masteruser is specified, the replica will authenticate against its # master using the new AUTH form: AUTH \u0026lt;username\u0026gt; \u0026lt;password\u0026gt;. # When a replica loses its connection with the master, or when the replication # is still in progress, the replica can act in two different ways: # # 1) if replica-serve-stale-data is set to \u0026#39;yes\u0026#39; (the default) the replica will # still reply to client requests, possibly with out of date data, or the # data set may just be empty if this is the first synchronization. # # 2) If replica-serve-stale-data is set to \u0026#39;no\u0026#39; the replica will reply with # an error \u0026#34;SYNC with master in progress\u0026#34; to all commands except: # INFO, REPLICAOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE, # UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST, # HOST and LATENCY. # replica-serve-stale-data yes # You can configure a replica instance to accept writes or not. Writing against # a replica instance may be useful to store some ephemeral data (because data # written on a replica will be easily deleted after resync with the master) but # may also cause problems if clients are writing to it because of a # misconfiguration. # # Since Redis 2.6 by default replicas are read-only. # # Note: read only replicas are not designed to be exposed to untrusted clients # on the internet. It\u0026#39;s just a protection layer against misuse of the instance. # Still a read only replica exports by default all the administrative commands # such as CONFIG, DEBUG, and so forth. To a limited extent you can improve # security of read only replicas using \u0026#39;rename-command\u0026#39; to shadow all the # administrative / dangerous commands. replica-read-only yes # Replication SYNC strategy: disk or socket. # # New replicas and reconnecting replicas that are not able to continue the # replication process just receiving differences, need to do what is called a # \u0026#34;full synchronization\u0026#34;. An RDB file is transmitted from the master to the # replicas. # # The transmission can happen in two different ways: # # 1) Disk-backed: The Redis master creates a new process that writes the RDB # file on disk. Later the file is transferred by the parent # process to the replicas incrementally. # 2) Diskless: The Redis master creates a new process that directly writes the # RDB file to replica sockets, without touching the disk at all. # # With disk-backed replication, while the RDB file is generated, more replicas # can be queued and served with the RDB file as soon as the current child # producing the RDB file finishes its work. With diskless replication instead # once the transfer starts, new replicas arriving will be queued and a new # transfer will start when the current one terminates. # # When diskless replication is used, the master waits a configurable amount of # time (in seconds) before starting the transfer in the hope that multiple # replicas will arrive and the transfer can be parallelized. # # With slow disks and fast (large bandwidth) networks, diskless replication # works better. repl-diskless-sync no # When diskless replication is enabled, it is possible to configure the delay # the server waits in order to spawn the child that transfers the RDB via socket # to the replicas. # # This is important since once the transfer starts, it is not possible to serve # new replicas arriving, that will be queued for the next RDB transfer, so the # server waits a delay in order to let more replicas arrive. # # The delay is specified in seconds, and by default is 5 seconds. To disable # it entirely just set it to 0 seconds and the transfer will start ASAP. repl-diskless-sync-delay 5 # ----------------------------------------------------------------------------- # WARNING: RDB diskless load is experimental. Since in this setup the replica # does not immediately store an RDB on disk, it may cause data loss during # failovers. RDB diskless load + Redis modules not handling I/O reads may also # cause Redis to abort in case of I/O errors during the initial synchronization # stage with the master. Use only if you know what you are doing. # ----------------------------------------------------------------------------- # # Replica can load the RDB it reads from the replication link directly from the # socket, or store the RDB to a file and read that file after it was completely # received from the master. # # In many cases the disk is slower than the network, and storing and loading # the RDB file may increase replication time (and even increase the master\u0026#39;s # Copy on Write memory and salve buffers). # However, parsing the RDB file directly from the socket may mean that we have # to flush the contents of the current database before the full rdb was # received. For this reason we have the following options: # # \u0026#34;disabled\u0026#34; - Don\u0026#39;t use diskless load (store the rdb file to the disk first) # \u0026#34;on-empty-db\u0026#34; - Use diskless load only when it is completely safe. # \u0026#34;swapdb\u0026#34; - Keep a copy of the current db contents in RAM while parsing # the data directly from the socket. note that this requires # sufficient memory, if you don\u0026#39;t have it, you risk an OOM kill. repl-diskless-load disabled # Replicas send PINGs to server in a predefined interval. It\u0026#39;s possible to # change this interval with the repl_ping_replica_period option. The default # value is 10 seconds. # # repl-ping-replica-period 10 # The following option sets the replication timeout for: # # 1) Bulk transfer I/O during SYNC, from the point of view of replica. # 2) Master timeout from the point of view of replicas (data, pings). # 3) Replica timeout from the point of view of masters (REPLCONF ACK pings). # # It is important to make sure that this value is greater than the value # specified for repl-ping-replica-period otherwise a timeout will be detected # every time there is low traffic between the master and the replica. The default # value is 60 seconds. # # repl-timeout 60 # Disable TCP_NODELAY on the replica socket after SYNC? # # If you select \u0026#34;yes\u0026#34; Redis will use a smaller number of TCP packets and # less bandwidth to send data to replicas. But this can add a delay for # the data to appear on the replica side, up to 40 milliseconds with # Linux kernels using a default configuration. # # If you select \u0026#34;no\u0026#34; the delay for data to appear on the replica side will # be reduced but more bandwidth will be used for replication. # # By default we optimize for low latency, but in very high traffic conditions # or when the master and replicas are many hops away, turning this to \u0026#34;yes\u0026#34; may # be a good idea. repl-disable-tcp-nodelay no # Set the replication backlog size. The backlog is a buffer that accumulates # replica data when replicas are disconnected for some time, so that when a # replica wants to reconnect again, often a full resync is not needed, but a # partial resync is enough, just passing the portion of data the replica # missed while disconnected. # # The bigger the replication backlog, the longer the replica can endure the # disconnect and later be able to perform a partial resynchronization. # # The backlog is only allocated if there is at least one replica connected. # # repl-backlog-size 1mb # After a master has no connected replicas for some time, the backlog will be # freed. The following option configures the amount of seconds that need to # elapse, starting from the time the last replica disconnected, for the backlog # buffer to be freed. # # Note that replicas never free the backlog for timeout, since they may be # promoted to masters later, and should be able to correctly \u0026#34;partially # resynchronize\u0026#34; with other replicas: hence they should always accumulate backlog. # # A value of 0 means to never release the backlog. # # repl-backlog-ttl 3600 # The replica priority is an integer number published by Redis in the INFO # output. It is used by Redis Sentinel in order to select a replica to promote # into a master if the master is no longer working correctly. # # A replica with a low priority number is considered better for promotion, so # for instance if there are three replicas with priority 10, 100, 25 Sentinel # will pick the one with priority 10, that is the lowest. # # However a special priority of 0 marks the replica as not able to perform the # role of master, so a replica with priority of 0 will never be selected by # Redis Sentinel for promotion. # # By default the priority is 100. replica-priority 100 # It is possible for a master to stop accepting writes if there are less than # N replicas connected, having a lag less or equal than M seconds. # # The N replicas need to be in \u0026#34;online\u0026#34; state. # # The lag in seconds, that must be \u0026lt;= the specified value, is calculated from # the last ping received from the replica, that is usually sent every second. # # This option does not GUARANTEE that N replicas will accept the write, but # will limit the window of exposure for lost writes in case not enough replicas # are available, to the specified number of seconds. # # For example to require at least 3 replicas with a lag \u0026lt;= 10 seconds use: # # min-replicas-to-write 3 # min-replicas-max-lag 10 # # Setting one or the other to 0 disables the feature. # # By default min-replicas-to-write is set to 0 (feature disabled) and # min-replicas-max-lag is set to 10. # A Redis master is able to list the address and port of the attached # replicas in different ways. For example the \u0026#34;INFO replication\u0026#34; section # offers this information, which is used, among other tools, by # Redis Sentinel in order to discover replica instances. # Another place where this info is available is in the output of the # \u0026#34;ROLE\u0026#34; command of a master. # # The listed IP address and port normally reported by a replica is # obtained in the following way: # # IP: The address is auto detected by checking the peer address # of the socket used by the replica to connect with the master. # # Port: The port is communicated by the replica during the replication # handshake, and is normally the port that the replica is using to # listen for connections. # # However when port forwarding or Network Address Translation (NAT) is # used, the replica may actually be reachable via different IP and port # pairs. The following two options can be used by a replica in order to # report to its master a specific set of IP and port, so that both INFO # and ROLE will report those values. # # There is no need to use both the options if you need to override just # the port or the IP address. # # replica-announce-ip 5.5.5.5 # replica-announce-port 1234 ############################### KEYS TRACKING ################################# # Redis implements server assisted support for client side caching of values. # This is implemented using an invalidation table that remembers, using # a radix key indexed by key name, what clients have which keys. In turn # this is used in order to send invalidation messages to clients. Please # check this page to understand more about the feature: # # https://redis.io/topics/client-side-caching # # When tracking is enabled for a client, all the read only queries are assumed # to be cached: this will force Redis to store information in the invalidation # table. When keys are modified, such information is flushed away, and # invalidation messages are sent to the clients. However if the workload is # heavily dominated by reads, Redis could use more and more memory in order # to track the keys fetched by many clients. # # For this reason it is possible to configure a maximum fill value for the # invalidation table. By default it is set to 1M of keys, and once this limit # is reached, Redis will start to evict keys in the invalidation table # even if they were not modified, just to reclaim memory: this will in turn # force the clients to invalidate the cached values. Basically the table # maximum size is a trade off between the memory you want to spend server # side to track information about who cached what, and the ability of clients # to retain cached objects in memory. # # If you set the value to 0, it means there are no limits, and Redis will # retain as many keys as needed in the invalidation table. # In the \u0026#34;stats\u0026#34; INFO section, you can find information about the number of # keys in the invalidation table at every given moment. # # Note: when key tracking is used in broadcasting mode, no memory is used # in the server side so this setting is useless. # # tracking-table-max-keys 1000000 ################################## SECURITY ################################### # Warning: since Redis is pretty fast, an outside user can try up to # 1 million passwords per second against a modern box. This means that you # should use very strong passwords, otherwise they will be very easy to break. # Note that because the password is really a shared secret between the client # and the server, and should not be memorized by any human, the password # can be easily a long string from /dev/urandom or whatever, so by using a # long and unguessable password no brute force attack will be possible. # Redis ACL users are defined in the following format: # # user \u0026lt;username\u0026gt; ... acl rules ... # # For example: # # user worker +@list +@connection ~jobs:* on \u0026gt;ffa9203c493aa99 # # The special username \u0026#34;default\u0026#34; is used for new connections. If this user # has the \u0026#34;nopass\u0026#34; rule, then new connections will be immediately authenticated # as the \u0026#34;default\u0026#34; user without the need of any password provided via the # AUTH command. Otherwise if the \u0026#34;default\u0026#34; user is not flagged with \u0026#34;nopass\u0026#34; # the connections will start in not authenticated state, and will require # AUTH (or the HELLO command AUTH option) in order to be authenticated and # start to work. # # The ACL rules that describe what a user can do are the following: # # on Enable the user: it is possible to authenticate as this user. # off Disable the user: it\u0026#39;s no longer possible to authenticate # with this user, however the already authenticated connections # will still work. # skip-sanitize-payload RESTORE dump-payload sanitation is skipped. # sanitize-payload RESTORE dump-payload is sanitized (default). # +\u0026lt;command\u0026gt; Allow the execution of that command # -\u0026lt;command\u0026gt; Disallow the execution of that command # +@\u0026lt;category\u0026gt; Allow the execution of all the commands in such category # with valid categories are like @admin, @set, @sortedset, ... # and so forth, see the full list in the server.c file where # the Redis command table is described and defined. # The special category @all means all the commands, but currently # present in the server, and that will be loaded in the future # via modules. # +\u0026lt;command\u0026gt;|subcommand Allow a specific subcommand of an otherwise # disabled command. Note that this form is not # allowed as negative like -DEBUG|SEGFAULT, but # only additive starting with \u0026#34;+\u0026#34;. # allcommands Alias for +@all. Note that it implies the ability to execute # all the future commands loaded via the modules system. # nocommands Alias for -@all. # ~\u0026lt;pattern\u0026gt; Add a pattern of keys that can be mentioned as part of # commands. For instance ~* allows all the keys. The pattern # is a glob-style pattern like the one of KEYS. # It is possible to specify multiple patterns. # allkeys Alias for ~* # resetkeys Flush the list of allowed keys patterns. # \u0026amp;\u0026lt;pattern\u0026gt; Add a glob-style pattern of Pub/Sub channels that can be # accessed by the user. It is possible to specify multiple channel # patterns. # allchannels Alias for \u0026amp;* # resetchannels Flush the list of allowed channel patterns. # \u0026gt;\u0026lt;password\u0026gt; Add this password to the list of valid password for the user. # For example \u0026gt;mypass will add \u0026#34;mypass\u0026#34; to the list. # This directive clears the \u0026#34;nopass\u0026#34; flag (see later). # \u0026lt;\u0026lt;password\u0026gt; Remove this password from the list of valid passwords. # nopass All the set passwords of the user are removed, and the user # is flagged as requiring no password: it means that every # password will work against this user. If this directive is # used for the default user, every new connection will be # immediately authenticated with the default user without # any explicit AUTH command required. Note that the \u0026#34;resetpass\u0026#34; # directive will clear this condition. # resetpass Flush the list of allowed passwords. Moreover removes the # \u0026#34;nopass\u0026#34; status. After \u0026#34;resetpass\u0026#34; the user has no associated # passwords and there is no way to authenticate without adding # some password (or setting it as \u0026#34;nopass\u0026#34; later). # reset Performs the following actions: resetpass, resetkeys, off, # -@all. The user returns to the same state it has immediately # after its creation. # # ACL rules can be specified in any order: for instance you can start with # passwords, then flags, or key patterns. However note that the additive # and subtractive rules will CHANGE MEANING depending on the ordering. # For instance see the following example: # # user alice on +@all -DEBUG ~* \u0026gt;somepassword # # This will allow \u0026#34;alice\u0026#34; to use all the commands with the exception of the # DEBUG command, since +@all added all the commands to the set of the commands # alice can use, and later DEBUG was removed. However if we invert the order # of two ACL rules the result will be different: # # user alice on -DEBUG +@all ~* \u0026gt;somepassword # # Now DEBUG was removed when alice had yet no commands in the set of allowed # commands, later all the commands are added, so the user will be able to # execute everything. # # Basically ACL rules are processed left-to-right. # # For more information about ACL configuration please refer to # the Redis web site at https://redis.io/topics/acl # ACL LOG # # The ACL Log tracks failed commands and authentication events associated # with ACLs. The ACL Log is useful to troubleshoot failed commands blocked # by ACLs. The ACL Log is stored in memory. You can reclaim memory with # ACL LOG RESET. Define the maximum entry length of the ACL Log below. acllog-max-len 128 # Using an external ACL file # # Instead of configuring users here in this file, it is possible to use # a stand-alone file just listing users. The two methods cannot be mixed: # if you configure users here and at the same time you activate the external # ACL file, the server will refuse to start. # # The format of the external ACL user file is exactly the same as the # format that is used inside redis.conf to describe users. # # aclfile /etc/redis/users.acl # IMPORTANT NOTE: starting with Redis 6 \u0026#34;requirepass\u0026#34; is just a compatibility # layer on top of the new ACL system. The option effect will be just setting # the password for the default user. Clients will still authenticate using # AUTH \u0026lt;password\u0026gt; as usually, or more explicitly with AUTH default \u0026lt;password\u0026gt; # if they follow the new protocol: both will work. # # The requirepass is not compatable with aclfile option and the ACL LOAD # command, these will cause requirepass to be ignored. # =\u0026gt; Redis默认没有密码；可以在这里设置密码 # requirepass wpl19950815 # requirepass foobared # New users are initialized with restrictive permissions by default, via the # equivalent of this ACL rule \u0026#39;off resetkeys -@all\u0026#39;. Starting with Redis 6.2, it # is possible to manage access to Pub/Sub channels with ACL rules as well. The # default Pub/Sub channels permission if new users is controlled by the # acl-pubsub-default configuration directive, which accepts one of these values: # # allchannels: grants access to all Pub/Sub channels # resetchannels: revokes access to all Pub/Sub channels # # To ensure backward compatibility while upgrading Redis 6.0, acl-pubsub-default # defaults to the \u0026#39;allchannels\u0026#39; permission. # # Future compatibility note: it is very likely that in a future version of Redis # the directive\u0026#39;s default of \u0026#39;allchannels\u0026#39; will be changed to \u0026#39;resetchannels\u0026#39; in # order to provide better out-of-the-box Pub/Sub security. Therefore, it is # recommended that you explicitly define Pub/Sub permissions for all users # rather then rely on implicit default values. Once you\u0026#39;ve set explicit # Pub/Sub for all exisitn users, you should uncomment the following line. # # acl-pubsub-default resetchannels # Command renaming (DEPRECATED). # # ------------------------------------------------------------------------ # WARNING: avoid using this option if possible. Instead use ACLs to remove # commands from the default user, and put them only in some admin user you # create for administrative purposes. # ------------------------------------------------------------------------ # # It is possible to change the name of dangerous commands in a shared # environment. For instance the CONFIG command may be renamed into something # hard to guess so that it will still be available for internal-use tools # but not available for general clients. # # Example: # # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # # It is also possible to completely kill a command by renaming it into # an empty string: # # rename-command CONFIG \u0026#34;\u0026#34; # # Please note that changing the name of commands that are logged into the # AOF file or transmitted to replicas may cause problems. ################################### CLIENTS #################################### # Set the max number of connected clients at the same time. By default # this limit is set to 10000 clients, however if the Redis server is not # able to configure the process file limit to allow for the specified limit # the max number of allowed clients is set to the current file limit # minus 32 (as Redis reserves a few file descriptors for internal uses). # # Once the limit is reached Redis will close all the new connections sending # an error \u0026#39;max number of clients reached\u0026#39;. # # IMPORTANT: When Redis Cluster is used, the max number of connections is also # shared with the cluster bus: every node in the cluster will use two # connections, one incoming and another outgoing. It is important to size the # limit accordingly in case of very large clusters. # =\u0026gt; 限制client最大连接数 # maxclients 10000 ############################## MEMORY MANAGEMENT ################################ # Set a memory usage limit to the specified amount of bytes. # When the memory limit is reached Redis will try to remove keys # according to the eviction policy selected (see maxmemory-policy). # # If Redis can\u0026#39;t remove keys according to the policy, or if the policy is # set to \u0026#39;noeviction\u0026#39;, Redis will start to reply with errors to commands # that would use more memory, like SET, LPUSH, and so on, and will continue # to reply to read-only commands like GET. # # This option is usually useful when using Redis as an LRU or LFU cache, or to # set a hard memory limit for an instance (using the \u0026#39;noeviction\u0026#39; policy). # # WARNING: If you have replicas attached to an instance with maxmemory on, # the size of the output buffers needed to feed the replicas are subtracted # from the used memory count, so that network problems / resyncs will # not trigger a loop where keys are evicted, and in turn the output # buffer of replicas is full with DELs of keys evicted triggering the deletion # of more keys, and so forth until the database is completely emptied. # # In short... if you have replicas attached it is suggested that you set a lower # limit for maxmemory so that there is some free RAM on the system for replica # output buffers (but this is not needed if the policy is \u0026#39;noeviction\u0026#39;). # =\u0026gt; 配置Redis最大内存容量;单位字节 # maxmemory \u0026lt;bytes\u0026gt; # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select one from the following behaviors: # # volatile-lru -\u0026gt; Evict using approximated LRU, only keys with an expire set. # allkeys-lru -\u0026gt; Evict any key using approximated LRU. # volatile-lfu -\u0026gt; Evict using approximated LFU, only keys with an expire set. # allkeys-lfu -\u0026gt; Evict any key using approximated LFU. # volatile-random -\u0026gt; Remove a random key having an expire set. # allkeys-random -\u0026gt; Remove a random key, any key. # volatile-ttl -\u0026gt; Remove the key with the nearest expire time (minor TTL) # noeviction -\u0026gt; Don\u0026#39;t evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, when there are no suitable keys for # eviction, Redis will return an error on write operations that require # more memory. These are usually commands that create new keys, add data or # modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE, # SORT (due to the STORE argument), and EXEC (if the transaction includes any # command that requires memory). # # The default is: # =\u0026gt; 内存到达上限的处理策略 # maxmemory-policy noeviction # LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated # algorithms (in order to save memory), so you can tune it for speed or # accuracy. By default Redis will check five keys and pick the one that was # used least recently, you can change the sample size using the following # configuration directive. # # The default of 5 produces good enough results. 10 Approximates very closely # true LRU but costs more CPU. 3 is faster but not very accurate. # # maxmemory-samples 5 # Eviction processing is designed to function well with the default setting. # If there is an unusually large amount of write traffic, this value may need to # be increased. Decreasing this value may reduce latency at the risk of # eviction processing effectiveness # 0 = minimum latency, 10 = default, 100 = process without regard to latency # # maxmemory-eviction-tenacity 10 # Starting from Redis 5, by default a replica will ignore its maxmemory setting # (unless it is promoted to master after a failover or manually). It means # that the eviction of keys will be just handled by the master, sending the # DEL commands to the replica as keys evict in the master side. # # This behavior ensures that masters and replicas stay consistent, and is usually # what you want, however if your replica is writable, or you want the replica # to have a different memory setting, and you are sure all the writes performed # to the replica are idempotent, then you may change this default (but be sure # to understand what you are doing). # # Note that since the replica by default does not evict, it may end using more # memory than the one set via maxmemory (there are certain buffers that may # be larger on the replica, or data structures may sometimes take more memory # and so forth). So make sure you monitor your replicas and make sure they # have enough memory to never hit a real out-of-memory condition before the # master hits the configured maxmemory setting. # # replica-ignore-maxmemory yes # Redis reclaims expired keys in two ways: upon access when those keys are # found to be expired, and also in background, in what is called the # \u0026#34;active expire key\u0026#34;. The key space is slowly and interactively scanned # looking for expired keys to reclaim, so that it is possible to free memory # of keys that are expired and will never be accessed again in a short time. # # The default effort of the expire cycle will try to avoid having more than # ten percent of expired keys still in memory, and will try to avoid consuming # more than 25% of total memory and to add latency to the system. However # it is possible to increase the expire \u0026#34;effort\u0026#34; that is normally set to # \u0026#34;1\u0026#34;, to a greater value, up to the value \u0026#34;10\u0026#34;. At its maximum value the # system will use more CPU, longer cycles (and technically may introduce # more latency), and will tolerate less already expired keys still present # in the system. It\u0026#39;s a tradeoff between memory, CPU and latency. # # active-expire-effort 1 ############################# LAZY FREEING #################################### # Redis has two primitives to delete keys. One is called DEL and is a blocking # deletion of the object. It means that the server stops processing new commands # in order to reclaim all the memory associated with an object in a synchronous # way. If the key deleted is associated with a small object, the time needed # in order to execute the DEL command is very small and comparable to most other # O(1) or O(log_N) commands in Redis. However if the key is associated with an # aggregated value containing millions of elements, the server can block for # a long time (even seconds) in order to complete the operation. # # For the above reasons Redis also offers non blocking deletion primitives # such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and # FLUSHDB commands, in order to reclaim memory in background. Those commands # are executed in constant time. Another thread will incrementally free the # object in the background as fast as possible. # # DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled. # It\u0026#39;s up to the design of the application to understand when it is a good # idea to use one or the other. However the Redis server sometimes has to # delete keys or flush the whole database as a side effect of other operations. # Specifically Redis deletes objects independently of a user call in the # following scenarios: # # 1) On eviction, because of the maxmemory and maxmemory policy configurations, # in order to make room for new data, without going over the specified # memory limit. # 2) Because of expire: when a key with an associated time to live (see the # EXPIRE command) must be deleted from memory. # 3) Because of a side effect of a command that stores data on a key that may # already exist. For example the RENAME command may delete the old key # content when it is replaced with another one. Similarly SUNIONSTORE # or SORT with STORE option may delete existing keys. The SET command # itself removes any old content of the specified key in order to replace # it with the specified string. # 4) During replication, when a replica performs a full resynchronization with # its master, the content of the whole database is removed in order to # load the RDB file just transferred. # # In all the above cases the default is to delete objects in a blocking way, # like if DEL was called. However you can configure each case specifically # in order to instead release memory in a non-blocking way like if UNLINK # was called, using the following configuration directives. lazyfree-lazy-eviction no lazyfree-lazy-expire no lazyfree-lazy-server-del no replica-lazy-flush no # It is also possible, for the case when to replace the user code DEL calls # with UNLINK calls is not easy, to modify the default behavior of the DEL # command to act exactly like UNLINK, using the following configuration # directive: lazyfree-lazy-user-del no # FLUSHDB, FLUSHALL, and SCRIPT FLUSH support both asynchronous and synchronous # deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the # commands. When neither flag is passed, this directive will be used to determine # if the data should be deleted asynchronously. lazyfree-lazy-user-flush no ################################ THREADED I/O ################################# # Redis is mostly single threaded, however there are certain threaded # operations such as UNLINK, slow I/O accesses and other things that are # performed on side threads. # # Now it is also possible to handle Redis clients socket reads and writes # in different I/O threads. Since especially writing is so slow, normally # Redis users use pipelining in order to speed up the Redis performances per # core, and spawn multiple instances in order to scale more. Using I/O # threads it is possible to easily speedup two times Redis without resorting # to pipelining nor sharding of the instance. # # By default threading is disabled, we suggest enabling it only in machines # that have at least 4 or more cores, leaving at least one spare core. # Using more than 8 threads is unlikely to help much. We also recommend using # threaded I/O only if you actually have performance problems, with Redis # instances being able to use a quite big percentage of CPU time, otherwise # there is no point in using this feature. # # So for instance if you have a four cores boxes, try to use 2 or 3 I/O # threads, if you have a 8 cores, try to use 6 threads. In order to # enable I/O threads use the following configuration directive: # # io-threads 4 # # Setting io-threads to 1 will just use the main thread as usual. # When I/O threads are enabled, we only use threads for writes, that is # to thread the write(2) syscall and transfer the client buffers to the # socket. However it is also possible to enable threading of reads and # protocol parsing using the following configuration directive, by setting # it to yes: # # io-threads-do-reads no # # Usually threading reads doesn\u0026#39;t help much. # # NOTE 1: This configuration directive cannot be changed at runtime via # CONFIG SET. Aso this feature currently does not work when SSL is # enabled. # # NOTE 2: If you want to test the Redis speedup using redis-benchmark, make # sure you also run the benchmark itself in threaded mode, using the # --threads option to match the number of Redis threads, otherwise you\u0026#39;ll not # be able to notice the improvements. ############################ KERNEL OOM CONTROL ############################## # On Linux, it is possible to hint the kernel OOM killer on what processes # should be killed first when out of memory. # # Enabling this feature makes Redis actively control the oom_score_adj value # for all its processes, depending on their role. The default scores will # attempt to have background child processes killed before all others, and # replicas killed before masters. # # Redis supports three options: # # no: Don\u0026#39;t make changes to oom-score-adj (default). # yes: Alias to \u0026#34;relative\u0026#34; see below. # absolute: Values in oom-score-adj-values are written as is to the kernel. # relative: Values are used relative to the initial value of oom_score_adj when # the server starts and are then clamped to a range of -1000 to 1000. # Because typically the initial value is 0, they will often match the # absolute values. oom-score-adj no # When oom-score-adj is used, this directive controls the specific values used # for master, replica and background child processes. Values range -2000 to # 2000 (higher means more likely to be killed). # # Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities) # can freely increase their value, but not decrease it below its initial # settings. This means that setting oom-score-adj to \u0026#34;relative\u0026#34; and setting the # oom-score-adj-values to positive values will always succeed. oom-score-adj-values 0 200 800 #################### KERNEL transparent hugepage CONTROL ###################### # Usually the kernel Transparent Huge Pages control is set to \u0026#34;madvise\u0026#34; or # or \u0026#34;never\u0026#34; by default (/sys/kernel/mm/transparent_hugepage/enabled), in which # case this config has no effect. On systems in which it is set to \u0026#34;always\u0026#34;, # redis will attempt to disable it specifically for the redis process in order # to avoid latency problems specifically with fork(2) and CoW. # If for some reason you prefer to keep it enabled, you can set this config to # \u0026#34;no\u0026#34; and the kernel global to \u0026#34;always\u0026#34;. disable-thp yes ############################## APPEND ONLY MODE ############################### # By default Redis asynchronously dumps the dataset on disk. This mode is # good enough in many applications, but an issue with the Redis process or # a power outage may result into a few minutes of writes lost (depending on # the configured save points). # # The Append Only File is an alternative persistence mode that provides # much better durability. For instance using the default data fsync policy # (see later in the config file) Redis can lose just one second of writes in a # dramatic event like a server power outage, or a single write if something # wrong with the Redis process itself happens, but the operating system is # still running correctly. # # AOF and RDB persistence can be enabled at the same time without problems. # If the AOF is enabled on startup Redis will load the AOF, that is the file # with the better durability guarantees. # # Please check http://redis.io/topics/persistence for more information. # =\u0026gt; 是否开启aof模式；默认使用rdb方式持久化 appendonly no # The name of the append only file (default: \u0026#34;appendonly.aof\u0026#34;) # =\u0026gt; 使用aof持久化文件的名称 appendfilename \u0026#34;appendonly.aof\u0026#34; # The fsync() call tells the Operating System to actually write data on disk # instead of waiting for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP. # # Redis supports three different modes: # # no: don\u0026#39;t fsync, just let the OS flush the data when it wants. Faster. # always: fsync after every write to the append only log. Slow, Safest. # everysec: fsync only one time every second. Compromise. # # The default is \u0026#34;everysec\u0026#34;, as that\u0026#39;s usually the right compromise between # speed and data safety. It\u0026#39;s up to you to understand if you can relax this to # \u0026#34;no\u0026#34; that will let the operating system flush the output buffer when # it wants, for better performances (but if you can live with the idea of # some data loss consider the default persistence mode that\u0026#39;s snapshotting), # or on the contrary, use \u0026#34;always\u0026#34; that\u0026#39;s very slow but a bit safer than # everysec. # # More details please check the following article: # http://antirez.com/post/redis-persistence-demystified.html # # If unsure, use \u0026#34;everysec\u0026#34;. # =\u0026gt; 每次修改都会同步；耗费性能 # appendfsync always # =\u0026gt; 每秒执行一次同步；可能会丢失这一秒的数据 appendfsync everysec # =\u0026gt; 不执行同步；由操作系统自己同步 # appendfsync no # When the AOF fsync policy is set to always or everysec, and a background # saving process (a background save or AOF log background rewriting) is # performing a lot of I/O against the disk, in some Linux configurations # Redis may block too long on the fsync() call. Note that there is no fix for # this currently, as even performing fsync in a different thread will block # our synchronous write(2) call. # # In order to mitigate this problem it\u0026#39;s possible to use the following option # that will prevent fsync() from being called in the main process while a # BGSAVE or BGREWRITEAOF is in progress. # # This means that while another child is saving, the durability of Redis is # the same as \u0026#34;appendfsync none\u0026#34;. In practical terms, this means that it is # possible to lose up to 30 seconds of log in the worst scenario (with the # default Linux settings). # # If you have latency problems turn this to \u0026#34;yes\u0026#34;. Otherwise leave it as # \u0026#34;no\u0026#34; that is the safest pick from the point of view of durability. no-appendfsync-on-rewrite no # Automatic rewrite of the append only file. # Redis is able to automatically rewrite the log file implicitly calling # BGREWRITEAOF when the AOF log size grows by the specified percentage. # # This is how it works: Redis remembers the size of the AOF file after the # latest rewrite (if no rewrite has happened since the restart, the size of # the AOF at startup is used). # # This base size is compared to the current size. If the current size is # bigger than the specified percentage, the rewrite is triggered. Also # you need to specify a minimal size for the AOF file to be rewritten, this # is useful to avoid rewriting the AOF file even if the percentage increase # is reached but it is still pretty small. # # Specify a percentage of zero in order to disable the automatic AOF # rewrite feature. auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # An AOF file may be found to be truncated at the end during the Redis # startup process, when the AOF data gets loaded back into memory. # This may happen when the system where Redis is running # crashes, especially when an ext4 filesystem is mounted without the # data=ordered option (however this can\u0026#39;t happen when Redis itself # crashes or aborts but the operating system still works correctly). # # Redis can either exit with an error when this happens, or load as much # data as possible (the default now) and start if the AOF file is found # to be truncated at the end. The following option controls this behavior. # # If aof-load-truncated is set to yes, a truncated AOF file is loaded and # the Redis server starts emitting a log to inform the user of the event. # Otherwise if the option is set to no, the server aborts with an error # and refuses to start. When the option is set to no, the user requires # to fix the AOF file using the \u0026#34;redis-check-aof\u0026#34; utility before to restart # the server. # # Note that if the AOF file will be found to be corrupted in the middle # the server will still exit with an error. This option only applies when # Redis will try to read more data from the AOF file but not enough bytes # will be found. aof-load-truncated yes # When rewriting the AOF file, Redis is able to use an RDB preamble in the # AOF file for faster rewrites and recoveries. When this option is turned # on the rewritten AOF file is composed of two different stanzas: # # [RDB file][AOF tail] # # When loading, Redis recognizes that the AOF file starts with the \u0026#34;REDIS\u0026#34; # string and loads the prefixed RDB file, then continues loading the AOF # tail. aof-use-rdb-preamble yes ################################ LUA SCRIPTING ############################### # Max execution time of a Lua script in milliseconds. # # If the maximum execution time is reached Redis will log that a script is # still in execution after the maximum allowed time and will start to # reply to queries with an error. # # When a long running script exceeds the maximum execution time only the # SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be # used to stop a script that did not yet call any write commands. The second # is the only way to shut down the server in the case a write command was # already issued by the script but the user doesn\u0026#39;t want to wait for the natural # termination of the script. # # Set it to 0 or a negative value for unlimited execution without warnings. lua-time-limit 5000 ################################ REDIS CLUSTER ############################### # Normal Redis instances can\u0026#39;t be part of a Redis Cluster; only nodes that are # started as cluster nodes can. In order to start a Redis instance as a # cluster node enable the cluster support uncommenting the following: # # cluster-enabled yes # Every cluster node has a cluster configuration file. This file is not # intended to be edited by hand. It is created and updated by Redis nodes. # Every Redis Cluster node requires a different cluster configuration file. # Make sure that instances running in the same system do not have # overlapping cluster configuration file names. # # cluster-config-file nodes-6379.conf # Cluster node timeout is the amount of milliseconds a node must be unreachable # for it to be considered in failure state. # Most other internal time limits are a multiple of the node timeout. # # cluster-node-timeout 15000 # A replica of a failing master will avoid to start a failover if its data # looks too old. # # There is no simple way for a replica to actually have an exact measure of # its \u0026#34;data age\u0026#34;, so the following two checks are performed: # # 1) If there are multiple replicas able to failover, they exchange messages # in order to try to give an advantage to the replica with the best # replication offset (more data from the master processed). # Replicas will try to get their rank by offset, and apply to the start # of the failover a delay proportional to their rank. # # 2) Every single replica computes the time of the last interaction with # its master. This can be the last ping or command received (if the master # is still in the \u0026#34;connected\u0026#34; state), or the time that elapsed since the # disconnection with the master (if the replication link is currently down). # If the last interaction is too old, the replica will not try to failover # at all. # # The point \u0026#34;2\u0026#34; can be tuned by user. Specifically a replica will not perform # the failover if, since the last interaction with the master, the time # elapsed is greater than: # # (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period # # So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor # is 10, and assuming a default repl-ping-replica-period of 10 seconds, the # replica will not try to failover if it was not able to talk with the master # for longer than 310 seconds. # # A large cluster-replica-validity-factor may allow replicas with too old data to failover # a master, while a too small value may prevent the cluster from being able to # elect a replica at all. # # For maximum availability, it is possible to set the cluster-replica-validity-factor # to a value of 0, which means, that replicas will always try to failover the # master regardless of the last time they interacted with the master. # (However they\u0026#39;ll always try to apply a delay proportional to their # offset rank). # # Zero is the only value able to guarantee that when all the partitions heal # the cluster will always be able to continue. # # cluster-replica-validity-factor 10 # Cluster replicas are able to migrate to orphaned masters, that are masters # that are left without working replicas. This improves the cluster ability # to resist to failures as otherwise an orphaned master can\u0026#39;t be failed over # in case of failure if it has no working replicas. # # Replicas migrate to orphaned masters only if there are still at least a # given number of other working replicas for their old master. This number # is the \u0026#34;migration barrier\u0026#34;. A migration barrier of 1 means that a replica # will migrate only if there is at least 1 other working replica for its master # and so forth. It usually reflects the number of replicas you want for every # master in your cluster. # # Default is 1 (replicas migrate only if their masters remain with at least # one replica). To disable migration just set it to a very large value. # A value of 0 can be set but is useful only for debugging and dangerous # in production. # # cluster-migration-barrier 1 # By default Redis Cluster nodes stop accepting queries if they detect there # is at least a hash slot uncovered (no available node is serving it). # This way if the cluster is partially down (for example a range of hash slots # are no longer covered) all the cluster becomes, eventually, unavailable. # It automatically returns available as soon as all the slots are covered again. # # However sometimes you want the subset of the cluster which is working, # to continue to accept queries for the part of the key space that is still # covered. In order to do so, just set the cluster-require-full-coverage # option to no. # # cluster-require-full-coverage yes # This option, when set to yes, prevents replicas from trying to failover its # master during master failures. However the replica can still perform a # manual failover, if forced to do so. # # This is useful in different scenarios, especially in the case of multiple # data center operations, where we want one side to never be promoted if not # in the case of a total DC failure. # # cluster-replica-no-failover no # This option, when set to yes, allows nodes to serve read traffic while the # the cluster is in a down state, as long as it believes it owns the slots. # # This is useful for two cases. The first case is for when an application # doesn\u0026#39;t require consistency of data during node failures or network partitions. # One example of this is a cache, where as long as the node has the data it # should be able to serve it. # # The second use case is for configurations that don\u0026#39;t meet the recommended # three shards but want to enable cluster mode and scale later. A # master outage in a 1 or 2 shard configuration causes a read/write outage to the # entire cluster without this option set, with it set there is only a write outage. # Without a quorum of masters, slot ownership will not change automatically. # # cluster-allow-reads-when-down no # In order to setup your cluster make sure to read the documentation # available at http://redis.io web site. ########################## CLUSTER DOCKER/NAT support ######################## # In certain deployments, Redis Cluster nodes address discovery fails, because # addresses are NAT-ted or because ports are forwarded (the typical case is # Docker and other containers). # # In order to make Redis Cluster working in such environments, a static # configuration where each node knows its public address is needed. The # following two options are used for this scope, and are: # # * cluster-announce-ip # * cluster-announce-port # * cluster-announce-bus-port # # Each instructs the node about its address, client port, and cluster message # bus port. The information is then published in the header of the bus packets # so that other nodes will be able to correctly map the address of the node # publishing the information. # # If the above options are not used, the normal Redis Cluster auto-detection # will be used instead. # # Note that when remapped, the bus port may not be at the fixed offset of # clients port + 10000, so you can specify any port and bus-port depending # on how they get remapped. If the bus-port is not set, a fixed offset of # 10000 will be used as usual. # # Example: # # cluster-announce-ip 10.1.1.5 # cluster-announce-port 6379 # cluster-announce-bus-port 6380 ################################## SLOW LOG ################################### # The Redis Slow Log is a system to log queries that exceeded a specified # execution time. The execution time does not include the I/O operations # like talking with the client, sending the reply and so forth, # but just the time needed to actually execute the command (this is the only # stage of command execution where the thread is blocked and can not serve # other requests in the meantime). # # You can configure the slow log with two parameters: one tells Redis # what is the execution time, in microseconds, to exceed in order for the # command to get logged, and the other parameter is the length of the # slow log. When a new command is logged the oldest one is removed from the # queue of logged commands. # The following time is expressed in microseconds, so 1000000 is equivalent # to one second. Note that a negative number disables the slow log, while # a value of zero forces the logging of every command. slowlog-log-slower-than 10000 # There is no limit to this length. Just be aware that it will consume memory. # You can reclaim memory used by the slow log with SLOWLOG RESET. slowlog-max-len 128 ################################ LATENCY MONITOR ############################## # The Redis latency monitoring subsystem samples different operations # at runtime in order to collect data related to possible sources of # latency of a Redis instance. # # Via the LATENCY command this information is available to the user that can # print graphs and obtain reports. # # The system only logs operations that were performed in a time equal or # greater than the amount of milliseconds specified via the # latency-monitor-threshold configuration directive. When its value is set # to zero, the latency monitor is turned off. # # By default latency monitoring is disabled since it is mostly not needed # if you don\u0026#39;t have latency issues, and collecting data has a performance # impact, that while very small, can be measured under big load. Latency # monitoring can easily be enabled at runtime using the command # \u0026#34;CONFIG SET latency-monitor-threshold \u0026lt;milliseconds\u0026gt;\u0026#34; if needed. latency-monitor-threshold 0 ############################# EVENT NOTIFICATION ############################## # Redis can notify Pub/Sub clients about events happening in the key space. # This feature is documented at http://redis.io/topics/notifications # # For instance if keyspace events notification is enabled, and a client # performs a DEL operation on key \u0026#34;foo\u0026#34; stored in the Database 0, two # messages will be published via Pub/Sub: # # PUBLISH __keyspace@0__:foo del # PUBLISH __keyevent@0__:del foo # # It is possible to select the events that Redis will notify among a set # of classes. Every class is identified by a single character: # # K Keyspace events, published with __keyspace@\u0026lt;db\u0026gt;__ prefix. # E Keyevent events, published with __keyevent@\u0026lt;db\u0026gt;__ prefix. # g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ... # $ String commands # l List commands # s Set commands # h Hash commands # z Sorted set commands # x Expired events (events generated every time a key expires) # e Evicted events (events generated when a key is evicted for maxmemory) # t Stream commands # m Key-miss events (Note: It is not included in the \u0026#39;A\u0026#39; class) # A Alias for g$lshzxet, so that the \u0026#34;AKE\u0026#34; string means all the events # (Except key-miss events which are excluded from \u0026#39;A\u0026#39; due to their # unique nature). # # The \u0026#34;notify-keyspace-events\u0026#34; takes as argument a string that is composed # of zero or multiple characters. The empty string means that notifications # are disabled. # # Example: to enable list and generic events, from the point of view of the # event name, use: # # notify-keyspace-events Elg # # Example 2: to get the stream of the expired keys subscribing to channel # name __keyevent@0__:expired use: # # notify-keyspace-events Ex # # By default all notifications are disabled because most users don\u0026#39;t need # this feature and the feature has some overhead. Note that if you don\u0026#39;t # specify at least one of K or E, no events will be delivered. notify-keyspace-events \u0026#34;\u0026#34; ############################### GOPHER SERVER ################################# # Redis contains an implementation of the Gopher protocol, as specified in # the RFC 1436 (https://www.ietf.org/rfc/rfc1436.txt). # # The Gopher protocol was very popular in the late \u0026#39;90s. It is an alternative # to the web, and the implementation both server and client side is so simple # that the Redis server has just 100 lines of code in order to implement this # support. # # What do you do with Gopher nowadays? Well Gopher never *really* died, and # lately there is a movement in order for the Gopher more hierarchical content # composed of just plain text documents to be resurrected. Some want a simpler # internet, others believe that the mainstream internet became too much # controlled, and it\u0026#39;s cool to create an alternative space for people that # want a bit of fresh air. # # Anyway for the 10nth birthday of the Redis, we gave it the Gopher protocol # as a gift. # # --- HOW IT WORKS? --- # # The Redis Gopher support uses the inline protocol of Redis, and specifically # two kind of inline requests that were anyway illegal: an empty request # or any request that starts with \u0026#34;/\u0026#34; (there are no Redis commands starting # with such a slash). Normal RESP2/RESP3 requests are completely out of the # path of the Gopher protocol implementation and are served as usual as well. # # If you open a connection to Redis when Gopher is enabled and send it # a string like \u0026#34;/foo\u0026#34;, if there is a key named \u0026#34;/foo\u0026#34; it is served via the # Gopher protocol. # # In order to create a real Gopher \u0026#34;hole\u0026#34; (the name of a Gopher site in Gopher # talking), you likely need a script like the following: # # https://github.com/antirez/gopher2redis # # --- SECURITY WARNING --- # # If you plan to put Redis on the internet in a publicly accessible address # to server Gopher pages MAKE SURE TO SET A PASSWORD to the instance. # Once a password is set: # # 1. The Gopher server (when enabled, not by default) will still serve # content via Gopher. # 2. However other commands cannot be called before the client will # authenticate. # # So use the \u0026#39;requirepass\u0026#39; option to protect your instance. # # Note that Gopher is not currently supported when \u0026#39;io-threads-do-reads\u0026#39; # is enabled. # # To enable Gopher support, uncomment the following line and set the option # from no (the default) to yes. # # gopher-enabled no ############################### ADVANCED CONFIG ############################### # Hashes are encoded using a memory efficient data structure when they have a # small number of entries, and the biggest entry does not exceed a given # threshold. These thresholds can be configured using the following directives. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # Lists are also encoded in a special way to save a lot of space. # The number of entries allowed per internal list node can be specified # as a fixed maximum size or a maximum number of elements. # For a fixed maximum size, use -5 through -1, meaning: # -5: max size: 64 Kb \u0026lt;-- not recommended for normal workloads # -4: max size: 32 Kb \u0026lt;-- not recommended # -3: max size: 16 Kb \u0026lt;-- probably not recommended # -2: max size: 8 Kb \u0026lt;-- good # -1: max size: 4 Kb \u0026lt;-- good # Positive numbers mean store up to _exactly_ that number of elements # per list node. # The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size), # but if your use case is unique, adjust the settings as necessary. list-max-ziplist-size -2 # Lists may also be compressed. # Compress depth is the number of quicklist ziplist nodes from *each* side of # the list to *exclude* from compression. The head and tail of the list # are always uncompressed for fast push/pop operations. Settings are: # 0: disable all list compression # 1: depth 1 means \u0026#34;don\u0026#39;t start compressing until after 1 node into the list, # going from either the head or tail\u0026#34; # So: [head]-\u0026gt;node-\u0026gt;node-\u0026gt;...-\u0026gt;node-\u0026gt;[tail] # [head], [tail] will always be uncompressed; inner nodes will compress. # 2: [head]-\u0026gt;[next]-\u0026gt;node-\u0026gt;node-\u0026gt;...-\u0026gt;node-\u0026gt;[prev]-\u0026gt;[tail] # 2 here means: don\u0026#39;t compress head or head-\u0026gt;next or tail-\u0026gt;prev or tail, # but compress all nodes between them. # 3: [head]-\u0026gt;[next]-\u0026gt;[next]-\u0026gt;node-\u0026gt;node-\u0026gt;...-\u0026gt;node-\u0026gt;[prev]-\u0026gt;[prev]-\u0026gt;[tail] # etc. list-compress-depth 0 # Sets have a special encoding in just one case: when a set is composed # of just strings that happen to be integers in radix 10 in the range # of 64 bit signed integers. # The following configuration setting sets the limit in the size of the # set in order to use this special memory saving encoding. set-max-intset-entries 512 # Similarly to hashes and lists, sorted sets are also specially encoded in # order to save a lot of space. This encoding is only used when the length and # elements of a sorted set are below the following limits: zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog sparse representation bytes limit. The limit includes the # 16 bytes header. When an HyperLogLog using the sparse representation crosses # this limit, it is converted into the dense representation. # # A value greater than 16000 is totally useless, since at that point the # dense representation is more memory efficient. # # The suggested value is ~ 3000 in order to have the benefits of # the space efficient encoding without slowing down too much PFADD, # which is O(N) with the sparse encoding. The value can be raised to # ~ 10000 when CPU is not a concern, but space is, and the data set is # composed of many HyperLogLogs with cardinality in the 0 - 15000 range. hll-sparse-max-bytes 3000 # Streams macro node max size / items. The stream data structure is a radix # tree of big nodes that encode multiple items inside. Using this configuration # it is possible to configure how big a single node can be in bytes, and the # maximum number of items it may contain before switching to a new node when # appending new stream entries. If any of the following settings are set to # zero, the limit is ignored, so for instance it is possible to set just a # max entries limit by setting max-bytes to 0 and max-entries to the desired # value. stream-node-max-bytes 4096 stream-node-max-entries 100 # Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in # order to help rehashing the main Redis hash table (the one mapping top-level # keys to values). The hash table implementation Redis uses (see dict.c) # performs a lazy rehashing: the more operation you run into a hash table # that is rehashing, the more rehashing \u0026#34;steps\u0026#34; are performed, so if the # server is idle the rehashing is never complete and some more memory is used # by the hash table. # # The default is to use this millisecond 10 times every second in order to # actively rehash the main dictionaries, freeing memory when possible. # # If unsure: # use \u0026#34;activerehashing no\u0026#34; if you have hard latency requirements and it is # not a good thing in your environment that Redis can reply from time to time # to queries with 2 milliseconds delay. # # use \u0026#34;activerehashing yes\u0026#34; if you don\u0026#39;t have such hard requirements but # want to free memory asap when possible. activerehashing yes # The client output buffer limits can be used to force disconnection of clients # that are not reading data from the server fast enough for some reason (a # common reason is that a Pub/Sub client can\u0026#39;t consume messages as fast as the # publisher can produce them). # # The limit can be set differently for the three different classes of clients: # # normal -\u0026gt; normal clients including MONITOR clients # replica -\u0026gt; replica clients # pubsub -\u0026gt; clients subscribed to at least one pubsub channel or pattern # # The syntax of every client-output-buffer-limit directive is the following: # # client-output-buffer-limit \u0026lt;class\u0026gt; \u0026lt;hard limit\u0026gt; \u0026lt;soft limit\u0026gt; \u0026lt;soft seconds\u0026gt; # # A client is immediately disconnected once the hard limit is reached, or if # the soft limit is reached and remains reached for the specified number of # seconds (continuously). # So for instance if the hard limit is 32 megabytes and the soft limit is # 16 megabytes / 10 seconds, the client will get disconnected immediately # if the size of the output buffers reach 32 megabytes, but will also get # disconnected if the client reaches 16 megabytes and continuously overcomes # the limit for 10 seconds. # # By default normal clients are not limited because they don\u0026#39;t receive data # without asking (in a push way), but just after a request, so only # asynchronous clients may create a scenario where data is requested faster # than it can read. # # Instead there is a default limit for pubsub and replica clients, since # subscribers and replicas receive data in a push fashion. # # Both the hard or the soft limit can be disabled by setting them to zero. client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Client query buffers accumulate new commands. They are limited to a fixed # amount by default in order to avoid that a protocol desynchronization (for # instance due to a bug in the client) will lead to unbound memory usage in # the query buffer. However you can configure it here if you have very special # needs, such us huge multi/exec requests or alike. # # client-query-buffer-limit 1gb # In the Redis protocol, bulk requests, that are, elements representing single # strings, are normally limited to 512 mb. However you can change this limit # here, but must be 1mb or greater # # proto-max-bulk-len 512mb # Redis calls an internal function to perform many background tasks, like # closing connections of clients in timeout, purging expired keys that are # never requested, and so forth. # # Not all tasks are performed with the same frequency, but Redis checks for # tasks to perform according to the specified \u0026#34;hz\u0026#34; value. # # By default \u0026#34;hz\u0026#34; is set to 10. Raising the value will use more CPU when # Redis is idle, but at the same time will make Redis more responsive when # there are many keys expiring at the same time, and timeouts may be # handled with more precision. # # The range is between 1 and 500, however a value over 100 is usually not # a good idea. Most users should use the default of 10 and raise this up to # 100 only in environments where very low latency is required. hz 10 # Normally it is useful to have an HZ value which is proportional to the # number of clients connected. This is useful in order, for instance, to # avoid too many clients are processed for each background task invocation # in order to avoid latency spikes. # # Since the default HZ value by default is conservatively set to 10, Redis # offers, and enables by default, the ability to use an adaptive HZ value # which will temporarily raise when there are many connected clients. # # When dynamic HZ is enabled, the actual configured HZ will be used # as a baseline, but multiples of the configured HZ value will be actually # used as needed once more clients are connected. In this way an idle # instance will use very little CPU time while a busy instance will be # more responsive. dynamic-hz yes # When a child rewrites the AOF file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. aof-rewrite-incremental-fsync yes # When redis saves RDB file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. rdb-save-incremental-fsync yes # Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good # idea to start with the default settings and only change them after investigating # how to improve the performances and how the keys LFU change over time, which # is possible to inspect via the OBJECT FREQ command. # # There are two tunable parameters in the Redis LFU implementation: the # counter logarithm factor and the counter decay time. It is important to # understand what the two parameters mean before changing them. # # The LFU counter is just 8 bits per key, it\u0026#39;s maximum value is 255, so Redis # uses a probabilistic increment with logarithmic behavior. Given the value # of the old counter, when a key is accessed, the counter is incremented in # this way: # # 1. A random number R between 0 and 1 is extracted. # 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1). # 3. The counter is incremented only if R \u0026lt; P. # # The default lfu-log-factor is 10. This is a table of how the frequency # counter changes with a different number of accesses with different # logarithmic factors: # # +--------+------------+------------+------------+------------+------------+ # | factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits | # +--------+------------+------------+------------+------------+------------+ # | 0 | 104 | 255 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 1 | 18 | 49 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 10 | 10 | 18 | 142 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 100 | 8 | 11 | 49 | 143 | 255 | # +--------+------------+------------+------------+------------+------------+ # # NOTE: The above table was obtained by running the following commands: # # redis-benchmark -n 1000000 incr foo # redis-cli object freq foo # # NOTE 2: The counter initial value is 5 in order to give new objects a chance # to accumulate hits. # # The counter decay time is the time, in minutes, that must elapse in order # for the key counter to be divided by two (or decremented if it has a value # less \u0026lt;= 10). # # The default value for the lfu-decay-time is 1. A special value of 0 means to # decay the counter every time it happens to be scanned. # # lfu-log-factor 10 # lfu-decay-time 1 ########################### ACTIVE DEFRAGMENTATION ####################### # # What is active defragmentation? # ------------------------------- # # Active (online) defragmentation allows a Redis server to compact the # spaces left between small allocations and deallocations of data in memory, # thus allowing to reclaim back memory. # # Fragmentation is a natural process that happens with every allocator (but # less so with Jemalloc, fortunately) and certain workloads. Normally a server # restart is needed in order to lower the fragmentation, or at least to flush # away all the data and create it again. However thanks to this feature # implemented by Oran Agra for Redis 4.0 this process can happen at runtime # in a \u0026#34;hot\u0026#34; way, while the server is running. # # Basically when the fragmentation is over a certain level (see the # configuration options below) Redis will start to create new copies of the # values in contiguous memory regions by exploiting certain specific Jemalloc # features (in order to understand if an allocation is causing fragmentation # and to allocate it in a better place), and at the same time, will release the # old copies of the data. This process, repeated incrementally for all the keys # will cause the fragmentation to drop back to normal values. # # Important things to understand: # # 1. This feature is disabled by default, and only works if you compiled Redis # to use the copy of Jemalloc we ship with the source code of Redis. # This is the default with Linux builds. # # 2. You never need to enable this feature if you don\u0026#39;t have fragmentation # issues. # # 3. Once you experience fragmentation, you can enable this feature when # needed with the command \u0026#34;CONFIG SET activedefrag yes\u0026#34;. # # The configuration parameters are able to fine tune the behavior of the # defragmentation process. If you are not sure about what they mean it is # a good idea to leave the defaults untouched. # Enabled active defragmentation # activedefrag no # Minimum amount of fragmentation waste to start active defrag # active-defrag-ignore-bytes 100mb # Minimum percentage of fragmentation to start active defrag # active-defrag-threshold-lower 10 # Maximum percentage of fragmentation at which we use maximum effort # active-defrag-threshold-upper 100 # Minimal effort for defrag in CPU percentage, to be used when the lower # threshold is reached # active-defrag-cycle-min 1 # Maximal effort for defrag in CPU percentage, to be used when the upper # threshold is reached # active-defrag-cycle-max 25 # Maximum number of set/hash/zset/list fields that will be processed from # the main dictionary scan # active-defrag-max-scan-fields 1000 # Jemalloc background thread for purging will be enabled by default jemalloc-bg-thread yes # It is possible to pin different threads and processes of Redis to specific # CPUs in your system, in order to maximize the performances of the server. # This is useful both in order to pin different Redis threads in different # CPUs, but also in order to make sure that multiple Redis instances running # in the same host will be pinned to different CPUs. # # Normally you can do this using the \u0026#34;taskset\u0026#34; command, however it is also # possible to this via Redis configuration directly, both in Linux and FreeBSD. # # You can pin the server/IO threads, bio threads, aof rewrite child process, and # the bgsave child process. The syntax to specify the cpu list is the same as # the taskset command: # # Set redis server/io threads to cpu affinity 0,2,4,6: # server_cpulist 0-7:2 # # Set bio threads to cpu affinity 1,3: # bio_cpulist 1,3 # # Set aof rewrite child process to cpu affinity 8,9,10,11: # aof_rewrite_cpulist 8-11 # # Set bgsave child process to cpu affinity 1,10,11 # bgsave_cpulist 1,10-11 # In some cases redis will emit warnings and even refuse to start if it detects # that the system is in bad state, it is possible to suppress these warnings # by setting the following config which takes a space delimited list of warnings # to suppress # # ignore-warnings ARM64-COW-BUG"},{"id":98,"href":"/docs/redis/1.7redis%E6%8C%81%E4%B9%85%E5%8C%96/","title":"1.7 Redis持久化","section":"所有文章","content":"Rdb# Rdb （Redis DataBase）是Redis用来进行持久化的一种方式，是把当前内存中的数据集快照写入磁盘，也就是 Snapshot 快照（数据库中所有键值对数据）。恢复时将快照文件直接读到内存里。\nRdb 是 Redis 默认的持久化方案。在指定的时间间隔内，执行指定次数的写操作，则会将内存中的数据写入到磁盘中。即在指定目录下生成一个 dump.rdb (默认名称)文件。Redis 重启会通过加载dump.rdb文件恢复数据。\n基本原理# Rdb 持久化主要是通过 SAVE 和 BGSAVE 两个命令对 Redis 数据库中当前的数据做 snapshot 并生成 rdb 文件来实现的。其中SAVE 是阻塞的，BGSAVE 是非阻塞的，通过 fork 了一个子进程来完成的。在 Redis启动时会检测 rdb 文件，然后载入 rdb 文件中未过期的数据到服务器中。\n触发方式# Rdb 有两种触发方式：自动触发/手动触发。\n自动触发# 在 redis.conf 配置文件中的 SNAPSHOTTING 下\n# You can set these explicitly by uncommenting the three following lines. # # *快照持久化规则设置 # *如果3600秒内，至少一个Key进行了修改，就会进行持久化 # save 3600 1 # save 300 100 # save 60 10000 # 60s内至少一个Key进行了修改就会进行持久化 save 60 1相关配置\n指定本地数据库文件名，一般采用默认的 dump.rdb\ndbfilename dump.rdb指定本地数据库存放目录，一般用默认配置即可\ndir ./默认开启数据压缩\nrdbcompression yes[root@wangpengliang bin]# ls conf redis-benchmark redis-check-rdb redis-sentinel dump.rdb redis-check-aof redis-cli redis-server # 删除dump.rdb文件 [root@wangpengliang bin]# rm -f dump.rdb [root@wangpengliang bin]# ls conf redis-check-aof redis-cli redis-server redis-benchmark redis-check-rdb redis-sentinel[root@wangpengliang bin]# ./redis-server conf/redis.conf # 触发自动快照策略 [root@wangpengliang bin]# ./redis-cli -p 6379 127.0.0.1:6379\u0026gt; SET KEY A OK 127.0.0.1:6379\u0026gt; SET KEY B OK 127.0.0.1:6379\u0026gt; SET KEY C OK 127.0.0.1:6379\u0026gt; SET KEY D OK# dump.rdb又存在了 [root@wangpengliang bin]# ls conf redis-benchmark redis-check-rdb redis-sentinel dump.rdb redis-check-aof redis-cli redis-server手动触发# 操作 描述 save 该命令会阻塞当前Redis 服务器，执行 save 命令期间，Redis 不能处理其他命令，直到 Rdb 过程完成为止 bgsave 执行该命令时，Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体操作是 Redis 进程执行 fork 操作创建子进程，Rdb 持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短 flushall shutdown Rdb文件恢复数据# 将 dump.rdb 文件拷贝到 Redis 的安装目录的bin 目录下，重启 Redis 服务即可。在实际开发中，一般会考虑到物理机硬盘损坏情况，选择备份dump.rdb 。\nRdb优缺点# 优点 缺点 适合大规模的数据恢复 数据的完整性和一致性不高，因为可能在最后一次备份时宕机了 二进制压缩文件，恢复速度快 备份时占用内存，因为Redis 在备份时会独立创建一个子进程，将数据写入到一个临时文件（此时内存中的数据是原来的两倍），最后再将临时文件替换之前的备份文件 如果业务对数据完整性和一致性要求不高，Rdb是很好的选择 注意：假设 save 策略设置的是60秒，Redis在58秒宕机，会丢失最后一次的数据。\nAof# Redis 默认不开启。它的出现是为了弥补Rdb的不足（数据的不一致性），所以它采用日志的形式来记录每个写操作，并追加到文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。\n基本原理# AOF（Append Only File ）持久化是通过将存储每次执行的客户端命令，然后由一个伪客户端来执行这些命令将数据写入到服务器中的方式实现的。一共分为命令追加（append）/文件写入/文件同步（sync）三个步骤完成。\n在 redis.conf 配置文件中的APPEND ONLY MODE下\n1 redis 默认关闭，开启需要手动把 no 改为 yes\nappendonly yes2 指定本地数据库文件名，默认值为 appendonly.aof\nappendfilename \u0026#34;appendonly.aof\u0026#34;3 指定更新日志条件\n# appendfsync always appendfsync everysec # appendfsync noalways：同步持久化，每次发生数据变化会立刻写入到磁盘中。性能较差但数据完整性比较好（慢，安全）\neverysec：出厂默认推荐，每秒异步记录一次（默认值）\nno：不同步\n4 配置重写触发机制\n当 aof 文件大小是上次 rewrite 后大小的一倍且文件大于 64M 时触发；Redis 会 fork出一条新进程，读取内存中的数据，并重新写到一个临时文件中。并没有读取旧文件最后替换旧的aof文件。这里的“一倍”和“64M” 可以通过配置文件修改。\nauto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb触发方式# 根据 redis.conf 配置文件的配置内容触发。\nAof文件恢复数据# 正常情况下，将 appendonly.aof 文件拷贝到redis的安装目录的bin 目录下，重启redis服务即可。\nAof文件修复# 在实际开发中，可能因为某些原因导致 appendonly.aof 文件格式异常，从而导致数据还原失败，可以通过命令 redis-check-aof --fix appendonly.aof 进行修复。\nAof 优缺点# 优点 缺点 数据的完整性和一致性更高 因为AOF记录的内容多，文件会越来越大 因为文件较大数据恢复也会比较慢 总结# Redis 默认开启rdb持久化方式。在指定的时间间隔内，执行指定次数的写操作，则将内存中的数据写入到磁盘中。\nrdb持久化适合大规模的数据恢复但它的数据一致性和完整性较差。\nRedis 需要手动开启 aof 持久化方式，默认是每秒将写操作日志追加到 aof 文件中。\naof 的数据完整性比 rdb 高，但记录内容多了，会影响数据恢复的效率。\nRedis 针对 aof 文件大的问题，提供重写的瘦身机制。\n若只打算用Redis 做缓存，可以关闭持久化。\n若打算使用Redis 的持久化。建议rdb和aof都开启。其实rdb更适合做数据的备份，留一后手。aof 出问题了，还有 rdb。\n当 rdb 和 aof 文件同时存在时，Redis会优先使用 aof 文件恢复。\n"},{"id":99,"href":"/docs/redis/1.8redis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/","title":"1.8 Redis发布订阅","section":"所有文章","content":" TODO：知道有这个东西，需要用的时候看下文档即可。\n"},{"id":100,"href":"/docs/redis/1.9redis%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88/","title":"1.9 Redis集群方案","section":"所有文章","content":"Redis集群# Redis支持三种集群方案\n主从复制 Sentinel（哨兵） Cluster 主从复制# 通过持久化功能，Redis保证了即使在服务器重启的情况下也不会丢失（或少量丢失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。 但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。\n为此： Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。\n在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，只接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。\n实现原理# 从库启动成功后连接主库，发送 SYNC 命令 主库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 rdb 文件并使用缓冲区记录此后执行的所有写命令 主库 BGSAVE 执行完毕后，向所有从库发送快照文件，并在发送期间继续记录被执行的写命令 从库收到快照文件后丢弃所有旧数据，载入收到的快照 主库快照发送完毕后开始向从库发送缓冲区中的写命令 从库完成对快照的载入，开始接收命令请求，并执行来自主库缓冲区的写命令（至此：从库初始化完成） 主库每执行一个写命令就会向从库发送相同的写命令，从库接收并执行收到的写命令（备注：从库初始化完成后的操作） 出现断开重连后，2.8之后的版本会将断线期间的命令传给从库。增量复制 主从刚连接时：进行全量同步。全同步结束后：进行增量同步。当然如果有需要 slave 可以在任何时候都可以发起全量同步。Redis 的策略是：无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步 主从复制优缺点# 优点\n主机会自动将数据同步到从机，可以进行读写分离 为了分载 master 的读操作压力，slave 服务器可以为客户端提供只读操作的服务，但写服务仍必须由 master 完成 slave 同样可以接受其它 slaves 的连接和同步请求，这样可以有效的分载 master 的同步压力 master-server 是以非阻塞的方式为 slaves提供服务。所以在 master-slave 同步期间，客户端仍然可以提交查询或修改请求 slave-server 同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，则返回同步之前的数据 缺点\n不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换 IP 才能恢复（人工介入方式） 主机宕机，宕机前如有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性 如果多个 slave 掉线需要重启时，尽量不要在同一时间段进行重启。因为只要 slave 启动，就会发送sync 请求和主机全量同步，当多个 slave 重启时，可能会导致 master IO 剧增从而宕机 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂 主从复制搭建# 集群至少需要3个节点，因为投票容错机制要求超过半数节点认为某个节点挂了该节点才是挂了，所以低于3个节点无法构成集群 要保证集群的高可用，需要每个节点都有从节点，也就是备份节点。所以Redis集群至少需要6台服务器。这里模拟搭建的是伪分布式集群（单机多实例） 默认情况下不指定主机的话，每台 Redis 都是主节点 1)：虚机运行3个 Redis 实例（一主二从），修改端口号为（79-81）。复制2份 redis.conf 模拟2个从机实例\n[root@wangpengliang bin]# ls conf dump.rdb redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server [root@wangpengliang bin]# cd conf [root@wangpengliang conf]# ls redis.conf [root@wangpengliang conf]# cp redis.conf redis80.conf [root@wangpengliang conf]# cp redis.conf redis81.conf 类型 端口 配置文件 master 6379 redis.conf slave1 6380 redis80.conf slave2 6381 redis81.conf 2)：修改配置\nlogfile dbfilename port pidfile redis.conf\nlogfile \u0026#34;6379.log\u0026#34; dbfilename dump6379.rdbredis80.conf\nlogfile \u0026#34;6380.log\u0026#34; dbfilename dump6380.rdb port 6380 pidfile /var/run/redis_6380.pidredis81.conf\nlogfile \u0026#34;6381.log\u0026#34; dbfilename dump6381.rdb port 6381 pidfile /var/run/redis_6381.pid3)：查看Redis进程信息\n[root@wangpengliang conf]# ps -ef|grep redis root 2679 1 0 02:53 ? 00:00:00 ./redis-server 0.0.0.0:6379 root 2685 1 0 02:54 ? 00:00:00 ./redis-server 0.0.0.0:6380 root 2691 1 0 02:54 ? 00:00:00 ./redis-server 0.0.0.0:6381 root 2697 2643 0 02:54 pts/3 00:00:00 grep --color=auto redis4)：设置主从：SLAVEOF {host} {port}\n80\n[root@wangpengliang bin]# ./redis-cli -p 6380 127.0.0.1:6380\u0026gt; SLAVEOF 0.0.0.0 6379 OK 127.0.0.1:6380\u0026gt; info replication # Replication role:slave master_host:0.0.0.0 master_port:6379 master_link_status:up master_last_io_seconds_ago:0 master_sync_in_progress:0 slave_repl_offset:28 slave_priority:100 slave_read_only:1 connected_slaves:0 master_failover_state:no-failover master_replid:fb828085ccb5c0b804cfa2e8112656aef5f561c8 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:28 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:2881\n[root@wangpengliang bin]# ./redis-cli -p 6381 127.0.0.1:6381\u0026gt; clear 127.0.0.1:6381\u0026gt; SLAVEOF 0.0.0.0 6379 OK 127.0.0.1:6381\u0026gt; info replication # Replication role:slave master_host:0.0.0.0 master_port:6379 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_repl_offset:210 slave_priority:100 slave_read_only:1 connected_slaves:0 master_failover_state:no-failover master_replid:fb828085ccb5c0b804cfa2e8112656aef5f561c8 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:210 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:183 repl_backlog_histlen:2879（master）\n127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6380,state=online,offset=210,lag=0 slave1:ip=127.0.0.1,port=6381,state=online,offset=210,lag=0 master_failover_state:no-failover master_replid:fb828085ccb5c0b804cfa2e8112656aef5f561c8 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:210 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:210注意：使用命令的方式集群是暂时的；如果需要永久生效需要修改配置文件\n5)：修改配置文件设置主从\nreplicaof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt;redis80.conf\nreplicaof 0.0.0.0 6379redis81.conf\nreplicaof 0.0.0.0 6379如果主机有密码通过 masterauth \u0026lt;master-password\u0026gt; 设置。\n注意\n主机可写，从机只能读不能写 主机中数据会自动备份到从机 6)：主机宕机测试\n127.0.0.1:6379\u0026gt; SHUTDOWN not connected\u0026gt; exit[root@wangpengliang bin]# ps -ef|grep redis root 2723 1 0 03:12 ? 00:00:00 ./redis-server 0.0.0.0:6380 root 2728 2605 0 03:12 pts/1 00:00:00 ./redis-cli -p 6380 root 2730 1 0 03:12 ? 00:00:00 ./redis-server 0.0.0.0:6381 root 2735 2624 0 03:12 pts/2 00:00:00 ./redis-cli -p 6381 root 2738 2643 0 03:16 pts/3 00:00:00 grep --color=auto redis80\n此时并没有配置哨兵，所以在 Master 79宕机后，80依旧是从机。\n127.0.0.1:6380\u0026gt; info replication # Replication role:slave master_host:0.0.0.0 master_port:6379 master_link_status:down master_last_io_seconds_ago:-1 master_sync_in_progress:0 slave_repl_offset:1130 master_link_down_since_seconds:17 slave_priority:100 slave_read_only:1 connected_slaves:0 master_failover_state:no-failover master_replid:fb828085ccb5c0b804cfa2e8112656aef5f561c8 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1130 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:771 repl_backlog_histlen:360 主机断线重连后，从机依旧可以读取到主机的值 从机断线重连后，从机依旧可以读取到主机的值 7)：手动切换主节点\n此时使用 Slaveof no one 命令可以使80变成主机。\nSentinel（哨兵）模式# 主从切换的方法是：当主服务器宕机后，需要手动把从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式。哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是：哨兵通过发送命令等待Redis服务器响应，从而监控运行的多个Redis实例。\n哨兵作用# 通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器 当哨兵监测到 master 宕机，会自动将 slave切换成 master ，然后通过 发布订阅模式通知其他的从机修改配置文件，让它们切换主机 master 切换后，master_redis.conf 、slave_redis.conf 和 sentinel.conf 的内容都会发生改变，master_redis.conf 中会多一行 slaveof 的配置，sentinel.conf 的监控目标会随之调换 一个哨兵进程对 Redis 服务器进行监控，可能会出现问题，为此可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这就形成了多哨兵模式 故障切换（failover）过程# 假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover，仅仅是哨兵1主观的认为主服务器不可用，这个现象称为 主观下线 当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为 客观下线 哨兵工作方式# 每个sentinel以每秒钟一次的频率向它所知的master、slave、 sentinel 实例发送一个 PING 命令 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds选项所指定的值， 则这个实例会被 sentinel 标记为主观下线 如果一个master被标记为主观下线，则正在监视这个master的所有 sentinels 要以每秒一次的频率确认master 的确进入了主观下线状态 当有足够数量的 sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 master 的确进入了主观下线状态，则 master 会被标记为客观下线 一般情况下， 每个 sentinel 会以每 10 秒一次的频率向它已知的所有 master、slave发送 INFO 命令 当master被 sentinel 标记为客观下线时，sentinel 向 master 的所有 slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 若没有足够数量的 sentinel 同意 master 已经下线， master 的客观下线状态就会被移除。若master 重新向 sentinel 的 PING 命令返回有效回复，master 的主观下线状态就会被移除 哨兵模式优缺点# 优点\n哨兵模式是基于主从模式的，所有主从的优点哨兵模式都具有 主从可以自动切换。系统更健壮、可用性更高（可以看作自动版的主从复制） 缺点\nRedis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂 哨兵模式搭建# 1)：Redis安装目录下有一个 sentinel.conf 文件，copy 一份进行修改\n2)：配置哨兵\n# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义 # 192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。权值为2，这里的权值，是用来计算我们需要将哪一台服务器升级升主服务器 sentinel monitor mymaster 0.0.0.0 6379 23)：启动哨兵\n[root@wangpengliang bin]# ./redis-sentinel conf/sentinel.conf 2821:X 19 Apr 2021 04:13:16.075 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 2821:X 19 Apr 2021 04:13:16.075 # Redis version=6.2.1, bits=64, commit=00000000, modified=0, pid=2821, just sta rted2821:X 19 Apr 2021 04:13:16.075 # Configuration loaded 2821:X 19 Apr 2021 04:13:16.076 * Increased maximum number of open files to 10032 (it was originally set to 102 4).2821:X 19 Apr 2021 04:13:16.076 * monotonic clock: POSIX clock_gettime _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 6.2.1 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in sentinel mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 26379 | `-._ `._ / _.-\u0026#39; | PID: 2821 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | http://redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 2821:X 19 Apr 2021 04:13:16.076 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/ net/core/somaxconn is set to the lower value of 128.2821:X 19 Apr 2021 04:13:16.077 # Sentinel ID is fdcb482b76a22f67429b1473ddc33d0d3769f7f3 2821:X 19 Apr 2021 04:13:16.077 # +monitor master mymaster 0.0.0.0 6379 quorum 1 2821:X 19 Apr 2021 04:13:16.078 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:13:16.080 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 0.0.0.0 6379Sentinel 启动之后，就会监视到现在有一个主服务器，两个从服务器；当把其中一个从服务器器关闭之后，可以看到日志\n2821:X 19 Apr 2021 04:14:03.125 # +sdown master mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:03.125 # +odown master mymaster 0.0.0.0 6379 #quorum 1/1 2821:X 19 Apr 2021 04:14:03.125 # +new-epoch 1 2821:X 19 Apr 2021 04:14:03.125 # +try-failover master mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:03.132 # +vote-for-leader fdcb482b76a22f67429b1473ddc33d0d3769f7f3 1 2821:X 19 Apr 2021 04:14:03.132 # +elected-leader master mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:03.132 # +failover-state-select-slave master mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:03.199 # +selected-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:03.199 * +failover-state-send-slaveof-noone slave 127.0.0.1:6380 127.0.0.1 6380 @ myma ster 0.0.0.0 63792821:X 19 Apr 2021 04:14:03.282 * +failover-state-wait-promotion slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 0.0.0.0 63792821:X 19 Apr 2021 04:14:03.288 # +promoted-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:03.288 # +failover-state-reconf-slaves master mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:03.340 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 0.0.0.0 637 92821:X 19 Apr 2021 04:14:04.312 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 0.0.0.0 6 3792821:X 19 Apr 2021 04:14:04.312 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 0.0.0.0 637 92821:X 19 Apr 2021 04:14:04.378 # +failover-end master mymaster 0.0.0.0 6379 2821:X 19 Apr 2021 04:14:04.378 # +switch-master mymaster 0.0.0.0 6379 127.0.0.1 6380 2821:X 19 Apr 2021 04:14:04.379 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380 2821:X 19 Apr 2021 04:14:04.379 * +slave slave 0.0.0.0:6379 0.0.0.0 6379 @ mymaster 127.0.0.1 6380 2821:X 19 Apr 2021 04:14:34.411 # +sdown slave 0.0.0.0:6379 0.0.0.0 6379 @ mymaster 127.0.0.1 6380此时Master从79转移到了80\n127.0.0.1:6380\u0026gt; info replication # Replication role:master connected_slaves:1 slave0:ip=127.0.0.1,port=6381,state=online,offset=4615,lag=1 master_failover_state:no-failover master_replid:872d3e4c9538abb9f117dcc47de99ac57791433a master_replid2:612af05d7a22d2b35e595f43be74ddd771765798 master_repl_offset:4615 second_repl_offset:1212 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:461579重新连接\n[root@wangpengliang bin]# ./redis-server conf/redis.conf [root@wangpengliang bin]# ./redis-cli -p 6379 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; info replication # Replication role:slave master_host:127.0.0.1 master_port:6380 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_repl_offset:35074 slave_priority:100 slave_read_only:1 connected_slaves:0 master_failover_state:no-failover master_replid:872d3e4c9538abb9f117dcc47de99ac57791433a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:35074 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:32735 repl_backlog_histlen:234079重新连接后只能是从机了，master已经被80抢占。\nCluster 集群模式# Redis Cluster是一种服务器 Sharding 技术，3.0版本开始正式提供。Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 Redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储。也就是说每台 Redis 节点上存储不同的内容。\nCluster特点# 多主多从去中心化：从节点作为备用，复制主节点，不做读写操作不提供服务（可通过 readOnly 实现只读） 不支持处理多个key：因为数据分散在多个节点，在数据量大高并发的情况下会影响性能 支持动态扩容节点：Rerdis Cluster 最大的优点之一 节点之间相互通信，相互选举，不再依赖Sentinel：准确来说是主节点之间相互“监督”，保证及时故障转移 Cluster集群模式对比# 相比哨兵模式：多个master节点保证主要业务（比如master节点主要负责写）稳定性，不需要搭建多个sentinel实例监控一个master节点 相比一主多从模式：不需要手动切换，具有自我故障检测，故障转移的特点 相比其哨兵和主从：对数据进行分片（sharding），不同节点存储数据不一样支持动态扩容。从某种程度上来说，Sentinel模式主要针对高可用（HA），而Cluster模式是不仅针对大数据量，高并发，同时也支持HA 数据存储设计# 通过算法设计，计算出key应该保存的位置 将所有的存储空间计划切割成16384份，每台主机保存一部分每份代表的是一个存储空间，不是一个key的保存空间 将key按照计算出的结果放到对应的存储空间 1)：key通过hash算法计算出一个值，然后拿这个值%16384\n2)：得到一个数（假如是37）为key的保存位置，然后再存入相应的存储空间位置\n3)：假如又增加了一个节点，之前每个节点都会拿出部分槽给新的节点\n4)：如果是去除节点，则把被去除节点的槽加入到存在的节点当中\n哈希槽Slot# Redis集群使用一种称作一致性哈希的复合分区形式（组合了哈希分区和列表分袂的特征来计算键的归属实例），键的CRC16哈希值被称为哈希槽。比如对于三个Redis节点，哈希槽的分配方式如下：\n第一节点拥有0-5500哈希槽 第二节点拥有5501-11000哈希槽 第三节点拥有剩余的11001-16384哈希槽 通过计算键的 CRC16 哈希值，然后对16384进行取模得到：HASH_SLOT=CRC16(key) modulo 16383，Redis提供了CLUSTER KEYSLOT命令来执行哈希槽的计算。\n注意：集群节点保存键值对以及键值对过期时间的处理方式与Redis单机模式是一样的，唯一不同就是节点只能使用0号数据库，而单机Redis服务器则没有限制。\n集群内部通讯机制# 各个数据库互相通信，保存各个库中槽的编号数据。\n1)：客户端发出一个key访问A，通过算法计算出key的存储位置\n2)：如果一次命中，直接返回\n3)：一次未命中，告知具体位置\n4)：一次命中或者两次命中提高数据访问效率\nCluster集群搭建# 1)：单虚机运行6个redis实例（三主三从），端口号为（79-84）\n[root@wangpengliang local]# cd /usr/local/redis/bin [root@wangpengliang bin]# ls conf redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server [root@wangpengliang bin]# cd conf [root@wangpengliang conf]# ls redis80.conf redis81.conf redis.conf sentinel.conf [root@wangpengliang conf]# cp redis.conf redis82.conf [root@wangpengliang conf]# cp redis.conf redis83.conf [root@wangpengliang conf]# cp redis.conf redis84.conf [root@wangpengliang conf]# 端口 配置文件 6379 redis.conf 6380 redis80.conf 6381 redis81.conf 6382 redis82.conf 6383 redis83.conf 6384 redis84.conf 2)：修改配置\ndaemonize yes # 后台启动 protected-mode no ; # 允许外部访问 port 6379 # 修改端口号，从79~84 cluster-enabled yes # 开启cluster，去掉注释 cluster-config-file nodes-6379.conf # 自动生成 cluster-node-timeout 15000 # 节点通信时间 logfile /usr/local/redis/bin/6379.log dbfilename 6379dump.rdb # 做伪集群的时候，一定要修改rdb文件的名字，如果aof也开的话也需要修改，否则扩容的时候会出现提示说新增扩容节点存在数据，需要先删除数据的提示。3)：启动Redis\n[root@wangpengliang bin]# ./redis-server conf/redis.conf [root@wangpengliang bin]# ./redis-server conf/redis80.conf [root@wangpengliang bin]# ./redis-server conf/redis81.conf [root@wangpengliang bin]# ./redis-server conf/redis82.conf [root@wangpengliang bin]# ./redis-server conf/redis83.conf [root@wangpengliang bin]# ./redis-server conf/redis84.conf查看Redis进程信息\n[root@wangpengliang bin]# ps -ef|grep redis root 3538 1 0 13:37 ? 00:00:01 ./redis-server 0.0.0.0:6382 [cluster] root 3545 1 0 13:38 ? 00:00:01 ./redis-server 0.0.0.0:6383 [cluster] root 3551 1 0 13:38 ? 00:00:01 ./redis-server 0.0.0.0:6384 [cluster] root 3797 1 0 13:48 ? 00:00:00 ./redis-server 0.0.0.0:6380 [cluster] root 3803 1 0 13:48 ? 00:00:00 ./redis-server 0.0.0.0:6381 [cluster] root 3816 1 0 13:49 ? 00:00:00 ./redis-server 0.0.0.0:6379 [cluster] root 3826 3494 0 13:49 pts/0 00:00:00 grep --color=auto redis4)：创建集群\n--cluster create 192.168.80.251:6379 192.168.80.251:6380 192.168.80.251:6381 192.168.80.251:6382 192.168.80.251:6383 192.168.80.251:6384 --cluster-replicas 1[root@wangpengliang bin]# ./redis-cli --cluster create 192.168.15.251:6379 192.168.15.251:6380 192.168.15.251:6381 192.168.15.251:6382 192.168.15.251:6383 192.168.15.251:6384 --cluster-replicas 1 \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 192.168.15.251:6383 to 192.168.15.251:6379 Adding replica 192.168.15.251:6384 to 192.168.15.251:6380 Adding replica 192.168.15.251:6382 to 192.168.15.251:6381 \u0026gt;\u0026gt;\u0026gt; Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: 48f3cbacb014f1d0f89fe99bb494e1cabb1f80f4 192.168.15.251:6379 slots:[0-5460] (5461 slots) master M: ee511eed5a7d08d39ceef29823b98e299435523e 192.168.15.251:6380 slots:[5461-10922] (5462 slots) master M: e4c70b085d10d51a3201c6bf4bfa47adfa000f2e 192.168.15.251:6381 slots:[10923-16383] (5461 slots) master S: 5261a1ccb42ac160a93572beae7344e6b0c7c520 192.168.15.251:6382 replicates 48f3cbacb014f1d0f89fe99bb494e1cabb1f80f4 S: d420ca1e3ef8edd538286e1c7698783447312148 192.168.15.251:6383 replicates ee511eed5a7d08d39ceef29823b98e299435523e S: 235fb6093a7f1c92e7144109aee10d1e341d2fb9 192.168.15.251:6384 replicates e4c70b085d10d51a3201c6bf4bfa47adfa000f2e Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.15.251:6379) M: 48f3cbacb014f1d0f89fe99bb494e1cabb1f80f4 192.168.15.251:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: e4c70b085d10d51a3201c6bf4bfa47adfa000f2e 192.168.15.251:6381 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: ee511eed5a7d08d39ceef29823b98e299435523e 192.168.15.251:6380 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: 5261a1ccb42ac160a93572beae7344e6b0c7c520 192.168.15.251:6382 slots: (0 slots) slave replicates 48f3cbacb014f1d0f89fe99bb494e1cabb1f80f4 S: 235fb6093a7f1c92e7144109aee10d1e341d2fb9 192.168.15.251:6384 slots: (0 slots) slave replicates e4c70b085d10d51a3201c6bf4bfa47adfa000f2e S: d420ca1e3ef8edd538286e1c7698783447312148 192.168.15.251:6383 slots: (0 slots) slave replicates ee511eed5a7d08d39ceef29823b98e299435523e [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered.Redis-Cluster集群命令# cluster info ：打印集群的信息 cluster nodes：列出集群当前已知的所有节点（ node），以及这些节点的相关信息 cluster meet ：将 ip 和 port 所指定的节点添加到集群当中 cluster forget \u0026lt;node_id\u0026gt; ：从集群中移除 node_id 指定的节点 cluster replicate \u0026lt;master_node_id\u0026gt; ：将当前从节点设置为 node_id 指定的master节点的slave节点。只能针对slave节点操作 cluster saveconfig：将节点的配置文件保存到硬盘里面 cluster addslots [slot ...] ：将一个或多个槽（ slot）指派（ assign）给当前节点 cluster delslots [slot ...] ：移除一个或多个槽对当前节点的指派 cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点 cluster setslot node \u0026lt;node_id\u0026gt; ：将槽 slot 指派给 node_id 指定的节点 cluster setslot migrating \u0026lt;node_id\u0026gt; ：将本节点的槽 slot 迁移到 node_id 指定的节点中 cluster setslot importing \u0026lt;node_id\u0026gt; ：从 node_id 指定的节点中导入槽 slot 到本节点 cluster setslot stable ：取消对槽 slot 的导入（ import）或者迁移（ migrate） cluster keyslot ：计算键 key 应该被放置在哪个槽上 cluster countkeysinslot ：返回槽 slot 目前包含的键值对数量 cluster getkeysinslot ：返回 count 个 slot 槽中的键 查看Redis数据库信息# info replication\n127.0.0.1:6379\u0026gt; info replication # Replication # 角色 role:master # 连接的从机数量 connected_slaves:0 master_failover_state:no-failover master_replid:28d568fba5f2ed0f9034a4f63acc4960287099af master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0"},{"id":101,"href":"/docs/redis/%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BAredis%E9%9B%86%E7%BE%A4/","title":"使用 Docker搭建 Redis集群","section":"所有文章","content":"环境准备# IP 操作系统 192.168.252.191 CentOS Linux release 7.9.2009 (Core) 192.168.252.192 CentOS Linux release 7.9.2009 (Core) 192.168.252.193 CentOS Linux release 7.9.2009 (Core) 192.168.252.194 CentOS Linux release 7.9.2009 (Core) 192.168.252.195 CentOS Linux release 7.9.2009 (Core) 192.168.252.196 CentOS Linux release 7.9.2009 (Core) 整体搭建步骤# 整体搭建步骤主要分为以下几步：\n下载 Redis 镜像（可以省略，创建容器时如果本地镜像不存在就会去远程拉取） 更改 Redis 配置文件 创建并运行 Redis 容器 使用集群命令创建 Redis Cluster 集群 Step1：下载镜像# 省略\nStep2：更改配置文件# 获取 redis.conf 修改默认配置\nbind 127.0.0.1 ： 修改为 0.0.0.0 或指定IP（127.0.0.1 限制了 Redis 只能本地访问） protected-mode no： 改为yes ：开启保护模式限制为本地访问 daemonize no ：改为 yes：是否以守护进程方式启动可后台运行 dir ./ ：Redis 数据存放文件夹（可选） appendonly yes ：Redis 持久化（可选） cluster-enabled ：设置为集群节点 Step3：创建并启动容器# docker run -d --net host --name redis -v /usr/confs/redis.conf:/etc/redis/redis.conf -v /usr/redisdata:/data redis redis-server /etc/redis/redis.conf --appendonly yes命令解释：\n--name redis ：指定容器名称 -v ：挂载目录，前表示主机部分/后表示容器部分 -d ：表示后台启动 redis-server /etc/redis/redis.conf ：以配置文件启动 Redis ，加载容器内的 conf 文件，最终找到的是 /usr/confs/redis.conf appendonly yes：开启 Redis 持久化 --requirepass：\u0026ldquo;如果有密码\u0026rdquo; 在每台虚机上重复执行 Step2 和 Step3 启动6个redis节点。\n注意：如果在执行创建集群命令时卡在\u0026quot; Waiting for the cluster to join \u0026hellip;\u0026hellip;\u0026quot;，启动容器时添加 --net host\nStep4：创建Redis集群# 格式：\ndocker exec -it redis redis-cli --cluster create 192.168.252.191:6379 192.168.252.192:6379 192.168.252.193:6379 192.168.252.194:6379 192.168.252.195:6379 192.168.252.196:6379 --cluster-replicas 1查看结果\n[root@centos-01 ~]# docker exec -it redis /bin/bash root@centos-01:/data# redis-cli 127.0.0.1:6379\u0026gt; CLUSTER NODES ea3bd63f54103bf7873bfa1b8bea4b7c1190d489 192.168.252.191:6379@16379 myself,master - 0 1631258399000 1 connected 0-5460 9d512a4a1bb7b2a92f09005298065c974d3cd545 192.168.252.194:6379@16379 master - 0 1631258399500 9 connected 10923-16383 752d6f9633db932d8347f69d3a4eb52f640d2bdb 192.168.252.192:6379@16379 slave 05debcade3fbaae47c561fefd6c982641a74185c 0 1631258398000 10 connected 7020b7697b4c0c3f5237f8d56a8ee24b41e1faa2 192.168.252.193:6379@16379 slave 9d512a4a1bb7b2a92f09005298065c974d3cd545 0 1631258400520 9 connected 05debcade3fbaae47c561fefd6c982641a74185c 192.168.252.196:6379@16379 master - 0 1631258398478 10 connected 5461-10922 60f3a530a42c1f984d82f93fbb9a4017f40fb498 192.168.252.195:6379@16379 slave ea3bd63f54103bf7873bfa1b8bea4b7c1190d489 0 1631258397457 1 connected 127.0.0.1:6379\u0026gt; CLUSTER INFO cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 cluster_size:3 cluster_current_epoch:10 cluster_my_epoch:1 cluster_stats_messages_ping_sent:6497 cluster_stats_messages_pong_sent:6333 cluster_stats_messages_fail_sent:32 cluster_stats_messages_auth-ack_sent:4 cluster_stats_messages_sent:12866 cluster_stats_messages_ping_received:6328 cluster_stats_messages_pong_received:6488 cluster_stats_messages_meet_received:5 cluster_stats_messages_fail_received:6 cluster_stats_messages_auth-req_received:4 cluster_stats_mes"},{"id":102,"href":"/docs/redis/%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5redis/","title":"客户端连接 Redis","section":"所有文章","content":"测试代码：https://github.com/wangpengliang815/CodeSnippet/tree/master/CommonLib/CommonLib\n参考文档：https://www.bookstack.cn/books/StackExchange.Redis-docs-cn\n客户端# ServiceStack.Redis 是商业版，免费版有限制 StackExchange.Redis 是免费版，但是内核在 .NETCore 运行有问题经常 Timeout，暂无法解决 csRedis于2016年开始支持.NETCore一直迭代至今，实现了低门槛、高性能，和分区高级玩法的.NETCore redis-cli SDK ServiceStack.Redis# 商业版，免费版有限制。放弃。\nStackExchange.Redis# 安装# StackExchange.Redis 是 C# 操作 Redis 数据库的客户端。在 NuGet 中搜索 StackExchange.Redis ，直接点击按钮安装即可。\n封装# RedisHelper\nnamespace CommonLib { using Newtonsoft.Json; using StackExchange.Redis; using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; /// \u0026lt;summary\u0026gt; /// 基于StackExchange.Redis封装的Helper /// /// \u0026lt;/summary\u0026gt; public class RedisHelper { /// \u0026lt;summary\u0026gt; /// 自定义缓存Key前缀 /// \u0026lt;/summary\u0026gt; /// \u0026lt;value\u0026gt; /// The custom key prefix. /// \u0026lt;/value\u0026gt; private string CustomKeyPrefix { get; } /// \u0026lt;summary\u0026gt; /// ConnectionMultiplexer对象 /// \u0026lt;/summary\u0026gt; private readonly ConnectionMultiplexer conn; /// \u0026lt;summary\u0026gt; /// Redis数据库对象 /// \u0026lt;/summary\u0026gt; public readonly IDatabase db; /// \u0026lt;summary\u0026gt; /// Initializes a new instance of the \u0026lt;see cref=\u0026#34;RedisHelper\u0026#34;/\u0026gt; class. /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;dbSerialNumber\u0026#34;\u0026gt;The database serial number.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;redisConnectionString\u0026#34;\u0026gt;The redis connection string.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;customKeyPrefix\u0026#34;\u0026gt;The custom key prefix.\u0026lt;/param\u0026gt; public RedisHelper(int dbSerialNumber , string redisConnectionString , string customKeyPrefix = null) { CustomKeyPrefix = customKeyPrefix; #if customSingleton RedisConnectionMultiplexerHelper.RedisConnectionString = redisConnectionString; conn = RedisConnectionMultiplexerHelper.Instance; #endif conn = ConnectionMultiplexer.Connect(redisConnectionString); db = conn.GetDatabase(dbSerialNumber); } /// \u0026lt;summary\u0026gt; /// 保存单个k/v /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;The value.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;expiry\u0026#34;\u0026gt;The expiry.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool StringSet(string key, string value, TimeSpan? expiry = default) { key = GenerateCustomKey(key); return db.StringSet(key, value, expiry); } /// \u0026lt;summary\u0026gt; /// 保存多个k/v /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;keyValues\u0026#34;\u0026gt;The key values.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool StringSet(List\u0026lt;KeyValuePair\u0026lt;RedisKey, RedisValue\u0026gt;\u0026gt; keyValues) { List\u0026lt;KeyValuePair\u0026lt;RedisKey, RedisValue\u0026gt;\u0026gt; newkeyValues = keyValues .Select(p =\u0026gt; new KeyValuePair\u0026lt;RedisKey, RedisValue\u0026gt;(GenerateCustomKey(p.Key), p.Value)) .ToList(); return db.StringSet(newkeyValues.ToArray()); } /// \u0026lt;summary\u0026gt; /// 以Json格式保存对象 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;object\u0026#34;\u0026gt;The object.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;expiry\u0026#34;\u0026gt;The expiry.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool StringSet\u0026lt;T\u0026gt;(string key, T @object, TimeSpan? expiry = default) { key = GenerateCustomKey(key); string json = ConvertToJson(@object); return db.StringSet(key, json, expiry); } /// \u0026lt;summary\u0026gt; /// 获取单个Key /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public string StringGet(string key) { key = GenerateCustomKey(key); return db.StringGet(key); } /// \u0026lt;summary\u0026gt; /// 获取多个Key /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;listKeys\u0026#34;\u0026gt;The list keys.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public RedisValue[] StringGet(List\u0026lt;string\u0026gt; listKeys) { List\u0026lt;string\u0026gt; redisKeys = listKeys.Select(GenerateCustomKey).ToList(); return db.StringGet(ConvertToRedisKeys(redisKeys)); } /// \u0026lt;summary\u0026gt; /// 获取value转换为Object /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public T StringGet\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); return ConvertToObject\u0026lt;T\u0026gt;(db.StringGet(key)); } /// \u0026lt;summary\u0026gt; /// Increment,如果key存在,则:value+=value /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;incrementVal\u0026#34;\u0026gt;The increment value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public double StringIncrement(string key, double incrementVal = 1) { key = GenerateCustomKey(key); return db.StringIncrement(key, incrementVal); } /// \u0026lt;summary\u0026gt; /// Decrement,如果key存在,则:value-=value /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;decrementVal\u0026#34;\u0026gt;The decrement value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;减少后的值\u0026lt;/returns\u0026gt; public double StringDecrement(string key, double decrementVal = 1) { key = GenerateCustomKey(key); return db.StringDecrement(key, decrementVal); } /// \u0026lt;summary\u0026gt; /// 判断hash中某个key是否已经被缓存 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashFieldName\u0026#34;\u0026gt;Name of the hash field.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool HashExists(string key, string hashFieldName) { key = GenerateCustomKey(key); return db.HashExists(key, hashFieldName); } /// \u0026lt;summary\u0026gt; /// 存储数据到hash表 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashFieldName\u0026#34;\u0026gt;Name of the hash field.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashValue\u0026#34;\u0026gt;The hash value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool HashSet\u0026lt;T\u0026gt;(string key, string hashFieldName, T hashValue) { key = GenerateCustomKey(key); string json = ConvertToJson(hashValue); return db.HashSet(key, hashFieldName, json); } /// \u0026lt;summary\u0026gt; /// 移除hash中的某值 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashFieldName\u0026#34;\u0026gt;Name of the hash field.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool HashDelete(string key, string hashFieldName) { key = GenerateCustomKey(key); return db.HashDelete(key, hashFieldName); } /// \u0026lt;summary\u0026gt; /// 移除hash中的多个值 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashFieldNames\u0026#34;\u0026gt;The hash field names.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public long HashDelete(string key, List\u0026lt;RedisValue\u0026gt; hashFieldNames) { key = GenerateCustomKey(key); return db.HashDelete(key, hashFieldNames.ToArray()); } /// \u0026lt;summary\u0026gt; /// 从hash表获取数据 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashFieldName\u0026#34;\u0026gt;Name of the hash field.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public T HashGet\u0026lt;T\u0026gt;(string key, string hashFieldName) { key = GenerateCustomKey(key); string value = db.HashGet(key, hashFieldName); return ConvertToObject\u0026lt;T\u0026gt;(value); } /// \u0026lt;summary\u0026gt; /// hash为数字增长value /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashFieldName\u0026#34;\u0026gt;Name of the hash field.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;incrementVal\u0026#34;\u0026gt;The increment value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public double HashIncrement(string key, string hashFieldName, double incrementVal = 1) { key = GenerateCustomKey(key); return db.HashIncrement(key, hashFieldName, incrementVal); } /// \u0026lt;summary\u0026gt; /// hash为数字减少value /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;hashFieldName\u0026#34;\u0026gt;Name of the hash field.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;decrementVal\u0026#34;\u0026gt;The decrement value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public double HashDecrement(string key, string hashFieldName, double decrementVal = 1) { key = GenerateCustomKey(key); return db.HashDecrement(key, hashFieldName, decrementVal); } /// \u0026lt;summary\u0026gt; /// 获取hashkey所有rediskey /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public List\u0026lt;T\u0026gt; HashKeys\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); RedisValue[] values = db.HashKeys(key); return ConvetToList\u0026lt;T\u0026gt;(values); } /// \u0026lt;summary\u0026gt; /// 移除指定List内部的值 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;The value.\u0026lt;/param\u0026gt; public void ListRemove\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); db.ListRemove(key, ConvertToJson(value)); } /// \u0026lt;summary\u0026gt; /// 获取指定key的List /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public List\u0026lt;T\u0026gt; ListRange\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); RedisValue[] values = db.ListRange(key); return ConvetToList\u0026lt;T\u0026gt;(values); } /// \u0026lt;summary\u0026gt; /// 入队：列表从最右边插入一个元素 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;The value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public long ListRightPush\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); return db.ListRightPush(key, ConvertToJson(value)); } /// \u0026lt;summary\u0026gt; /// 出队：列表从最右边获取一个元素 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public T ListRightPop\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); RedisValue value = db.ListRightPop(key); return ConvertToObject\u0026lt;T\u0026gt;(value); } /// \u0026lt;summary\u0026gt; /// 入栈：列表从最左边插入一个元素 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;The value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public long ListLeftPush\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); return db.ListLeftPush(key, ConvertToJson(value)); } /// \u0026lt;summary\u0026gt; /// 出栈：列表从最左边获取一个元素 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public T ListLeftPop\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); var value = db.ListLeftPop(key); return ConvertToObject\u0026lt;T\u0026gt;(value); } /// \u0026lt;summary\u0026gt; /// 获取集合中的数量 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public long ListLength(string key) { key = GenerateCustomKey(key); return db.ListLength(key); } /// \u0026lt;summary\u0026gt; /// Sorteds the set add. /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;The value.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;score\u0026#34;\u0026gt;The score.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool SortedSetAdd\u0026lt;T\u0026gt;(string key, T value, double score) { key = GenerateCustomKey(key); return db.SortedSetAdd(key, ConvertToJson\u0026lt;T\u0026gt;(value), score); } /// \u0026lt;summary\u0026gt; /// Sorteds the set remove. /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;The value.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool SortedSetRemove\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); return db.SortedSetRemove(key, ConvertToJson(value)); } /// \u0026lt;summary\u0026gt; /// Sorteds the set range by rank. /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;start\u0026#34;\u0026gt;The start.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;stop\u0026#34;\u0026gt;The stop.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;order\u0026#34;\u0026gt;The order.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public List\u0026lt;T\u0026gt; SortedSetRangeByRank\u0026lt;T\u0026gt;(string key, long start, long stop, Order order = Order.Ascending) { key = GenerateCustomKey(key); var values = db.SortedSetRangeByRank(key, start, stop, order); return ConvetToList\u0026lt;T\u0026gt;(values); } /// \u0026lt;summary\u0026gt; /// Sorteds the length of the set. /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public long SortedSetLength(string key) { key = GenerateCustomKey(key); return db.SortedSetLength(key); } /// \u0026lt;summary\u0026gt; /// 删除单个key /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool KeyDelete(string key) { key = GenerateCustomKey(key); return db.KeyDelete(key); } /// \u0026lt;summary\u0026gt; /// 删除多个key /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;keys\u0026#34;\u0026gt;The keys.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public long KeyDelete(List\u0026lt;string\u0026gt; keys) { List\u0026lt;string\u0026gt; newKeys = keys.Select(GenerateCustomKey).ToList(); return db.KeyDelete(ConvertToRedisKeys(newKeys)); } /// \u0026lt;summary\u0026gt; /// 判断key是否存储 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool KeyExists(string key) { key = GenerateCustomKey(key); return db.KeyExists(key); } /// \u0026lt;summary\u0026gt; /// 重命名key /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;newKey\u0026#34;\u0026gt;The new key.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool KeyRename(string key, string newKey) { key = GenerateCustomKey(key); return db.KeyRename(key, newKey); } /// \u0026lt;summary\u0026gt; /// 设置Key过期时间 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;key\u0026#34;\u0026gt;The key.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;expiry\u0026#34;\u0026gt;The expiry.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public bool KeyExpire(string key, TimeSpan? expiry = default) { key = GenerateCustomKey(key); return db.KeyExpire(key, expiry); } /// \u0026lt;summary\u0026gt; /// Redis订阅 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;subChannel\u0026#34;\u0026gt;The sub channel.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;handler\u0026#34;\u0026gt;The handler.\u0026lt;/param\u0026gt; public void Subscribe(string subChannel, Action\u0026lt;RedisChannel, RedisValue\u0026gt; handler = null) { ISubscriber sub = conn.GetSubscriber(); sub.Subscribe(subChannel, (channel, message) =\u0026gt; { if (handler == null) { Console.WriteLine(subChannel + \u0026#34; 订阅收到消息：\u0026#34; + message); } else { handler(channel, message); } }); } /// \u0026lt;summary\u0026gt; /// Redis发布 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;channel\u0026#34;\u0026gt;The channel.\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;message\u0026#34;\u0026gt;The message.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public long Publish\u0026lt;T\u0026gt;(string channel, T message) { ISubscriber sub = conn.GetSubscriber(); return sub.Publish(channel, ConvertToJson(message)); } /// \u0026lt;summary\u0026gt; /// Redis取消订阅 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;channel\u0026#34;\u0026gt;The channel.\u0026lt;/param\u0026gt; public void Unsubscribe(string channel) { ISubscriber sub = conn.GetSubscriber(); sub.Unsubscribe(channel); } /// \u0026lt;summary\u0026gt; /// Redis取消全部订阅 /// \u0026lt;/summary\u0026gt; public void UnsubscribeAll() { ISubscriber sub = conn.GetSubscriber(); sub.UnsubscribeAll(); } /// \u0026lt;summary\u0026gt; /// 创建一个Redis事务 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;dbSerialNumber\u0026#34;\u0026gt;The database serial number.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public ITransaction CreateTransaction(int dbSerialNumber) { return conn.GetDatabase(dbSerialNumber).CreateTransaction(); } public async Task\u0026lt;bool\u0026gt; StringSetAsync(string key, string value, TimeSpan? expiry = default) { key = GenerateCustomKey(key); return await db.StringSetAsync(key, value, expiry); } public async Task\u0026lt;bool\u0026gt; StringSetAsync(List\u0026lt;KeyValuePair\u0026lt;RedisKey, RedisValue\u0026gt;\u0026gt; keyValues) { List\u0026lt;KeyValuePair\u0026lt;RedisKey, RedisValue\u0026gt;\u0026gt; newkeyValues = keyValues .Select(p =\u0026gt; new KeyValuePair\u0026lt;RedisKey, RedisValue\u0026gt;(GenerateCustomKey(p.Key), p.Value)) .ToList(); return await db.StringSetAsync(newkeyValues.ToArray()); } public async Task\u0026lt;bool\u0026gt; StringSetAsync\u0026lt;T\u0026gt;(string key, T @object, TimeSpan? expiry = default) { key = GenerateCustomKey(key); string json = ConvertToJson(@object); return await db.StringSetAsync(key, json, expiry); } public async Task\u0026lt;string\u0026gt; StringGetAsync(string key) { key = GenerateCustomKey(key); return await db.StringGetAsync(key); } public async Task\u0026lt;RedisValue[]\u0026gt; StringGetAsync(List\u0026lt;string\u0026gt; listKeys) { List\u0026lt;string\u0026gt; redisKeys = listKeys.Select(GenerateCustomKey).ToList(); return await db.StringGetAsync(ConvertToRedisKeys(redisKeys)); } public async Task\u0026lt;T\u0026gt; StringGetAsync\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); return ConvertToObject\u0026lt;T\u0026gt;(await db.StringGetAsync(key)); } public async Task\u0026lt;double\u0026gt; StringIncrementAsync(string key, double incrementVal = 1) { key = GenerateCustomKey(key); return await db.StringIncrementAsync(key, incrementVal); } public async Task\u0026lt;double\u0026gt; StringDecrementAsync(string key, double decrementVal = 1) { key = GenerateCustomKey(key); return await db.StringDecrementAsync(key, decrementVal); } public async Task\u0026lt;bool\u0026gt; HashExistsAsync(string key, string dataKey) { key = GenerateCustomKey(key); return await db.HashExistsAsync(key, dataKey); } public async Task\u0026lt;bool\u0026gt; HashSetAsync\u0026lt;T\u0026gt;(string key, string hashFieldName, T hashValue) { key = GenerateCustomKey(key); string json = ConvertToJson(hashValue); return await db.HashSetAsync(key, hashFieldName, json); } public async Task\u0026lt;bool\u0026gt; HashDeleteAsync(string key, string hashFieldName) { key = GenerateCustomKey(key); return await db.HashDeleteAsync(key, hashFieldName); } public async Task\u0026lt;long\u0026gt; HashDeleteAsync(string key, List\u0026lt;RedisValue\u0026gt; hashFieldNames) { key = GenerateCustomKey(key); return await db.HashDeleteAsync(key, hashFieldNames.ToArray()); } public async Task\u0026lt;T\u0026gt; HashGetAsync\u0026lt;T\u0026gt;(string key, string hashFieldName) { key = GenerateCustomKey(key); string value = await db.HashGetAsync(key, hashFieldName); return ConvertToObject\u0026lt;T\u0026gt;(value); } public async Task\u0026lt;double\u0026gt; HashIncrementAsync(string key, string hashFieldName, double incrementVal = 1) { key = GenerateCustomKey(key); return await db.HashIncrementAsync(key, hashFieldName, incrementVal); } public async Task\u0026lt;double\u0026gt; HashDecrementAsync(string key, string hashFieldName, double decrementVal = 1) { key = GenerateCustomKey(key); return await db.HashDecrementAsync(key, hashFieldName, decrementVal); } public async Task\u0026lt;List\u0026lt;T\u0026gt;\u0026gt; HashKeysAsync\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); RedisValue[] values = await db.HashKeysAsync(key); return ConvetToList\u0026lt;T\u0026gt;(values); } public async Task\u0026lt;long\u0026gt; ListRemoveAsync\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); return await db.ListRemoveAsync(key, ConvertToJson(value)); } public async Task\u0026lt;List\u0026lt;T\u0026gt;\u0026gt; ListRangeAsync\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); RedisValue[] values = await db.ListRangeAsync(key); return ConvetToList\u0026lt;T\u0026gt;(values); } public async Task\u0026lt;long\u0026gt; ListRightPushAsync\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); return await db.ListRightPushAsync(key, ConvertToJson(value)); } public async Task\u0026lt;T\u0026gt; ListRightPopAsync\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); RedisValue value = await db.ListRightPopAsync(key); return ConvertToObject\u0026lt;T\u0026gt;(value); } public async Task\u0026lt;long\u0026gt; ListLeftPushAsync\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); return await db.ListLeftPushAsync(key, ConvertToJson(value)); } public async Task\u0026lt;T\u0026gt; ListLeftPopAsync\u0026lt;T\u0026gt;(string key) { key = GenerateCustomKey(key); var value = await db.ListLeftPopAsync(key); return ConvertToObject\u0026lt;T\u0026gt;(value); } public async Task\u0026lt;long\u0026gt; ListLengthAsync(string key) { key = GenerateCustomKey(key); return await db.ListLengthAsync(key); } public async Task\u0026lt;bool\u0026gt; SortedSetAddAsync\u0026lt;T\u0026gt;(string key, T value, double score) { key = GenerateCustomKey(key); return await db.SortedSetAddAsync(key, ConvertToJson\u0026lt;T\u0026gt;(value), score); } public async Task\u0026lt;bool\u0026gt; SortedSetRemoveAsync\u0026lt;T\u0026gt;(string key, T value) { key = GenerateCustomKey(key); return await db.SortedSetRemoveAsync(key, ConvertToJson(value)); } public async Task\u0026lt;List\u0026lt;T\u0026gt;\u0026gt; SortedSetRangeByRankAsync\u0026lt;T\u0026gt;(string key, long start, long stop, Order order = Order.Ascending) { key = GenerateCustomKey(key); var values = await db.SortedSetRangeByRankAsync(key, start, stop, order); return ConvetToList\u0026lt;T\u0026gt;(values); } public async Task\u0026lt;long\u0026gt; SortedSetLengthAsync(string key) { key = GenerateCustomKey(key); return await db.SortedSetLengthAsync(key); } public async Task\u0026lt;bool\u0026gt; KeyDeleteAsync(string key) { key = GenerateCustomKey(key); return await db.KeyDeleteAsync(key); } public async Task\u0026lt;long\u0026gt; KeyDeleteAsync(List\u0026lt;string\u0026gt; keys) { List\u0026lt;string\u0026gt; newKeys = keys.Select(GenerateCustomKey).ToList(); return await db.KeyDeleteAsync(ConvertToRedisKeys(newKeys)); } public async Task\u0026lt;bool\u0026gt; KeyExistsAsync(string key) { key = GenerateCustomKey(key); return await db.KeyExistsAsync(key); } public async Task\u0026lt;bool\u0026gt; KeyRenameAsync(string key, string newKey) { key = GenerateCustomKey(key); return await db.KeyRenameAsync(key, newKey); } public async Task\u0026lt;bool\u0026gt; KeyExpireAsync(string key, TimeSpan? expiry = default) { key = GenerateCustomKey(key); return await db.KeyExpireAsync(key, expiry); } public async Task SubscribeAsync(string subChannel, Action\u0026lt;RedisChannel, RedisValue\u0026gt; handler = null) { ISubscriber sub = conn.GetSubscriber(); await sub.SubscribeAsync(subChannel, (channel, message) =\u0026gt; { if (handler == null) { Console.WriteLine(subChannel + \u0026#34; 订阅收到消息：\u0026#34; + message); } else { handler(channel, message); } }); } public async Task\u0026lt;long\u0026gt; PublishAsync\u0026lt;T\u0026gt;(string channel, T message) { ISubscriber sub = conn.GetSubscriber(); return await sub.PublishAsync(channel, ConvertToJson(message)); } public async Task UnsubscribeAsync(string channel) { ISubscriber sub = conn.GetSubscriber(); await sub.UnsubscribeAsync(channel); } public async Task UnsubscribeAllAsync() { ISubscriber sub = conn.GetSubscriber(); await sub.UnsubscribeAllAsync(); } /// \u0026lt;summary\u0026gt; /// 生成自定义Key,格式(CustomKeyPrefix+\u0026#34;_\u0026#34;+Key) /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;oldKey\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private string GenerateCustomKey(string oldKey) { if (!string.IsNullOrWhiteSpace(CustomKeyPrefix)) { return $\u0026#34;{CustomKeyPrefix}_{oldKey}\u0026#34;; } return oldKey; } /// \u0026lt;summary\u0026gt; /// 对象序列化 /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private static string ConvertToJson\u0026lt;T\u0026gt;(T value) { return value is string ? value.ToString() : JsonConvert.SerializeObject(value); } /// \u0026lt;summary\u0026gt; /// RedisValue转Object /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;value\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private static T ConvertToObject\u0026lt;T\u0026gt;(RedisValue value) { if (typeof(T).Name.Equals(typeof(string).Name)) { return JsonConvert.DeserializeObject\u0026lt;T\u0026gt;($\u0026#34;\u0026#39;{value}\u0026#39;\u0026#34;); } return JsonConvert.DeserializeObject\u0026lt;T\u0026gt;(value); } /// \u0026lt;summary\u0026gt; /// RedisValue转List /// \u0026lt;/summary\u0026gt; /// \u0026lt;typeparam name=\u0026#34;T\u0026#34;\u0026gt;\u0026lt;/typeparam\u0026gt; /// \u0026lt;param name=\u0026#34;values\u0026#34;\u0026gt;The values.\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private static List\u0026lt;T\u0026gt; ConvetToList\u0026lt;T\u0026gt;(RedisValue[] values) { List\u0026lt;T\u0026gt; result = new(); foreach (RedisValue item in values) { T @object = ConvertToObject\u0026lt;T\u0026gt;(item); result.Add(@object); } return result; } /// \u0026lt;summary\u0026gt; /// 转换为RedisKey /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;redisKeys\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private static RedisKey[] ConvertToRedisKeys(List\u0026lt;string\u0026gt; redisKeys) { return redisKeys.Select(redisKey =\u0026gt; (RedisKey)redisKey).ToArray(); } } /// \u0026lt;summary\u0026gt; /// 单例获取RedisConnectionMultiplexer /// \u0026lt;/summary\u0026gt; static class RedisConnectionMultiplexerHelper { /// \u0026lt;summary\u0026gt; /// Redis连接字符串 /// \u0026lt;/summary\u0026gt; public static string RedisConnectionString { get; set; } private static readonly object locker = new(); /// \u0026lt;summary\u0026gt; /// ConnectionMultiplexer对象 /// \u0026lt;/summary\u0026gt; private static ConnectionMultiplexer connectionMultiplexerInstance; /// \u0026lt;summary\u0026gt; /// 单例获取 /// \u0026lt;/summary\u0026gt; public static ConnectionMultiplexer Instance { get { if (connectionMultiplexerInstance == null) { lock (locker) { if (connectionMultiplexerInstance == null || !connectionMultiplexerInstance.IsConnected) { connectionMultiplexerInstance = GetConnectionMultiplexer(); } } } return connectionMultiplexerInstance; } } private static ConnectionMultiplexer GetConnectionMultiplexer() { if (string.IsNullOrWhiteSpace(RedisConnectionString)) { throw new Exception(\u0026#34;RedisConnectionString IsNullOrWhiteSpace!\u0026#34;); } var connect = ConnectionMultiplexer.Connect(RedisConnectionString); connect.ConnectionFailed += MuxerConnectionFailed; connect.ConnectionRestored += MuxerConnectionRestored; connect.ErrorMessage += MuxerErrorMessage; connect.ConfigurationChanged += MuxerConfigurationChanged; connect.HashSlotMoved += MuxerHashSlotMoved; connect.InternalError += MuxerInternalError; return connect; } /// \u0026lt;summary\u0026gt; /// 配置更改时 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;sender\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;e\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private static void MuxerConfigurationChanged(object sender, EndPointEventArgs e) { Console.WriteLine($\u0026#34;Configuration changed: {e.EndPoint}\u0026#34;); } /// \u0026lt;summary\u0026gt; /// 发生错误时 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;sender\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;e\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private static void MuxerErrorMessage(object sender, RedisErrorEventArgs e) { Console.WriteLine($\u0026#34;ErrorMessage:{e.Message}\u0026#34;); } /// \u0026lt;summary\u0026gt; /// 重新建立连接之前的错误 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;sender\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;e\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private static void MuxerConnectionRestored(object sender, ConnectionFailedEventArgs e) { Console.WriteLine($\u0026#34;ConnectionRestored:{e.EndPoint}\u0026#34;); } /// \u0026lt;summary\u0026gt; /// 连接失败,如果重新连接成功将不会收到这个通知 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;sender\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;e\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private static void MuxerConnectionFailed(object sender, ConnectionFailedEventArgs e) { Console.WriteLine($\u0026#34;重新连接：Endpoint failed:{e.EndPoint},{e.FailureType},{e.Exception.Message}\u0026#34;); } /// \u0026lt;summary\u0026gt; /// 更改集群 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;sender\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;e\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private static void MuxerHashSlotMoved(object sender, HashSlotMovedEventArgs e) { Console.WriteLine($\u0026#34;HashSlotMoved:NewEndPoint={e.NewEndPoint},OldEndPoint={ e.OldEndPoint}\u0026#34;); } /// \u0026lt;summary\u0026gt; /// Redis类库错误 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;sender\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;e\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; private static void MuxerInternalError(object sender, InternalErrorEventArgs e) { Console.WriteLine($\u0026#34;InternalError:Message={e.Exception.Message}\u0026#34;); } } }CSRedisCore# csRedis 对所有方法名称进行了调整，使其和 redis-cli保持一致，如果熟悉 redis-cli 的命令可以直接上手，学习成本降低很多。\n安装# Github：https://github.com/2881099/csRedis\ncsRedisCore 是 C# 操作 Redis 数据库的另一个客户端。在 NuGet 中搜索 csRedisCore ，直接点击按钮安装即可。\n初始化# 使用连接字符串创建redis实例，可使用以下两种方式\n使用RedisHelper ： RedisHelper.Initialization(new csRedisClient(\u0026quot;127.0.0.1:6379\u0026quot;)) 使用csRedisClient：csRedisClient var csRedis = new csRedisClient(\u0026quot;127.0.0.1:6379\u0026quot;); 然后就可以进行操作了。\n字符串(string)# 关于字符串的value：\nvalue 可以用来存储任意格式的数据，如 json、jpg 甚至视频文件 value 最大容量为 512M value 可以存储3种类型的值：字节串（byte string）/整数（int）/浮点数（double）string / 对象 其中，整数的取值范围和系统的长整数取值范围相同。\n在32位的操作系统上，整数就是32位的 在64位操作系统上，整数就是64位有符号整数 浮点数的取值范围和IEEE 754标准的双精度浮点数相同 简单操作# /* 字符串操作键值对 */ csRedis.Set(\u0026#34;name\u0026#34;, \u0026#34;wangpengliang\u0026#34;); csRedis.Set(\u0026#34;name2\u0026#34;, \u0026#34;wangkaining\u0026#34;); csRedis.Set(\u0026#34;name\u0026#34;, \u0026#34;wangpengliang2\u0026#34;); // 根据键获取对应的值 csRedis.Get(\u0026#34;name\u0026#34;); // 移除元素 csRedis.Del(\u0026#34;name2\u0026#34;);在对同一个键多次赋值时，该键的值是最后一次赋值时的值，实例中 hello 对应的值最终为wangpengliang2。\n由于 Redis 可以对字符串的类型进行“识别”，所以除了对字符串进行增、删、查、之外，我们还可以对整数类型进行自增、自减操作，对字节串的一部分进行读取或者写入。\n/* 数值操作 */ csRedis.Set(\u0026#34;num-key\u0026#34;, \u0026#34;24\u0026#34;); // value += 5 csRedis.IncrBy(\u0026#34;num-key\u0026#34;,5); // output -\u0026gt; 29 // value -= 10 csRedis.IncrBy(\u0026#34;num-key\u0026#34;, -10); // output -\u0026gt; 19 /* 字节串操作 */ csRedis.Set(\u0026#34;string-key\u0026#34;, \u0026#34;hello \u0026#34;); // 在指定key的value末尾追加字符串 csRedis.Append(\u0026#34;string-key\u0026#34;, \u0026#34;world\u0026#34;); // output -\u0026gt; \u0026#34;hello world\u0026#34; // 获取从指定范围所有字符构成的子串（start:3,end:7） csRedis.GetRange(\u0026#34;string-key\u0026#34;,3,7) // output -\u0026gt; \u0026#34;lo wo\u0026#34; // 用新字符串从指定位置覆写原value（index:4） csRedis.SetRange(\u0026#34;string-key\u0026#34;, 4, \u0026#34;aa\u0026#34;); // output -\u0026gt; \u0026#34;hellaaword\u0026#34;非正常情况# 对字节串进行自增、自减操作时，redis会报错 使用Append、SetRange方法对 value 写入时，字节串的长度可能不够用，这时redis会使用空字符(null ) 将 value扩充到指定长度，然后再进行写入操作 列表(List)# The speed of adding a new element with the LPUSH command to the head of a list with ten elements is the same as adding an element to the head of list with 10 million elements.\n译：使用LPUSH命令，向包含10个元素的列表添加新元素的速度等于向包含一千万个元素的列表添加新元素的速度。\n列表可以有序的存储多个字符串操作（字符串可以重复） 列表是通过链表来实现的，所以它添加新元素的速度非常快 // 从右端推入元素 csRedis.RPush(\u0026#34;my-list\u0026#34;, \u0026#34;item1\u0026#34;, \u0026#34;item2\u0026#34;, \u0026#34;item3\u0026#34;, \u0026#34;item4\u0026#34;); // 从右端弹出元素 csRedis.RPop(\u0026#34;my-list\u0026#34;); // 从左端推入元素 csRedis.LPush(\u0026#34;my-list\u0026#34;,\u0026#34;LeftPushItem\u0026#34;); // 从左端弹出元素 csRedis.LPop(\u0026#34;my-list\u0026#34;); // 遍历链表元素（start:0,end:-1即可返回所有元素） foreach (var item in csRedis.LRange(\u0026#34;my-list\u0026#34;, 0, -1)) { Console.WriteLine(item); } // 按索引值获取元素（当索引值大于链表长度，返回空值，不会报错） Console.WriteLine($\u0026#34;{csRedis.LIndex(\u0026#34;my-list\u0026#34;, 1)}\u0026#34;); // 修剪指定范围内的元素（start:4,end:10） csRedis.LTrim(\u0026#34;my-list\u0026#34;, 4, 10);除了对列表中的元素进行以上简单的处理之外，还可以将一个列表中的元素复制到另一个列表中。在语义上，列表的左端默认为“头部”，列表的右端为“尾部”。\n// 将my-list最后一个元素弹出并压入another-list的头部 csRedis.RPopLPush(\u0026#34;my-list\u0026#34;, \u0026#34;another-list\u0026#34;);集合(Set)# 集合以无序的方式存储各不相同的元素，也就是说在集合中的每个元素的Key都不重复。在 Redis中可以快速地对集合执行添加、移除等操作。\n// 实际上只插入了两个元素(\u0026#34;item1\u0026#34;,\u0026#34;item2\u0026#34;) csRedis.SAdd(\u0026#34;my-set\u0026#34;, \u0026#34;item1\u0026#34;, \u0026#34;item1\u0026#34;, \u0026#34;item2\u0026#34;); // 集合的遍历 foreach (var member in csRedis.SMembers(\u0026#34;my-set\u0026#34;)) { Console.WriteLine($\u0026#34;集合成员：{member.ToString()}\u0026#34;); } // 判断元素是否存在 string member = \u0026#34;item1\u0026#34;; Console.WriteLine($\u0026#34;{member}是否存在:{csRedis.SIsMember(\u0026#34;my-set\u0026#34;, member)}\u0026#34;); // output -\u0026gt; True // 移除元素 csRedis.SRem(\u0026#34;my-set\u0026#34;, member); Console.WriteLine($\u0026#34;{member}是否存在:{csRedis.SIsMember(\u0026#34;my-set\u0026#34;, member)}\u0026#34;); // output -\u0026gt; False // 随机移除一个元素 csRedis.SPop(\u0026#34;my-set\u0026#34;);以上是对一个集合中的元素进行操作，除此之外还可以对两个集合进行交、并、差操作。\ncsRedis.SAdd(\u0026#34;set-a\u0026#34;, \u0026#34;item1\u0026#34;, \u0026#34;item2\u0026#34;, \u0026#34;item3\u0026#34;,\u0026#34;item4\u0026#34;,\u0026#34;item5\u0026#34;); csRedis.SAdd(\u0026#34;set-b\u0026#34;, \u0026#34;item2\u0026#34;, \u0026#34;item5\u0026#34;, \u0026#34;item6\u0026#34;, \u0026#34;item7\u0026#34;); // 差集 csRedis.SDiff(\u0026#34;set-a\u0026#34;, \u0026#34;set-b\u0026#34;); // output -\u0026gt; \u0026#34;item1\u0026#34;, \u0026#34;item3\u0026#34;,\u0026#34;item4\u0026#34; // 交集 csRedis.SInter(\u0026#34;set-a\u0026#34;, \u0026#34;set-b\u0026#34;); // output -\u0026gt; \u0026#34;item2\u0026#34;,\u0026#34;item5\u0026#34; // 并集 csRedis.SUnion(\u0026#34;set-a\u0026#34;, \u0026#34;set-b\u0026#34;); // output -\u0026gt; \u0026#34;item1\u0026#34;,\u0026#34;item2\u0026#34;,\u0026#34;item3\u0026#34;,\u0026#34;item4\u0026#34;,\u0026#34;item5\u0026#34;,\u0026#34;item6\u0026#34;,\u0026#34;item7\u0026#34;另外还可以用 SDiffStore,SInterStore,SUnionStore 将操作后的结果存储在新的集合中。\n散列(HashMap)# 在 Redis 中可以使用散列将多个键值对存储在一个 key 上，从而达到将一系列相关数据存放在一起的目的。\n// 向散列添加元素 csRedis.HSet(\u0026#34;ArticleID:10001\u0026#34;, \u0026#34;Title\u0026#34;, \u0026#34;了解简单的Redis数据结构\u0026#34;); csRedis.HSet(\u0026#34;ArticleID:10001\u0026#34;, \u0026#34;Author\u0026#34;, \u0026#34;xscape\u0026#34;); csRedis.HSet(\u0026#34;ArticleID:10001\u0026#34;, \u0026#34;PublishTime\u0026#34;, \u0026#34;2019-01-01\u0026#34;); // 根据Key获取散列中的元素 csRedis.HGet(\u0026#34;ArticleID:10001\u0026#34;, \u0026#34;Title\u0026#34;); // 获取散列中的所有元素 foreach (var item in csRedis.HGetAll(\u0026#34;ArticleID:10001\u0026#34;)) { Console.WriteLine(item.Value); }HGet和HSet方法执行一次只能处理一个键值对，而HMGet和HMSet是他们的多参数版本，一次可以处理多个键值对。\nvar keys = new string[] { \u0026#34;Title\u0026#34;,\u0026#34;Author\u0026#34;,\u0026#34;publishTime\u0026#34;}; csRedis.HMGet(\u0026#34;ID:10001\u0026#34;, keys);虽然使用HGetAll可以取出所有的value，但是有时候散列包含的值可能非常大，容易造成服务器的堵塞，为了避免这种情况，我们可以使用HKeys取到散列的所有键(HVals可以取出所有值)，然后再使用 HGet方法一个一个地取出键对应的值。\nforeach (var item in csRedis.HKeys(\u0026#34;ID:10001\u0026#34;)) { Console.WriteLine($\u0026#34;{item} - {csRedis.HGet(\u0026#34;ID:10001\u0026#34;, item)}\u0026#34;); }和处理字符串一样，也可以对散列中的值进行自增、自减操作，原理同字符串是一样的。\ncsRedis.HSet(\u0026#34;ArticleID:10001\u0026#34;, \u0026#34;votes\u0026#34;, \u0026#34;257\u0026#34;); csRedis.HIncrBy(\u0026#34;ID:10001\u0026#34;, \u0026#34;votes\u0026#34;, 40); // output -\u0026gt; 297有序集合# 有序集合可以看作是可排序的散列，不过有序集合的 val 成为score 分值，集合内的元素就是基于score 进行排序的，score 以双精度浮点数的格式存储。\n// 向有序集合添加元素 csRedis.ZAdd(\u0026#34;Quiz\u0026#34;, (79, \u0026#34;Math\u0026#34;)); csRedis.ZAdd(\u0026#34;Quiz\u0026#34;, (98, \u0026#34;English\u0026#34;)); csRedis.ZAdd(\u0026#34;Quiz\u0026#34;, (87, \u0026#34;Algorithm\u0026#34;)); csRedis.ZAdd(\u0026#34;Quiz\u0026#34;, (84, \u0026#34;Database\u0026#34;)); csRedis.ZAdd(\u0026#34;Quiz\u0026#34;, (59, \u0026#34;Operation System\u0026#34;)); //返回集合中的元素数量 csRedis.ZCard(\u0026#34;Quiz\u0026#34;); // 获取集合中指定范围(90~100)的元素集合 csRedis.ZRangeByScore(\u0026#34;Quiz\u0026#34;,90,100); // 获取集合所有元素并升序排序 csRedis.ZRangeWithScores(\u0026#34;Quiz\u0026#34;, 0, -1); // 移除集合中的元素 csRedis.ZRem(\u0026#34;Quiz\u0026#34;, \u0026#34;Math\u0026#34;);事务# 事务可以保证一个客户端在执行多条命令时，不被其他客户端打断，这跟关系型数据库的事务是不一样的。事务需要使用 MULTI 和 EXEC 命令，Redis 会将被MULTI 和 EXEC所包围的代码依次执行，当该事务结束之后才会处理其他客户端的命令。\n管道(pipeline)\nRedis 的事务是通过 pipeline 实现的，使用时客户端会自动调用 MULTI 和 EXEX 命令，将多条命令打包并一次性地发送给 Redis，然后 Redis再将命令的执行结果全部打包并一次性返回给客户端，这样有效的减少了Redis与客户端的通信次数，提升执行多次命令时的性能。\n/// \u0026lt;summary\u0026gt; /// 事务处理 /// \u0026lt;/summary\u0026gt; [TestMethod] public void Transaction() { string strKey = Guid.NewGuid().ToString(); string strval = Faker.Name.FullName(); string intKey = Guid.NewGuid().ToString(); int intVal = Faker.RandomNumber.Next(1, 10); #if one // 第一种方式:正常情况下redis命令批处理,返回[true,true] object[] result = csRedis.StartPipe() .Set(strKey, strval) .Set(intKey, intVal) .EndPipe(); Console.WriteLine(JsonConvert.SerializeObject(result)); #endif #if two // 第二种方式：对string类型进行IncrBy操作,会抛出异常但不影响执行,返回[false, false, null]; Redis中多了两条数据 object[] result2 = csRedis.StartPipe() .Set(strKey, strval) .Set(intKey, intVal) .IncrBy(strKey, 5) .EndPipe(); Console.WriteLine(JsonConvert.SerializeObject(result2)); #endif #if three // 第三种方式：对string类型进行IncrBy操作,错误的命令不被执行,Redis中多了两条数据 using var rc = csRedis.Nodes.First().Value.Get(); rc.Value.Multi(); rc.Value.SAdd(strKey, strval); rc.Value.SAdd(intKey, intVal); rc.Value.SAdd(strKey, 5); // 此时报错：EXEC ---\u0026gt; CSRedis.RedisException: WRONGTYPE Operation against a key holding the wrong kind of value rc.Value.Exec(); #endif #if four // 第四种方式：对string类型进行IncrBy操作,错误的命令不被执行,Redis中多了两条数据 var tran = csRedis.StartPipe(); tran.Set(strKey, strval); tran.Set(intKey, intVal); tran.IncrBy(strKey, 5); var b = tran.EndPipe(); #endif }Key的过期# Redis允许为key设置有效期，当key过期之后，key就不存在了。\n[TestMethod] public void KeyExpire() { string key = \u0026#34;name\u0026#34;; string value = \u0026#34;wangpengliang\u0026#34;; csRedis.Set(key, value); csRedis.Expire(key, 3); string result = csRedis.Get(key); Assert.AreEqual(value, result); Thread.Sleep(4000); result = csRedis.Get(key); Assert.AreEqual(null, result); }分区# 多个服务节点共同分担存储，与官方的分区、集群、高可用方案不同。\n例如：缓存数据达到500G，如果使用一台redis-server服务器光靠内存存储将非常吃力，使用硬盘又影响性能。 可以使用此功能自动管理N台redis-server服务器分担存储，每台服务器只需约 (500/N)G 内存，且每台服务器匀可以配置官方高可用架构。\nvar rds = new CSRedis.CSRedisClient(null, \u0026#34;127.0.0.1:6371,password=123,defaultDatabase=11,poolsize=10,ssl=false,writeBuffer=10240,prefix=key前辍\u0026#34;, \u0026#34;127.0.0.1:6372,password=123,defaultDatabase=12,poolsize=11,ssl=false,writeBuffer=10240,prefix=key前辍\u0026#34;, \u0026#34;127.0.0.1:6373,password=123,defaultDatabase=13,poolsize=12,ssl=false,writeBuffer=10240,prefix=key前辍\u0026#34;, \u0026#34;127.0.0.1:6374,password=123,defaultDatabase=14,poolsize=13,ssl=false,writeBuffer=10240,prefix=key前辍\u0026#34;); //实现思路：根据key.GetHashCode() % 节点总数量，确定连向的节点 //也可以自定义规则(第一个参数设置) rds.MSet(\u0026#34;key1\u0026#34;, 1, \u0026#34;key2\u0026#34;, 2, \u0026#34;key3\u0026#34;, 3, \u0026#34;key4\u0026#34;, 4); rds.MGet(\u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;key3\u0026#34;, \u0026#34;key4\u0026#34;);发布订阅# //普通订阅 rds.Subscribe( (\u0026#34;chan1\u0026#34;, msg =\u0026gt; Console.WriteLine(msg.Body)), (\u0026#34;chan2\u0026#34;, msg =\u0026gt; Console.WriteLine(msg.Body))); //模式订阅（通配符） rds.PSubscribe(new[] { \u0026#34;test*\u0026#34;, \u0026#34;*test001\u0026#34;, \u0026#34;test*002\u0026#34; }, msg =\u0026gt; { Console.WriteLine($\u0026#34;PSUB {msg.MessageId}:{msg.Body} {msg.Pattern}: chan:{msg.Channel}\u0026#34;); }); //模式订阅已经解决的难题： //1、分区的节点匹配规则，导致通配符最大可能匹配全部节点，所以全部节点都要订阅 //2、本组 \u0026#34;test*\u0026#34;, \u0026#34;*test001\u0026#34;, \u0026#34;test*002\u0026#34; 订阅全部节点时，需要解决同一条消息不可执行多次 //发布 rds.Publish(\u0026#34;chan1\u0026#34;, \u0026#34;123123123\u0026#34;); //无论是分区或普通模式，rds.Publish 都可以正常通信缓存壳# /// \u0026lt;summary\u0026gt; /// 缓存壳 /// \u0026lt;/summary\u0026gt; [TestMethod] public void CacheShell() { string value = \u0026#34;wangpengliang\u0026#34;; #if debug // 一般的缓存代码，如不封装比较繁琐 var cacheValue = csRedis.Get(\u0026#34;name\u0026#34;); // 如果已被缓存 if (!string.IsNullOrEmpty(cacheValue)) { try { // } catch { //出错时删除key csRedis.Del(\u0026#34;name\u0026#34;); throw; } } else { csRedis.Set(\u0026#34;name\u0026#34;, value, 10); } #endif // 判断key=name是否已存在,存在返回value,不存在设置 string t1 = csRedis.CacheShell(\u0026#34;name\u0026#34;, 10, () =\u0026gt; value); Assert.AreEqual(value, t1); string t2 = csRedis.CacheShell(\u0026#34;name\u0026#34;, 10, () =\u0026gt; \u0026#34;wangpengliang2\u0026#34;); Assert.AreEqual(value, t2); string t3 = csRedis.CacheShell(\u0026#34;name2\u0026#34;, 10, () =\u0026gt; \u0026#34;wangpengliang2\u0026#34;); Assert.AreEqual(\u0026#34;wangpengliang2\u0026#34;, t3); }管道# 使用管道模式，打包多条命令一起执行，从而提高性能。\nvar ret1 = rds.StartPipe().Set(\u0026#34;a\u0026#34;, \u0026#34;1\u0026#34;).Get(\u0026#34;a\u0026#34;).EndPipe(); var ret2 = rds.StartPipe(p =\u0026gt; p.Set(\u0026#34;a\u0026#34;, \u0026#34;1\u0026#34;).Get(\u0026#34;a\u0026#34;)); var ret3 = rds.StartPipe().Get(\u0026#34;b\u0026#34;).Get(\u0026#34;a\u0026#34;).Get(\u0026#34;a\u0026#34;).EndPipe(); //与 rds.MGet(\u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;) 性能相比，经测试差之毫厘多数据库# 如果确定一定以及肯定非要有切换数据库的需求，请看以下代码：通过定义多个CSRedisClient实现\n/// \u0026lt;summary\u0026gt; /// 多数据库,使用多个CSRedisClient实现 /// \u0026lt;/summary\u0026gt; [TestMethod] public void MultiDatabase() { // 实际使用必须要单例 CSRedisClient[] redis = new CSRedisClient[14]; for (int i = 0; i \u0026lt; redis.Length; i++) { redis[i] = new CSRedisClient($\u0026#34;{redisConnection},defaultDatabase={i}\u0026#34;); } redis[0].Set(\u0026#34;db0\u0026#34;, \u0026#34;db0\u0026#34;); string t1 = redis[0].Get(\u0026#34;db0\u0026#34;); Assert.AreEqual(\u0026#34;db0\u0026#34;, t1); redis[1].Set(\u0026#34;db1\u0026#34;, \u0026#34;db1\u0026#34;); string t2 = redis[1].Get(\u0026#34;db1\u0026#34;); Assert.AreEqual(\u0026#34;db1\u0026#34;, t2); redis[2].Set(\u0026#34;db2\u0026#34;, \u0026#34;db2\u0026#34;); string t3 = redis[2].Get(\u0026#34;db2\u0026#34;); Assert.AreEqual(\u0026#34;db2\u0026#34;, t3); }"},{"id":103,"href":"/docs/test/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","title":"单元测试","section":"所有文章","content":"常见测试类型# 单元测试 集成测试 Web测试 负载测试 其他 依赖倒置原则(DIP）# 很多情况下,一个类或者是方法它会依赖一些外部组件，如其他开发写的代码、第三方类库、数据库、网络等，当被测试的代码与这些组件紧耦合时，这段代码将可能是不可测的。如一个方法中依赖一个数据库组件去访问数据库，那么在执行这个方法时，必然要与数据库交互，如果没有数据库，那么该方法就无法运行。所以单元测试不仅是对代码逻辑进行检查，同时还对整个代码结构有所限制，面向对象编程时应当遵循“依赖倒置”原则，模块应该依赖抽象，抽象不应该依赖实现。并且所依赖的抽象，应该显示的通过构造或者方法参数进行暴露，让组件的使用者对组件的依赖一目了然,在单元测试时为了屏蔽这些抽象依赖，不同测试框架中提供了stub、mock、fake 等方式对抽象进行模拟，以便于代码能够正常执行。\n单元测试# 软件应用程序有多种类型的测试。 其中包括集成测试、Web 测试、负载测试和其他测试。 “单元测试”用于对软件中的最小可测试单元进行检查和验证。 单元测试仅测试开发人员控件内的代码。 它们不测试基础结构问题。 基础结构问题包括数据库、文件系统和网络资源。\n编写单元测试时，尽量不要引入基础结构依赖项。这些依赖项会降低测试速度，使测试更加脆弱，应将其保留供集成测试使用。 可以通过遵循Explicit Dependencies Principle（显式依赖项原则）和使用Dependency Injection（依赖项注入）避免应用程序中的这些依赖项。还可以将单元测试保留在单独的项目中，与集成测试相分隔。 这可确保单元测试项目没有引用或依赖于基础结构包。\n单元测试的好处# 比执行功能测试节省时间 防止回归：新功能上线时可通过单元测试来确保之前存在的功能正常运行不会破坏现有功能 减少耦合：当代码紧密耦合时，可能很难进行单元测试，如果不为代码编写单元测试，耦合可能就不太明显了 优质单元测试的特征# 快速： 对成熟项目进行数千次单元测试，这很常见。 应花非常少的时间来运行单元测试 独立： 单元测试是独立的，可以单独运行，并且不依赖文件系统或数据库等任何外部因素 可重复：运行单元测试的结果应该保持一致，也就是说，如果在运行期间不更改任何内容，总是返回相同结果 自检查： 测试应该能够在没有任何人工交互的情况下，自动检测测试是否通过 代码覆盖率# 高代码覆盖率百分比通常与较高的代码质量相关联，但该度量值本身无法确定代码的质量。 设置过高的代码覆盖率百分比目标可能会适得其反，高代码覆盖率百分比不代表代码质量就高， 它仅仅表示单元测试所涵盖的代码量。\n代码覆盖率工具有两种类型\n数据收集器： 数据收集器监视测试执行并收集有关测试运行的信息。 它们以各种输出格式（例如 XML和 JSON）报告收集的信息 报表生成器： 使用从测试运行收集的数据生成报表，通常为带样式的 HTML 若要通过 Coverlet 获得代码覆盖率，现有单元测试项目必须具有相应的包依赖项，或者依赖于全局工具和对应的 coverlet.console NuGet 包，代码覆盖率是单元测试运行的代码量（行、分支或方法）的度量值，企业版的VS自带了代码覆盖率分析工具，参考：\nhttps://docs.microsoft.com/en-us/visualstudio/test/using-code-coverage-to-determine-how-much-code-is-being-tested https://github.com/Microsoft/vstest-docs/blob/master/docs/analyze.md#coverage .dotnet Core（暂不支持.NetFramework）获取代码覆盖率的大致步骤：coverlet(数据收集器)=\u0026gt;ReportGenerator(报表生成器)=\u0026gt;代码覆盖率报告。\n单元测试框架# dotnet core 中常用的单元测试的框架有MSTest、NUnit和xUnit.net，使用方法都非常相似，都是通过特性标记的方式声明测试方法，然后在方法中使用断言Assertions来判别方法执行结果是否达到预期。\ndotnet 平台下单元测试各框架介绍\n框架特性及断言比较参考\nMSBuild# 使用 MSBuild 方式运行测试并生成指定名称的测试结果文件，输出到指定目录：\ndotnet test TestApplication.UnitTests.csproj /p:CollectCoverage=true /p:CoverletOutputFormat=opencover /p:CoverletOutput=./TestResults/ 这里有个问题：对使用依赖注入的项目这里获取的覆盖率为0，详情：\nhttps://github.com/coverlet-coverage/coverlet/blob/master/Documentation/KnownIssues.md https://github.com/coverlet-coverage/coverlet/issues/922 VSTest# 使用 coverlet 命令生成覆盖率xml：\ndotnet test TestApplication.UnitTests.csproj --collect:\u0026#34;XPlat Code Coverage\u0026#34;Reportgenerator# 使用 reportgenerator 命令将xml文件渲染成Html，因为Msbuild 和 VsTest 方式生成的目录结果有所不同所以渲染命令也有所不同。\nMSBuild# reportgenerator \u0026#34;-reports:./TestResults/*.xml;\u0026#34;\u0026#34;--targetdir:D:\\RunTime\\TestReport\u0026#34; -reporttypes:HtmlVSTest# reportgenerator \u0026#34;-reports:./TestResults/*/*.xml\u0026#34; \u0026#34;--targetdir:D:\\RunTime\\TestReport\u0026#34; -reporttypes:Html合并渲染# 找到xml文件路径，-reports 命令中以;分割即可。\nreportgenerator \u0026#34;-reports:TestApplication.UnitTests/TestResults/*.xml;TestApplication.IntegrationTests/TestResults/*.xml;\u0026#34; \u0026#34;--targetdir:D:\\RunTime\\TestReport\u0026#34; -reporttypes:Html注意当前的工作目录\n参考：\nhttps://www.cnblogs.com/cgzl/p/9326127.html https://github.com/coverlet-coverage/coverlet https://github.com/danielpalme/ReportGenerator 测试可重复性# 使用COM+自动事务(TestFixture) 使用数据清理来保证测试用例的独立和可重复性TestInitialize/TestCleanup Mock# 面向对象编程应该显式依赖抽象，单元测试时应屏蔽依赖的影响(无论是依赖还未实现，或者实现的依赖会阻碍代码执行)，为了满足这一需求出现了Mock、Fake等方式，其原理就是创建一个\u0026quot;假\u0026quot;的\u0026quot;空\u0026quot;的依赖，并用其替代真实依赖，以确保代码能够运行。\npublic class OrgPublisherServiceTests : TestBase { private readonly Mock\u0026lt;ILogRecorder\u0026lt;OrgPublisherService\u0026gt;\u0026gt; _logger; public OrgPublisherServiceTests() { _logger = new Mock\u0026lt;ILogRecorder\u0026lt;OrgPublisherService\u0026gt;\u0026gt;(); } }单元测试最佳实践\n单元测试规范\n注意# 单元测试仅能保证软件的最小可执行单元是正确的，真正的软件是由这些最小可执行单元组成的一个整体，单元的正确性无法保证整体的正确性。\n"},{"id":104,"href":"/docs/test/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95k6/","title":"压力测试k6","section":"所有文章","content":"k6 是GitHub上提供的开源负载测试工具，使用Go编写。测试脚本使用JavaScript编写。\n先决条件# 安装K6 https://k6.io/docs/getting-started/installation 环境变量配置；cd 到压测脚本目录 概念# vu：虚拟用户 duration:持续时长 入门# import http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export default function() { http.get(\u0026#39;http://localhost:5000/api/values\u0026#39;); }k6 run ValuesApiK6.js多Vu和指定时长# k6 run --vus 10 --duration 10s ValuesApiK6.js使用配置选项# import http from \u0026#34;k6/http\u0026#34;; import { sleep,check } from \u0026#34;k6\u0026#34;; export let options = { vus: 10, duration: \u0026#39;10s\u0026#39;, }; // 脚本至少必须包含一个default函数,这定义了VU的入口点，类似于许多其他语言中的main()函数 export default function() { let res = http.get(\u0026#34;http://localhost:5000/api/values\u0026#34;); check(res, { \u0026#39;status was 200\u0026#39;: r =\u0026gt; r.status == 200 }); sleep(1); }阶段负载# import http from \u0026#34;k6/http\u0026#34;; import { sleep, check } from \u0026#34;k6\u0026#34;; export let options = { // 阶段负载 stages: [ { duration: \u0026#34;3s\u0026#34;, target: 2 }, { duration: \u0026#34;5s\u0026#34;, target: 3 }, { duration: \u0026#34;6s\u0026#34;, target: 10 }, ], }; // 脚本至少必须包含一个default函数,这定义了VU的入口点，类似于许多其他语言中的main()函数 export default function () { let res = http.get(\u0026#34;http://localhost:5000/api/values\u0026#34;); check(res, { \u0026#34;status was 200\u0026#34;: (r) =\u0026gt; r.status == 200 }); sleep(1); }可能出现的异常：using multiple execution config shortcuts (durationandstages) simultaneously is not allowed 不允许同时使用多个执行配置快捷方式(“duration”和“stages”)。\n断言# 需要import { sleep, check } from \u0026quot;k6\u0026quot;; 引入check模块。\ncheck(res, { \u0026#34;status was 200\u0026#34;: (r) =\u0026gt; r.status == 200 });测试结果# execution: local- script: ValuesApiK6.js output: - scenarios: (100.00%) 1 executors, 10 max VUs, 44s max duration (incl. graceful stop): * default: Up to 10 looping VUs for 14s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s) I running (16.0s), 00/10 VUs, 38 complete and 0 interrupted iterations default ✓ [======================================] 00/10 VUs 14s9 ✓ status was 200 checks.....................: 100.00% ✓ 38 ✗ 0 data_received..............: 176 MB 11 MB/s data_sent..................: 3.3 kB 208 B/s http_req_blocked...........: avg=79.1µs min=0s med=0s max=2ms p(90)=0s p(95)=149.71µs http_req_connecting........: avg=52.85µs min=0s med=0s max=1.01ms p(90)=0s p(95)=149.71µs http_req_duration..........: avg=682.14ms min=332.4ms med=516.59ms max=1.66s p(90)=1.22s p(95)=1.44s http_req_receiving.........: avg=10.39ms min=3.98ms med=8.97ms max=37.89ms p(90)=16.85ms p(95)=23.37ms http_req_sending...........: avg=0s min=0s med=0s max=0s p(90)=0s p(95)=0s http_req_tls_handshaking...: avg=0s min=0s med=0s max=0s p(90)=0s p(95)=0s http_req_waiting...........: avg=671.75ms min=323.42ms med=508.61ms max=1.65s p(90)=1.21s p(95)=1.43s http_reqs..................: 38 2.374567/s iteration_duration.........: avg=1.68s min=1.33s med=1.51s max=2.66s p(90)=2.22s p(95)=2.44s iterations.................: 38 2.374567/s vus........................: 0 min=0 max=9 vus_max....................: 10 min=10 max=10测试细节\nexecution k6执行模式（本地或云） output 测试结果的输出。默认值为stdout script: script.js 显示正在执行的脚本的名称 duration 测试运行时间 iterations VU 迭代的总数 vus 测试将开始运行的VU的初始数量 max 测试将扩展的VU的最大数量 测试指标分析参考：https://k6.io/docs/using-k6/metrics\n测试结果输出第三方平台# 参考：https://k6.io/docs/getting-started/results-output#output-plugins\n输出Json格式# k6 run --summary-export=export.json test.js输出JSON格式详细信息# 使用 --out/-o 选项使k6输出JSON格式的详细统计信息\nk6 run --out json=my_test_result.json test.jstags打标签分组# 参考：https://k6.io/docs/using-k6/http-requests#url-grouping\nK6内置指标# 参考：https://k6.io/docs/using-k6/metrics#custom-metrics\nHTTP内置指标# 参考：https://k6.io/docs/using-k6/metrics#metric-types\n阈值# 阈值是通过/失败标准，用于指定被测系统的性能期望\n预期示例（阈值）：\n系统产生的错误不超过1％ 95％的请求的响应时间应小于200ms 99％的请求的响应时间应低于400毫秒 特定端点必须始终在300毫秒内响应 阈值分析性能指标并确定最终测试结果（通过/失败）。阈值对于负载测试自动化至关重要 参考：https://k6.io/docs/using-k6/thresholds\n分析结果可视化# influxdb# 安装目录下运行启动 influxdb 启动客户端输入命令开始操作 influx k6 run --out influxdb=http://localhost:8080/test ValuesApiK6.js Grafana# "},{"id":105,"href":"/docs/test/%E8%87%AA%E5%8A%A8%E5%8C%96ui%E6%B5%8B%E8%AF%95/","title":"自动化 Ui测试","section":"所有文章","content":"Selenium可以用来做自动化UI测试，支持多语言，这里使用C#编写测试脚本。\n.NetFramework# Selenium.Support，Selenium.WebDriver,Selenium.RC\nDotnet core# 核心库：Selenium.Support，Selenium.WebDriver,Selenium.Chrome.WebDriver\n注意：Selenium.RC包在dotnetcore会存在不兼容的问题，无法正常找到chromedriver.exe 文件。\nException\nThe chromedriver.exe file does not exist in the current directory or in a directory on the PATH environment variable. The driver can be downloaded at http://chromedriver.storage.googleapis.com/index.html.”\n解决方法\nnuget Selenium.Chrome.WebDriver。将ChromeDriver.exe放入构建目录中\n注意：.netcore2.1中引入了Selenium.Chrome.WebDriver包依旧会出现上面的异常\n浏览器驱动下载# 需下载本机对应版本，不区分32/64\nhttps://npm.taobao.org/mirrors/chromedriver/\nPageObject# 解决的问题：版本迭代太快，UI层元素的属性经常变换，导致维护人员需要花大把的时间去维护代码，为了节省维护成本及时间，就可以利用PageObject 这种设计模式，它就大大的减少了维护时间。\n创建对应浏览器配置，创建WebDriver对象：\npublic abstract class TestBase { protected IWebDriver driver; public void WebDriverInit(string url) { ChromeOptions options = new ChromeOptions(); // 窗口最大化 options.AddArgument(\u0026#34;start-maximized\u0026#34;); driver = new ChromeDriver(options); driver.Navigate().GoToUrl(url); Thread.Sleep(1000); } }ClockInPage，页面模型，封装页面标签属性以及对应操作：\npublic class ClockInPage { public static class PagePath { public static readonly string input_loginName_id = \u0026#34;tb_LoginID_Account_589f1fc067ff4031\u0026#34;; public static readonly string input_passWord_id = \u0026#34;tb_Password\u0026#34;; public static readonly string submit_login_Name = \u0026#34;ctl10\u0026#34;; } public void LoginClick(IWebDriver driver, string logiName, string passWord) { driver.FindElement(By .Id(PagePath.input_loginName_id)).SendKeys(logiName); driver.FindElement(By .Id(PagePath.input_passWord_id)).SendKeys(passWord); driver.FindElement(By .Name(PagePath.submit_login_Name)).Click(); Thread.Sleep(1000); } }ClockInTests，测试方法,采用DDT数据驱动方式提供测试数据：\n[TestCategory(\u0026#34;ui\\\\CodedUITest\u0026#34;)] [TestClass()] public class ClockInTests : TestBase { [TestCleanup] public void Clean() { driver.Dispose(); } [DataTestMethod] [DataRow(\u0026#34;http://11.11.141.10/OMSP//Login/JSS.aspx\u0026#34;, \u0026#34;wangpengliang\u0026#34;, \u0026#34;Wpl-19950815\u0026#34;, true)] [DataRow(\u0026#34;http://11.11.141.10/OMSP//Login/JSS.aspx\u0026#34;, \u0026#34;111111\u0026#34;, \u0026#34;222222\u0026#34;, false)] public void ClockIn_Login_01_Normal(string url, string loginName, string passWord, bool expect) { WebDriverInit(url); ClockInPage page = new ClockInPage(); page.LoginClick(driver, loginName, passWord); Assert.AreEqual(expect, driver.Url != url); } }"},{"id":106,"href":"/docs/test/%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95/","title":"集成测试","section":"所有文章","content":"学习一下C#中集成测试\n集成测试# 集成测试可在包含应用支持基础结构（如数据库、文件系统和网络）的级别上确保应用组件功能正常。\n单元测试关注是的软件最小可执行单元是否能够正常执行，但软件是由一个个最小执行单元组成的集合体，单元与单元之间存在着种种依赖或联系，所以在开发时仅仅确保最小单元的正确往往不够，为了保证软件能够正确运行，单元与单元之间的集成测试是非常必要。\n与单元测试相比，集成测试可在更广泛的级别上评估应用的组件。 单元测试用于测试独立软件组件，如单独的类方法。 集成测试确认两个或更多应用组件一起工作以生成预期结果，可能包括完整处理请求所需的每个组件。\nTestServer# 使用 TestServer 测试API接口\nprotected TestServer CreateSingleTestServer() { if (testServer == null) { lock (singleton_Lock) { if (testServer == null) { string path = Assembly.GetAssembly(typeof(TestBase)).Location; IWebHostBuilder hostBuilder = new WebHostBuilder() .UseContentRoot(Path.GetDirectoryName(path)) .ConfigureAppConfiguration(cb =\u0026gt; { cb.AddJsonFile(\u0026#34;appsettings.test.json\u0026#34;, true, true); }) .UseEnvironment(\u0026#34;Development\u0026#34;) .UseStartup\u0026lt;TestStartup\u0026gt;(); testServer = new TestServer(hostBuilder); } } } return testServer; } public class TestStartup : Startup { public TestStartup( IConfiguration configuration, IHostingEnvironment env) : base(configuration, env) { if debug string connectionString = Configuration.GetSection(\u0026#34;Database:ConnectString\u0026#34;).Value; testDbContext = new ApplicationDbContext(new DbContextOptionsBuilder\u0026lt;ApplicationDbContext\u0026gt;() .UseSqlServer(connectionString) .Options); endif } } } [TestClass] [TestCategory(\u0026#34;integration\u0026#34;)] public class ApiTest : TestBase { private HttpClient client; [TestInitialize] public void Init() { client = testServer.CreateClient(); } [TestCleanup] public void Cleanup() { client.Dispose(); } [TestMethod] public async Task GetAsync() { var response = await client.GetAsync($\u0026#34;/api/values\u0026#34;); Assert.AreEqual(HttpStatusCode.OK, response.StatusCode); } }参考：\nhttps://www.cnblogs.com/selimsong/p/9263957.html https://docs.microsoft.com/zh-cn/dotnet/core/testing/?pivots=mstest https://docs.microsoft.com/zh-cn/aspnet/core/test/integration-tests?view=aspnetcore-3.1#test-app-prerequisites https://www.cnblogs.com/selimsong/p/9306221.html "}]