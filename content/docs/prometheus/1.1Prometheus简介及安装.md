# 简介

Prometheus 是一个开源的完整监控解决方案，基于中央化的规则计算、统一分析和告警的新模型。 相比于传统监控系统具有以下优点：

# 易于管理

Prometheus 核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。

**Prometheus 基于 `Pull` 模型的架构方式，可以在任何地方（本地电脑，开发环境，测试环境）搭建监控系统**。对于一些复杂的情况，还可以使用服务发现( `Service Discovery` )的能力动态管理监控目标。

# 监控服务内部状态

Pometheus 鼓励用户监控服务的内部状态，基于 Prometheus 丰富的 Client 库，可以轻松的在应用程序中添加对 Prometheus 的支持，从而可以获取服务和应用内部真正的运行状态。

![监控服务内部运行状态](https://www.prometheus.wang/quickstart/static/monitor-internal.png)

# 强大的数据模型

所有采集的监控数据均以指标 `metric` 的形式保存在内置的时间序列数据库当中( `TSDB` )。所有样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签。如下所示：

```bash
http_request_status{code='200',content_path='/api/path', environment='produment'} => [value1@timestamp1,value2@timestamp2...]

http_request_status{code='200',content_path='/api/path2', environment='produment'} => [value1@timestamp1,value2@timestamp2...]
```

每一条时间序列由指标名称( `Metrics Name` )以及一组标签( `Labels` )唯一标识。每条时间序列按照时间的先后顺序存储一系列的样本值。

表示维度的标签可能来源于监控对象的状态，比如 `code=404` 或者 `content_path=/api/path` 。也可能来源于的环境定义，比如 `environment=produment` 。基于这些 `Labels` 可以方便地对监控数据进行聚合，过滤，裁剪。

# PromQL 查询

Prometheus 内置了一个强大的数据查询语言 `PromQL` 。 通过 PromQL 可以实现对监控数据的查询、聚合。同时PromQL 也被应用于数据可视化(如Grafana)以及告警当中。

通过 PromQL 可以轻松回答类似于以下问题：

- 过去一段时间中95%应用延迟时间的分布范围？
- 预测在4小时后，磁盘空间占用大致会是什么情况？
- CPU占用率前5位的服务有哪些？(过滤)

# 高效

对于监控系统而言，大量的监控任务必然导致有大量的数据产生。而 Prometheus 可以高效地处理这些数据，对于单个 Prometheus Server 实例而言它可以处理：

- 数以百万的监控指标
- 每秒处理数十万的数据点

# 可扩展

Prometheus 非常简单，因此可以在每个数据中心、每个团队运行独立的 Prometheus Sevrer。Prometheus 对于联邦集群的支持，可以让多个 Prometheus 实例产生一个逻辑集群，当单实例 Prometheus Server 处理的任务量过大时，通过使用功能分区( sharding )+联邦集群( federation )对其进行扩展。

# 易于集成

使用 Prometheus 可以快速搭建监控服务，并且可以非常方便地在应用程序中进行集成。目前支持： `Java`， `JMX`， `Python`， `Go`，`Ruby`， `.Net`， `Node.js` 等语言的客户端SDK，基于这些SDK可以快速让应用程序纳入到 Prometheus 的监控当中，或者开发自己的监控数据收集程序。同时这些客户端收集的监控数据，不仅仅支持Prometheus，还能支持 Graphite 这些其他的监控工具。

> Prometheus还支持与其他的监控系统进行集成：Graphite， Statsd， Collected， Scollector， muini， Nagios 等。

Prometheus 社区还提供了大量第三方实现的监控数据采集支持：JMX， CloudWatch， EC2， MySQL， PostgresSQL， Haskell， Bash， SNMP， Consul， Haproxy， Mesos， Bind， CouchDB， Django， Memcached， RabbitMQ， Redis， RethinkDB， Rsyslog 等等。

# 可视化

Prometheus Server 中自带了一个 `Prometheus UI` ，通过这个UI可以方便地直接对数据进行查询，并且支持直接以图形化的形式展示数据。同时 Prometheus 还提供了一个独立的基于 `Ruby On Rails` 的 Dashboard 解决方案`Promdash`。最新的 `Grafana` 可视化工具也已经提供了完整的 Prometheus 支持，基于 Grafana 可以创建更加精美的监控图标。基于 Prometheus 提供的API还可以实现自己的监控可视化UI。r

# 开放性

通常来说当需要监控一个应用程序时，一般需要该应用程序提供对相应监控系统协议的支持。因此应用程序会与所选择的监控系统进行绑定。为了减少这种绑定所带来的限制。对于决策者而言要么直接在应用中集成该监控系统的支持，要么就在外部创建单独的服务来适配不同的监控系统。

而对于 Prometheus 来说，使用 Prometheus 的 client library 的输出格式不止支持 Prometheus 的格式化数据，也可以输出支持其它监控系统的格式化数据，比如Graphite。

> 甚至可以在不使用 Prometheus 的情况下，采用Prometheus的 client library 来让应用程序支持监控数据采集

# Prometheus 架构

这里从 Prometheus 的架构角度了解一下 Prometheus 生态中的各个组件，下图展示 Prometheus 的基本架构：

![](/images/2022-07-04-16-38-34.png)

## Prometheus Server

Prometheus Server 是 Prometheus 组件中的核心部分，负责实现对监控数据的获取，存储以及查询。

Prometheus Server 可以通过静态配置管理监控目标，也可以配合使用 `Service Discovery` 的方式动态管理监控目标，并从这些监控目标中获取数据。

Prometheus Server 需要对采集到的监控数据进行存储，Prometheus Server 本身就是一个时序数据库，将采集到的监控数据按照时间序列的方式存储在本地磁盘当中。

 Prometheus Server 对外提供了自定义的 `PromQL` 语言，实现对数据的查询以及分析。 内置的 `Express Browser UI`，通过这个UI可以直接通过 PromQL 实现数据的查询以及可视化。

Prometheus Server 的联邦集群能力可以使其从其他的 Prometheus Server 实例中获取数据，因此在大规模监控的情况下，可以通过联邦集群以及功能分区的方式对 Prometheus Server 进行扩展。

## Exporters

Exporter 将监控数据采集的端点通过HTTP服务的形式暴露给 Prometheus Server，Prometheus Server 通过访问该Exporter 提供的 Endpoint 端点，即可获取到需要采集的监控数据。

一般可以将 Exporter 分为两类：

- 直接采集：这一类 Exporter 直接内置了对 Prometheus 监控的支持，比如 `cAdvisor`，`Kubernetes`，`Etcd`，`Gokit`等，都直接内置了用于向 Prometheus 暴露监控数据的端点
- 间接采集：原有监控目标并不直接支持 Prometheus，需要通过 Prometheus 提供的 `Client Library` 编写该监控目标的监控采集程序。例如： `Mysql Exporter`，`JMX Exporter`，`Consul Exporter` 等

## AlertManager

在 Prometheus Server 中支持基于 `PromQL` 创建告警规则，如果满足 PromQL 定义的规则，则会产生一条告警，而告警的后续处理流程则由 `AlertManager` 进行管理。在 AlertManager 中可以与邮件，Slack等等内置的通知方式进行集成，也可以通过 `Webhook` 自定义告警处理方式。AlertManager 是 Prometheus 体系中的告警处理中心。

## PushGateway

由于 Prometheus 数据采集基于 `Pull` 模型进行设计，因此在网络环境的配置上必须要让 Prometheus Server 能够直接与 Exporter 进行通信。 当这种网络需求无法直接满足时，就可以利用 `PushGateway` 来进行中转。通过 PushGateway 将内部网络的监控数据主动 `Push` 到 Gateway 当中。而 Prometheus Server 同样采用 Pull 的方式从 PushGateway 中获取到监控数据。

# Prometheus  安装

Prometheus 基于 `Golang` 编写，编译后的软件包，不依赖于任何的第三方依赖。用户只需要下载对应平台的二进制包，解压并且添加基本的配置即可正常启动 Prometheus Server。

## 二进制包安装

对于非 Docker 用户，可以从 https://prometheus.io/download/ 找到最新版本的 Prometheus Sevrer 软件包：

```bash
curl -LO https://github.com/prometheus/prometheus/releases/download/v2.36.2/prometheus-2.36.2.linux-amd64.tar.gz
```

解压，并将 Prometheus 相关的命令，添加到系统环境变量路径即可：

```bash
tar -xzf prometheus-2.36.2.linux-amd64.tar.gz
cd prometheus-2.36.2.linux-amd64
```

解压后当前目录会包含默认的 Prometheus 配置文件 `promethes.yml`

```
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']
```

Promtheus 作为一个时间序列数据库，其采集的数据会以文件的形似存储在本地中，默认的存储路径为 `data/`，因此需要先手动创建该目录：

```
mkdir -p data
```

也可以通过参数 `--storage.tsdb.path="data/"` 修改本地数据存储的路径。

启动 Prometheus 服务，其会默认加载当前路径下的 `prometheus.yaml` 文件：

```
./prometheus
```

正常的情况下，可以看到以下输出内容：

```
level=info ts=2018-10-23T14:55:14.499484Z caller=main.go:554 msg="Starting TSDB ..."
level=info ts=2018-10-23T14:55:14.499531Z caller=web.go:397 component=web msg="Start listening for connections" address=0.0.0.0:9090
level=info ts=2018-10-23T14:55:14.507999Z caller=main.go:564 msg="TSDB started"
level=info ts=2018-10-23T14:55:14.508068Z caller=main.go:624 msg="Loading configuration file" filename=prometheus.yml
level=info ts=2018-10-23T14:55:14.509509Z caller=main.go:650 msg="Completed loading of configuration file" filename=prometheus.yml
level=info ts=2018-10-23T14:55:14.509537Z caller=main.go:523 msg="Server is ready to receive web requests."
```

## 容器安装

对于 Docker 用户，直接使用 Prometheus 的镜像即可启动Prometheus Server：

在 `etc` 下创建目录 `prometheus` ：

```bash
[root@wangpengliang100ecs ~]# cd /etc/
[root@wangpengliang100ecs etc]# mkdir prometheus
```

设置权限目录：

```bash
chown -R root:root /etc/prometheus
```

手动创建 `prometheus.yml`配置文件，内容如下：

```yml
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']
```

启动容器：

```bash
docker run -d --name prometheus -p 9090:9090 -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus
```

## 浏览器访问

启动完成后，可以通过 http://ipaddress:9090 访问 Prometheus 的UI界面：

![](/images/2022-07-04-19-49-09.png)