<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='Redis.Config 配置文件# 经常使用的配置使用“# =>”方式写了注释
# Redis configuration file example. # # Note that in order to read the configuration file, Redis must be # started with the file path as first argument: # # ./redis-server /path/to/redis.conf # Note on units: when memory size is needed, it is possible to specify # it in the usual form of 1k 5GB 4M and so forth: # # => 单位设置 # 1k => 1000 bytes # 1kb => 1024 bytes # 1m => 1000000 bytes # 1mb => 1024*1024 bytes # 1g => 1000000000 bytes # 1gb => 1024*1024*1024 bytes # # => Redis单位对大小写不敏感 # units are case insensitive so 1GB 1Gb 1gB are all the same. # => 包含：可以把多个Redis.conf组合成一个conf ################################## INCLUDES ################################### # Include one or more other config files here. This is useful if you # have a standard template that goes to all Redis servers but also need # to customize a few per-server settings. Include files can include # other files, so use this wisely. # # Note that option "include" won&#39;t be rewritten by command "CONFIG REWRITE" # from admin or Redis Sentinel. Since Redis always uses the last processed # line as value of a configuration directive, you&#39;d better put includes # at the beginning of this file to avoid overwriting config change at runtime. # # If instead you are interested in using includes to override configuration # options, it is better to use include as the last line. # # include /path/to/local.conf # include /path/to/other.conf ################################## MODULES ##################################### # Load modules at startup. If the server is not able to load modules # it will abort. It is possible to use multiple loadmodule directives. # # loadmodule /path/to/my_module.so # loadmodule /path/to/other_module.so # => 网络配置 ################################## NETWORK ##################################### # By default, if no "bind" configuration directive is specified, Redis listens # for connections from all available network interfaces on the host machine. # It is possible to listen to just one or multiple selected interfaces using # the "bind" configuration directive, followed by one or more IP addresses. # Each address can be prefixed by "-", which means that redis will not fail to # start if the address is not available. Being not available only refers to # addresses that does not correspond to any network interfece. Addresses that # are already in use will always fail, and unsupported protocols will always BE # silently skipped. # # Examples: # # bind 192.168.1.100 10.0.0.1 # listens on two specific IPv4 addresses # bind 127.0.0.1 ::1 # listens on loopback IPv4 and IPv6 # bind * -::* # like the default, all available interfaces # # ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the # internet, binding to all the interfaces is dangerous and will expose the # instance to everybody on the internet. So by default we uncomment the # following bind directive, that will force Redis to listen only on the # IPv4 and IPv6 (if available) loopback interface addresses (this means Redis # will only be able to accept client connections from the same host that it is # running on). # # IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES # JUST COMMENT OUT THE FOLLOWING LINE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # => 绑定的IP:127.0.0.1只能是本地使用，如果需要提供给远程访问，需要设置为*统配或者指定IP bind 0.0.0.0 -::1 # Protected mode is a layer of security protection, in order to avoid that # Redis instances left open on the internet are accessed and exploited. # # When protected mode is on and if: # # 1) The server is not binding explicitly to a set of addresses using the # "bind" directive. # 2) No password is configured. # # The server only accepts connections from clients connecting from the # IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain # sockets. # # By default protected mode is enabled. You should disable it only if # you are sure you want clients from other hosts to connect to Redis # even if no authentication is configured, nor a specific set of interfaces # are explicitly listed using the "bind" directive. # => 是否受保护模式 protected-mode yes # Accept connections on the specified port, default is 6379 (IANA #815344). # If port 0 is specified Redis will not listen on a TCP socket. # => 端口设置 port 6379 # TCP listen() backlog. # # In high requests-per-second environments you need a high backlog in order # to avoid slow clients connection issues. Note that the Linux kernel # will silently truncate it to the value of /proc/sys/net/core/somaxconn so # make sure to raise both the value of somaxconn and tcp_max_syn_backlog # in order to get the desired effect. tcp-backlog 511 # Unix socket. # # Specify the path for the Unix socket that will be used to listen for # incoming connections. There is no default, so Redis will not listen # on a unix socket when not specified. # # unixsocket /run/redis.sock # unixsocketperm 700 # Close the connection after a client is idle for N seconds (0 to disable) timeout 0 # TCP keepalive. # # If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence # of communication. This is useful for two reasons: # # 1) Detect dead peers. # 2) Force network equipment in the middle to consider the connection to be # alive. # # On Linux, the specified value (in seconds) is the period used to send ACKs. # Note that to close the connection the double of the time is needed. # On other kernels the period depends on the kernel configuration. # # A reasonable value for this option is 300 seconds, which is the new # Redis default starting with Redis 3.2.1. tcp-keepalive 300 ################################# TLS/SSL ##################################### # By default, TLS/SSL is disabled. To enable it, the "tls-port" configuration # directive can be used to define TLS-listening ports. To enable TLS on the # default port, use: # # port 0 # tls-port 6379 # Configure a X.509 certificate and private key to use for authenticating the # server to connected clients, masters or cluster peers. These files should be # PEM formatted. # # tls-cert-file redis.crt # tls-key-file redis.key # Normally Redis uses the same certificate for both server functions (accepting # connections) and client functions (replicating from a master, establishing # cluster bus connections, etc.). # # Sometimes certificates are issued with attributes that designate them as # client-only or server-only certificates. In that case it may be desired to use # different certificates for incoming (server) and outgoing (client) # connections. To do that, use the following directives: # # tls-client-cert-file client.crt # tls-client-key-file client.key # Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange: # # tls-dh-params-file redis.dh # Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL # clients and peers. Redis requires an explicit configuration of at least one # of these, and will not implicitly use the system wide configuration. # # tls-ca-cert-file ca.crt # tls-ca-cert-dir /etc/ssl/certs # By default, clients (including replica servers) on a TLS port are required # to authenticate using valid client side certificates. # # If "no" is specified, client certificates are not required and not accepted. # If "optional" is specified, client certificates are accepted and must be # valid if provided, but are not required. # # tls-auth-clients no # tls-auth-clients optional # By default, a Redis replica does not attempt to establish a TLS connection # with its master. # # Use the following directive to enable TLS on replication links. # # tls-replication yes # By default, the Redis Cluster bus uses a plain TCP connection. To enable # TLS for the bus protocol, use the following directive: # # tls-cluster yes # By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended # that older formally deprecated versions are kept disabled to reduce the attack surface. # You can explicitly specify TLS versions to support. # Allowed values are case insensitive and include "TLSv1", "TLSv1.1", "TLSv1.2", # "TLSv1.3" (OpenSSL >= 1.1.1) or any combination. # To enable only TLSv1.2 and TLSv1.3, use: # # tls-protocols "TLSv1.2 TLSv1.3" # Configure allowed ciphers. See the ciphers(1ssl) manpage for more information # about the syntax of this string. # # Note: this configuration applies only to <= TLSv1.2. # # tls-ciphers DEFAULT:!MEDIUM # Configure allowed TLSv1.3 ciphersuites. See the ciphers(1ssl) manpage for more # information about the syntax of this string, and specifically for TLSv1.3 # ciphersuites. # # tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256 # When choosing a cipher, use the server&#39;s preference instead of the client # preference. By default, the server follows the client&#39;s preference. # # tls-prefer-server-ciphers yes # By default, TLS session caching is enabled to allow faster and less expensive # reconnections by clients that support it. Use the following directive to disable # caching. # # tls-session-caching no # Change the default number of TLS sessions cached. A zero value sets the cache # to unlimited size. The default size is 20480. # # tls-session-cache-size 5000 # Change the default timeout of cached TLS sessions. The default timeout is 300 # seconds. # # tls-session-cache-timeout 60 ################################# GENERAL ##################################### # By default Redis does not run as a daemon. Use &#39;yes&#39; if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. # When Redis is supervised by upstart or systemd, this parameter has no impact. # => 是否以守护进程的方式运行，默认是no daemonize yes # If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # requires "expect stop" in your upstart job config # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # on startup, and updating Redis status on a regular # basis. # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal "process is ready." # They do not enable continuous pings back to your supervisor. # # The default is "no". To run under upstart/systemd, you can simply uncomment # the line below: # # supervised auto # If a pid file is specified, Redis writes it where specified at startup # and removes it at exit. # # When the server runs non daemonized, no pid file is created if none is # specified in the configuration. When the server is daemonized, the pid file # is used even if not specified, defaulting to "/var/run/redis.pid". # # Creating a pid file is best effort: if Redis is not able to create it # nothing bad happens, the server will start and run normally. # # Note that on modern Linux systems "/run/redis.pid" is more conforming # and should be used instead. # => 如果以守护进程方式运行，需要指定一个守护进程的文件 pidfile /var/run/redis_6379.pid # Specify the server verbosity level. # This can be one of: # debug (a lot of information, useful for development/testing) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) # => 设置日志级别 loglevel notice # Specify the log file name. Also the empty string can be used to force # Redis to log on the standard output. Note that if you use standard # output for logging but daemonize, logs will be sent to /dev/null # => 设置日志的存储位置 logfile "" # To enable logging to the system logger, just set &#39;syslog-enabled&#39; to yes, # and optionally update the other syslog parameters to suit your needs. # syslog-enabled no # Specify the syslog identity. # syslog-ident redis # Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7. # syslog-facility local0 # To disable the built in crash log, which will possibly produce cleaner core # dumps when they are needed, uncomment the following: # # crash-log-enabled no # To disable the fast memory check that&#39;s run as part of the crash log, which # will possibly let redis terminate sooner, uncomment the following: # # crash-memcheck-enabled no # Set the number of databases. The default database is DB 0, you can select # a different one on a per-connection basis using SELECT <dbid> where # dbid is a number between 0 and &#39;databases&#39;-1 # => 默认数据库数量 databases 16 # By default Redis shows an ASCII art logo only when started to log to the # standard output and if the standard output is a TTY and syslog logging is # disabled. Basically this means that normally a logo is displayed only in # interactive sessions. # # However it is possible to force the pre-4.0 behavior and always show a # ASCII art logo in startup logs by setting the following option to yes. # => 是否总是显示Logo always-show-logo no # By default, Redis modifies the process title (as seen in &#39;top&#39; and &#39;ps&#39;) to # provide some runtime information. It is possible to disable this and leave # the process name as executed by setting the following to no. set-proc-title yes # When changing the process title, Redis uses the following template to construct # the modified title. # # Template variables are specified in curly brackets. The following variables are # supported: # # {title} Name of process as executed if parent, or type of child process. # {listen-addr} Bind address or &#39;*&#39; followed by TCP or TLS port listening on, or # Unix socket if only that&#39;s available. # {server-mode} Special mode, i.e. "[sentinel]" or "[cluster]". # {port} TCP port listening on, or 0. # {tls-port} TLS port listening on, or 0. # {unixsocket} Unix domain socket listening on, or "". # {config-file} Name of configuration file used. # proc-title-template "{title} {listen-addr} {server-mode}" ################################ SNAPSHOTTING ################################ # Save the DB to disk. # # save <seconds> <changes> # # Redis will save the DB if both the given number of seconds and the given # number of write operations against the DB occurred. # # Snapshotting can be completely disabled with a single empty string argument # as in following example: # # save "" # # Unless specified otherwise, by default Redis will save the DB: # * After 3600 seconds (an hour) if at least 1 key changed # * After 300 seconds (5 minutes) if at least 100 keys changed # * After 60 seconds if at least 10000 keys changed # # You can set these explicitly by uncommenting the three following lines. # # => 快照持久化规则设置 # => 如果3600秒内，至少一个Key进行了修改，就会进行持久化 # save 3600 1 # save 300 100 # save 60 10000 # By default Redis will stop accepting writes if RDB snapshots are enabled # (at least one save point) and the latest background save failed. # This will make the user aware (in a hard way) that data is not persisting # on disk properly, otherwise chances are that no one will notice and some # disaster will happen. # # If the background saving process will start working again Redis will # automatically allow writes again. # # However if you have setup your proper monitoring of the Redis server # and persistence, you may want to disable this feature so that Redis will # continue to work as usual even if there are problems with disk, # permissions, and so forth. # => 持久化出错时，是否继续工作 stop-writes-on-bgsave-error yes # Compress string objects using LZF when dump .rdb databases? # By default compression is enabled as it&#39;s almost always a win. # If you want to save some CPU in the saving child set it to &#39;no&#39; but # the dataset will likely be bigger if you have compressible values or keys. # => 是否压缩rdb文件；压缩是需要耗费一些CPU资源的 rdbcompression yes # Since version 5 of RDB a CRC64 checksum is placed at the end of the file. # This makes the format more resistant to corruption but there is a performance # hit to pay (around 10%) when saving and loading RDB files, so you can disable it # for maximum performances. # # RDB files created with checksum disabled have a checksum of zero that will # tell the loading code to skip the check. # => 保存rdb文件时，是否校验rdb文件 rdbchecksum yes # Enables or disables full sanitation checks for ziplist and listpack etc when # loading an RDB or RESTORE payload. This reduces the chances of a assertion or # crash later on while processing commands. # Options: # no - Never perform full sanitation # yes - Always perform full sanitation # clients - Perform full sanitation only for user connections. # Excludes: RDB files, RESTORE commands received from the master # connection, and client connections which have the # skip-sanitize-payload ACL flag. # The default should be &#39;clients&#39; but since it currently affects cluster # resharding via MIGRATE, it is temporarily set to &#39;no&#39; by default. # # sanitize-dump-payload no # The filename where to dump the DB dbfilename dump.rdb # Remove RDB files used by replication in instances without persistence # enabled. By default this option is disabled, however there are environments # where for regulations or other security concerns, RDB files persisted on # disk by masters in order to feed replicas, or stored on disk by replicas # in order to load them for the initial synchronization, should be deleted # ASAP. Note that this option ONLY WORKS in instances that have both AOF # and RDB persistence disabled, otherwise is completely ignored. # # An alternative (and sometimes better) way to obtain the same effect is # to use diskless replication on both master and replicas instances. However # in the case of replicas, diskless is not always an option. rdb-del-sync-files no # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the &#39;dbfilename&#39; configuration directive. # # The Append Only File will also be created inside this directory. # # Note that you must specify a directory here, not a file name. # => rdb文件保存目录 dir ./ ################################# REPLICATION ################################# # Master-Replica replication. Use replicaof to make a Redis instance a copy of # another Redis server. A few things to understand ASAP about Redis replication. # # +------------------+ +---------------+ # | Master | ---> | Replica | # | (receive writes) | | (exact copy) | # +------------------+ +---------------+ # # 1) Redis replication is asynchronous, but you can configure a master to # stop accepting writes if it appears to be not connected with at least # a given number of replicas. # 2) Redis replicas are able to perform a partial resynchronization with the # master if the replication link is lost for a relatively small amount of # time. You may want to configure the replication backlog size (see the next # sections of this file) with a sensible value depending on your needs. # 3) Replication is automatic and does not need user intervention. After a # network partition replicas automatically try to reconnect to masters # and resynchronize with them. # # replicaof <masterip> <masterport> # If the master is password protected (using the "requirepass" configuration # directive below) it is possible to tell the replica to authenticate before # starting the replication synchronization process, otherwise the master will # refuse the replica request. # # masterauth <master-password> # # However this is not enough if you are using Redis ACLs (for Redis version # 6 or greater), and the default user is not capable of running the PSYNC # command and/or other commands needed for replication. In this case it&#39;s # better to configure a special user to use with replication, and specify the # masteruser configuration as such: # # masteruser <username> # # When masteruser is specified, the replica will authenticate against its # master using the new AUTH form: AUTH <username> <password>. # When a replica loses its connection with the master, or when the replication # is still in progress, the replica can act in two different ways: # # 1) if replica-serve-stale-data is set to &#39;yes&#39; (the default) the replica will # still reply to client requests, possibly with out of date data, or the # data set may just be empty if this is the first synchronization. # # 2) If replica-serve-stale-data is set to &#39;no&#39; the replica will reply with # an error "SYNC with master in progress" to all commands except: # INFO, REPLICAOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE, # UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST, # HOST and LATENCY. # replica-serve-stale-data yes # You can configure a replica instance to accept writes or not. Writing against # a replica instance may be useful to store some ephemeral data (because data # written on a replica will be easily deleted after resync with the master) but # may also cause problems if clients are writing to it because of a # misconfiguration. # # Since Redis 2.6 by default replicas are read-only. # # Note: read only replicas are not designed to be exposed to untrusted clients # on the internet. It&#39;s just a protection layer against misuse of the instance. # Still a read only replica exports by default all the administrative commands # such as CONFIG, DEBUG, and so forth. To a limited extent you can improve # security of read only replicas using &#39;rename-command&#39; to shadow all the # administrative / dangerous commands. replica-read-only yes # Replication SYNC strategy: disk or socket. # # New replicas and reconnecting replicas that are not able to continue the # replication process just receiving differences, need to do what is called a # "full synchronization". An RDB file is transmitted from the master to the # replicas. # # The transmission can happen in two different ways: # # 1) Disk-backed: The Redis master creates a new process that writes the RDB # file on disk. Later the file is transferred by the parent # process to the replicas incrementally. # 2) Diskless: The Redis master creates a new process that directly writes the # RDB file to replica sockets, without touching the disk at all. # # With disk-backed replication, while the RDB file is generated, more replicas # can be queued and served with the RDB file as soon as the current child # producing the RDB file finishes its work. With diskless replication instead # once the transfer starts, new replicas arriving will be queued and a new # transfer will start when the current one terminates. # # When diskless replication is used, the master waits a configurable amount of # time (in seconds) before starting the transfer in the hope that multiple # replicas will arrive and the transfer can be parallelized. # # With slow disks and fast (large bandwidth) networks, diskless replication # works better. repl-diskless-sync no # When diskless replication is enabled, it is possible to configure the delay # the server waits in order to spawn the child that transfers the RDB via socket # to the replicas. # # This is important since once the transfer starts, it is not possible to serve # new replicas arriving, that will be queued for the next RDB transfer, so the # server waits a delay in order to let more replicas arrive. # # The delay is specified in seconds, and by default is 5 seconds. To disable # it entirely just set it to 0 seconds and the transfer will start ASAP. repl-diskless-sync-delay 5 # ----------------------------------------------------------------------------- # WARNING: RDB diskless load is experimental. Since in this setup the replica # does not immediately store an RDB on disk, it may cause data loss during # failovers. RDB diskless load + Redis modules not handling I/O reads may also # cause Redis to abort in case of I/O errors during the initial synchronization # stage with the master. Use only if you know what you are doing. # ----------------------------------------------------------------------------- # # Replica can load the RDB it reads from the replication link directly from the # socket, or store the RDB to a file and read that file after it was completely # received from the master. # # In many cases the disk is slower than the network, and storing and loading # the RDB file may increase replication time (and even increase the master&#39;s # Copy on Write memory and salve buffers). # However, parsing the RDB file directly from the socket may mean that we have # to flush the contents of the current database before the full rdb was # received. For this reason we have the following options: # # "disabled" - Don&#39;t use diskless load (store the rdb file to the disk first) # "on-empty-db" - Use diskless load only when it is completely safe. # "swapdb" - Keep a copy of the current db contents in RAM while parsing # the data directly from the socket. note that this requires # sufficient memory, if you don&#39;t have it, you risk an OOM kill. repl-diskless-load disabled # Replicas send PINGs to server in a predefined interval. It&#39;s possible to # change this interval with the repl_ping_replica_period option. The default # value is 10 seconds. # # repl-ping-replica-period 10 # The following option sets the replication timeout for: # # 1) Bulk transfer I/O during SYNC, from the point of view of replica. # 2) Master timeout from the point of view of replicas (data, pings). # 3) Replica timeout from the point of view of masters (REPLCONF ACK pings). # # It is important to make sure that this value is greater than the value # specified for repl-ping-replica-period otherwise a timeout will be detected # every time there is low traffic between the master and the replica. The default # value is 60 seconds. # # repl-timeout 60 # Disable TCP_NODELAY on the replica socket after SYNC? # # If you select "yes" Redis will use a smaller number of TCP packets and # less bandwidth to send data to replicas. But this can add a delay for # the data to appear on the replica side, up to 40 milliseconds with # Linux kernels using a default configuration. # # If you select "no" the delay for data to appear on the replica side will # be reduced but more bandwidth will be used for replication. # # By default we optimize for low latency, but in very high traffic conditions # or when the master and replicas are many hops away, turning this to "yes" may # be a good idea. repl-disable-tcp-nodelay no # Set the replication backlog size. The backlog is a buffer that accumulates # replica data when replicas are disconnected for some time, so that when a # replica wants to reconnect again, often a full resync is not needed, but a # partial resync is enough, just passing the portion of data the replica # missed while disconnected. # # The bigger the replication backlog, the longer the replica can endure the # disconnect and later be able to perform a partial resynchronization. # # The backlog is only allocated if there is at least one replica connected. # # repl-backlog-size 1mb # After a master has no connected replicas for some time, the backlog will be # freed. The following option configures the amount of seconds that need to # elapse, starting from the time the last replica disconnected, for the backlog # buffer to be freed. # # Note that replicas never free the backlog for timeout, since they may be # promoted to masters later, and should be able to correctly "partially # resynchronize" with other replicas: hence they should always accumulate backlog. # # A value of 0 means to never release the backlog. # # repl-backlog-ttl 3600 # The replica priority is an integer number published by Redis in the INFO # output. It is used by Redis Sentinel in order to select a replica to promote # into a master if the master is no longer working correctly. # # A replica with a low priority number is considered better for promotion, so # for instance if there are three replicas with priority 10, 100, 25 Sentinel # will pick the one with priority 10, that is the lowest. # # However a special priority of 0 marks the replica as not able to perform the # role of master, so a replica with priority of 0 will never be selected by # Redis Sentinel for promotion. # # By default the priority is 100. replica-priority 100 # It is possible for a master to stop accepting writes if there are less than # N replicas connected, having a lag less or equal than M seconds. # # The N replicas need to be in "online" state. # # The lag in seconds, that must be <= the specified value, is calculated from # the last ping received from the replica, that is usually sent every second. # # This option does not GUARANTEE that N replicas will accept the write, but # will limit the window of exposure for lost writes in case not enough replicas # are available, to the specified number of seconds. # # For example to require at least 3 replicas with a lag <= 10 seconds use: # # min-replicas-to-write 3 # min-replicas-max-lag 10 # # Setting one or the other to 0 disables the feature. # # By default min-replicas-to-write is set to 0 (feature disabled) and # min-replicas-max-lag is set to 10. # A Redis master is able to list the address and port of the attached # replicas in different ways. For example the "INFO replication" section # offers this information, which is used, among other tools, by # Redis Sentinel in order to discover replica instances. # Another place where this info is available is in the output of the # "ROLE" command of a master. # # The listed IP address and port normally reported by a replica is # obtained in the following way: # # IP: The address is auto detected by checking the peer address # of the socket used by the replica to connect with the master. # # Port: The port is communicated by the replica during the replication # handshake, and is normally the port that the replica is using to # listen for connections. # # However when port forwarding or Network Address Translation (NAT) is # used, the replica may actually be reachable via different IP and port # pairs. The following two options can be used by a replica in order to # report to its master a specific set of IP and port, so that both INFO # and ROLE will report those values. # # There is no need to use both the options if you need to override just # the port or the IP address. # # replica-announce-ip 5.5.5.5 # replica-announce-port 1234 ############################### KEYS TRACKING ################################# # Redis implements server assisted support for client side caching of values. # This is implemented using an invalidation table that remembers, using # a radix key indexed by key name, what clients have which keys. In turn # this is used in order to send invalidation messages to clients. Please # check this page to understand more about the feature: # # https://redis.io/topics/client-side-caching # # When tracking is enabled for a client, all the read only queries are assumed # to be cached: this will force Redis to store information in the invalidation # table. When keys are modified, such information is flushed away, and # invalidation messages are sent to the clients. However if the workload is # heavily dominated by reads, Redis could use more and more memory in order # to track the keys fetched by many clients. # # For this reason it is possible to configure a maximum fill value for the # invalidation table. By default it is set to 1M of keys, and once this limit # is reached, Redis will start to evict keys in the invalidation table # even if they were not modified, just to reclaim memory: this will in turn # force the clients to invalidate the cached values. Basically the table # maximum size is a trade off between the memory you want to spend server # side to track information about who cached what, and the ability of clients # to retain cached objects in memory. # # If you set the value to 0, it means there are no limits, and Redis will # retain as many keys as needed in the invalidation table. # In the "stats" INFO section, you can find information about the number of # keys in the invalidation table at every given moment. # # Note: when key tracking is used in broadcasting mode, no memory is used # in the server side so this setting is useless. # # tracking-table-max-keys 1000000 ################################## SECURITY ################################### # Warning: since Redis is pretty fast, an outside user can try up to # 1 million passwords per second against a modern box. This means that you # should use very strong passwords, otherwise they will be very easy to break. # Note that because the password is really a shared secret between the client # and the server, and should not be memorized by any human, the password # can be easily a long string from /dev/urandom or whatever, so by using a # long and unguessable password no brute force attack will be possible. # Redis ACL users are defined in the following format: # # user <username> ... acl rules ... # # For example: # # user worker +@list +@connection ~jobs:* on >ffa9203c493aa99 # # The special username "default" is used for new connections. If this user # has the "nopass" rule, then new connections will be immediately authenticated # as the "default" user without the need of any password provided via the # AUTH command. Otherwise if the "default" user is not flagged with "nopass" # the connections will start in not authenticated state, and will require # AUTH (or the HELLO command AUTH option) in order to be authenticated and # start to work. # # The ACL rules that describe what a user can do are the following: # # on Enable the user: it is possible to authenticate as this user. # off Disable the user: it&#39;s no longer possible to authenticate # with this user, however the already authenticated connections # will still work. # skip-sanitize-payload RESTORE dump-payload sanitation is skipped. # sanitize-payload RESTORE dump-payload is sanitized (default). # +<command> Allow the execution of that command # -<command> Disallow the execution of that command # +@<category> Allow the execution of all the commands in such category # with valid categories are like @admin, @set, @sortedset, ... # and so forth, see the full list in the server.c file where # the Redis command table is described and defined. # The special category @all means all the commands, but currently # present in the server, and that will be loaded in the future # via modules. # +<command>|subcommand Allow a specific subcommand of an otherwise # disabled command. Note that this form is not # allowed as negative like -DEBUG|SEGFAULT, but # only additive starting with "+". # allcommands Alias for +@all. Note that it implies the ability to execute # all the future commands loaded via the modules system. # nocommands Alias for -@all. # ~<pattern> Add a pattern of keys that can be mentioned as part of # commands. For instance ~* allows all the keys. The pattern # is a glob-style pattern like the one of KEYS. # It is possible to specify multiple patterns. # allkeys Alias for ~* # resetkeys Flush the list of allowed keys patterns. # &<pattern> Add a glob-style pattern of Pub/Sub channels that can be # accessed by the user. It is possible to specify multiple channel # patterns. # allchannels Alias for &* # resetchannels Flush the list of allowed channel patterns. # ><password> Add this password to the list of valid password for the user. # For example >mypass will add "mypass" to the list. # This directive clears the "nopass" flag (see later). # <<password> Remove this password from the list of valid passwords. # nopass All the set passwords of the user are removed, and the user # is flagged as requiring no password: it means that every # password will work against this user. If this directive is # used for the default user, every new connection will be # immediately authenticated with the default user without # any explicit AUTH command required. Note that the "resetpass" # directive will clear this condition. # resetpass Flush the list of allowed passwords. Moreover removes the # "nopass" status. After "resetpass" the user has no associated # passwords and there is no way to authenticate without adding # some password (or setting it as "nopass" later). # reset Performs the following actions: resetpass, resetkeys, off, # -@all. The user returns to the same state it has immediately # after its creation. # # ACL rules can be specified in any order: for instance you can start with # passwords, then flags, or key patterns. However note that the additive # and subtractive rules will CHANGE MEANING depending on the ordering. # For instance see the following example: # # user alice on +@all -DEBUG ~* >somepassword # # This will allow "alice" to use all the commands with the exception of the # DEBUG command, since +@all added all the commands to the set of the commands # alice can use, and later DEBUG was removed. However if we invert the order # of two ACL rules the result will be different: # # user alice on -DEBUG +@all ~* >somepassword # # Now DEBUG was removed when alice had yet no commands in the set of allowed # commands, later all the commands are added, so the user will be able to # execute everything. # # Basically ACL rules are processed left-to-right. # # For more information about ACL configuration please refer to # the Redis web site at https://redis.io/topics/acl # ACL LOG # # The ACL Log tracks failed commands and authentication events associated # with ACLs. The ACL Log is useful to troubleshoot failed commands blocked # by ACLs. The ACL Log is stored in memory. You can reclaim memory with # ACL LOG RESET. Define the maximum entry length of the ACL Log below. acllog-max-len 128 # Using an external ACL file # # Instead of configuring users here in this file, it is possible to use # a stand-alone file just listing users. The two methods cannot be mixed: # if you configure users here and at the same time you activate the external # ACL file, the server will refuse to start. # # The format of the external ACL user file is exactly the same as the # format that is used inside redis.conf to describe users. # # aclfile /etc/redis/users.acl # IMPORTANT NOTE: starting with Redis 6 "requirepass" is just a compatibility # layer on top of the new ACL system. The option effect will be just setting # the password for the default user. Clients will still authenticate using # AUTH <password> as usually, or more explicitly with AUTH default <password> # if they follow the new protocol: both will work. # # The requirepass is not compatable with aclfile option and the ACL LOAD # command, these will cause requirepass to be ignored. # => Redis默认没有密码；可以在这里设置密码 # requirepass wpl19950815 # requirepass foobared # New users are initialized with restrictive permissions by default, via the # equivalent of this ACL rule &#39;off resetkeys -@all&#39;. Starting with Redis 6.2, it # is possible to manage access to Pub/Sub channels with ACL rules as well. The # default Pub/Sub channels permission if new users is controlled by the # acl-pubsub-default configuration directive, which accepts one of these values: # # allchannels: grants access to all Pub/Sub channels # resetchannels: revokes access to all Pub/Sub channels # # To ensure backward compatibility while upgrading Redis 6.0, acl-pubsub-default # defaults to the &#39;allchannels&#39; permission. # # Future compatibility note: it is very likely that in a future version of Redis # the directive&#39;s default of &#39;allchannels&#39; will be changed to &#39;resetchannels&#39; in # order to provide better out-of-the-box Pub/Sub security. Therefore, it is # recommended that you explicitly define Pub/Sub permissions for all users # rather then rely on implicit default values. Once you&#39;ve set explicit # Pub/Sub for all exisitn users, you should uncomment the following line. # # acl-pubsub-default resetchannels # Command renaming (DEPRECATED). # # ------------------------------------------------------------------------ # WARNING: avoid using this option if possible. Instead use ACLs to remove # commands from the default user, and put them only in some admin user you # create for administrative purposes. # ------------------------------------------------------------------------ # # It is possible to change the name of dangerous commands in a shared # environment. For instance the CONFIG command may be renamed into something # hard to guess so that it will still be available for internal-use tools # but not available for general clients. # # Example: # # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # # It is also possible to completely kill a command by renaming it into # an empty string: # # rename-command CONFIG "" # # Please note that changing the name of commands that are logged into the # AOF file or transmitted to replicas may cause problems. ################################### CLIENTS #################################### # Set the max number of connected clients at the same time. By default # this limit is set to 10000 clients, however if the Redis server is not # able to configure the process file limit to allow for the specified limit # the max number of allowed clients is set to the current file limit # minus 32 (as Redis reserves a few file descriptors for internal uses). # # Once the limit is reached Redis will close all the new connections sending # an error &#39;max number of clients reached&#39;. # # IMPORTANT: When Redis Cluster is used, the max number of connections is also # shared with the cluster bus: every node in the cluster will use two # connections, one incoming and another outgoing. It is important to size the # limit accordingly in case of very large clusters. # => 限制client最大连接数 # maxclients 10000 ############################## MEMORY MANAGEMENT ################################ # Set a memory usage limit to the specified amount of bytes. # When the memory limit is reached Redis will try to remove keys # according to the eviction policy selected (see maxmemory-policy). # # If Redis can&#39;t remove keys according to the policy, or if the policy is # set to &#39;noeviction&#39;, Redis will start to reply with errors to commands # that would use more memory, like SET, LPUSH, and so on, and will continue # to reply to read-only commands like GET. # # This option is usually useful when using Redis as an LRU or LFU cache, or to # set a hard memory limit for an instance (using the &#39;noeviction&#39; policy). # # WARNING: If you have replicas attached to an instance with maxmemory on, # the size of the output buffers needed to feed the replicas are subtracted # from the used memory count, so that network problems / resyncs will # not trigger a loop where keys are evicted, and in turn the output # buffer of replicas is full with DELs of keys evicted triggering the deletion # of more keys, and so forth until the database is completely emptied. # # In short... if you have replicas attached it is suggested that you set a lower # limit for maxmemory so that there is some free RAM on the system for replica # output buffers (but this is not needed if the policy is &#39;noeviction&#39;). # => 配置Redis最大内存容量;单位字节 # maxmemory <bytes> # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select one from the following behaviors: # # volatile-lru -> Evict using approximated LRU, only keys with an expire set. # allkeys-lru -> Evict any key using approximated LRU. # volatile-lfu -> Evict using approximated LFU, only keys with an expire set. # allkeys-lfu -> Evict any key using approximated LFU. # volatile-random -> Remove a random key having an expire set. # allkeys-random -> Remove a random key, any key. # volatile-ttl -> Remove the key with the nearest expire time (minor TTL) # noeviction -> Don&#39;t evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, when there are no suitable keys for # eviction, Redis will return an error on write operations that require # more memory. These are usually commands that create new keys, add data or # modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE, # SORT (due to the STORE argument), and EXEC (if the transaction includes any # command that requires memory). # # The default is: # => 内存到达上限的处理策略 # maxmemory-policy noeviction # LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated # algorithms (in order to save memory), so you can tune it for speed or # accuracy. By default Redis will check five keys and pick the one that was # used least recently, you can change the sample size using the following # configuration directive. # # The default of 5 produces good enough results. 10 Approximates very closely # true LRU but costs more CPU. 3 is faster but not very accurate. # # maxmemory-samples 5 # Eviction processing is designed to function well with the default setting. # If there is an unusually large amount of write traffic, this value may need to # be increased. Decreasing this value may reduce latency at the risk of # eviction processing effectiveness # 0 = minimum latency, 10 = default, 100 = process without regard to latency # # maxmemory-eviction-tenacity 10 # Starting from Redis 5, by default a replica will ignore its maxmemory setting # (unless it is promoted to master after a failover or manually). It means # that the eviction of keys will be just handled by the master, sending the # DEL commands to the replica as keys evict in the master side. # # This behavior ensures that masters and replicas stay consistent, and is usually # what you want, however if your replica is writable, or you want the replica # to have a different memory setting, and you are sure all the writes performed # to the replica are idempotent, then you may change this default (but be sure # to understand what you are doing). # # Note that since the replica by default does not evict, it may end using more # memory than the one set via maxmemory (there are certain buffers that may # be larger on the replica, or data structures may sometimes take more memory # and so forth). So make sure you monitor your replicas and make sure they # have enough memory to never hit a real out-of-memory condition before the # master hits the configured maxmemory setting. # # replica-ignore-maxmemory yes # Redis reclaims expired keys in two ways: upon access when those keys are # found to be expired, and also in background, in what is called the # "active expire key". The key space is slowly and interactively scanned # looking for expired keys to reclaim, so that it is possible to free memory # of keys that are expired and will never be accessed again in a short time. # # The default effort of the expire cycle will try to avoid having more than # ten percent of expired keys still in memory, and will try to avoid consuming # more than 25% of total memory and to add latency to the system. However # it is possible to increase the expire "effort" that is normally set to # "1", to a greater value, up to the value "10". At its maximum value the # system will use more CPU, longer cycles (and technically may introduce # more latency), and will tolerate less already expired keys still present # in the system. It&#39;s a tradeoff between memory, CPU and latency. # # active-expire-effort 1 ############################# LAZY FREEING #################################### # Redis has two primitives to delete keys. One is called DEL and is a blocking # deletion of the object. It means that the server stops processing new commands # in order to reclaim all the memory associated with an object in a synchronous # way. If the key deleted is associated with a small object, the time needed # in order to execute the DEL command is very small and comparable to most other # O(1) or O(log_N) commands in Redis. However if the key is associated with an # aggregated value containing millions of elements, the server can block for # a long time (even seconds) in order to complete the operation. # # For the above reasons Redis also offers non blocking deletion primitives # such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and # FLUSHDB commands, in order to reclaim memory in background. Those commands # are executed in constant time. Another thread will incrementally free the # object in the background as fast as possible. # # DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled. # It&#39;s up to the design of the application to understand when it is a good # idea to use one or the other. However the Redis server sometimes has to # delete keys or flush the whole database as a side effect of other operations. # Specifically Redis deletes objects independently of a user call in the # following scenarios: # # 1) On eviction, because of the maxmemory and maxmemory policy configurations, # in order to make room for new data, without going over the specified # memory limit. # 2) Because of expire: when a key with an associated time to live (see the # EXPIRE command) must be deleted from memory. # 3) Because of a side effect of a command that stores data on a key that may # already exist. For example the RENAME command may delete the old key # content when it is replaced with another one. Similarly SUNIONSTORE # or SORT with STORE option may delete existing keys. The SET command # itself removes any old content of the specified key in order to replace # it with the specified string. # 4) During replication, when a replica performs a full resynchronization with # its master, the content of the whole database is removed in order to # load the RDB file just transferred. # # In all the above cases the default is to delete objects in a blocking way, # like if DEL was called. However you can configure each case specifically # in order to instead release memory in a non-blocking way like if UNLINK # was called, using the following configuration directives. lazyfree-lazy-eviction no lazyfree-lazy-expire no lazyfree-lazy-server-del no replica-lazy-flush no # It is also possible, for the case when to replace the user code DEL calls # with UNLINK calls is not easy, to modify the default behavior of the DEL # command to act exactly like UNLINK, using the following configuration # directive: lazyfree-lazy-user-del no # FLUSHDB, FLUSHALL, and SCRIPT FLUSH support both asynchronous and synchronous # deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the # commands. When neither flag is passed, this directive will be used to determine # if the data should be deleted asynchronously. lazyfree-lazy-user-flush no ################################ THREADED I/O ################################# # Redis is mostly single threaded, however there are certain threaded # operations such as UNLINK, slow I/O accesses and other things that are # performed on side threads. # # Now it is also possible to handle Redis clients socket reads and writes # in different I/O threads. Since especially writing is so slow, normally # Redis users use pipelining in order to speed up the Redis performances per # core, and spawn multiple instances in order to scale more. Using I/O # threads it is possible to easily speedup two times Redis without resorting # to pipelining nor sharding of the instance. # # By default threading is disabled, we suggest enabling it only in machines # that have at least 4 or more cores, leaving at least one spare core. # Using more than 8 threads is unlikely to help much. We also recommend using # threaded I/O only if you actually have performance problems, with Redis # instances being able to use a quite big percentage of CPU time, otherwise # there is no point in using this feature. # # So for instance if you have a four cores boxes, try to use 2 or 3 I/O # threads, if you have a 8 cores, try to use 6 threads. In order to # enable I/O threads use the following configuration directive: # # io-threads 4 # # Setting io-threads to 1 will just use the main thread as usual. # When I/O threads are enabled, we only use threads for writes, that is # to thread the write(2) syscall and transfer the client buffers to the # socket. However it is also possible to enable threading of reads and # protocol parsing using the following configuration directive, by setting # it to yes: # # io-threads-do-reads no # # Usually threading reads doesn&#39;t help much. # # NOTE 1: This configuration directive cannot be changed at runtime via # CONFIG SET. Aso this feature currently does not work when SSL is # enabled. # # NOTE 2: If you want to test the Redis speedup using redis-benchmark, make # sure you also run the benchmark itself in threaded mode, using the # --threads option to match the number of Redis threads, otherwise you&#39;ll not # be able to notice the improvements. ############################ KERNEL OOM CONTROL ############################## # On Linux, it is possible to hint the kernel OOM killer on what processes # should be killed first when out of memory. # # Enabling this feature makes Redis actively control the oom_score_adj value # for all its processes, depending on their role. The default scores will # attempt to have background child processes killed before all others, and # replicas killed before masters. # # Redis supports three options: # # no: Don&#39;t make changes to oom-score-adj (default). # yes: Alias to "relative" see below. # absolute: Values in oom-score-adj-values are written as is to the kernel. # relative: Values are used relative to the initial value of oom_score_adj when # the server starts and are then clamped to a range of -1000 to 1000. # Because typically the initial value is 0, they will often match the # absolute values. oom-score-adj no # When oom-score-adj is used, this directive controls the specific values used # for master, replica and background child processes. Values range -2000 to # 2000 (higher means more likely to be killed). # # Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities) # can freely increase their value, but not decrease it below its initial # settings. This means that setting oom-score-adj to "relative" and setting the # oom-score-adj-values to positive values will always succeed. oom-score-adj-values 0 200 800 #################### KERNEL transparent hugepage CONTROL ###################### # Usually the kernel Transparent Huge Pages control is set to "madvise" or # or "never" by default (/sys/kernel/mm/transparent_hugepage/enabled), in which # case this config has no effect. On systems in which it is set to "always", # redis will attempt to disable it specifically for the redis process in order # to avoid latency problems specifically with fork(2) and CoW. # If for some reason you prefer to keep it enabled, you can set this config to # "no" and the kernel global to "always". disable-thp yes ############################## APPEND ONLY MODE ############################### # By default Redis asynchronously dumps the dataset on disk. This mode is # good enough in many applications, but an issue with the Redis process or # a power outage may result into a few minutes of writes lost (depending on # the configured save points). # # The Append Only File is an alternative persistence mode that provides # much better durability. For instance using the default data fsync policy # (see later in the config file) Redis can lose just one second of writes in a # dramatic event like a server power outage, or a single write if something # wrong with the Redis process itself happens, but the operating system is # still running correctly. # # AOF and RDB persistence can be enabled at the same time without problems. # If the AOF is enabled on startup Redis will load the AOF, that is the file # with the better durability guarantees. # # Please check http://redis.io/topics/persistence for more information. # => 是否开启aof模式；默认使用rdb方式持久化 appendonly no # The name of the append only file (default: "appendonly.aof") # => 使用aof持久化文件的名称 appendfilename "appendonly.aof" # The fsync() call tells the Operating System to actually write data on disk # instead of waiting for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP. # # Redis supports three different modes: # # no: don&#39;t fsync, just let the OS flush the data when it wants. Faster. # always: fsync after every write to the append only log. Slow, Safest. # everysec: fsync only one time every second. Compromise. # # The default is "everysec", as that&#39;s usually the right compromise between # speed and data safety. It&#39;s up to you to understand if you can relax this to # "no" that will let the operating system flush the output buffer when # it wants, for better performances (but if you can live with the idea of # some data loss consider the default persistence mode that&#39;s snapshotting), # or on the contrary, use "always" that&#39;s very slow but a bit safer than # everysec. # # More details please check the following article: # http://antirez.com/post/redis-persistence-demystified.html # # If unsure, use "everysec". # => 每次修改都会同步；耗费性能 # appendfsync always # => 每秒执行一次同步；可能会丢失这一秒的数据 appendfsync everysec # => 不执行同步；由操作系统自己同步 # appendfsync no # When the AOF fsync policy is set to always or everysec, and a background # saving process (a background save or AOF log background rewriting) is # performing a lot of I/O against the disk, in some Linux configurations # Redis may block too long on the fsync() call. Note that there is no fix for # this currently, as even performing fsync in a different thread will block # our synchronous write(2) call. # # In order to mitigate this problem it&#39;s possible to use the following option # that will prevent fsync() from being called in the main process while a # BGSAVE or BGREWRITEAOF is in progress. # # This means that while another child is saving, the durability of Redis is # the same as "appendfsync none". In practical terms, this means that it is # possible to lose up to 30 seconds of log in the worst scenario (with the # default Linux settings). # # If you have latency problems turn this to "yes". Otherwise leave it as # "no" that is the safest pick from the point of view of durability. no-appendfsync-on-rewrite no # Automatic rewrite of the append only file. # Redis is able to automatically rewrite the log file implicitly calling # BGREWRITEAOF when the AOF log size grows by the specified percentage. # # This is how it works: Redis remembers the size of the AOF file after the # latest rewrite (if no rewrite has happened since the restart, the size of # the AOF at startup is used). # # This base size is compared to the current size. If the current size is # bigger than the specified percentage, the rewrite is triggered. Also # you need to specify a minimal size for the AOF file to be rewritten, this # is useful to avoid rewriting the AOF file even if the percentage increase # is reached but it is still pretty small. # # Specify a percentage of zero in order to disable the automatic AOF # rewrite feature. auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # An AOF file may be found to be truncated at the end during the Redis # startup process, when the AOF data gets loaded back into memory. # This may happen when the system where Redis is running # crashes, especially when an ext4 filesystem is mounted without the # data=ordered option (however this can&#39;t happen when Redis itself # crashes or aborts but the operating system still works correctly). # # Redis can either exit with an error when this happens, or load as much # data as possible (the default now) and start if the AOF file is found # to be truncated at the end. The following option controls this behavior. # # If aof-load-truncated is set to yes, a truncated AOF file is loaded and # the Redis server starts emitting a log to inform the user of the event. # Otherwise if the option is set to no, the server aborts with an error # and refuses to start. When the option is set to no, the user requires # to fix the AOF file using the "redis-check-aof" utility before to restart # the server. # # Note that if the AOF file will be found to be corrupted in the middle # the server will still exit with an error. This option only applies when # Redis will try to read more data from the AOF file but not enough bytes # will be found. aof-load-truncated yes # When rewriting the AOF file, Redis is able to use an RDB preamble in the # AOF file for faster rewrites and recoveries. When this option is turned # on the rewritten AOF file is composed of two different stanzas: # # [RDB file][AOF tail] # # When loading, Redis recognizes that the AOF file starts with the "REDIS" # string and loads the prefixed RDB file, then continues loading the AOF # tail. aof-use-rdb-preamble yes ################################ LUA SCRIPTING ############################### # Max execution time of a Lua script in milliseconds. # # If the maximum execution time is reached Redis will log that a script is # still in execution after the maximum allowed time and will start to # reply to queries with an error. # # When a long running script exceeds the maximum execution time only the # SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be # used to stop a script that did not yet call any write commands. The second # is the only way to shut down the server in the case a write command was # already issued by the script but the user doesn&#39;t want to wait for the natural # termination of the script. # # Set it to 0 or a negative value for unlimited execution without warnings. lua-time-limit 5000 ################################ REDIS CLUSTER ############################### # Normal Redis instances can&#39;t be part of a Redis Cluster; only nodes that are # started as cluster nodes can. In order to start a Redis instance as a # cluster node enable the cluster support uncommenting the following: # # cluster-enabled yes # Every cluster node has a cluster configuration file. This file is not # intended to be edited by hand. It is created and updated by Redis nodes. # Every Redis Cluster node requires a different cluster configuration file. # Make sure that instances running in the same system do not have # overlapping cluster configuration file names. # # cluster-config-file nodes-6379.conf # Cluster node timeout is the amount of milliseconds a node must be unreachable # for it to be considered in failure state. # Most other internal time limits are a multiple of the node timeout. # # cluster-node-timeout 15000 # A replica of a failing master will avoid to start a failover if its data # looks too old. # # There is no simple way for a replica to actually have an exact measure of # its "data age", so the following two checks are performed: # # 1) If there are multiple replicas able to failover, they exchange messages # in order to try to give an advantage to the replica with the best # replication offset (more data from the master processed). # Replicas will try to get their rank by offset, and apply to the start # of the failover a delay proportional to their rank. # # 2) Every single replica computes the time of the last interaction with # its master. This can be the last ping or command received (if the master # is still in the "connected" state), or the time that elapsed since the # disconnection with the master (if the replication link is currently down). # If the last interaction is too old, the replica will not try to failover # at all. # # The point "2" can be tuned by user. Specifically a replica will not perform # the failover if, since the last interaction with the master, the time # elapsed is greater than: # # (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period # # So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor # is 10, and assuming a default repl-ping-replica-period of 10 seconds, the # replica will not try to failover if it was not able to talk with the master # for longer than 310 seconds. # # A large cluster-replica-validity-factor may allow replicas with too old data to failover # a master, while a too small value may prevent the cluster from being able to # elect a replica at all. # # For maximum availability, it is possible to set the cluster-replica-validity-factor # to a value of 0, which means, that replicas will always try to failover the # master regardless of the last time they interacted with the master. # (However they&#39;ll always try to apply a delay proportional to their # offset rank). # # Zero is the only value able to guarantee that when all the partitions heal # the cluster will always be able to continue. # # cluster-replica-validity-factor 10 # Cluster replicas are able to migrate to orphaned masters, that are masters # that are left without working replicas. This improves the cluster ability # to resist to failures as otherwise an orphaned master can&#39;t be failed over # in case of failure if it has no working replicas. # # Replicas migrate to orphaned masters only if there are still at least a # given number of other working replicas for their old master. This number # is the "migration barrier". A migration barrier of 1 means that a replica # will migrate only if there is at least 1 other working replica for its master # and so forth. It usually reflects the number of replicas you want for every # master in your cluster. # # Default is 1 (replicas migrate only if their masters remain with at least # one replica). To disable migration just set it to a very large value. # A value of 0 can be set but is useful only for debugging and dangerous # in production. # # cluster-migration-barrier 1 # By default Redis Cluster nodes stop accepting queries if they detect there # is at least a hash slot uncovered (no available node is serving it). # This way if the cluster is partially down (for example a range of hash slots # are no longer covered) all the cluster becomes, eventually, unavailable. # It automatically returns available as soon as all the slots are covered again. # # However sometimes you want the subset of the cluster which is working, # to continue to accept queries for the part of the key space that is still # covered. In order to do so, just set the cluster-require-full-coverage # option to no. # # cluster-require-full-coverage yes # This option, when set to yes, prevents replicas from trying to failover its # master during master failures. However the replica can still perform a # manual failover, if forced to do so. # # This is useful in different scenarios, especially in the case of multiple # data center operations, where we want one side to never be promoted if not # in the case of a total DC failure. # # cluster-replica-no-failover no # This option, when set to yes, allows nodes to serve read traffic while the # the cluster is in a down state, as long as it believes it owns the slots. # # This is useful for two cases. The first case is for when an application # doesn&#39;t require consistency of data during node failures or network partitions. # One example of this is a cache, where as long as the node has the data it # should be able to serve it. # # The second use case is for configurations that don&#39;t meet the recommended # three shards but want to enable cluster mode and scale later. A # master outage in a 1 or 2 shard configuration causes a read/write outage to the # entire cluster without this option set, with it set there is only a write outage. # Without a quorum of masters, slot ownership will not change automatically. # # cluster-allow-reads-when-down no # In order to setup your cluster make sure to read the documentation # available at http://redis.io web site. ########################## CLUSTER DOCKER/NAT support ######################## # In certain deployments, Redis Cluster nodes address discovery fails, because # addresses are NAT-ted or because ports are forwarded (the typical case is # Docker and other containers). # # In order to make Redis Cluster working in such environments, a static # configuration where each node knows its public address is needed. The # following two options are used for this scope, and are: # # * cluster-announce-ip # * cluster-announce-port # * cluster-announce-bus-port # # Each instructs the node about its address, client port, and cluster message # bus port. The information is then published in the header of the bus packets # so that other nodes will be able to correctly map the address of the node # publishing the information. # # If the above options are not used, the normal Redis Cluster auto-detection # will be used instead. # # Note that when remapped, the bus port may not be at the fixed offset of # clients port + 10000, so you can specify any port and bus-port depending # on how they get remapped. If the bus-port is not set, a fixed offset of # 10000 will be used as usual. # # Example: # # cluster-announce-ip 10.1.1.5 # cluster-announce-port 6379 # cluster-announce-bus-port 6380 ################################## SLOW LOG ################################### # The Redis Slow Log is a system to log queries that exceeded a specified # execution time. The execution time does not include the I/O operations # like talking with the client, sending the reply and so forth, # but just the time needed to actually execute the command (this is the only # stage of command execution where the thread is blocked and can not serve # other requests in the meantime). # # You can configure the slow log with two parameters: one tells Redis # what is the execution time, in microseconds, to exceed in order for the # command to get logged, and the other parameter is the length of the # slow log. When a new command is logged the oldest one is removed from the # queue of logged commands. # The following time is expressed in microseconds, so 1000000 is equivalent # to one second. Note that a negative number disables the slow log, while # a value of zero forces the logging of every command. slowlog-log-slower-than 10000 # There is no limit to this length. Just be aware that it will consume memory. # You can reclaim memory used by the slow log with SLOWLOG RESET. slowlog-max-len 128 ################################ LATENCY MONITOR ############################## # The Redis latency monitoring subsystem samples different operations # at runtime in order to collect data related to possible sources of # latency of a Redis instance. # # Via the LATENCY command this information is available to the user that can # print graphs and obtain reports. # # The system only logs operations that were performed in a time equal or # greater than the amount of milliseconds specified via the # latency-monitor-threshold configuration directive. When its value is set # to zero, the latency monitor is turned off. # # By default latency monitoring is disabled since it is mostly not needed # if you don&#39;t have latency issues, and collecting data has a performance # impact, that while very small, can be measured under big load. Latency # monitoring can easily be enabled at runtime using the command # "CONFIG SET latency-monitor-threshold <milliseconds>" if needed. latency-monitor-threshold 0 ############################# EVENT NOTIFICATION ############################## # Redis can notify Pub/Sub clients about events happening in the key space. # This feature is documented at http://redis.io/topics/notifications # # For instance if keyspace events notification is enabled, and a client # performs a DEL operation on key "foo" stored in the Database 0, two # messages will be published via Pub/Sub: # # PUBLISH __keyspace@0__:foo del # PUBLISH __keyevent@0__:del foo # # It is possible to select the events that Redis will notify among a set # of classes. Every class is identified by a single character: # # K Keyspace events, published with __keyspace@<db>__ prefix. # E Keyevent events, published with __keyevent@<db>__ prefix. # g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ... # $ String commands # l List commands # s Set commands # h Hash commands # z Sorted set commands # x Expired events (events generated every time a key expires) # e Evicted events (events generated when a key is evicted for maxmemory) # t Stream commands # m Key-miss events (Note: It is not included in the &#39;A&#39; class) # A Alias for g$lshzxet, so that the "AKE" string means all the events # (Except key-miss events which are excluded from &#39;A&#39; due to their # unique nature). # # The "notify-keyspace-events" takes as argument a string that is composed # of zero or multiple characters. The empty string means that notifications # are disabled. # # Example: to enable list and generic events, from the point of view of the # event name, use: # # notify-keyspace-events Elg # # Example 2: to get the stream of the expired keys subscribing to channel # name __keyevent@0__:expired use: # # notify-keyspace-events Ex # # By default all notifications are disabled because most users don&#39;t need # this feature and the feature has some overhead. Note that if you don&#39;t # specify at least one of K or E, no events will be delivered. notify-keyspace-events "" ############################### GOPHER SERVER ################################# # Redis contains an implementation of the Gopher protocol, as specified in # the RFC 1436 (https://www.ietf.org/rfc/rfc1436.txt). # # The Gopher protocol was very popular in the late &#39;90s. It is an alternative # to the web, and the implementation both server and client side is so simple # that the Redis server has just 100 lines of code in order to implement this # support. # # What do you do with Gopher nowadays? Well Gopher never *really* died, and # lately there is a movement in order for the Gopher more hierarchical content # composed of just plain text documents to be resurrected. Some want a simpler # internet, others believe that the mainstream internet became too much # controlled, and it&#39;s cool to create an alternative space for people that # want a bit of fresh air. # # Anyway for the 10nth birthday of the Redis, we gave it the Gopher protocol # as a gift. # # --- HOW IT WORKS? --- # # The Redis Gopher support uses the inline protocol of Redis, and specifically # two kind of inline requests that were anyway illegal: an empty request # or any request that starts with "/" (there are no Redis commands starting # with such a slash). Normal RESP2/RESP3 requests are completely out of the # path of the Gopher protocol implementation and are served as usual as well. # # If you open a connection to Redis when Gopher is enabled and send it # a string like "/foo", if there is a key named "/foo" it is served via the # Gopher protocol. # # In order to create a real Gopher "hole" (the name of a Gopher site in Gopher # talking), you likely need a script like the following: # # https://github.com/antirez/gopher2redis # # --- SECURITY WARNING --- # # If you plan to put Redis on the internet in a publicly accessible address # to server Gopher pages MAKE SURE TO SET A PASSWORD to the instance. # Once a password is set: # # 1. The Gopher server (when enabled, not by default) will still serve # content via Gopher. # 2. However other commands cannot be called before the client will # authenticate. # # So use the &#39;requirepass&#39; option to protect your instance. # # Note that Gopher is not currently supported when &#39;io-threads-do-reads&#39; # is enabled. # # To enable Gopher support, uncomment the following line and set the option # from no (the default) to yes. # # gopher-enabled no ############################### ADVANCED CONFIG ############################### # Hashes are encoded using a memory efficient data structure when they have a # small number of entries, and the biggest entry does not exceed a given # threshold. These thresholds can be configured using the following directives. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # Lists are also encoded in a special way to save a lot of space. # The number of entries allowed per internal list node can be specified # as a fixed maximum size or a maximum number of elements. # For a fixed maximum size, use -5 through -1, meaning: # -5: max size: 64 Kb <-- not recommended for normal workloads # -4: max size: 32 Kb <-- not recommended # -3: max size: 16 Kb <-- probably not recommended # -2: max size: 8 Kb <-- good # -1: max size: 4 Kb <-- good # Positive numbers mean store up to _exactly_ that number of elements # per list node. # The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size), # but if your use case is unique, adjust the settings as necessary. list-max-ziplist-size -2 # Lists may also be compressed. # Compress depth is the number of quicklist ziplist nodes from *each* side of # the list to *exclude* from compression. The head and tail of the list # are always uncompressed for fast push/pop operations. Settings are: # 0: disable all list compression # 1: depth 1 means "don&#39;t start compressing until after 1 node into the list, # going from either the head or tail" # So: [head]->node->node->...->node->[tail] # [head], [tail] will always be uncompressed; inner nodes will compress. # 2: [head]->[next]->node->node->...->node->[prev]->[tail] # 2 here means: don&#39;t compress head or head->next or tail->prev or tail, # but compress all nodes between them. # 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail] # etc. list-compress-depth 0 # Sets have a special encoding in just one case: when a set is composed # of just strings that happen to be integers in radix 10 in the range # of 64 bit signed integers. # The following configuration setting sets the limit in the size of the # set in order to use this special memory saving encoding. set-max-intset-entries 512 # Similarly to hashes and lists, sorted sets are also specially encoded in # order to save a lot of space. This encoding is only used when the length and # elements of a sorted set are below the following limits: zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog sparse representation bytes limit. The limit includes the # 16 bytes header. When an HyperLogLog using the sparse representation crosses # this limit, it is converted into the dense representation. # # A value greater than 16000 is totally useless, since at that point the # dense representation is more memory efficient. # # The suggested value is ~ 3000 in order to have the benefits of # the space efficient encoding without slowing down too much PFADD, # which is O(N) with the sparse encoding. The value can be raised to # ~ 10000 when CPU is not a concern, but space is, and the data set is # composed of many HyperLogLogs with cardinality in the 0 - 15000 range. hll-sparse-max-bytes 3000 # Streams macro node max size / items. The stream data structure is a radix # tree of big nodes that encode multiple items inside. Using this configuration # it is possible to configure how big a single node can be in bytes, and the # maximum number of items it may contain before switching to a new node when # appending new stream entries. If any of the following settings are set to # zero, the limit is ignored, so for instance it is possible to set just a # max entries limit by setting max-bytes to 0 and max-entries to the desired # value. stream-node-max-bytes 4096 stream-node-max-entries 100 # Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in # order to help rehashing the main Redis hash table (the one mapping top-level # keys to values). The hash table implementation Redis uses (see dict.c) # performs a lazy rehashing: the more operation you run into a hash table # that is rehashing, the more rehashing "steps" are performed, so if the # server is idle the rehashing is never complete and some more memory is used # by the hash table. # # The default is to use this millisecond 10 times every second in order to # actively rehash the main dictionaries, freeing memory when possible. # # If unsure: # use "activerehashing no" if you have hard latency requirements and it is # not a good thing in your environment that Redis can reply from time to time # to queries with 2 milliseconds delay. # # use "activerehashing yes" if you don&#39;t have such hard requirements but # want to free memory asap when possible. activerehashing yes # The client output buffer limits can be used to force disconnection of clients # that are not reading data from the server fast enough for some reason (a # common reason is that a Pub/Sub client can&#39;t consume messages as fast as the # publisher can produce them). # # The limit can be set differently for the three different classes of clients: # # normal -> normal clients including MONITOR clients # replica -> replica clients # pubsub -> clients subscribed to at least one pubsub channel or pattern # # The syntax of every client-output-buffer-limit directive is the following: # # client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds> # # A client is immediately disconnected once the hard limit is reached, or if # the soft limit is reached and remains reached for the specified number of # seconds (continuously). # So for instance if the hard limit is 32 megabytes and the soft limit is # 16 megabytes / 10 seconds, the client will get disconnected immediately # if the size of the output buffers reach 32 megabytes, but will also get # disconnected if the client reaches 16 megabytes and continuously overcomes # the limit for 10 seconds. # # By default normal clients are not limited because they don&#39;t receive data # without asking (in a push way), but just after a request, so only # asynchronous clients may create a scenario where data is requested faster # than it can read. # # Instead there is a default limit for pubsub and replica clients, since # subscribers and replicas receive data in a push fashion. # # Both the hard or the soft limit can be disabled by setting them to zero. client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Client query buffers accumulate new commands. They are limited to a fixed # amount by default in order to avoid that a protocol desynchronization (for # instance due to a bug in the client) will lead to unbound memory usage in # the query buffer. However you can configure it here if you have very special # needs, such us huge multi/exec requests or alike. # # client-query-buffer-limit 1gb # In the Redis protocol, bulk requests, that are, elements representing single # strings, are normally limited to 512 mb. However you can change this limit # here, but must be 1mb or greater # # proto-max-bulk-len 512mb # Redis calls an internal function to perform many background tasks, like # closing connections of clients in timeout, purging expired keys that are # never requested, and so forth. # # Not all tasks are performed with the same frequency, but Redis checks for # tasks to perform according to the specified "hz" value. # # By default "hz" is set to 10. Raising the value will use more CPU when # Redis is idle, but at the same time will make Redis more responsive when # there are many keys expiring at the same time, and timeouts may be # handled with more precision. # # The range is between 1 and 500, however a value over 100 is usually not # a good idea. Most users should use the default of 10 and raise this up to # 100 only in environments where very low latency is required. hz 10 # Normally it is useful to have an HZ value which is proportional to the # number of clients connected. This is useful in order, for instance, to # avoid too many clients are processed for each background task invocation # in order to avoid latency spikes. # # Since the default HZ value by default is conservatively set to 10, Redis # offers, and enables by default, the ability to use an adaptive HZ value # which will temporarily raise when there are many connected clients. # # When dynamic HZ is enabled, the actual configured HZ will be used # as a baseline, but multiples of the configured HZ value will be actually # used as needed once more clients are connected. In this way an idle # instance will use very little CPU time while a busy instance will be # more responsive. dynamic-hz yes # When a child rewrites the AOF file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. aof-rewrite-incremental-fsync yes # When redis saves RDB file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. rdb-save-incremental-fsync yes # Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good # idea to start with the default settings and only change them after investigating # how to improve the performances and how the keys LFU change over time, which # is possible to inspect via the OBJECT FREQ command. # # There are two tunable parameters in the Redis LFU implementation: the # counter logarithm factor and the counter decay time. It is important to # understand what the two parameters mean before changing them. # # The LFU counter is just 8 bits per key, it&#39;s maximum value is 255, so Redis # uses a probabilistic increment with logarithmic behavior. Given the value # of the old counter, when a key is accessed, the counter is incremented in # this way: # # 1. A random number R between 0 and 1 is extracted. # 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1). # 3. The counter is incremented only if R < P. # # The default lfu-log-factor is 10. This is a table of how the frequency # counter changes with a different number of accesses with different # logarithmic factors: # # +--------+------------+------------+------------+------------+------------+ # | factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits | # +--------+------------+------------+------------+------------+------------+ # | 0 | 104 | 255 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 1 | 18 | 49 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 10 | 10 | 18 | 142 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 100 | 8 | 11 | 49 | 143 | 255 | # +--------+------------+------------+------------+------------+------------+ # # NOTE: The above table was obtained by running the following commands: # # redis-benchmark -n 1000000 incr foo # redis-cli object freq foo # # NOTE 2: The counter initial value is 5 in order to give new objects a chance # to accumulate hits. # # The counter decay time is the time, in minutes, that must elapse in order # for the key counter to be divided by two (or decremented if it has a value # less <= 10). # # The default value for the lfu-decay-time is 1. A special value of 0 means to # decay the counter every time it happens to be scanned. # # lfu-log-factor 10 # lfu-decay-time 1 ########################### ACTIVE DEFRAGMENTATION ####################### # # What is active defragmentation? # ------------------------------- # # Active (online) defragmentation allows a Redis server to compact the # spaces left between small allocations and deallocations of data in memory, # thus allowing to reclaim back memory. # # Fragmentation is a natural process that happens with every allocator (but # less so with Jemalloc, fortunately) and certain workloads. Normally a server # restart is needed in order to lower the fragmentation, or at least to flush # away all the data and create it again. However thanks to this feature # implemented by Oran Agra for Redis 4.0 this process can happen at runtime # in a "hot" way, while the server is running. # # Basically when the fragmentation is over a certain level (see the # configuration options below) Redis will start to create new copies of the # values in contiguous memory regions by exploiting certain specific Jemalloc # features (in order to understand if an allocation is causing fragmentation # and to allocate it in a better place), and at the same time, will release the # old copies of the data. This process, repeated incrementally for all the keys # will cause the fragmentation to drop back to normal values. # # Important things to understand: # # 1. This feature is disabled by default, and only works if you compiled Redis # to use the copy of Jemalloc we ship with the source code of Redis. # This is the default with Linux builds. # # 2. You never need to enable this feature if you don&#39;t have fragmentation # issues. # # 3. Once you experience fragmentation, you can enable this feature when # needed with the command "CONFIG SET activedefrag yes". # # The configuration parameters are able to fine tune the behavior of the # defragmentation process. If you are not sure about what they mean it is # a good idea to leave the defaults untouched. # Enabled active defragmentation # activedefrag no # Minimum amount of fragmentation waste to start active defrag # active-defrag-ignore-bytes 100mb # Minimum percentage of fragmentation to start active defrag # active-defrag-threshold-lower 10 # Maximum percentage of fragmentation at which we use maximum effort # active-defrag-threshold-upper 100 # Minimal effort for defrag in CPU percentage, to be used when the lower # threshold is reached # active-defrag-cycle-min 1 # Maximal effort for defrag in CPU percentage, to be used when the upper # threshold is reached # active-defrag-cycle-max 25 # Maximum number of set/hash/zset/list fields that will be processed from # the main dictionary scan # active-defrag-max-scan-fields 1000 # Jemalloc background thread for purging will be enabled by default jemalloc-bg-thread yes # It is possible to pin different threads and processes of Redis to specific # CPUs in your system, in order to maximize the performances of the server. # This is useful both in order to pin different Redis threads in different # CPUs, but also in order to make sure that multiple Redis instances running # in the same host will be pinned to different CPUs. # # Normally you can do this using the "taskset" command, however it is also # possible to this via Redis configuration directly, both in Linux and FreeBSD. # # You can pin the server/IO threads, bio threads, aof rewrite child process, and # the bgsave child process. The syntax to specify the cpu list is the same as # the taskset command: # # Set redis server/io threads to cpu affinity 0,2,4,6: # server_cpulist 0-7:2 # # Set bio threads to cpu affinity 1,3: # bio_cpulist 1,3 # # Set aof rewrite child process to cpu affinity 8,9,10,11: # aof_rewrite_cpulist 8-11 # # Set bgsave child process to cpu affinity 1,10,11 # bgsave_cpulist 1,10-11 # In some cases redis will emit warnings and even refuse to start if it detects # that the system is in bad state, it is possible to suppress these warnings # by setting the following config which takes a space delimited list of warnings # to suppress # # ignore-warnings ARM64-COW-BUG'><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://wangpengliang815.github.io/docs/redis/1.6redis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"><meta property="og:site_name" content="CODE'NOTE"><meta property="og:title" content="CODE'NOTE"><meta property="og:description" content='Redis.Config 配置文件# 经常使用的配置使用“# =>”方式写了注释
# Redis configuration file example. # # Note that in order to read the configuration file, Redis must be # started with the file path as first argument: # # ./redis-server /path/to/redis.conf # Note on units: when memory size is needed, it is possible to specify # it in the usual form of 1k 5GB 4M and so forth: # # => 单位设置 # 1k => 1000 bytes # 1kb => 1024 bytes # 1m => 1000000 bytes # 1mb => 1024*1024 bytes # 1g => 1000000000 bytes # 1gb => 1024*1024*1024 bytes # # => Redis单位对大小写不敏感 # units are case insensitive so 1GB 1Gb 1gB are all the same. # => 包含：可以把多个Redis.conf组合成一个conf ################################## INCLUDES ################################### # Include one or more other config files here. This is useful if you # have a standard template that goes to all Redis servers but also need # to customize a few per-server settings. Include files can include # other files, so use this wisely. # # Note that option "include" won&#39;t be rewritten by command "CONFIG REWRITE" # from admin or Redis Sentinel. Since Redis always uses the last processed # line as value of a configuration directive, you&#39;d better put includes # at the beginning of this file to avoid overwriting config change at runtime. # # If instead you are interested in using includes to override configuration # options, it is better to use include as the last line. # # include /path/to/local.conf # include /path/to/other.conf ################################## MODULES ##################################### # Load modules at startup. If the server is not able to load modules # it will abort. It is possible to use multiple loadmodule directives. # # loadmodule /path/to/my_module.so # loadmodule /path/to/other_module.so # => 网络配置 ################################## NETWORK ##################################### # By default, if no "bind" configuration directive is specified, Redis listens # for connections from all available network interfaces on the host machine. # It is possible to listen to just one or multiple selected interfaces using # the "bind" configuration directive, followed by one or more IP addresses. # Each address can be prefixed by "-", which means that redis will not fail to # start if the address is not available. Being not available only refers to # addresses that does not correspond to any network interfece. Addresses that # are already in use will always fail, and unsupported protocols will always BE # silently skipped. # # Examples: # # bind 192.168.1.100 10.0.0.1 # listens on two specific IPv4 addresses # bind 127.0.0.1 ::1 # listens on loopback IPv4 and IPv6 # bind * -::* # like the default, all available interfaces # # ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the # internet, binding to all the interfaces is dangerous and will expose the # instance to everybody on the internet. So by default we uncomment the # following bind directive, that will force Redis to listen only on the # IPv4 and IPv6 (if available) loopback interface addresses (this means Redis # will only be able to accept client connections from the same host that it is # running on). # # IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES # JUST COMMENT OUT THE FOLLOWING LINE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # => 绑定的IP:127.0.0.1只能是本地使用，如果需要提供给远程访问，需要设置为*统配或者指定IP bind 0.0.0.0 -::1 # Protected mode is a layer of security protection, in order to avoid that # Redis instances left open on the internet are accessed and exploited. # # When protected mode is on and if: # # 1) The server is not binding explicitly to a set of addresses using the # "bind" directive. # 2) No password is configured. # # The server only accepts connections from clients connecting from the # IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain # sockets. # # By default protected mode is enabled. You should disable it only if # you are sure you want clients from other hosts to connect to Redis # even if no authentication is configured, nor a specific set of interfaces # are explicitly listed using the "bind" directive. # => 是否受保护模式 protected-mode yes # Accept connections on the specified port, default is 6379 (IANA #815344). # If port 0 is specified Redis will not listen on a TCP socket. # => 端口设置 port 6379 # TCP listen() backlog. # # In high requests-per-second environments you need a high backlog in order # to avoid slow clients connection issues. Note that the Linux kernel # will silently truncate it to the value of /proc/sys/net/core/somaxconn so # make sure to raise both the value of somaxconn and tcp_max_syn_backlog # in order to get the desired effect. tcp-backlog 511 # Unix socket. # # Specify the path for the Unix socket that will be used to listen for # incoming connections. There is no default, so Redis will not listen # on a unix socket when not specified. # # unixsocket /run/redis.sock # unixsocketperm 700 # Close the connection after a client is idle for N seconds (0 to disable) timeout 0 # TCP keepalive. # # If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence # of communication. This is useful for two reasons: # # 1) Detect dead peers. # 2) Force network equipment in the middle to consider the connection to be # alive. # # On Linux, the specified value (in seconds) is the period used to send ACKs. # Note that to close the connection the double of the time is needed. # On other kernels the period depends on the kernel configuration. # # A reasonable value for this option is 300 seconds, which is the new # Redis default starting with Redis 3.2.1. tcp-keepalive 300 ################################# TLS/SSL ##################################### # By default, TLS/SSL is disabled. To enable it, the "tls-port" configuration # directive can be used to define TLS-listening ports. To enable TLS on the # default port, use: # # port 0 # tls-port 6379 # Configure a X.509 certificate and private key to use for authenticating the # server to connected clients, masters or cluster peers. These files should be # PEM formatted. # # tls-cert-file redis.crt # tls-key-file redis.key # Normally Redis uses the same certificate for both server functions (accepting # connections) and client functions (replicating from a master, establishing # cluster bus connections, etc.). # # Sometimes certificates are issued with attributes that designate them as # client-only or server-only certificates. In that case it may be desired to use # different certificates for incoming (server) and outgoing (client) # connections. To do that, use the following directives: # # tls-client-cert-file client.crt # tls-client-key-file client.key # Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange: # # tls-dh-params-file redis.dh # Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL # clients and peers. Redis requires an explicit configuration of at least one # of these, and will not implicitly use the system wide configuration. # # tls-ca-cert-file ca.crt # tls-ca-cert-dir /etc/ssl/certs # By default, clients (including replica servers) on a TLS port are required # to authenticate using valid client side certificates. # # If "no" is specified, client certificates are not required and not accepted. # If "optional" is specified, client certificates are accepted and must be # valid if provided, but are not required. # # tls-auth-clients no # tls-auth-clients optional # By default, a Redis replica does not attempt to establish a TLS connection # with its master. # # Use the following directive to enable TLS on replication links. # # tls-replication yes # By default, the Redis Cluster bus uses a plain TCP connection. To enable # TLS for the bus protocol, use the following directive: # # tls-cluster yes # By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended # that older formally deprecated versions are kept disabled to reduce the attack surface. # You can explicitly specify TLS versions to support. # Allowed values are case insensitive and include "TLSv1", "TLSv1.1", "TLSv1.2", # "TLSv1.3" (OpenSSL >= 1.1.1) or any combination. # To enable only TLSv1.2 and TLSv1.3, use: # # tls-protocols "TLSv1.2 TLSv1.3" # Configure allowed ciphers. See the ciphers(1ssl) manpage for more information # about the syntax of this string. # # Note: this configuration applies only to <= TLSv1.2. # # tls-ciphers DEFAULT:!MEDIUM # Configure allowed TLSv1.3 ciphersuites. See the ciphers(1ssl) manpage for more # information about the syntax of this string, and specifically for TLSv1.3 # ciphersuites. # # tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256 # When choosing a cipher, use the server&#39;s preference instead of the client # preference. By default, the server follows the client&#39;s preference. # # tls-prefer-server-ciphers yes # By default, TLS session caching is enabled to allow faster and less expensive # reconnections by clients that support it. Use the following directive to disable # caching. # # tls-session-caching no # Change the default number of TLS sessions cached. A zero value sets the cache # to unlimited size. The default size is 20480. # # tls-session-cache-size 5000 # Change the default timeout of cached TLS sessions. The default timeout is 300 # seconds. # # tls-session-cache-timeout 60 ################################# GENERAL ##################################### # By default Redis does not run as a daemon. Use &#39;yes&#39; if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. # When Redis is supervised by upstart or systemd, this parameter has no impact. # => 是否以守护进程的方式运行，默认是no daemonize yes # If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # requires "expect stop" in your upstart job config # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # on startup, and updating Redis status on a regular # basis. # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal "process is ready." # They do not enable continuous pings back to your supervisor. # # The default is "no". To run under upstart/systemd, you can simply uncomment # the line below: # # supervised auto # If a pid file is specified, Redis writes it where specified at startup # and removes it at exit. # # When the server runs non daemonized, no pid file is created if none is # specified in the configuration. When the server is daemonized, the pid file # is used even if not specified, defaulting to "/var/run/redis.pid". # # Creating a pid file is best effort: if Redis is not able to create it # nothing bad happens, the server will start and run normally. # # Note that on modern Linux systems "/run/redis.pid" is more conforming # and should be used instead. # => 如果以守护进程方式运行，需要指定一个守护进程的文件 pidfile /var/run/redis_6379.pid # Specify the server verbosity level. # This can be one of: # debug (a lot of information, useful for development/testing) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) # => 设置日志级别 loglevel notice # Specify the log file name. Also the empty string can be used to force # Redis to log on the standard output. Note that if you use standard # output for logging but daemonize, logs will be sent to /dev/null # => 设置日志的存储位置 logfile "" # To enable logging to the system logger, just set &#39;syslog-enabled&#39; to yes, # and optionally update the other syslog parameters to suit your needs. # syslog-enabled no # Specify the syslog identity. # syslog-ident redis # Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7. # syslog-facility local0 # To disable the built in crash log, which will possibly produce cleaner core # dumps when they are needed, uncomment the following: # # crash-log-enabled no # To disable the fast memory check that&#39;s run as part of the crash log, which # will possibly let redis terminate sooner, uncomment the following: # # crash-memcheck-enabled no # Set the number of databases. The default database is DB 0, you can select # a different one on a per-connection basis using SELECT <dbid> where # dbid is a number between 0 and &#39;databases&#39;-1 # => 默认数据库数量 databases 16 # By default Redis shows an ASCII art logo only when started to log to the # standard output and if the standard output is a TTY and syslog logging is # disabled. Basically this means that normally a logo is displayed only in # interactive sessions. # # However it is possible to force the pre-4.0 behavior and always show a # ASCII art logo in startup logs by setting the following option to yes. # => 是否总是显示Logo always-show-logo no # By default, Redis modifies the process title (as seen in &#39;top&#39; and &#39;ps&#39;) to # provide some runtime information. It is possible to disable this and leave # the process name as executed by setting the following to no. set-proc-title yes # When changing the process title, Redis uses the following template to construct # the modified title. # # Template variables are specified in curly brackets. The following variables are # supported: # # {title} Name of process as executed if parent, or type of child process. # {listen-addr} Bind address or &#39;*&#39; followed by TCP or TLS port listening on, or # Unix socket if only that&#39;s available. # {server-mode} Special mode, i.e. "[sentinel]" or "[cluster]". # {port} TCP port listening on, or 0. # {tls-port} TLS port listening on, or 0. # {unixsocket} Unix domain socket listening on, or "". # {config-file} Name of configuration file used. # proc-title-template "{title} {listen-addr} {server-mode}" ################################ SNAPSHOTTING ################################ # Save the DB to disk. # # save <seconds> <changes> # # Redis will save the DB if both the given number of seconds and the given # number of write operations against the DB occurred. # # Snapshotting can be completely disabled with a single empty string argument # as in following example: # # save "" # # Unless specified otherwise, by default Redis will save the DB: # * After 3600 seconds (an hour) if at least 1 key changed # * After 300 seconds (5 minutes) if at least 100 keys changed # * After 60 seconds if at least 10000 keys changed # # You can set these explicitly by uncommenting the three following lines. # # => 快照持久化规则设置 # => 如果3600秒内，至少一个Key进行了修改，就会进行持久化 # save 3600 1 # save 300 100 # save 60 10000 # By default Redis will stop accepting writes if RDB snapshots are enabled # (at least one save point) and the latest background save failed. # This will make the user aware (in a hard way) that data is not persisting # on disk properly, otherwise chances are that no one will notice and some # disaster will happen. # # If the background saving process will start working again Redis will # automatically allow writes again. # # However if you have setup your proper monitoring of the Redis server # and persistence, you may want to disable this feature so that Redis will # continue to work as usual even if there are problems with disk, # permissions, and so forth. # => 持久化出错时，是否继续工作 stop-writes-on-bgsave-error yes # Compress string objects using LZF when dump .rdb databases? # By default compression is enabled as it&#39;s almost always a win. # If you want to save some CPU in the saving child set it to &#39;no&#39; but # the dataset will likely be bigger if you have compressible values or keys. # => 是否压缩rdb文件；压缩是需要耗费一些CPU资源的 rdbcompression yes # Since version 5 of RDB a CRC64 checksum is placed at the end of the file. # This makes the format more resistant to corruption but there is a performance # hit to pay (around 10%) when saving and loading RDB files, so you can disable it # for maximum performances. # # RDB files created with checksum disabled have a checksum of zero that will # tell the loading code to skip the check. # => 保存rdb文件时，是否校验rdb文件 rdbchecksum yes # Enables or disables full sanitation checks for ziplist and listpack etc when # loading an RDB or RESTORE payload. This reduces the chances of a assertion or # crash later on while processing commands. # Options: # no - Never perform full sanitation # yes - Always perform full sanitation # clients - Perform full sanitation only for user connections. # Excludes: RDB files, RESTORE commands received from the master # connection, and client connections which have the # skip-sanitize-payload ACL flag. # The default should be &#39;clients&#39; but since it currently affects cluster # resharding via MIGRATE, it is temporarily set to &#39;no&#39; by default. # # sanitize-dump-payload no # The filename where to dump the DB dbfilename dump.rdb # Remove RDB files used by replication in instances without persistence # enabled. By default this option is disabled, however there are environments # where for regulations or other security concerns, RDB files persisted on # disk by masters in order to feed replicas, or stored on disk by replicas # in order to load them for the initial synchronization, should be deleted # ASAP. Note that this option ONLY WORKS in instances that have both AOF # and RDB persistence disabled, otherwise is completely ignored. # # An alternative (and sometimes better) way to obtain the same effect is # to use diskless replication on both master and replicas instances. However # in the case of replicas, diskless is not always an option. rdb-del-sync-files no # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the &#39;dbfilename&#39; configuration directive. # # The Append Only File will also be created inside this directory. # # Note that you must specify a directory here, not a file name. # => rdb文件保存目录 dir ./ ################################# REPLICATION ################################# # Master-Replica replication. Use replicaof to make a Redis instance a copy of # another Redis server. A few things to understand ASAP about Redis replication. # # +------------------+ +---------------+ # | Master | ---> | Replica | # | (receive writes) | | (exact copy) | # +------------------+ +---------------+ # # 1) Redis replication is asynchronous, but you can configure a master to # stop accepting writes if it appears to be not connected with at least # a given number of replicas. # 2) Redis replicas are able to perform a partial resynchronization with the # master if the replication link is lost for a relatively small amount of # time. You may want to configure the replication backlog size (see the next # sections of this file) with a sensible value depending on your needs. # 3) Replication is automatic and does not need user intervention. After a # network partition replicas automatically try to reconnect to masters # and resynchronize with them. # # replicaof <masterip> <masterport> # If the master is password protected (using the "requirepass" configuration # directive below) it is possible to tell the replica to authenticate before # starting the replication synchronization process, otherwise the master will # refuse the replica request. # # masterauth <master-password> # # However this is not enough if you are using Redis ACLs (for Redis version # 6 or greater), and the default user is not capable of running the PSYNC # command and/or other commands needed for replication. In this case it&#39;s # better to configure a special user to use with replication, and specify the # masteruser configuration as such: # # masteruser <username> # # When masteruser is specified, the replica will authenticate against its # master using the new AUTH form: AUTH <username> <password>. # When a replica loses its connection with the master, or when the replication # is still in progress, the replica can act in two different ways: # # 1) if replica-serve-stale-data is set to &#39;yes&#39; (the default) the replica will # still reply to client requests, possibly with out of date data, or the # data set may just be empty if this is the first synchronization. # # 2) If replica-serve-stale-data is set to &#39;no&#39; the replica will reply with # an error "SYNC with master in progress" to all commands except: # INFO, REPLICAOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE, # UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST, # HOST and LATENCY. # replica-serve-stale-data yes # You can configure a replica instance to accept writes or not. Writing against # a replica instance may be useful to store some ephemeral data (because data # written on a replica will be easily deleted after resync with the master) but # may also cause problems if clients are writing to it because of a # misconfiguration. # # Since Redis 2.6 by default replicas are read-only. # # Note: read only replicas are not designed to be exposed to untrusted clients # on the internet. It&#39;s just a protection layer against misuse of the instance. # Still a read only replica exports by default all the administrative commands # such as CONFIG, DEBUG, and so forth. To a limited extent you can improve # security of read only replicas using &#39;rename-command&#39; to shadow all the # administrative / dangerous commands. replica-read-only yes # Replication SYNC strategy: disk or socket. # # New replicas and reconnecting replicas that are not able to continue the # replication process just receiving differences, need to do what is called a # "full synchronization". An RDB file is transmitted from the master to the # replicas. # # The transmission can happen in two different ways: # # 1) Disk-backed: The Redis master creates a new process that writes the RDB # file on disk. Later the file is transferred by the parent # process to the replicas incrementally. # 2) Diskless: The Redis master creates a new process that directly writes the # RDB file to replica sockets, without touching the disk at all. # # With disk-backed replication, while the RDB file is generated, more replicas # can be queued and served with the RDB file as soon as the current child # producing the RDB file finishes its work. With diskless replication instead # once the transfer starts, new replicas arriving will be queued and a new # transfer will start when the current one terminates. # # When diskless replication is used, the master waits a configurable amount of # time (in seconds) before starting the transfer in the hope that multiple # replicas will arrive and the transfer can be parallelized. # # With slow disks and fast (large bandwidth) networks, diskless replication # works better. repl-diskless-sync no # When diskless replication is enabled, it is possible to configure the delay # the server waits in order to spawn the child that transfers the RDB via socket # to the replicas. # # This is important since once the transfer starts, it is not possible to serve # new replicas arriving, that will be queued for the next RDB transfer, so the # server waits a delay in order to let more replicas arrive. # # The delay is specified in seconds, and by default is 5 seconds. To disable # it entirely just set it to 0 seconds and the transfer will start ASAP. repl-diskless-sync-delay 5 # ----------------------------------------------------------------------------- # WARNING: RDB diskless load is experimental. Since in this setup the replica # does not immediately store an RDB on disk, it may cause data loss during # failovers. RDB diskless load + Redis modules not handling I/O reads may also # cause Redis to abort in case of I/O errors during the initial synchronization # stage with the master. Use only if you know what you are doing. # ----------------------------------------------------------------------------- # # Replica can load the RDB it reads from the replication link directly from the # socket, or store the RDB to a file and read that file after it was completely # received from the master. # # In many cases the disk is slower than the network, and storing and loading # the RDB file may increase replication time (and even increase the master&#39;s # Copy on Write memory and salve buffers). # However, parsing the RDB file directly from the socket may mean that we have # to flush the contents of the current database before the full rdb was # received. For this reason we have the following options: # # "disabled" - Don&#39;t use diskless load (store the rdb file to the disk first) # "on-empty-db" - Use diskless load only when it is completely safe. # "swapdb" - Keep a copy of the current db contents in RAM while parsing # the data directly from the socket. note that this requires # sufficient memory, if you don&#39;t have it, you risk an OOM kill. repl-diskless-load disabled # Replicas send PINGs to server in a predefined interval. It&#39;s possible to # change this interval with the repl_ping_replica_period option. The default # value is 10 seconds. # # repl-ping-replica-period 10 # The following option sets the replication timeout for: # # 1) Bulk transfer I/O during SYNC, from the point of view of replica. # 2) Master timeout from the point of view of replicas (data, pings). # 3) Replica timeout from the point of view of masters (REPLCONF ACK pings). # # It is important to make sure that this value is greater than the value # specified for repl-ping-replica-period otherwise a timeout will be detected # every time there is low traffic between the master and the replica. The default # value is 60 seconds. # # repl-timeout 60 # Disable TCP_NODELAY on the replica socket after SYNC? # # If you select "yes" Redis will use a smaller number of TCP packets and # less bandwidth to send data to replicas. But this can add a delay for # the data to appear on the replica side, up to 40 milliseconds with # Linux kernels using a default configuration. # # If you select "no" the delay for data to appear on the replica side will # be reduced but more bandwidth will be used for replication. # # By default we optimize for low latency, but in very high traffic conditions # or when the master and replicas are many hops away, turning this to "yes" may # be a good idea. repl-disable-tcp-nodelay no # Set the replication backlog size. The backlog is a buffer that accumulates # replica data when replicas are disconnected for some time, so that when a # replica wants to reconnect again, often a full resync is not needed, but a # partial resync is enough, just passing the portion of data the replica # missed while disconnected. # # The bigger the replication backlog, the longer the replica can endure the # disconnect and later be able to perform a partial resynchronization. # # The backlog is only allocated if there is at least one replica connected. # # repl-backlog-size 1mb # After a master has no connected replicas for some time, the backlog will be # freed. The following option configures the amount of seconds that need to # elapse, starting from the time the last replica disconnected, for the backlog # buffer to be freed. # # Note that replicas never free the backlog for timeout, since they may be # promoted to masters later, and should be able to correctly "partially # resynchronize" with other replicas: hence they should always accumulate backlog. # # A value of 0 means to never release the backlog. # # repl-backlog-ttl 3600 # The replica priority is an integer number published by Redis in the INFO # output. It is used by Redis Sentinel in order to select a replica to promote # into a master if the master is no longer working correctly. # # A replica with a low priority number is considered better for promotion, so # for instance if there are three replicas with priority 10, 100, 25 Sentinel # will pick the one with priority 10, that is the lowest. # # However a special priority of 0 marks the replica as not able to perform the # role of master, so a replica with priority of 0 will never be selected by # Redis Sentinel for promotion. # # By default the priority is 100. replica-priority 100 # It is possible for a master to stop accepting writes if there are less than # N replicas connected, having a lag less or equal than M seconds. # # The N replicas need to be in "online" state. # # The lag in seconds, that must be <= the specified value, is calculated from # the last ping received from the replica, that is usually sent every second. # # This option does not GUARANTEE that N replicas will accept the write, but # will limit the window of exposure for lost writes in case not enough replicas # are available, to the specified number of seconds. # # For example to require at least 3 replicas with a lag <= 10 seconds use: # # min-replicas-to-write 3 # min-replicas-max-lag 10 # # Setting one or the other to 0 disables the feature. # # By default min-replicas-to-write is set to 0 (feature disabled) and # min-replicas-max-lag is set to 10. # A Redis master is able to list the address and port of the attached # replicas in different ways. For example the "INFO replication" section # offers this information, which is used, among other tools, by # Redis Sentinel in order to discover replica instances. # Another place where this info is available is in the output of the # "ROLE" command of a master. # # The listed IP address and port normally reported by a replica is # obtained in the following way: # # IP: The address is auto detected by checking the peer address # of the socket used by the replica to connect with the master. # # Port: The port is communicated by the replica during the replication # handshake, and is normally the port that the replica is using to # listen for connections. # # However when port forwarding or Network Address Translation (NAT) is # used, the replica may actually be reachable via different IP and port # pairs. The following two options can be used by a replica in order to # report to its master a specific set of IP and port, so that both INFO # and ROLE will report those values. # # There is no need to use both the options if you need to override just # the port or the IP address. # # replica-announce-ip 5.5.5.5 # replica-announce-port 1234 ############################### KEYS TRACKING ################################# # Redis implements server assisted support for client side caching of values. # This is implemented using an invalidation table that remembers, using # a radix key indexed by key name, what clients have which keys. In turn # this is used in order to send invalidation messages to clients. Please # check this page to understand more about the feature: # # https://redis.io/topics/client-side-caching # # When tracking is enabled for a client, all the read only queries are assumed # to be cached: this will force Redis to store information in the invalidation # table. When keys are modified, such information is flushed away, and # invalidation messages are sent to the clients. However if the workload is # heavily dominated by reads, Redis could use more and more memory in order # to track the keys fetched by many clients. # # For this reason it is possible to configure a maximum fill value for the # invalidation table. By default it is set to 1M of keys, and once this limit # is reached, Redis will start to evict keys in the invalidation table # even if they were not modified, just to reclaim memory: this will in turn # force the clients to invalidate the cached values. Basically the table # maximum size is a trade off between the memory you want to spend server # side to track information about who cached what, and the ability of clients # to retain cached objects in memory. # # If you set the value to 0, it means there are no limits, and Redis will # retain as many keys as needed in the invalidation table. # In the "stats" INFO section, you can find information about the number of # keys in the invalidation table at every given moment. # # Note: when key tracking is used in broadcasting mode, no memory is used # in the server side so this setting is useless. # # tracking-table-max-keys 1000000 ################################## SECURITY ################################### # Warning: since Redis is pretty fast, an outside user can try up to # 1 million passwords per second against a modern box. This means that you # should use very strong passwords, otherwise they will be very easy to break. # Note that because the password is really a shared secret between the client # and the server, and should not be memorized by any human, the password # can be easily a long string from /dev/urandom or whatever, so by using a # long and unguessable password no brute force attack will be possible. # Redis ACL users are defined in the following format: # # user <username> ... acl rules ... # # For example: # # user worker +@list +@connection ~jobs:* on >ffa9203c493aa99 # # The special username "default" is used for new connections. If this user # has the "nopass" rule, then new connections will be immediately authenticated # as the "default" user without the need of any password provided via the # AUTH command. Otherwise if the "default" user is not flagged with "nopass" # the connections will start in not authenticated state, and will require # AUTH (or the HELLO command AUTH option) in order to be authenticated and # start to work. # # The ACL rules that describe what a user can do are the following: # # on Enable the user: it is possible to authenticate as this user. # off Disable the user: it&#39;s no longer possible to authenticate # with this user, however the already authenticated connections # will still work. # skip-sanitize-payload RESTORE dump-payload sanitation is skipped. # sanitize-payload RESTORE dump-payload is sanitized (default). # +<command> Allow the execution of that command # -<command> Disallow the execution of that command # +@<category> Allow the execution of all the commands in such category # with valid categories are like @admin, @set, @sortedset, ... # and so forth, see the full list in the server.c file where # the Redis command table is described and defined. # The special category @all means all the commands, but currently # present in the server, and that will be loaded in the future # via modules. # +<command>|subcommand Allow a specific subcommand of an otherwise # disabled command. Note that this form is not # allowed as negative like -DEBUG|SEGFAULT, but # only additive starting with "+". # allcommands Alias for +@all. Note that it implies the ability to execute # all the future commands loaded via the modules system. # nocommands Alias for -@all. # ~<pattern> Add a pattern of keys that can be mentioned as part of # commands. For instance ~* allows all the keys. The pattern # is a glob-style pattern like the one of KEYS. # It is possible to specify multiple patterns. # allkeys Alias for ~* # resetkeys Flush the list of allowed keys patterns. # &<pattern> Add a glob-style pattern of Pub/Sub channels that can be # accessed by the user. It is possible to specify multiple channel # patterns. # allchannels Alias for &* # resetchannels Flush the list of allowed channel patterns. # ><password> Add this password to the list of valid password for the user. # For example >mypass will add "mypass" to the list. # This directive clears the "nopass" flag (see later). # <<password> Remove this password from the list of valid passwords. # nopass All the set passwords of the user are removed, and the user # is flagged as requiring no password: it means that every # password will work against this user. If this directive is # used for the default user, every new connection will be # immediately authenticated with the default user without # any explicit AUTH command required. Note that the "resetpass" # directive will clear this condition. # resetpass Flush the list of allowed passwords. Moreover removes the # "nopass" status. After "resetpass" the user has no associated # passwords and there is no way to authenticate without adding # some password (or setting it as "nopass" later). # reset Performs the following actions: resetpass, resetkeys, off, # -@all. The user returns to the same state it has immediately # after its creation. # # ACL rules can be specified in any order: for instance you can start with # passwords, then flags, or key patterns. However note that the additive # and subtractive rules will CHANGE MEANING depending on the ordering. # For instance see the following example: # # user alice on +@all -DEBUG ~* >somepassword # # This will allow "alice" to use all the commands with the exception of the # DEBUG command, since +@all added all the commands to the set of the commands # alice can use, and later DEBUG was removed. However if we invert the order # of two ACL rules the result will be different: # # user alice on -DEBUG +@all ~* >somepassword # # Now DEBUG was removed when alice had yet no commands in the set of allowed # commands, later all the commands are added, so the user will be able to # execute everything. # # Basically ACL rules are processed left-to-right. # # For more information about ACL configuration please refer to # the Redis web site at https://redis.io/topics/acl # ACL LOG # # The ACL Log tracks failed commands and authentication events associated # with ACLs. The ACL Log is useful to troubleshoot failed commands blocked # by ACLs. The ACL Log is stored in memory. You can reclaim memory with # ACL LOG RESET. Define the maximum entry length of the ACL Log below. acllog-max-len 128 # Using an external ACL file # # Instead of configuring users here in this file, it is possible to use # a stand-alone file just listing users. The two methods cannot be mixed: # if you configure users here and at the same time you activate the external # ACL file, the server will refuse to start. # # The format of the external ACL user file is exactly the same as the # format that is used inside redis.conf to describe users. # # aclfile /etc/redis/users.acl # IMPORTANT NOTE: starting with Redis 6 "requirepass" is just a compatibility # layer on top of the new ACL system. The option effect will be just setting # the password for the default user. Clients will still authenticate using # AUTH <password> as usually, or more explicitly with AUTH default <password> # if they follow the new protocol: both will work. # # The requirepass is not compatable with aclfile option and the ACL LOAD # command, these will cause requirepass to be ignored. # => Redis默认没有密码；可以在这里设置密码 # requirepass wpl19950815 # requirepass foobared # New users are initialized with restrictive permissions by default, via the # equivalent of this ACL rule &#39;off resetkeys -@all&#39;. Starting with Redis 6.2, it # is possible to manage access to Pub/Sub channels with ACL rules as well. The # default Pub/Sub channels permission if new users is controlled by the # acl-pubsub-default configuration directive, which accepts one of these values: # # allchannels: grants access to all Pub/Sub channels # resetchannels: revokes access to all Pub/Sub channels # # To ensure backward compatibility while upgrading Redis 6.0, acl-pubsub-default # defaults to the &#39;allchannels&#39; permission. # # Future compatibility note: it is very likely that in a future version of Redis # the directive&#39;s default of &#39;allchannels&#39; will be changed to &#39;resetchannels&#39; in # order to provide better out-of-the-box Pub/Sub security. Therefore, it is # recommended that you explicitly define Pub/Sub permissions for all users # rather then rely on implicit default values. Once you&#39;ve set explicit # Pub/Sub for all exisitn users, you should uncomment the following line. # # acl-pubsub-default resetchannels # Command renaming (DEPRECATED). # # ------------------------------------------------------------------------ # WARNING: avoid using this option if possible. Instead use ACLs to remove # commands from the default user, and put them only in some admin user you # create for administrative purposes. # ------------------------------------------------------------------------ # # It is possible to change the name of dangerous commands in a shared # environment. For instance the CONFIG command may be renamed into something # hard to guess so that it will still be available for internal-use tools # but not available for general clients. # # Example: # # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # # It is also possible to completely kill a command by renaming it into # an empty string: # # rename-command CONFIG "" # # Please note that changing the name of commands that are logged into the # AOF file or transmitted to replicas may cause problems. ################################### CLIENTS #################################### # Set the max number of connected clients at the same time. By default # this limit is set to 10000 clients, however if the Redis server is not # able to configure the process file limit to allow for the specified limit # the max number of allowed clients is set to the current file limit # minus 32 (as Redis reserves a few file descriptors for internal uses). # # Once the limit is reached Redis will close all the new connections sending # an error &#39;max number of clients reached&#39;. # # IMPORTANT: When Redis Cluster is used, the max number of connections is also # shared with the cluster bus: every node in the cluster will use two # connections, one incoming and another outgoing. It is important to size the # limit accordingly in case of very large clusters. # => 限制client最大连接数 # maxclients 10000 ############################## MEMORY MANAGEMENT ################################ # Set a memory usage limit to the specified amount of bytes. # When the memory limit is reached Redis will try to remove keys # according to the eviction policy selected (see maxmemory-policy). # # If Redis can&#39;t remove keys according to the policy, or if the policy is # set to &#39;noeviction&#39;, Redis will start to reply with errors to commands # that would use more memory, like SET, LPUSH, and so on, and will continue # to reply to read-only commands like GET. # # This option is usually useful when using Redis as an LRU or LFU cache, or to # set a hard memory limit for an instance (using the &#39;noeviction&#39; policy). # # WARNING: If you have replicas attached to an instance with maxmemory on, # the size of the output buffers needed to feed the replicas are subtracted # from the used memory count, so that network problems / resyncs will # not trigger a loop where keys are evicted, and in turn the output # buffer of replicas is full with DELs of keys evicted triggering the deletion # of more keys, and so forth until the database is completely emptied. # # In short... if you have replicas attached it is suggested that you set a lower # limit for maxmemory so that there is some free RAM on the system for replica # output buffers (but this is not needed if the policy is &#39;noeviction&#39;). # => 配置Redis最大内存容量;单位字节 # maxmemory <bytes> # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select one from the following behaviors: # # volatile-lru -> Evict using approximated LRU, only keys with an expire set. # allkeys-lru -> Evict any key using approximated LRU. # volatile-lfu -> Evict using approximated LFU, only keys with an expire set. # allkeys-lfu -> Evict any key using approximated LFU. # volatile-random -> Remove a random key having an expire set. # allkeys-random -> Remove a random key, any key. # volatile-ttl -> Remove the key with the nearest expire time (minor TTL) # noeviction -> Don&#39;t evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, when there are no suitable keys for # eviction, Redis will return an error on write operations that require # more memory. These are usually commands that create new keys, add data or # modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE, # SORT (due to the STORE argument), and EXEC (if the transaction includes any # command that requires memory). # # The default is: # => 内存到达上限的处理策略 # maxmemory-policy noeviction # LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated # algorithms (in order to save memory), so you can tune it for speed or # accuracy. By default Redis will check five keys and pick the one that was # used least recently, you can change the sample size using the following # configuration directive. # # The default of 5 produces good enough results. 10 Approximates very closely # true LRU but costs more CPU. 3 is faster but not very accurate. # # maxmemory-samples 5 # Eviction processing is designed to function well with the default setting. # If there is an unusually large amount of write traffic, this value may need to # be increased. Decreasing this value may reduce latency at the risk of # eviction processing effectiveness # 0 = minimum latency, 10 = default, 100 = process without regard to latency # # maxmemory-eviction-tenacity 10 # Starting from Redis 5, by default a replica will ignore its maxmemory setting # (unless it is promoted to master after a failover or manually). It means # that the eviction of keys will be just handled by the master, sending the # DEL commands to the replica as keys evict in the master side. # # This behavior ensures that masters and replicas stay consistent, and is usually # what you want, however if your replica is writable, or you want the replica # to have a different memory setting, and you are sure all the writes performed # to the replica are idempotent, then you may change this default (but be sure # to understand what you are doing). # # Note that since the replica by default does not evict, it may end using more # memory than the one set via maxmemory (there are certain buffers that may # be larger on the replica, or data structures may sometimes take more memory # and so forth). So make sure you monitor your replicas and make sure they # have enough memory to never hit a real out-of-memory condition before the # master hits the configured maxmemory setting. # # replica-ignore-maxmemory yes # Redis reclaims expired keys in two ways: upon access when those keys are # found to be expired, and also in background, in what is called the # "active expire key". The key space is slowly and interactively scanned # looking for expired keys to reclaim, so that it is possible to free memory # of keys that are expired and will never be accessed again in a short time. # # The default effort of the expire cycle will try to avoid having more than # ten percent of expired keys still in memory, and will try to avoid consuming # more than 25% of total memory and to add latency to the system. However # it is possible to increase the expire "effort" that is normally set to # "1", to a greater value, up to the value "10". At its maximum value the # system will use more CPU, longer cycles (and technically may introduce # more latency), and will tolerate less already expired keys still present # in the system. It&#39;s a tradeoff between memory, CPU and latency. # # active-expire-effort 1 ############################# LAZY FREEING #################################### # Redis has two primitives to delete keys. One is called DEL and is a blocking # deletion of the object. It means that the server stops processing new commands # in order to reclaim all the memory associated with an object in a synchronous # way. If the key deleted is associated with a small object, the time needed # in order to execute the DEL command is very small and comparable to most other # O(1) or O(log_N) commands in Redis. However if the key is associated with an # aggregated value containing millions of elements, the server can block for # a long time (even seconds) in order to complete the operation. # # For the above reasons Redis also offers non blocking deletion primitives # such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and # FLUSHDB commands, in order to reclaim memory in background. Those commands # are executed in constant time. Another thread will incrementally free the # object in the background as fast as possible. # # DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled. # It&#39;s up to the design of the application to understand when it is a good # idea to use one or the other. However the Redis server sometimes has to # delete keys or flush the whole database as a side effect of other operations. # Specifically Redis deletes objects independently of a user call in the # following scenarios: # # 1) On eviction, because of the maxmemory and maxmemory policy configurations, # in order to make room for new data, without going over the specified # memory limit. # 2) Because of expire: when a key with an associated time to live (see the # EXPIRE command) must be deleted from memory. # 3) Because of a side effect of a command that stores data on a key that may # already exist. For example the RENAME command may delete the old key # content when it is replaced with another one. Similarly SUNIONSTORE # or SORT with STORE option may delete existing keys. The SET command # itself removes any old content of the specified key in order to replace # it with the specified string. # 4) During replication, when a replica performs a full resynchronization with # its master, the content of the whole database is removed in order to # load the RDB file just transferred. # # In all the above cases the default is to delete objects in a blocking way, # like if DEL was called. However you can configure each case specifically # in order to instead release memory in a non-blocking way like if UNLINK # was called, using the following configuration directives. lazyfree-lazy-eviction no lazyfree-lazy-expire no lazyfree-lazy-server-del no replica-lazy-flush no # It is also possible, for the case when to replace the user code DEL calls # with UNLINK calls is not easy, to modify the default behavior of the DEL # command to act exactly like UNLINK, using the following configuration # directive: lazyfree-lazy-user-del no # FLUSHDB, FLUSHALL, and SCRIPT FLUSH support both asynchronous and synchronous # deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the # commands. When neither flag is passed, this directive will be used to determine # if the data should be deleted asynchronously. lazyfree-lazy-user-flush no ################################ THREADED I/O ################################# # Redis is mostly single threaded, however there are certain threaded # operations such as UNLINK, slow I/O accesses and other things that are # performed on side threads. # # Now it is also possible to handle Redis clients socket reads and writes # in different I/O threads. Since especially writing is so slow, normally # Redis users use pipelining in order to speed up the Redis performances per # core, and spawn multiple instances in order to scale more. Using I/O # threads it is possible to easily speedup two times Redis without resorting # to pipelining nor sharding of the instance. # # By default threading is disabled, we suggest enabling it only in machines # that have at least 4 or more cores, leaving at least one spare core. # Using more than 8 threads is unlikely to help much. We also recommend using # threaded I/O only if you actually have performance problems, with Redis # instances being able to use a quite big percentage of CPU time, otherwise # there is no point in using this feature. # # So for instance if you have a four cores boxes, try to use 2 or 3 I/O # threads, if you have a 8 cores, try to use 6 threads. In order to # enable I/O threads use the following configuration directive: # # io-threads 4 # # Setting io-threads to 1 will just use the main thread as usual. # When I/O threads are enabled, we only use threads for writes, that is # to thread the write(2) syscall and transfer the client buffers to the # socket. However it is also possible to enable threading of reads and # protocol parsing using the following configuration directive, by setting # it to yes: # # io-threads-do-reads no # # Usually threading reads doesn&#39;t help much. # # NOTE 1: This configuration directive cannot be changed at runtime via # CONFIG SET. Aso this feature currently does not work when SSL is # enabled. # # NOTE 2: If you want to test the Redis speedup using redis-benchmark, make # sure you also run the benchmark itself in threaded mode, using the # --threads option to match the number of Redis threads, otherwise you&#39;ll not # be able to notice the improvements. ############################ KERNEL OOM CONTROL ############################## # On Linux, it is possible to hint the kernel OOM killer on what processes # should be killed first when out of memory. # # Enabling this feature makes Redis actively control the oom_score_adj value # for all its processes, depending on their role. The default scores will # attempt to have background child processes killed before all others, and # replicas killed before masters. # # Redis supports three options: # # no: Don&#39;t make changes to oom-score-adj (default). # yes: Alias to "relative" see below. # absolute: Values in oom-score-adj-values are written as is to the kernel. # relative: Values are used relative to the initial value of oom_score_adj when # the server starts and are then clamped to a range of -1000 to 1000. # Because typically the initial value is 0, they will often match the # absolute values. oom-score-adj no # When oom-score-adj is used, this directive controls the specific values used # for master, replica and background child processes. Values range -2000 to # 2000 (higher means more likely to be killed). # # Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities) # can freely increase their value, but not decrease it below its initial # settings. This means that setting oom-score-adj to "relative" and setting the # oom-score-adj-values to positive values will always succeed. oom-score-adj-values 0 200 800 #################### KERNEL transparent hugepage CONTROL ###################### # Usually the kernel Transparent Huge Pages control is set to "madvise" or # or "never" by default (/sys/kernel/mm/transparent_hugepage/enabled), in which # case this config has no effect. On systems in which it is set to "always", # redis will attempt to disable it specifically for the redis process in order # to avoid latency problems specifically with fork(2) and CoW. # If for some reason you prefer to keep it enabled, you can set this config to # "no" and the kernel global to "always". disable-thp yes ############################## APPEND ONLY MODE ############################### # By default Redis asynchronously dumps the dataset on disk. This mode is # good enough in many applications, but an issue with the Redis process or # a power outage may result into a few minutes of writes lost (depending on # the configured save points). # # The Append Only File is an alternative persistence mode that provides # much better durability. For instance using the default data fsync policy # (see later in the config file) Redis can lose just one second of writes in a # dramatic event like a server power outage, or a single write if something # wrong with the Redis process itself happens, but the operating system is # still running correctly. # # AOF and RDB persistence can be enabled at the same time without problems. # If the AOF is enabled on startup Redis will load the AOF, that is the file # with the better durability guarantees. # # Please check http://redis.io/topics/persistence for more information. # => 是否开启aof模式；默认使用rdb方式持久化 appendonly no # The name of the append only file (default: "appendonly.aof") # => 使用aof持久化文件的名称 appendfilename "appendonly.aof" # The fsync() call tells the Operating System to actually write data on disk # instead of waiting for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP. # # Redis supports three different modes: # # no: don&#39;t fsync, just let the OS flush the data when it wants. Faster. # always: fsync after every write to the append only log. Slow, Safest. # everysec: fsync only one time every second. Compromise. # # The default is "everysec", as that&#39;s usually the right compromise between # speed and data safety. It&#39;s up to you to understand if you can relax this to # "no" that will let the operating system flush the output buffer when # it wants, for better performances (but if you can live with the idea of # some data loss consider the default persistence mode that&#39;s snapshotting), # or on the contrary, use "always" that&#39;s very slow but a bit safer than # everysec. # # More details please check the following article: # http://antirez.com/post/redis-persistence-demystified.html # # If unsure, use "everysec". # => 每次修改都会同步；耗费性能 # appendfsync always # => 每秒执行一次同步；可能会丢失这一秒的数据 appendfsync everysec # => 不执行同步；由操作系统自己同步 # appendfsync no # When the AOF fsync policy is set to always or everysec, and a background # saving process (a background save or AOF log background rewriting) is # performing a lot of I/O against the disk, in some Linux configurations # Redis may block too long on the fsync() call. Note that there is no fix for # this currently, as even performing fsync in a different thread will block # our synchronous write(2) call. # # In order to mitigate this problem it&#39;s possible to use the following option # that will prevent fsync() from being called in the main process while a # BGSAVE or BGREWRITEAOF is in progress. # # This means that while another child is saving, the durability of Redis is # the same as "appendfsync none". In practical terms, this means that it is # possible to lose up to 30 seconds of log in the worst scenario (with the # default Linux settings). # # If you have latency problems turn this to "yes". Otherwise leave it as # "no" that is the safest pick from the point of view of durability. no-appendfsync-on-rewrite no # Automatic rewrite of the append only file. # Redis is able to automatically rewrite the log file implicitly calling # BGREWRITEAOF when the AOF log size grows by the specified percentage. # # This is how it works: Redis remembers the size of the AOF file after the # latest rewrite (if no rewrite has happened since the restart, the size of # the AOF at startup is used). # # This base size is compared to the current size. If the current size is # bigger than the specified percentage, the rewrite is triggered. Also # you need to specify a minimal size for the AOF file to be rewritten, this # is useful to avoid rewriting the AOF file even if the percentage increase # is reached but it is still pretty small. # # Specify a percentage of zero in order to disable the automatic AOF # rewrite feature. auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # An AOF file may be found to be truncated at the end during the Redis # startup process, when the AOF data gets loaded back into memory. # This may happen when the system where Redis is running # crashes, especially when an ext4 filesystem is mounted without the # data=ordered option (however this can&#39;t happen when Redis itself # crashes or aborts but the operating system still works correctly). # # Redis can either exit with an error when this happens, or load as much # data as possible (the default now) and start if the AOF file is found # to be truncated at the end. The following option controls this behavior. # # If aof-load-truncated is set to yes, a truncated AOF file is loaded and # the Redis server starts emitting a log to inform the user of the event. # Otherwise if the option is set to no, the server aborts with an error # and refuses to start. When the option is set to no, the user requires # to fix the AOF file using the "redis-check-aof" utility before to restart # the server. # # Note that if the AOF file will be found to be corrupted in the middle # the server will still exit with an error. This option only applies when # Redis will try to read more data from the AOF file but not enough bytes # will be found. aof-load-truncated yes # When rewriting the AOF file, Redis is able to use an RDB preamble in the # AOF file for faster rewrites and recoveries. When this option is turned # on the rewritten AOF file is composed of two different stanzas: # # [RDB file][AOF tail] # # When loading, Redis recognizes that the AOF file starts with the "REDIS" # string and loads the prefixed RDB file, then continues loading the AOF # tail. aof-use-rdb-preamble yes ################################ LUA SCRIPTING ############################### # Max execution time of a Lua script in milliseconds. # # If the maximum execution time is reached Redis will log that a script is # still in execution after the maximum allowed time and will start to # reply to queries with an error. # # When a long running script exceeds the maximum execution time only the # SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be # used to stop a script that did not yet call any write commands. The second # is the only way to shut down the server in the case a write command was # already issued by the script but the user doesn&#39;t want to wait for the natural # termination of the script. # # Set it to 0 or a negative value for unlimited execution without warnings. lua-time-limit 5000 ################################ REDIS CLUSTER ############################### # Normal Redis instances can&#39;t be part of a Redis Cluster; only nodes that are # started as cluster nodes can. In order to start a Redis instance as a # cluster node enable the cluster support uncommenting the following: # # cluster-enabled yes # Every cluster node has a cluster configuration file. This file is not # intended to be edited by hand. It is created and updated by Redis nodes. # Every Redis Cluster node requires a different cluster configuration file. # Make sure that instances running in the same system do not have # overlapping cluster configuration file names. # # cluster-config-file nodes-6379.conf # Cluster node timeout is the amount of milliseconds a node must be unreachable # for it to be considered in failure state. # Most other internal time limits are a multiple of the node timeout. # # cluster-node-timeout 15000 # A replica of a failing master will avoid to start a failover if its data # looks too old. # # There is no simple way for a replica to actually have an exact measure of # its "data age", so the following two checks are performed: # # 1) If there are multiple replicas able to failover, they exchange messages # in order to try to give an advantage to the replica with the best # replication offset (more data from the master processed). # Replicas will try to get their rank by offset, and apply to the start # of the failover a delay proportional to their rank. # # 2) Every single replica computes the time of the last interaction with # its master. This can be the last ping or command received (if the master # is still in the "connected" state), or the time that elapsed since the # disconnection with the master (if the replication link is currently down). # If the last interaction is too old, the replica will not try to failover # at all. # # The point "2" can be tuned by user. Specifically a replica will not perform # the failover if, since the last interaction with the master, the time # elapsed is greater than: # # (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period # # So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor # is 10, and assuming a default repl-ping-replica-period of 10 seconds, the # replica will not try to failover if it was not able to talk with the master # for longer than 310 seconds. # # A large cluster-replica-validity-factor may allow replicas with too old data to failover # a master, while a too small value may prevent the cluster from being able to # elect a replica at all. # # For maximum availability, it is possible to set the cluster-replica-validity-factor # to a value of 0, which means, that replicas will always try to failover the # master regardless of the last time they interacted with the master. # (However they&#39;ll always try to apply a delay proportional to their # offset rank). # # Zero is the only value able to guarantee that when all the partitions heal # the cluster will always be able to continue. # # cluster-replica-validity-factor 10 # Cluster replicas are able to migrate to orphaned masters, that are masters # that are left without working replicas. This improves the cluster ability # to resist to failures as otherwise an orphaned master can&#39;t be failed over # in case of failure if it has no working replicas. # # Replicas migrate to orphaned masters only if there are still at least a # given number of other working replicas for their old master. This number # is the "migration barrier". A migration barrier of 1 means that a replica # will migrate only if there is at least 1 other working replica for its master # and so forth. It usually reflects the number of replicas you want for every # master in your cluster. # # Default is 1 (replicas migrate only if their masters remain with at least # one replica). To disable migration just set it to a very large value. # A value of 0 can be set but is useful only for debugging and dangerous # in production. # # cluster-migration-barrier 1 # By default Redis Cluster nodes stop accepting queries if they detect there # is at least a hash slot uncovered (no available node is serving it). # This way if the cluster is partially down (for example a range of hash slots # are no longer covered) all the cluster becomes, eventually, unavailable. # It automatically returns available as soon as all the slots are covered again. # # However sometimes you want the subset of the cluster which is working, # to continue to accept queries for the part of the key space that is still # covered. In order to do so, just set the cluster-require-full-coverage # option to no. # # cluster-require-full-coverage yes # This option, when set to yes, prevents replicas from trying to failover its # master during master failures. However the replica can still perform a # manual failover, if forced to do so. # # This is useful in different scenarios, especially in the case of multiple # data center operations, where we want one side to never be promoted if not # in the case of a total DC failure. # # cluster-replica-no-failover no # This option, when set to yes, allows nodes to serve read traffic while the # the cluster is in a down state, as long as it believes it owns the slots. # # This is useful for two cases. The first case is for when an application # doesn&#39;t require consistency of data during node failures or network partitions. # One example of this is a cache, where as long as the node has the data it # should be able to serve it. # # The second use case is for configurations that don&#39;t meet the recommended # three shards but want to enable cluster mode and scale later. A # master outage in a 1 or 2 shard configuration causes a read/write outage to the # entire cluster without this option set, with it set there is only a write outage. # Without a quorum of masters, slot ownership will not change automatically. # # cluster-allow-reads-when-down no # In order to setup your cluster make sure to read the documentation # available at http://redis.io web site. ########################## CLUSTER DOCKER/NAT support ######################## # In certain deployments, Redis Cluster nodes address discovery fails, because # addresses are NAT-ted or because ports are forwarded (the typical case is # Docker and other containers). # # In order to make Redis Cluster working in such environments, a static # configuration where each node knows its public address is needed. The # following two options are used for this scope, and are: # # * cluster-announce-ip # * cluster-announce-port # * cluster-announce-bus-port # # Each instructs the node about its address, client port, and cluster message # bus port. The information is then published in the header of the bus packets # so that other nodes will be able to correctly map the address of the node # publishing the information. # # If the above options are not used, the normal Redis Cluster auto-detection # will be used instead. # # Note that when remapped, the bus port may not be at the fixed offset of # clients port + 10000, so you can specify any port and bus-port depending # on how they get remapped. If the bus-port is not set, a fixed offset of # 10000 will be used as usual. # # Example: # # cluster-announce-ip 10.1.1.5 # cluster-announce-port 6379 # cluster-announce-bus-port 6380 ################################## SLOW LOG ################################### # The Redis Slow Log is a system to log queries that exceeded a specified # execution time. The execution time does not include the I/O operations # like talking with the client, sending the reply and so forth, # but just the time needed to actually execute the command (this is the only # stage of command execution where the thread is blocked and can not serve # other requests in the meantime). # # You can configure the slow log with two parameters: one tells Redis # what is the execution time, in microseconds, to exceed in order for the # command to get logged, and the other parameter is the length of the # slow log. When a new command is logged the oldest one is removed from the # queue of logged commands. # The following time is expressed in microseconds, so 1000000 is equivalent # to one second. Note that a negative number disables the slow log, while # a value of zero forces the logging of every command. slowlog-log-slower-than 10000 # There is no limit to this length. Just be aware that it will consume memory. # You can reclaim memory used by the slow log with SLOWLOG RESET. slowlog-max-len 128 ################################ LATENCY MONITOR ############################## # The Redis latency monitoring subsystem samples different operations # at runtime in order to collect data related to possible sources of # latency of a Redis instance. # # Via the LATENCY command this information is available to the user that can # print graphs and obtain reports. # # The system only logs operations that were performed in a time equal or # greater than the amount of milliseconds specified via the # latency-monitor-threshold configuration directive. When its value is set # to zero, the latency monitor is turned off. # # By default latency monitoring is disabled since it is mostly not needed # if you don&#39;t have latency issues, and collecting data has a performance # impact, that while very small, can be measured under big load. Latency # monitoring can easily be enabled at runtime using the command # "CONFIG SET latency-monitor-threshold <milliseconds>" if needed. latency-monitor-threshold 0 ############################# EVENT NOTIFICATION ############################## # Redis can notify Pub/Sub clients about events happening in the key space. # This feature is documented at http://redis.io/topics/notifications # # For instance if keyspace events notification is enabled, and a client # performs a DEL operation on key "foo" stored in the Database 0, two # messages will be published via Pub/Sub: # # PUBLISH __keyspace@0__:foo del # PUBLISH __keyevent@0__:del foo # # It is possible to select the events that Redis will notify among a set # of classes. Every class is identified by a single character: # # K Keyspace events, published with __keyspace@<db>__ prefix. # E Keyevent events, published with __keyevent@<db>__ prefix. # g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ... # $ String commands # l List commands # s Set commands # h Hash commands # z Sorted set commands # x Expired events (events generated every time a key expires) # e Evicted events (events generated when a key is evicted for maxmemory) # t Stream commands # m Key-miss events (Note: It is not included in the &#39;A&#39; class) # A Alias for g$lshzxet, so that the "AKE" string means all the events # (Except key-miss events which are excluded from &#39;A&#39; due to their # unique nature). # # The "notify-keyspace-events" takes as argument a string that is composed # of zero or multiple characters. The empty string means that notifications # are disabled. # # Example: to enable list and generic events, from the point of view of the # event name, use: # # notify-keyspace-events Elg # # Example 2: to get the stream of the expired keys subscribing to channel # name __keyevent@0__:expired use: # # notify-keyspace-events Ex # # By default all notifications are disabled because most users don&#39;t need # this feature and the feature has some overhead. Note that if you don&#39;t # specify at least one of K or E, no events will be delivered. notify-keyspace-events "" ############################### GOPHER SERVER ################################# # Redis contains an implementation of the Gopher protocol, as specified in # the RFC 1436 (https://www.ietf.org/rfc/rfc1436.txt). # # The Gopher protocol was very popular in the late &#39;90s. It is an alternative # to the web, and the implementation both server and client side is so simple # that the Redis server has just 100 lines of code in order to implement this # support. # # What do you do with Gopher nowadays? Well Gopher never *really* died, and # lately there is a movement in order for the Gopher more hierarchical content # composed of just plain text documents to be resurrected. Some want a simpler # internet, others believe that the mainstream internet became too much # controlled, and it&#39;s cool to create an alternative space for people that # want a bit of fresh air. # # Anyway for the 10nth birthday of the Redis, we gave it the Gopher protocol # as a gift. # # --- HOW IT WORKS? --- # # The Redis Gopher support uses the inline protocol of Redis, and specifically # two kind of inline requests that were anyway illegal: an empty request # or any request that starts with "/" (there are no Redis commands starting # with such a slash). Normal RESP2/RESP3 requests are completely out of the # path of the Gopher protocol implementation and are served as usual as well. # # If you open a connection to Redis when Gopher is enabled and send it # a string like "/foo", if there is a key named "/foo" it is served via the # Gopher protocol. # # In order to create a real Gopher "hole" (the name of a Gopher site in Gopher # talking), you likely need a script like the following: # # https://github.com/antirez/gopher2redis # # --- SECURITY WARNING --- # # If you plan to put Redis on the internet in a publicly accessible address # to server Gopher pages MAKE SURE TO SET A PASSWORD to the instance. # Once a password is set: # # 1. The Gopher server (when enabled, not by default) will still serve # content via Gopher. # 2. However other commands cannot be called before the client will # authenticate. # # So use the &#39;requirepass&#39; option to protect your instance. # # Note that Gopher is not currently supported when &#39;io-threads-do-reads&#39; # is enabled. # # To enable Gopher support, uncomment the following line and set the option # from no (the default) to yes. # # gopher-enabled no ############################### ADVANCED CONFIG ############################### # Hashes are encoded using a memory efficient data structure when they have a # small number of entries, and the biggest entry does not exceed a given # threshold. These thresholds can be configured using the following directives. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # Lists are also encoded in a special way to save a lot of space. # The number of entries allowed per internal list node can be specified # as a fixed maximum size or a maximum number of elements. # For a fixed maximum size, use -5 through -1, meaning: # -5: max size: 64 Kb <-- not recommended for normal workloads # -4: max size: 32 Kb <-- not recommended # -3: max size: 16 Kb <-- probably not recommended # -2: max size: 8 Kb <-- good # -1: max size: 4 Kb <-- good # Positive numbers mean store up to _exactly_ that number of elements # per list node. # The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size), # but if your use case is unique, adjust the settings as necessary. list-max-ziplist-size -2 # Lists may also be compressed. # Compress depth is the number of quicklist ziplist nodes from *each* side of # the list to *exclude* from compression. The head and tail of the list # are always uncompressed for fast push/pop operations. Settings are: # 0: disable all list compression # 1: depth 1 means "don&#39;t start compressing until after 1 node into the list, # going from either the head or tail" # So: [head]->node->node->...->node->[tail] # [head], [tail] will always be uncompressed; inner nodes will compress. # 2: [head]->[next]->node->node->...->node->[prev]->[tail] # 2 here means: don&#39;t compress head or head->next or tail->prev or tail, # but compress all nodes between them. # 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail] # etc. list-compress-depth 0 # Sets have a special encoding in just one case: when a set is composed # of just strings that happen to be integers in radix 10 in the range # of 64 bit signed integers. # The following configuration setting sets the limit in the size of the # set in order to use this special memory saving encoding. set-max-intset-entries 512 # Similarly to hashes and lists, sorted sets are also specially encoded in # order to save a lot of space. This encoding is only used when the length and # elements of a sorted set are below the following limits: zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog sparse representation bytes limit. The limit includes the # 16 bytes header. When an HyperLogLog using the sparse representation crosses # this limit, it is converted into the dense representation. # # A value greater than 16000 is totally useless, since at that point the # dense representation is more memory efficient. # # The suggested value is ~ 3000 in order to have the benefits of # the space efficient encoding without slowing down too much PFADD, # which is O(N) with the sparse encoding. The value can be raised to # ~ 10000 when CPU is not a concern, but space is, and the data set is # composed of many HyperLogLogs with cardinality in the 0 - 15000 range. hll-sparse-max-bytes 3000 # Streams macro node max size / items. The stream data structure is a radix # tree of big nodes that encode multiple items inside. Using this configuration # it is possible to configure how big a single node can be in bytes, and the # maximum number of items it may contain before switching to a new node when # appending new stream entries. If any of the following settings are set to # zero, the limit is ignored, so for instance it is possible to set just a # max entries limit by setting max-bytes to 0 and max-entries to the desired # value. stream-node-max-bytes 4096 stream-node-max-entries 100 # Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in # order to help rehashing the main Redis hash table (the one mapping top-level # keys to values). The hash table implementation Redis uses (see dict.c) # performs a lazy rehashing: the more operation you run into a hash table # that is rehashing, the more rehashing "steps" are performed, so if the # server is idle the rehashing is never complete and some more memory is used # by the hash table. # # The default is to use this millisecond 10 times every second in order to # actively rehash the main dictionaries, freeing memory when possible. # # If unsure: # use "activerehashing no" if you have hard latency requirements and it is # not a good thing in your environment that Redis can reply from time to time # to queries with 2 milliseconds delay. # # use "activerehashing yes" if you don&#39;t have such hard requirements but # want to free memory asap when possible. activerehashing yes # The client output buffer limits can be used to force disconnection of clients # that are not reading data from the server fast enough for some reason (a # common reason is that a Pub/Sub client can&#39;t consume messages as fast as the # publisher can produce them). # # The limit can be set differently for the three different classes of clients: # # normal -> normal clients including MONITOR clients # replica -> replica clients # pubsub -> clients subscribed to at least one pubsub channel or pattern # # The syntax of every client-output-buffer-limit directive is the following: # # client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds> # # A client is immediately disconnected once the hard limit is reached, or if # the soft limit is reached and remains reached for the specified number of # seconds (continuously). # So for instance if the hard limit is 32 megabytes and the soft limit is # 16 megabytes / 10 seconds, the client will get disconnected immediately # if the size of the output buffers reach 32 megabytes, but will also get # disconnected if the client reaches 16 megabytes and continuously overcomes # the limit for 10 seconds. # # By default normal clients are not limited because they don&#39;t receive data # without asking (in a push way), but just after a request, so only # asynchronous clients may create a scenario where data is requested faster # than it can read. # # Instead there is a default limit for pubsub and replica clients, since # subscribers and replicas receive data in a push fashion. # # Both the hard or the soft limit can be disabled by setting them to zero. client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Client query buffers accumulate new commands. They are limited to a fixed # amount by default in order to avoid that a protocol desynchronization (for # instance due to a bug in the client) will lead to unbound memory usage in # the query buffer. However you can configure it here if you have very special # needs, such us huge multi/exec requests or alike. # # client-query-buffer-limit 1gb # In the Redis protocol, bulk requests, that are, elements representing single # strings, are normally limited to 512 mb. However you can change this limit # here, but must be 1mb or greater # # proto-max-bulk-len 512mb # Redis calls an internal function to perform many background tasks, like # closing connections of clients in timeout, purging expired keys that are # never requested, and so forth. # # Not all tasks are performed with the same frequency, but Redis checks for # tasks to perform according to the specified "hz" value. # # By default "hz" is set to 10. Raising the value will use more CPU when # Redis is idle, but at the same time will make Redis more responsive when # there are many keys expiring at the same time, and timeouts may be # handled with more precision. # # The range is between 1 and 500, however a value over 100 is usually not # a good idea. Most users should use the default of 10 and raise this up to # 100 only in environments where very low latency is required. hz 10 # Normally it is useful to have an HZ value which is proportional to the # number of clients connected. This is useful in order, for instance, to # avoid too many clients are processed for each background task invocation # in order to avoid latency spikes. # # Since the default HZ value by default is conservatively set to 10, Redis # offers, and enables by default, the ability to use an adaptive HZ value # which will temporarily raise when there are many connected clients. # # When dynamic HZ is enabled, the actual configured HZ will be used # as a baseline, but multiples of the configured HZ value will be actually # used as needed once more clients are connected. In this way an idle # instance will use very little CPU time while a busy instance will be # more responsive. dynamic-hz yes # When a child rewrites the AOF file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. aof-rewrite-incremental-fsync yes # When redis saves RDB file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. rdb-save-incremental-fsync yes # Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good # idea to start with the default settings and only change them after investigating # how to improve the performances and how the keys LFU change over time, which # is possible to inspect via the OBJECT FREQ command. # # There are two tunable parameters in the Redis LFU implementation: the # counter logarithm factor and the counter decay time. It is important to # understand what the two parameters mean before changing them. # # The LFU counter is just 8 bits per key, it&#39;s maximum value is 255, so Redis # uses a probabilistic increment with logarithmic behavior. Given the value # of the old counter, when a key is accessed, the counter is incremented in # this way: # # 1. A random number R between 0 and 1 is extracted. # 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1). # 3. The counter is incremented only if R < P. # # The default lfu-log-factor is 10. This is a table of how the frequency # counter changes with a different number of accesses with different # logarithmic factors: # # +--------+------------+------------+------------+------------+------------+ # | factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits | # +--------+------------+------------+------------+------------+------------+ # | 0 | 104 | 255 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 1 | 18 | 49 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 10 | 10 | 18 | 142 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 100 | 8 | 11 | 49 | 143 | 255 | # +--------+------------+------------+------------+------------+------------+ # # NOTE: The above table was obtained by running the following commands: # # redis-benchmark -n 1000000 incr foo # redis-cli object freq foo # # NOTE 2: The counter initial value is 5 in order to give new objects a chance # to accumulate hits. # # The counter decay time is the time, in minutes, that must elapse in order # for the key counter to be divided by two (or decremented if it has a value # less <= 10). # # The default value for the lfu-decay-time is 1. A special value of 0 means to # decay the counter every time it happens to be scanned. # # lfu-log-factor 10 # lfu-decay-time 1 ########################### ACTIVE DEFRAGMENTATION ####################### # # What is active defragmentation? # ------------------------------- # # Active (online) defragmentation allows a Redis server to compact the # spaces left between small allocations and deallocations of data in memory, # thus allowing to reclaim back memory. # # Fragmentation is a natural process that happens with every allocator (but # less so with Jemalloc, fortunately) and certain workloads. Normally a server # restart is needed in order to lower the fragmentation, or at least to flush # away all the data and create it again. However thanks to this feature # implemented by Oran Agra for Redis 4.0 this process can happen at runtime # in a "hot" way, while the server is running. # # Basically when the fragmentation is over a certain level (see the # configuration options below) Redis will start to create new copies of the # values in contiguous memory regions by exploiting certain specific Jemalloc # features (in order to understand if an allocation is causing fragmentation # and to allocate it in a better place), and at the same time, will release the # old copies of the data. This process, repeated incrementally for all the keys # will cause the fragmentation to drop back to normal values. # # Important things to understand: # # 1. This feature is disabled by default, and only works if you compiled Redis # to use the copy of Jemalloc we ship with the source code of Redis. # This is the default with Linux builds. # # 2. You never need to enable this feature if you don&#39;t have fragmentation # issues. # # 3. Once you experience fragmentation, you can enable this feature when # needed with the command "CONFIG SET activedefrag yes". # # The configuration parameters are able to fine tune the behavior of the # defragmentation process. If you are not sure about what they mean it is # a good idea to leave the defaults untouched. # Enabled active defragmentation # activedefrag no # Minimum amount of fragmentation waste to start active defrag # active-defrag-ignore-bytes 100mb # Minimum percentage of fragmentation to start active defrag # active-defrag-threshold-lower 10 # Maximum percentage of fragmentation at which we use maximum effort # active-defrag-threshold-upper 100 # Minimal effort for defrag in CPU percentage, to be used when the lower # threshold is reached # active-defrag-cycle-min 1 # Maximal effort for defrag in CPU percentage, to be used when the upper # threshold is reached # active-defrag-cycle-max 25 # Maximum number of set/hash/zset/list fields that will be processed from # the main dictionary scan # active-defrag-max-scan-fields 1000 # Jemalloc background thread for purging will be enabled by default jemalloc-bg-thread yes # It is possible to pin different threads and processes of Redis to specific # CPUs in your system, in order to maximize the performances of the server. # This is useful both in order to pin different Redis threads in different # CPUs, but also in order to make sure that multiple Redis instances running # in the same host will be pinned to different CPUs. # # Normally you can do this using the "taskset" command, however it is also # possible to this via Redis configuration directly, both in Linux and FreeBSD. # # You can pin the server/IO threads, bio threads, aof rewrite child process, and # the bgsave child process. The syntax to specify the cpu list is the same as # the taskset command: # # Set redis server/io threads to cpu affinity 0,2,4,6: # server_cpulist 0-7:2 # # Set bio threads to cpu affinity 1,3: # bio_cpulist 1,3 # # Set aof rewrite child process to cpu affinity 8,9,10,11: # aof_rewrite_cpulist 8-11 # # Set bgsave child process to cpu affinity 1,10,11 # bgsave_cpulist 1,10-11 # In some cases redis will emit warnings and even refuse to start if it detects # that the system is in bad state, it is possible to suppress these warnings # by setting the following config which takes a space delimited list of warnings # to suppress # # ignore-warnings ARM64-COW-BUG'><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta itemprop=name content="CODE'NOTE"><meta itemprop=description content='Redis.Config 配置文件# 经常使用的配置使用“# =>”方式写了注释
# Redis configuration file example. # # Note that in order to read the configuration file, Redis must be # started with the file path as first argument: # # ./redis-server /path/to/redis.conf # Note on units: when memory size is needed, it is possible to specify # it in the usual form of 1k 5GB 4M and so forth: # # => 单位设置 # 1k => 1000 bytes # 1kb => 1024 bytes # 1m => 1000000 bytes # 1mb => 1024*1024 bytes # 1g => 1000000000 bytes # 1gb => 1024*1024*1024 bytes # # => Redis单位对大小写不敏感 # units are case insensitive so 1GB 1Gb 1gB are all the same. # => 包含：可以把多个Redis.conf组合成一个conf ################################## INCLUDES ################################### # Include one or more other config files here. This is useful if you # have a standard template that goes to all Redis servers but also need # to customize a few per-server settings. Include files can include # other files, so use this wisely. # # Note that option "include" won&#39;t be rewritten by command "CONFIG REWRITE" # from admin or Redis Sentinel. Since Redis always uses the last processed # line as value of a configuration directive, you&#39;d better put includes # at the beginning of this file to avoid overwriting config change at runtime. # # If instead you are interested in using includes to override configuration # options, it is better to use include as the last line. # # include /path/to/local.conf # include /path/to/other.conf ################################## MODULES ##################################### # Load modules at startup. If the server is not able to load modules # it will abort. It is possible to use multiple loadmodule directives. # # loadmodule /path/to/my_module.so # loadmodule /path/to/other_module.so # => 网络配置 ################################## NETWORK ##################################### # By default, if no "bind" configuration directive is specified, Redis listens # for connections from all available network interfaces on the host machine. # It is possible to listen to just one or multiple selected interfaces using # the "bind" configuration directive, followed by one or more IP addresses. # Each address can be prefixed by "-", which means that redis will not fail to # start if the address is not available. Being not available only refers to # addresses that does not correspond to any network interfece. Addresses that # are already in use will always fail, and unsupported protocols will always BE # silently skipped. # # Examples: # # bind 192.168.1.100 10.0.0.1 # listens on two specific IPv4 addresses # bind 127.0.0.1 ::1 # listens on loopback IPv4 and IPv6 # bind * -::* # like the default, all available interfaces # # ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the # internet, binding to all the interfaces is dangerous and will expose the # instance to everybody on the internet. So by default we uncomment the # following bind directive, that will force Redis to listen only on the # IPv4 and IPv6 (if available) loopback interface addresses (this means Redis # will only be able to accept client connections from the same host that it is # running on). # # IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES # JUST COMMENT OUT THE FOLLOWING LINE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # => 绑定的IP:127.0.0.1只能是本地使用，如果需要提供给远程访问，需要设置为*统配或者指定IP bind 0.0.0.0 -::1 # Protected mode is a layer of security protection, in order to avoid that # Redis instances left open on the internet are accessed and exploited. # # When protected mode is on and if: # # 1) The server is not binding explicitly to a set of addresses using the # "bind" directive. # 2) No password is configured. # # The server only accepts connections from clients connecting from the # IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain # sockets. # # By default protected mode is enabled. You should disable it only if # you are sure you want clients from other hosts to connect to Redis # even if no authentication is configured, nor a specific set of interfaces # are explicitly listed using the "bind" directive. # => 是否受保护模式 protected-mode yes # Accept connections on the specified port, default is 6379 (IANA #815344). # If port 0 is specified Redis will not listen on a TCP socket. # => 端口设置 port 6379 # TCP listen() backlog. # # In high requests-per-second environments you need a high backlog in order # to avoid slow clients connection issues. Note that the Linux kernel # will silently truncate it to the value of /proc/sys/net/core/somaxconn so # make sure to raise both the value of somaxconn and tcp_max_syn_backlog # in order to get the desired effect. tcp-backlog 511 # Unix socket. # # Specify the path for the Unix socket that will be used to listen for # incoming connections. There is no default, so Redis will not listen # on a unix socket when not specified. # # unixsocket /run/redis.sock # unixsocketperm 700 # Close the connection after a client is idle for N seconds (0 to disable) timeout 0 # TCP keepalive. # # If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence # of communication. This is useful for two reasons: # # 1) Detect dead peers. # 2) Force network equipment in the middle to consider the connection to be # alive. # # On Linux, the specified value (in seconds) is the period used to send ACKs. # Note that to close the connection the double of the time is needed. # On other kernels the period depends on the kernel configuration. # # A reasonable value for this option is 300 seconds, which is the new # Redis default starting with Redis 3.2.1. tcp-keepalive 300 ################################# TLS/SSL ##################################### # By default, TLS/SSL is disabled. To enable it, the "tls-port" configuration # directive can be used to define TLS-listening ports. To enable TLS on the # default port, use: # # port 0 # tls-port 6379 # Configure a X.509 certificate and private key to use for authenticating the # server to connected clients, masters or cluster peers. These files should be # PEM formatted. # # tls-cert-file redis.crt # tls-key-file redis.key # Normally Redis uses the same certificate for both server functions (accepting # connections) and client functions (replicating from a master, establishing # cluster bus connections, etc.). # # Sometimes certificates are issued with attributes that designate them as # client-only or server-only certificates. In that case it may be desired to use # different certificates for incoming (server) and outgoing (client) # connections. To do that, use the following directives: # # tls-client-cert-file client.crt # tls-client-key-file client.key # Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange: # # tls-dh-params-file redis.dh # Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL # clients and peers. Redis requires an explicit configuration of at least one # of these, and will not implicitly use the system wide configuration. # # tls-ca-cert-file ca.crt # tls-ca-cert-dir /etc/ssl/certs # By default, clients (including replica servers) on a TLS port are required # to authenticate using valid client side certificates. # # If "no" is specified, client certificates are not required and not accepted. # If "optional" is specified, client certificates are accepted and must be # valid if provided, but are not required. # # tls-auth-clients no # tls-auth-clients optional # By default, a Redis replica does not attempt to establish a TLS connection # with its master. # # Use the following directive to enable TLS on replication links. # # tls-replication yes # By default, the Redis Cluster bus uses a plain TCP connection. To enable # TLS for the bus protocol, use the following directive: # # tls-cluster yes # By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended # that older formally deprecated versions are kept disabled to reduce the attack surface. # You can explicitly specify TLS versions to support. # Allowed values are case insensitive and include "TLSv1", "TLSv1.1", "TLSv1.2", # "TLSv1.3" (OpenSSL >= 1.1.1) or any combination. # To enable only TLSv1.2 and TLSv1.3, use: # # tls-protocols "TLSv1.2 TLSv1.3" # Configure allowed ciphers. See the ciphers(1ssl) manpage for more information # about the syntax of this string. # # Note: this configuration applies only to <= TLSv1.2. # # tls-ciphers DEFAULT:!MEDIUM # Configure allowed TLSv1.3 ciphersuites. See the ciphers(1ssl) manpage for more # information about the syntax of this string, and specifically for TLSv1.3 # ciphersuites. # # tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256 # When choosing a cipher, use the server&#39;s preference instead of the client # preference. By default, the server follows the client&#39;s preference. # # tls-prefer-server-ciphers yes # By default, TLS session caching is enabled to allow faster and less expensive # reconnections by clients that support it. Use the following directive to disable # caching. # # tls-session-caching no # Change the default number of TLS sessions cached. A zero value sets the cache # to unlimited size. The default size is 20480. # # tls-session-cache-size 5000 # Change the default timeout of cached TLS sessions. The default timeout is 300 # seconds. # # tls-session-cache-timeout 60 ################################# GENERAL ##################################### # By default Redis does not run as a daemon. Use &#39;yes&#39; if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. # When Redis is supervised by upstart or systemd, this parameter has no impact. # => 是否以守护进程的方式运行，默认是no daemonize yes # If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # requires "expect stop" in your upstart job config # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # on startup, and updating Redis status on a regular # basis. # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal "process is ready." # They do not enable continuous pings back to your supervisor. # # The default is "no". To run under upstart/systemd, you can simply uncomment # the line below: # # supervised auto # If a pid file is specified, Redis writes it where specified at startup # and removes it at exit. # # When the server runs non daemonized, no pid file is created if none is # specified in the configuration. When the server is daemonized, the pid file # is used even if not specified, defaulting to "/var/run/redis.pid". # # Creating a pid file is best effort: if Redis is not able to create it # nothing bad happens, the server will start and run normally. # # Note that on modern Linux systems "/run/redis.pid" is more conforming # and should be used instead. # => 如果以守护进程方式运行，需要指定一个守护进程的文件 pidfile /var/run/redis_6379.pid # Specify the server verbosity level. # This can be one of: # debug (a lot of information, useful for development/testing) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) # => 设置日志级别 loglevel notice # Specify the log file name. Also the empty string can be used to force # Redis to log on the standard output. Note that if you use standard # output for logging but daemonize, logs will be sent to /dev/null # => 设置日志的存储位置 logfile "" # To enable logging to the system logger, just set &#39;syslog-enabled&#39; to yes, # and optionally update the other syslog parameters to suit your needs. # syslog-enabled no # Specify the syslog identity. # syslog-ident redis # Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7. # syslog-facility local0 # To disable the built in crash log, which will possibly produce cleaner core # dumps when they are needed, uncomment the following: # # crash-log-enabled no # To disable the fast memory check that&#39;s run as part of the crash log, which # will possibly let redis terminate sooner, uncomment the following: # # crash-memcheck-enabled no # Set the number of databases. The default database is DB 0, you can select # a different one on a per-connection basis using SELECT <dbid> where # dbid is a number between 0 and &#39;databases&#39;-1 # => 默认数据库数量 databases 16 # By default Redis shows an ASCII art logo only when started to log to the # standard output and if the standard output is a TTY and syslog logging is # disabled. Basically this means that normally a logo is displayed only in # interactive sessions. # # However it is possible to force the pre-4.0 behavior and always show a # ASCII art logo in startup logs by setting the following option to yes. # => 是否总是显示Logo always-show-logo no # By default, Redis modifies the process title (as seen in &#39;top&#39; and &#39;ps&#39;) to # provide some runtime information. It is possible to disable this and leave # the process name as executed by setting the following to no. set-proc-title yes # When changing the process title, Redis uses the following template to construct # the modified title. # # Template variables are specified in curly brackets. The following variables are # supported: # # {title} Name of process as executed if parent, or type of child process. # {listen-addr} Bind address or &#39;*&#39; followed by TCP or TLS port listening on, or # Unix socket if only that&#39;s available. # {server-mode} Special mode, i.e. "[sentinel]" or "[cluster]". # {port} TCP port listening on, or 0. # {tls-port} TLS port listening on, or 0. # {unixsocket} Unix domain socket listening on, or "". # {config-file} Name of configuration file used. # proc-title-template "{title} {listen-addr} {server-mode}" ################################ SNAPSHOTTING ################################ # Save the DB to disk. # # save <seconds> <changes> # # Redis will save the DB if both the given number of seconds and the given # number of write operations against the DB occurred. # # Snapshotting can be completely disabled with a single empty string argument # as in following example: # # save "" # # Unless specified otherwise, by default Redis will save the DB: # * After 3600 seconds (an hour) if at least 1 key changed # * After 300 seconds (5 minutes) if at least 100 keys changed # * After 60 seconds if at least 10000 keys changed # # You can set these explicitly by uncommenting the three following lines. # # => 快照持久化规则设置 # => 如果3600秒内，至少一个Key进行了修改，就会进行持久化 # save 3600 1 # save 300 100 # save 60 10000 # By default Redis will stop accepting writes if RDB snapshots are enabled # (at least one save point) and the latest background save failed. # This will make the user aware (in a hard way) that data is not persisting # on disk properly, otherwise chances are that no one will notice and some # disaster will happen. # # If the background saving process will start working again Redis will # automatically allow writes again. # # However if you have setup your proper monitoring of the Redis server # and persistence, you may want to disable this feature so that Redis will # continue to work as usual even if there are problems with disk, # permissions, and so forth. # => 持久化出错时，是否继续工作 stop-writes-on-bgsave-error yes # Compress string objects using LZF when dump .rdb databases? # By default compression is enabled as it&#39;s almost always a win. # If you want to save some CPU in the saving child set it to &#39;no&#39; but # the dataset will likely be bigger if you have compressible values or keys. # => 是否压缩rdb文件；压缩是需要耗费一些CPU资源的 rdbcompression yes # Since version 5 of RDB a CRC64 checksum is placed at the end of the file. # This makes the format more resistant to corruption but there is a performance # hit to pay (around 10%) when saving and loading RDB files, so you can disable it # for maximum performances. # # RDB files created with checksum disabled have a checksum of zero that will # tell the loading code to skip the check. # => 保存rdb文件时，是否校验rdb文件 rdbchecksum yes # Enables or disables full sanitation checks for ziplist and listpack etc when # loading an RDB or RESTORE payload. This reduces the chances of a assertion or # crash later on while processing commands. # Options: # no - Never perform full sanitation # yes - Always perform full sanitation # clients - Perform full sanitation only for user connections. # Excludes: RDB files, RESTORE commands received from the master # connection, and client connections which have the # skip-sanitize-payload ACL flag. # The default should be &#39;clients&#39; but since it currently affects cluster # resharding via MIGRATE, it is temporarily set to &#39;no&#39; by default. # # sanitize-dump-payload no # The filename where to dump the DB dbfilename dump.rdb # Remove RDB files used by replication in instances without persistence # enabled. By default this option is disabled, however there are environments # where for regulations or other security concerns, RDB files persisted on # disk by masters in order to feed replicas, or stored on disk by replicas # in order to load them for the initial synchronization, should be deleted # ASAP. Note that this option ONLY WORKS in instances that have both AOF # and RDB persistence disabled, otherwise is completely ignored. # # An alternative (and sometimes better) way to obtain the same effect is # to use diskless replication on both master and replicas instances. However # in the case of replicas, diskless is not always an option. rdb-del-sync-files no # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the &#39;dbfilename&#39; configuration directive. # # The Append Only File will also be created inside this directory. # # Note that you must specify a directory here, not a file name. # => rdb文件保存目录 dir ./ ################################# REPLICATION ################################# # Master-Replica replication. Use replicaof to make a Redis instance a copy of # another Redis server. A few things to understand ASAP about Redis replication. # # +------------------+ +---------------+ # | Master | ---> | Replica | # | (receive writes) | | (exact copy) | # +------------------+ +---------------+ # # 1) Redis replication is asynchronous, but you can configure a master to # stop accepting writes if it appears to be not connected with at least # a given number of replicas. # 2) Redis replicas are able to perform a partial resynchronization with the # master if the replication link is lost for a relatively small amount of # time. You may want to configure the replication backlog size (see the next # sections of this file) with a sensible value depending on your needs. # 3) Replication is automatic and does not need user intervention. After a # network partition replicas automatically try to reconnect to masters # and resynchronize with them. # # replicaof <masterip> <masterport> # If the master is password protected (using the "requirepass" configuration # directive below) it is possible to tell the replica to authenticate before # starting the replication synchronization process, otherwise the master will # refuse the replica request. # # masterauth <master-password> # # However this is not enough if you are using Redis ACLs (for Redis version # 6 or greater), and the default user is not capable of running the PSYNC # command and/or other commands needed for replication. In this case it&#39;s # better to configure a special user to use with replication, and specify the # masteruser configuration as such: # # masteruser <username> # # When masteruser is specified, the replica will authenticate against its # master using the new AUTH form: AUTH <username> <password>. # When a replica loses its connection with the master, or when the replication # is still in progress, the replica can act in two different ways: # # 1) if replica-serve-stale-data is set to &#39;yes&#39; (the default) the replica will # still reply to client requests, possibly with out of date data, or the # data set may just be empty if this is the first synchronization. # # 2) If replica-serve-stale-data is set to &#39;no&#39; the replica will reply with # an error "SYNC with master in progress" to all commands except: # INFO, REPLICAOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE, # UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST, # HOST and LATENCY. # replica-serve-stale-data yes # You can configure a replica instance to accept writes or not. Writing against # a replica instance may be useful to store some ephemeral data (because data # written on a replica will be easily deleted after resync with the master) but # may also cause problems if clients are writing to it because of a # misconfiguration. # # Since Redis 2.6 by default replicas are read-only. # # Note: read only replicas are not designed to be exposed to untrusted clients # on the internet. It&#39;s just a protection layer against misuse of the instance. # Still a read only replica exports by default all the administrative commands # such as CONFIG, DEBUG, and so forth. To a limited extent you can improve # security of read only replicas using &#39;rename-command&#39; to shadow all the # administrative / dangerous commands. replica-read-only yes # Replication SYNC strategy: disk or socket. # # New replicas and reconnecting replicas that are not able to continue the # replication process just receiving differences, need to do what is called a # "full synchronization". An RDB file is transmitted from the master to the # replicas. # # The transmission can happen in two different ways: # # 1) Disk-backed: The Redis master creates a new process that writes the RDB # file on disk. Later the file is transferred by the parent # process to the replicas incrementally. # 2) Diskless: The Redis master creates a new process that directly writes the # RDB file to replica sockets, without touching the disk at all. # # With disk-backed replication, while the RDB file is generated, more replicas # can be queued and served with the RDB file as soon as the current child # producing the RDB file finishes its work. With diskless replication instead # once the transfer starts, new replicas arriving will be queued and a new # transfer will start when the current one terminates. # # When diskless replication is used, the master waits a configurable amount of # time (in seconds) before starting the transfer in the hope that multiple # replicas will arrive and the transfer can be parallelized. # # With slow disks and fast (large bandwidth) networks, diskless replication # works better. repl-diskless-sync no # When diskless replication is enabled, it is possible to configure the delay # the server waits in order to spawn the child that transfers the RDB via socket # to the replicas. # # This is important since once the transfer starts, it is not possible to serve # new replicas arriving, that will be queued for the next RDB transfer, so the # server waits a delay in order to let more replicas arrive. # # The delay is specified in seconds, and by default is 5 seconds. To disable # it entirely just set it to 0 seconds and the transfer will start ASAP. repl-diskless-sync-delay 5 # ----------------------------------------------------------------------------- # WARNING: RDB diskless load is experimental. Since in this setup the replica # does not immediately store an RDB on disk, it may cause data loss during # failovers. RDB diskless load + Redis modules not handling I/O reads may also # cause Redis to abort in case of I/O errors during the initial synchronization # stage with the master. Use only if you know what you are doing. # ----------------------------------------------------------------------------- # # Replica can load the RDB it reads from the replication link directly from the # socket, or store the RDB to a file and read that file after it was completely # received from the master. # # In many cases the disk is slower than the network, and storing and loading # the RDB file may increase replication time (and even increase the master&#39;s # Copy on Write memory and salve buffers). # However, parsing the RDB file directly from the socket may mean that we have # to flush the contents of the current database before the full rdb was # received. For this reason we have the following options: # # "disabled" - Don&#39;t use diskless load (store the rdb file to the disk first) # "on-empty-db" - Use diskless load only when it is completely safe. # "swapdb" - Keep a copy of the current db contents in RAM while parsing # the data directly from the socket. note that this requires # sufficient memory, if you don&#39;t have it, you risk an OOM kill. repl-diskless-load disabled # Replicas send PINGs to server in a predefined interval. It&#39;s possible to # change this interval with the repl_ping_replica_period option. The default # value is 10 seconds. # # repl-ping-replica-period 10 # The following option sets the replication timeout for: # # 1) Bulk transfer I/O during SYNC, from the point of view of replica. # 2) Master timeout from the point of view of replicas (data, pings). # 3) Replica timeout from the point of view of masters (REPLCONF ACK pings). # # It is important to make sure that this value is greater than the value # specified for repl-ping-replica-period otherwise a timeout will be detected # every time there is low traffic between the master and the replica. The default # value is 60 seconds. # # repl-timeout 60 # Disable TCP_NODELAY on the replica socket after SYNC? # # If you select "yes" Redis will use a smaller number of TCP packets and # less bandwidth to send data to replicas. But this can add a delay for # the data to appear on the replica side, up to 40 milliseconds with # Linux kernels using a default configuration. # # If you select "no" the delay for data to appear on the replica side will # be reduced but more bandwidth will be used for replication. # # By default we optimize for low latency, but in very high traffic conditions # or when the master and replicas are many hops away, turning this to "yes" may # be a good idea. repl-disable-tcp-nodelay no # Set the replication backlog size. The backlog is a buffer that accumulates # replica data when replicas are disconnected for some time, so that when a # replica wants to reconnect again, often a full resync is not needed, but a # partial resync is enough, just passing the portion of data the replica # missed while disconnected. # # The bigger the replication backlog, the longer the replica can endure the # disconnect and later be able to perform a partial resynchronization. # # The backlog is only allocated if there is at least one replica connected. # # repl-backlog-size 1mb # After a master has no connected replicas for some time, the backlog will be # freed. The following option configures the amount of seconds that need to # elapse, starting from the time the last replica disconnected, for the backlog # buffer to be freed. # # Note that replicas never free the backlog for timeout, since they may be # promoted to masters later, and should be able to correctly "partially # resynchronize" with other replicas: hence they should always accumulate backlog. # # A value of 0 means to never release the backlog. # # repl-backlog-ttl 3600 # The replica priority is an integer number published by Redis in the INFO # output. It is used by Redis Sentinel in order to select a replica to promote # into a master if the master is no longer working correctly. # # A replica with a low priority number is considered better for promotion, so # for instance if there are three replicas with priority 10, 100, 25 Sentinel # will pick the one with priority 10, that is the lowest. # # However a special priority of 0 marks the replica as not able to perform the # role of master, so a replica with priority of 0 will never be selected by # Redis Sentinel for promotion. # # By default the priority is 100. replica-priority 100 # It is possible for a master to stop accepting writes if there are less than # N replicas connected, having a lag less or equal than M seconds. # # The N replicas need to be in "online" state. # # The lag in seconds, that must be <= the specified value, is calculated from # the last ping received from the replica, that is usually sent every second. # # This option does not GUARANTEE that N replicas will accept the write, but # will limit the window of exposure for lost writes in case not enough replicas # are available, to the specified number of seconds. # # For example to require at least 3 replicas with a lag <= 10 seconds use: # # min-replicas-to-write 3 # min-replicas-max-lag 10 # # Setting one or the other to 0 disables the feature. # # By default min-replicas-to-write is set to 0 (feature disabled) and # min-replicas-max-lag is set to 10. # A Redis master is able to list the address and port of the attached # replicas in different ways. For example the "INFO replication" section # offers this information, which is used, among other tools, by # Redis Sentinel in order to discover replica instances. # Another place where this info is available is in the output of the # "ROLE" command of a master. # # The listed IP address and port normally reported by a replica is # obtained in the following way: # # IP: The address is auto detected by checking the peer address # of the socket used by the replica to connect with the master. # # Port: The port is communicated by the replica during the replication # handshake, and is normally the port that the replica is using to # listen for connections. # # However when port forwarding or Network Address Translation (NAT) is # used, the replica may actually be reachable via different IP and port # pairs. The following two options can be used by a replica in order to # report to its master a specific set of IP and port, so that both INFO # and ROLE will report those values. # # There is no need to use both the options if you need to override just # the port or the IP address. # # replica-announce-ip 5.5.5.5 # replica-announce-port 1234 ############################### KEYS TRACKING ################################# # Redis implements server assisted support for client side caching of values. # This is implemented using an invalidation table that remembers, using # a radix key indexed by key name, what clients have which keys. In turn # this is used in order to send invalidation messages to clients. Please # check this page to understand more about the feature: # # https://redis.io/topics/client-side-caching # # When tracking is enabled for a client, all the read only queries are assumed # to be cached: this will force Redis to store information in the invalidation # table. When keys are modified, such information is flushed away, and # invalidation messages are sent to the clients. However if the workload is # heavily dominated by reads, Redis could use more and more memory in order # to track the keys fetched by many clients. # # For this reason it is possible to configure a maximum fill value for the # invalidation table. By default it is set to 1M of keys, and once this limit # is reached, Redis will start to evict keys in the invalidation table # even if they were not modified, just to reclaim memory: this will in turn # force the clients to invalidate the cached values. Basically the table # maximum size is a trade off between the memory you want to spend server # side to track information about who cached what, and the ability of clients # to retain cached objects in memory. # # If you set the value to 0, it means there are no limits, and Redis will # retain as many keys as needed in the invalidation table. # In the "stats" INFO section, you can find information about the number of # keys in the invalidation table at every given moment. # # Note: when key tracking is used in broadcasting mode, no memory is used # in the server side so this setting is useless. # # tracking-table-max-keys 1000000 ################################## SECURITY ################################### # Warning: since Redis is pretty fast, an outside user can try up to # 1 million passwords per second against a modern box. This means that you # should use very strong passwords, otherwise they will be very easy to break. # Note that because the password is really a shared secret between the client # and the server, and should not be memorized by any human, the password # can be easily a long string from /dev/urandom or whatever, so by using a # long and unguessable password no brute force attack will be possible. # Redis ACL users are defined in the following format: # # user <username> ... acl rules ... # # For example: # # user worker +@list +@connection ~jobs:* on >ffa9203c493aa99 # # The special username "default" is used for new connections. If this user # has the "nopass" rule, then new connections will be immediately authenticated # as the "default" user without the need of any password provided via the # AUTH command. Otherwise if the "default" user is not flagged with "nopass" # the connections will start in not authenticated state, and will require # AUTH (or the HELLO command AUTH option) in order to be authenticated and # start to work. # # The ACL rules that describe what a user can do are the following: # # on Enable the user: it is possible to authenticate as this user. # off Disable the user: it&#39;s no longer possible to authenticate # with this user, however the already authenticated connections # will still work. # skip-sanitize-payload RESTORE dump-payload sanitation is skipped. # sanitize-payload RESTORE dump-payload is sanitized (default). # +<command> Allow the execution of that command # -<command> Disallow the execution of that command # +@<category> Allow the execution of all the commands in such category # with valid categories are like @admin, @set, @sortedset, ... # and so forth, see the full list in the server.c file where # the Redis command table is described and defined. # The special category @all means all the commands, but currently # present in the server, and that will be loaded in the future # via modules. # +<command>|subcommand Allow a specific subcommand of an otherwise # disabled command. Note that this form is not # allowed as negative like -DEBUG|SEGFAULT, but # only additive starting with "+". # allcommands Alias for +@all. Note that it implies the ability to execute # all the future commands loaded via the modules system. # nocommands Alias for -@all. # ~<pattern> Add a pattern of keys that can be mentioned as part of # commands. For instance ~* allows all the keys. The pattern # is a glob-style pattern like the one of KEYS. # It is possible to specify multiple patterns. # allkeys Alias for ~* # resetkeys Flush the list of allowed keys patterns. # &<pattern> Add a glob-style pattern of Pub/Sub channels that can be # accessed by the user. It is possible to specify multiple channel # patterns. # allchannels Alias for &* # resetchannels Flush the list of allowed channel patterns. # ><password> Add this password to the list of valid password for the user. # For example >mypass will add "mypass" to the list. # This directive clears the "nopass" flag (see later). # <<password> Remove this password from the list of valid passwords. # nopass All the set passwords of the user are removed, and the user # is flagged as requiring no password: it means that every # password will work against this user. If this directive is # used for the default user, every new connection will be # immediately authenticated with the default user without # any explicit AUTH command required. Note that the "resetpass" # directive will clear this condition. # resetpass Flush the list of allowed passwords. Moreover removes the # "nopass" status. After "resetpass" the user has no associated # passwords and there is no way to authenticate without adding # some password (or setting it as "nopass" later). # reset Performs the following actions: resetpass, resetkeys, off, # -@all. The user returns to the same state it has immediately # after its creation. # # ACL rules can be specified in any order: for instance you can start with # passwords, then flags, or key patterns. However note that the additive # and subtractive rules will CHANGE MEANING depending on the ordering. # For instance see the following example: # # user alice on +@all -DEBUG ~* >somepassword # # This will allow "alice" to use all the commands with the exception of the # DEBUG command, since +@all added all the commands to the set of the commands # alice can use, and later DEBUG was removed. However if we invert the order # of two ACL rules the result will be different: # # user alice on -DEBUG +@all ~* >somepassword # # Now DEBUG was removed when alice had yet no commands in the set of allowed # commands, later all the commands are added, so the user will be able to # execute everything. # # Basically ACL rules are processed left-to-right. # # For more information about ACL configuration please refer to # the Redis web site at https://redis.io/topics/acl # ACL LOG # # The ACL Log tracks failed commands and authentication events associated # with ACLs. The ACL Log is useful to troubleshoot failed commands blocked # by ACLs. The ACL Log is stored in memory. You can reclaim memory with # ACL LOG RESET. Define the maximum entry length of the ACL Log below. acllog-max-len 128 # Using an external ACL file # # Instead of configuring users here in this file, it is possible to use # a stand-alone file just listing users. The two methods cannot be mixed: # if you configure users here and at the same time you activate the external # ACL file, the server will refuse to start. # # The format of the external ACL user file is exactly the same as the # format that is used inside redis.conf to describe users. # # aclfile /etc/redis/users.acl # IMPORTANT NOTE: starting with Redis 6 "requirepass" is just a compatibility # layer on top of the new ACL system. The option effect will be just setting # the password for the default user. Clients will still authenticate using # AUTH <password> as usually, or more explicitly with AUTH default <password> # if they follow the new protocol: both will work. # # The requirepass is not compatable with aclfile option and the ACL LOAD # command, these will cause requirepass to be ignored. # => Redis默认没有密码；可以在这里设置密码 # requirepass wpl19950815 # requirepass foobared # New users are initialized with restrictive permissions by default, via the # equivalent of this ACL rule &#39;off resetkeys -@all&#39;. Starting with Redis 6.2, it # is possible to manage access to Pub/Sub channels with ACL rules as well. The # default Pub/Sub channels permission if new users is controlled by the # acl-pubsub-default configuration directive, which accepts one of these values: # # allchannels: grants access to all Pub/Sub channels # resetchannels: revokes access to all Pub/Sub channels # # To ensure backward compatibility while upgrading Redis 6.0, acl-pubsub-default # defaults to the &#39;allchannels&#39; permission. # # Future compatibility note: it is very likely that in a future version of Redis # the directive&#39;s default of &#39;allchannels&#39; will be changed to &#39;resetchannels&#39; in # order to provide better out-of-the-box Pub/Sub security. Therefore, it is # recommended that you explicitly define Pub/Sub permissions for all users # rather then rely on implicit default values. Once you&#39;ve set explicit # Pub/Sub for all exisitn users, you should uncomment the following line. # # acl-pubsub-default resetchannels # Command renaming (DEPRECATED). # # ------------------------------------------------------------------------ # WARNING: avoid using this option if possible. Instead use ACLs to remove # commands from the default user, and put them only in some admin user you # create for administrative purposes. # ------------------------------------------------------------------------ # # It is possible to change the name of dangerous commands in a shared # environment. For instance the CONFIG command may be renamed into something # hard to guess so that it will still be available for internal-use tools # but not available for general clients. # # Example: # # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # # It is also possible to completely kill a command by renaming it into # an empty string: # # rename-command CONFIG "" # # Please note that changing the name of commands that are logged into the # AOF file or transmitted to replicas may cause problems. ################################### CLIENTS #################################### # Set the max number of connected clients at the same time. By default # this limit is set to 10000 clients, however if the Redis server is not # able to configure the process file limit to allow for the specified limit # the max number of allowed clients is set to the current file limit # minus 32 (as Redis reserves a few file descriptors for internal uses). # # Once the limit is reached Redis will close all the new connections sending # an error &#39;max number of clients reached&#39;. # # IMPORTANT: When Redis Cluster is used, the max number of connections is also # shared with the cluster bus: every node in the cluster will use two # connections, one incoming and another outgoing. It is important to size the # limit accordingly in case of very large clusters. # => 限制client最大连接数 # maxclients 10000 ############################## MEMORY MANAGEMENT ################################ # Set a memory usage limit to the specified amount of bytes. # When the memory limit is reached Redis will try to remove keys # according to the eviction policy selected (see maxmemory-policy). # # If Redis can&#39;t remove keys according to the policy, or if the policy is # set to &#39;noeviction&#39;, Redis will start to reply with errors to commands # that would use more memory, like SET, LPUSH, and so on, and will continue # to reply to read-only commands like GET. # # This option is usually useful when using Redis as an LRU or LFU cache, or to # set a hard memory limit for an instance (using the &#39;noeviction&#39; policy). # # WARNING: If you have replicas attached to an instance with maxmemory on, # the size of the output buffers needed to feed the replicas are subtracted # from the used memory count, so that network problems / resyncs will # not trigger a loop where keys are evicted, and in turn the output # buffer of replicas is full with DELs of keys evicted triggering the deletion # of more keys, and so forth until the database is completely emptied. # # In short... if you have replicas attached it is suggested that you set a lower # limit for maxmemory so that there is some free RAM on the system for replica # output buffers (but this is not needed if the policy is &#39;noeviction&#39;). # => 配置Redis最大内存容量;单位字节 # maxmemory <bytes> # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select one from the following behaviors: # # volatile-lru -> Evict using approximated LRU, only keys with an expire set. # allkeys-lru -> Evict any key using approximated LRU. # volatile-lfu -> Evict using approximated LFU, only keys with an expire set. # allkeys-lfu -> Evict any key using approximated LFU. # volatile-random -> Remove a random key having an expire set. # allkeys-random -> Remove a random key, any key. # volatile-ttl -> Remove the key with the nearest expire time (minor TTL) # noeviction -> Don&#39;t evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, when there are no suitable keys for # eviction, Redis will return an error on write operations that require # more memory. These are usually commands that create new keys, add data or # modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE, # SORT (due to the STORE argument), and EXEC (if the transaction includes any # command that requires memory). # # The default is: # => 内存到达上限的处理策略 # maxmemory-policy noeviction # LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated # algorithms (in order to save memory), so you can tune it for speed or # accuracy. By default Redis will check five keys and pick the one that was # used least recently, you can change the sample size using the following # configuration directive. # # The default of 5 produces good enough results. 10 Approximates very closely # true LRU but costs more CPU. 3 is faster but not very accurate. # # maxmemory-samples 5 # Eviction processing is designed to function well with the default setting. # If there is an unusually large amount of write traffic, this value may need to # be increased. Decreasing this value may reduce latency at the risk of # eviction processing effectiveness # 0 = minimum latency, 10 = default, 100 = process without regard to latency # # maxmemory-eviction-tenacity 10 # Starting from Redis 5, by default a replica will ignore its maxmemory setting # (unless it is promoted to master after a failover or manually). It means # that the eviction of keys will be just handled by the master, sending the # DEL commands to the replica as keys evict in the master side. # # This behavior ensures that masters and replicas stay consistent, and is usually # what you want, however if your replica is writable, or you want the replica # to have a different memory setting, and you are sure all the writes performed # to the replica are idempotent, then you may change this default (but be sure # to understand what you are doing). # # Note that since the replica by default does not evict, it may end using more # memory than the one set via maxmemory (there are certain buffers that may # be larger on the replica, or data structures may sometimes take more memory # and so forth). So make sure you monitor your replicas and make sure they # have enough memory to never hit a real out-of-memory condition before the # master hits the configured maxmemory setting. # # replica-ignore-maxmemory yes # Redis reclaims expired keys in two ways: upon access when those keys are # found to be expired, and also in background, in what is called the # "active expire key". The key space is slowly and interactively scanned # looking for expired keys to reclaim, so that it is possible to free memory # of keys that are expired and will never be accessed again in a short time. # # The default effort of the expire cycle will try to avoid having more than # ten percent of expired keys still in memory, and will try to avoid consuming # more than 25% of total memory and to add latency to the system. However # it is possible to increase the expire "effort" that is normally set to # "1", to a greater value, up to the value "10". At its maximum value the # system will use more CPU, longer cycles (and technically may introduce # more latency), and will tolerate less already expired keys still present # in the system. It&#39;s a tradeoff between memory, CPU and latency. # # active-expire-effort 1 ############################# LAZY FREEING #################################### # Redis has two primitives to delete keys. One is called DEL and is a blocking # deletion of the object. It means that the server stops processing new commands # in order to reclaim all the memory associated with an object in a synchronous # way. If the key deleted is associated with a small object, the time needed # in order to execute the DEL command is very small and comparable to most other # O(1) or O(log_N) commands in Redis. However if the key is associated with an # aggregated value containing millions of elements, the server can block for # a long time (even seconds) in order to complete the operation. # # For the above reasons Redis also offers non blocking deletion primitives # such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and # FLUSHDB commands, in order to reclaim memory in background. Those commands # are executed in constant time. Another thread will incrementally free the # object in the background as fast as possible. # # DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled. # It&#39;s up to the design of the application to understand when it is a good # idea to use one or the other. However the Redis server sometimes has to # delete keys or flush the whole database as a side effect of other operations. # Specifically Redis deletes objects independently of a user call in the # following scenarios: # # 1) On eviction, because of the maxmemory and maxmemory policy configurations, # in order to make room for new data, without going over the specified # memory limit. # 2) Because of expire: when a key with an associated time to live (see the # EXPIRE command) must be deleted from memory. # 3) Because of a side effect of a command that stores data on a key that may # already exist. For example the RENAME command may delete the old key # content when it is replaced with another one. Similarly SUNIONSTORE # or SORT with STORE option may delete existing keys. The SET command # itself removes any old content of the specified key in order to replace # it with the specified string. # 4) During replication, when a replica performs a full resynchronization with # its master, the content of the whole database is removed in order to # load the RDB file just transferred. # # In all the above cases the default is to delete objects in a blocking way, # like if DEL was called. However you can configure each case specifically # in order to instead release memory in a non-blocking way like if UNLINK # was called, using the following configuration directives. lazyfree-lazy-eviction no lazyfree-lazy-expire no lazyfree-lazy-server-del no replica-lazy-flush no # It is also possible, for the case when to replace the user code DEL calls # with UNLINK calls is not easy, to modify the default behavior of the DEL # command to act exactly like UNLINK, using the following configuration # directive: lazyfree-lazy-user-del no # FLUSHDB, FLUSHALL, and SCRIPT FLUSH support both asynchronous and synchronous # deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the # commands. When neither flag is passed, this directive will be used to determine # if the data should be deleted asynchronously. lazyfree-lazy-user-flush no ################################ THREADED I/O ################################# # Redis is mostly single threaded, however there are certain threaded # operations such as UNLINK, slow I/O accesses and other things that are # performed on side threads. # # Now it is also possible to handle Redis clients socket reads and writes # in different I/O threads. Since especially writing is so slow, normally # Redis users use pipelining in order to speed up the Redis performances per # core, and spawn multiple instances in order to scale more. Using I/O # threads it is possible to easily speedup two times Redis without resorting # to pipelining nor sharding of the instance. # # By default threading is disabled, we suggest enabling it only in machines # that have at least 4 or more cores, leaving at least one spare core. # Using more than 8 threads is unlikely to help much. We also recommend using # threaded I/O only if you actually have performance problems, with Redis # instances being able to use a quite big percentage of CPU time, otherwise # there is no point in using this feature. # # So for instance if you have a four cores boxes, try to use 2 or 3 I/O # threads, if you have a 8 cores, try to use 6 threads. In order to # enable I/O threads use the following configuration directive: # # io-threads 4 # # Setting io-threads to 1 will just use the main thread as usual. # When I/O threads are enabled, we only use threads for writes, that is # to thread the write(2) syscall and transfer the client buffers to the # socket. However it is also possible to enable threading of reads and # protocol parsing using the following configuration directive, by setting # it to yes: # # io-threads-do-reads no # # Usually threading reads doesn&#39;t help much. # # NOTE 1: This configuration directive cannot be changed at runtime via # CONFIG SET. Aso this feature currently does not work when SSL is # enabled. # # NOTE 2: If you want to test the Redis speedup using redis-benchmark, make # sure you also run the benchmark itself in threaded mode, using the # --threads option to match the number of Redis threads, otherwise you&#39;ll not # be able to notice the improvements. ############################ KERNEL OOM CONTROL ############################## # On Linux, it is possible to hint the kernel OOM killer on what processes # should be killed first when out of memory. # # Enabling this feature makes Redis actively control the oom_score_adj value # for all its processes, depending on their role. The default scores will # attempt to have background child processes killed before all others, and # replicas killed before masters. # # Redis supports three options: # # no: Don&#39;t make changes to oom-score-adj (default). # yes: Alias to "relative" see below. # absolute: Values in oom-score-adj-values are written as is to the kernel. # relative: Values are used relative to the initial value of oom_score_adj when # the server starts and are then clamped to a range of -1000 to 1000. # Because typically the initial value is 0, they will often match the # absolute values. oom-score-adj no # When oom-score-adj is used, this directive controls the specific values used # for master, replica and background child processes. Values range -2000 to # 2000 (higher means more likely to be killed). # # Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities) # can freely increase their value, but not decrease it below its initial # settings. This means that setting oom-score-adj to "relative" and setting the # oom-score-adj-values to positive values will always succeed. oom-score-adj-values 0 200 800 #################### KERNEL transparent hugepage CONTROL ###################### # Usually the kernel Transparent Huge Pages control is set to "madvise" or # or "never" by default (/sys/kernel/mm/transparent_hugepage/enabled), in which # case this config has no effect. On systems in which it is set to "always", # redis will attempt to disable it specifically for the redis process in order # to avoid latency problems specifically with fork(2) and CoW. # If for some reason you prefer to keep it enabled, you can set this config to # "no" and the kernel global to "always". disable-thp yes ############################## APPEND ONLY MODE ############################### # By default Redis asynchronously dumps the dataset on disk. This mode is # good enough in many applications, but an issue with the Redis process or # a power outage may result into a few minutes of writes lost (depending on # the configured save points). # # The Append Only File is an alternative persistence mode that provides # much better durability. For instance using the default data fsync policy # (see later in the config file) Redis can lose just one second of writes in a # dramatic event like a server power outage, or a single write if something # wrong with the Redis process itself happens, but the operating system is # still running correctly. # # AOF and RDB persistence can be enabled at the same time without problems. # If the AOF is enabled on startup Redis will load the AOF, that is the file # with the better durability guarantees. # # Please check http://redis.io/topics/persistence for more information. # => 是否开启aof模式；默认使用rdb方式持久化 appendonly no # The name of the append only file (default: "appendonly.aof") # => 使用aof持久化文件的名称 appendfilename "appendonly.aof" # The fsync() call tells the Operating System to actually write data on disk # instead of waiting for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP. # # Redis supports three different modes: # # no: don&#39;t fsync, just let the OS flush the data when it wants. Faster. # always: fsync after every write to the append only log. Slow, Safest. # everysec: fsync only one time every second. Compromise. # # The default is "everysec", as that&#39;s usually the right compromise between # speed and data safety. It&#39;s up to you to understand if you can relax this to # "no" that will let the operating system flush the output buffer when # it wants, for better performances (but if you can live with the idea of # some data loss consider the default persistence mode that&#39;s snapshotting), # or on the contrary, use "always" that&#39;s very slow but a bit safer than # everysec. # # More details please check the following article: # http://antirez.com/post/redis-persistence-demystified.html # # If unsure, use "everysec". # => 每次修改都会同步；耗费性能 # appendfsync always # => 每秒执行一次同步；可能会丢失这一秒的数据 appendfsync everysec # => 不执行同步；由操作系统自己同步 # appendfsync no # When the AOF fsync policy is set to always or everysec, and a background # saving process (a background save or AOF log background rewriting) is # performing a lot of I/O against the disk, in some Linux configurations # Redis may block too long on the fsync() call. Note that there is no fix for # this currently, as even performing fsync in a different thread will block # our synchronous write(2) call. # # In order to mitigate this problem it&#39;s possible to use the following option # that will prevent fsync() from being called in the main process while a # BGSAVE or BGREWRITEAOF is in progress. # # This means that while another child is saving, the durability of Redis is # the same as "appendfsync none". In practical terms, this means that it is # possible to lose up to 30 seconds of log in the worst scenario (with the # default Linux settings). # # If you have latency problems turn this to "yes". Otherwise leave it as # "no" that is the safest pick from the point of view of durability. no-appendfsync-on-rewrite no # Automatic rewrite of the append only file. # Redis is able to automatically rewrite the log file implicitly calling # BGREWRITEAOF when the AOF log size grows by the specified percentage. # # This is how it works: Redis remembers the size of the AOF file after the # latest rewrite (if no rewrite has happened since the restart, the size of # the AOF at startup is used). # # This base size is compared to the current size. If the current size is # bigger than the specified percentage, the rewrite is triggered. Also # you need to specify a minimal size for the AOF file to be rewritten, this # is useful to avoid rewriting the AOF file even if the percentage increase # is reached but it is still pretty small. # # Specify a percentage of zero in order to disable the automatic AOF # rewrite feature. auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # An AOF file may be found to be truncated at the end during the Redis # startup process, when the AOF data gets loaded back into memory. # This may happen when the system where Redis is running # crashes, especially when an ext4 filesystem is mounted without the # data=ordered option (however this can&#39;t happen when Redis itself # crashes or aborts but the operating system still works correctly). # # Redis can either exit with an error when this happens, or load as much # data as possible (the default now) and start if the AOF file is found # to be truncated at the end. The following option controls this behavior. # # If aof-load-truncated is set to yes, a truncated AOF file is loaded and # the Redis server starts emitting a log to inform the user of the event. # Otherwise if the option is set to no, the server aborts with an error # and refuses to start. When the option is set to no, the user requires # to fix the AOF file using the "redis-check-aof" utility before to restart # the server. # # Note that if the AOF file will be found to be corrupted in the middle # the server will still exit with an error. This option only applies when # Redis will try to read more data from the AOF file but not enough bytes # will be found. aof-load-truncated yes # When rewriting the AOF file, Redis is able to use an RDB preamble in the # AOF file for faster rewrites and recoveries. When this option is turned # on the rewritten AOF file is composed of two different stanzas: # # [RDB file][AOF tail] # # When loading, Redis recognizes that the AOF file starts with the "REDIS" # string and loads the prefixed RDB file, then continues loading the AOF # tail. aof-use-rdb-preamble yes ################################ LUA SCRIPTING ############################### # Max execution time of a Lua script in milliseconds. # # If the maximum execution time is reached Redis will log that a script is # still in execution after the maximum allowed time and will start to # reply to queries with an error. # # When a long running script exceeds the maximum execution time only the # SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be # used to stop a script that did not yet call any write commands. The second # is the only way to shut down the server in the case a write command was # already issued by the script but the user doesn&#39;t want to wait for the natural # termination of the script. # # Set it to 0 or a negative value for unlimited execution without warnings. lua-time-limit 5000 ################################ REDIS CLUSTER ############################### # Normal Redis instances can&#39;t be part of a Redis Cluster; only nodes that are # started as cluster nodes can. In order to start a Redis instance as a # cluster node enable the cluster support uncommenting the following: # # cluster-enabled yes # Every cluster node has a cluster configuration file. This file is not # intended to be edited by hand. It is created and updated by Redis nodes. # Every Redis Cluster node requires a different cluster configuration file. # Make sure that instances running in the same system do not have # overlapping cluster configuration file names. # # cluster-config-file nodes-6379.conf # Cluster node timeout is the amount of milliseconds a node must be unreachable # for it to be considered in failure state. # Most other internal time limits are a multiple of the node timeout. # # cluster-node-timeout 15000 # A replica of a failing master will avoid to start a failover if its data # looks too old. # # There is no simple way for a replica to actually have an exact measure of # its "data age", so the following two checks are performed: # # 1) If there are multiple replicas able to failover, they exchange messages # in order to try to give an advantage to the replica with the best # replication offset (more data from the master processed). # Replicas will try to get their rank by offset, and apply to the start # of the failover a delay proportional to their rank. # # 2) Every single replica computes the time of the last interaction with # its master. This can be the last ping or command received (if the master # is still in the "connected" state), or the time that elapsed since the # disconnection with the master (if the replication link is currently down). # If the last interaction is too old, the replica will not try to failover # at all. # # The point "2" can be tuned by user. Specifically a replica will not perform # the failover if, since the last interaction with the master, the time # elapsed is greater than: # # (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period # # So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor # is 10, and assuming a default repl-ping-replica-period of 10 seconds, the # replica will not try to failover if it was not able to talk with the master # for longer than 310 seconds. # # A large cluster-replica-validity-factor may allow replicas with too old data to failover # a master, while a too small value may prevent the cluster from being able to # elect a replica at all. # # For maximum availability, it is possible to set the cluster-replica-validity-factor # to a value of 0, which means, that replicas will always try to failover the # master regardless of the last time they interacted with the master. # (However they&#39;ll always try to apply a delay proportional to their # offset rank). # # Zero is the only value able to guarantee that when all the partitions heal # the cluster will always be able to continue. # # cluster-replica-validity-factor 10 # Cluster replicas are able to migrate to orphaned masters, that are masters # that are left without working replicas. This improves the cluster ability # to resist to failures as otherwise an orphaned master can&#39;t be failed over # in case of failure if it has no working replicas. # # Replicas migrate to orphaned masters only if there are still at least a # given number of other working replicas for their old master. This number # is the "migration barrier". A migration barrier of 1 means that a replica # will migrate only if there is at least 1 other working replica for its master # and so forth. It usually reflects the number of replicas you want for every # master in your cluster. # # Default is 1 (replicas migrate only if their masters remain with at least # one replica). To disable migration just set it to a very large value. # A value of 0 can be set but is useful only for debugging and dangerous # in production. # # cluster-migration-barrier 1 # By default Redis Cluster nodes stop accepting queries if they detect there # is at least a hash slot uncovered (no available node is serving it). # This way if the cluster is partially down (for example a range of hash slots # are no longer covered) all the cluster becomes, eventually, unavailable. # It automatically returns available as soon as all the slots are covered again. # # However sometimes you want the subset of the cluster which is working, # to continue to accept queries for the part of the key space that is still # covered. In order to do so, just set the cluster-require-full-coverage # option to no. # # cluster-require-full-coverage yes # This option, when set to yes, prevents replicas from trying to failover its # master during master failures. However the replica can still perform a # manual failover, if forced to do so. # # This is useful in different scenarios, especially in the case of multiple # data center operations, where we want one side to never be promoted if not # in the case of a total DC failure. # # cluster-replica-no-failover no # This option, when set to yes, allows nodes to serve read traffic while the # the cluster is in a down state, as long as it believes it owns the slots. # # This is useful for two cases. The first case is for when an application # doesn&#39;t require consistency of data during node failures or network partitions. # One example of this is a cache, where as long as the node has the data it # should be able to serve it. # # The second use case is for configurations that don&#39;t meet the recommended # three shards but want to enable cluster mode and scale later. A # master outage in a 1 or 2 shard configuration causes a read/write outage to the # entire cluster without this option set, with it set there is only a write outage. # Without a quorum of masters, slot ownership will not change automatically. # # cluster-allow-reads-when-down no # In order to setup your cluster make sure to read the documentation # available at http://redis.io web site. ########################## CLUSTER DOCKER/NAT support ######################## # In certain deployments, Redis Cluster nodes address discovery fails, because # addresses are NAT-ted or because ports are forwarded (the typical case is # Docker and other containers). # # In order to make Redis Cluster working in such environments, a static # configuration where each node knows its public address is needed. The # following two options are used for this scope, and are: # # * cluster-announce-ip # * cluster-announce-port # * cluster-announce-bus-port # # Each instructs the node about its address, client port, and cluster message # bus port. The information is then published in the header of the bus packets # so that other nodes will be able to correctly map the address of the node # publishing the information. # # If the above options are not used, the normal Redis Cluster auto-detection # will be used instead. # # Note that when remapped, the bus port may not be at the fixed offset of # clients port + 10000, so you can specify any port and bus-port depending # on how they get remapped. If the bus-port is not set, a fixed offset of # 10000 will be used as usual. # # Example: # # cluster-announce-ip 10.1.1.5 # cluster-announce-port 6379 # cluster-announce-bus-port 6380 ################################## SLOW LOG ################################### # The Redis Slow Log is a system to log queries that exceeded a specified # execution time. The execution time does not include the I/O operations # like talking with the client, sending the reply and so forth, # but just the time needed to actually execute the command (this is the only # stage of command execution where the thread is blocked and can not serve # other requests in the meantime). # # You can configure the slow log with two parameters: one tells Redis # what is the execution time, in microseconds, to exceed in order for the # command to get logged, and the other parameter is the length of the # slow log. When a new command is logged the oldest one is removed from the # queue of logged commands. # The following time is expressed in microseconds, so 1000000 is equivalent # to one second. Note that a negative number disables the slow log, while # a value of zero forces the logging of every command. slowlog-log-slower-than 10000 # There is no limit to this length. Just be aware that it will consume memory. # You can reclaim memory used by the slow log with SLOWLOG RESET. slowlog-max-len 128 ################################ LATENCY MONITOR ############################## # The Redis latency monitoring subsystem samples different operations # at runtime in order to collect data related to possible sources of # latency of a Redis instance. # # Via the LATENCY command this information is available to the user that can # print graphs and obtain reports. # # The system only logs operations that were performed in a time equal or # greater than the amount of milliseconds specified via the # latency-monitor-threshold configuration directive. When its value is set # to zero, the latency monitor is turned off. # # By default latency monitoring is disabled since it is mostly not needed # if you don&#39;t have latency issues, and collecting data has a performance # impact, that while very small, can be measured under big load. Latency # monitoring can easily be enabled at runtime using the command # "CONFIG SET latency-monitor-threshold <milliseconds>" if needed. latency-monitor-threshold 0 ############################# EVENT NOTIFICATION ############################## # Redis can notify Pub/Sub clients about events happening in the key space. # This feature is documented at http://redis.io/topics/notifications # # For instance if keyspace events notification is enabled, and a client # performs a DEL operation on key "foo" stored in the Database 0, two # messages will be published via Pub/Sub: # # PUBLISH __keyspace@0__:foo del # PUBLISH __keyevent@0__:del foo # # It is possible to select the events that Redis will notify among a set # of classes. Every class is identified by a single character: # # K Keyspace events, published with __keyspace@<db>__ prefix. # E Keyevent events, published with __keyevent@<db>__ prefix. # g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ... # $ String commands # l List commands # s Set commands # h Hash commands # z Sorted set commands # x Expired events (events generated every time a key expires) # e Evicted events (events generated when a key is evicted for maxmemory) # t Stream commands # m Key-miss events (Note: It is not included in the &#39;A&#39; class) # A Alias for g$lshzxet, so that the "AKE" string means all the events # (Except key-miss events which are excluded from &#39;A&#39; due to their # unique nature). # # The "notify-keyspace-events" takes as argument a string that is composed # of zero or multiple characters. The empty string means that notifications # are disabled. # # Example: to enable list and generic events, from the point of view of the # event name, use: # # notify-keyspace-events Elg # # Example 2: to get the stream of the expired keys subscribing to channel # name __keyevent@0__:expired use: # # notify-keyspace-events Ex # # By default all notifications are disabled because most users don&#39;t need # this feature and the feature has some overhead. Note that if you don&#39;t # specify at least one of K or E, no events will be delivered. notify-keyspace-events "" ############################### GOPHER SERVER ################################# # Redis contains an implementation of the Gopher protocol, as specified in # the RFC 1436 (https://www.ietf.org/rfc/rfc1436.txt). # # The Gopher protocol was very popular in the late &#39;90s. It is an alternative # to the web, and the implementation both server and client side is so simple # that the Redis server has just 100 lines of code in order to implement this # support. # # What do you do with Gopher nowadays? Well Gopher never *really* died, and # lately there is a movement in order for the Gopher more hierarchical content # composed of just plain text documents to be resurrected. Some want a simpler # internet, others believe that the mainstream internet became too much # controlled, and it&#39;s cool to create an alternative space for people that # want a bit of fresh air. # # Anyway for the 10nth birthday of the Redis, we gave it the Gopher protocol # as a gift. # # --- HOW IT WORKS? --- # # The Redis Gopher support uses the inline protocol of Redis, and specifically # two kind of inline requests that were anyway illegal: an empty request # or any request that starts with "/" (there are no Redis commands starting # with such a slash). Normal RESP2/RESP3 requests are completely out of the # path of the Gopher protocol implementation and are served as usual as well. # # If you open a connection to Redis when Gopher is enabled and send it # a string like "/foo", if there is a key named "/foo" it is served via the # Gopher protocol. # # In order to create a real Gopher "hole" (the name of a Gopher site in Gopher # talking), you likely need a script like the following: # # https://github.com/antirez/gopher2redis # # --- SECURITY WARNING --- # # If you plan to put Redis on the internet in a publicly accessible address # to server Gopher pages MAKE SURE TO SET A PASSWORD to the instance. # Once a password is set: # # 1. The Gopher server (when enabled, not by default) will still serve # content via Gopher. # 2. However other commands cannot be called before the client will # authenticate. # # So use the &#39;requirepass&#39; option to protect your instance. # # Note that Gopher is not currently supported when &#39;io-threads-do-reads&#39; # is enabled. # # To enable Gopher support, uncomment the following line and set the option # from no (the default) to yes. # # gopher-enabled no ############################### ADVANCED CONFIG ############################### # Hashes are encoded using a memory efficient data structure when they have a # small number of entries, and the biggest entry does not exceed a given # threshold. These thresholds can be configured using the following directives. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # Lists are also encoded in a special way to save a lot of space. # The number of entries allowed per internal list node can be specified # as a fixed maximum size or a maximum number of elements. # For a fixed maximum size, use -5 through -1, meaning: # -5: max size: 64 Kb <-- not recommended for normal workloads # -4: max size: 32 Kb <-- not recommended # -3: max size: 16 Kb <-- probably not recommended # -2: max size: 8 Kb <-- good # -1: max size: 4 Kb <-- good # Positive numbers mean store up to _exactly_ that number of elements # per list node. # The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size), # but if your use case is unique, adjust the settings as necessary. list-max-ziplist-size -2 # Lists may also be compressed. # Compress depth is the number of quicklist ziplist nodes from *each* side of # the list to *exclude* from compression. The head and tail of the list # are always uncompressed for fast push/pop operations. Settings are: # 0: disable all list compression # 1: depth 1 means "don&#39;t start compressing until after 1 node into the list, # going from either the head or tail" # So: [head]->node->node->...->node->[tail] # [head], [tail] will always be uncompressed; inner nodes will compress. # 2: [head]->[next]->node->node->...->node->[prev]->[tail] # 2 here means: don&#39;t compress head or head->next or tail->prev or tail, # but compress all nodes between them. # 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail] # etc. list-compress-depth 0 # Sets have a special encoding in just one case: when a set is composed # of just strings that happen to be integers in radix 10 in the range # of 64 bit signed integers. # The following configuration setting sets the limit in the size of the # set in order to use this special memory saving encoding. set-max-intset-entries 512 # Similarly to hashes and lists, sorted sets are also specially encoded in # order to save a lot of space. This encoding is only used when the length and # elements of a sorted set are below the following limits: zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog sparse representation bytes limit. The limit includes the # 16 bytes header. When an HyperLogLog using the sparse representation crosses # this limit, it is converted into the dense representation. # # A value greater than 16000 is totally useless, since at that point the # dense representation is more memory efficient. # # The suggested value is ~ 3000 in order to have the benefits of # the space efficient encoding without slowing down too much PFADD, # which is O(N) with the sparse encoding. The value can be raised to # ~ 10000 when CPU is not a concern, but space is, and the data set is # composed of many HyperLogLogs with cardinality in the 0 - 15000 range. hll-sparse-max-bytes 3000 # Streams macro node max size / items. The stream data structure is a radix # tree of big nodes that encode multiple items inside. Using this configuration # it is possible to configure how big a single node can be in bytes, and the # maximum number of items it may contain before switching to a new node when # appending new stream entries. If any of the following settings are set to # zero, the limit is ignored, so for instance it is possible to set just a # max entries limit by setting max-bytes to 0 and max-entries to the desired # value. stream-node-max-bytes 4096 stream-node-max-entries 100 # Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in # order to help rehashing the main Redis hash table (the one mapping top-level # keys to values). The hash table implementation Redis uses (see dict.c) # performs a lazy rehashing: the more operation you run into a hash table # that is rehashing, the more rehashing "steps" are performed, so if the # server is idle the rehashing is never complete and some more memory is used # by the hash table. # # The default is to use this millisecond 10 times every second in order to # actively rehash the main dictionaries, freeing memory when possible. # # If unsure: # use "activerehashing no" if you have hard latency requirements and it is # not a good thing in your environment that Redis can reply from time to time # to queries with 2 milliseconds delay. # # use "activerehashing yes" if you don&#39;t have such hard requirements but # want to free memory asap when possible. activerehashing yes # The client output buffer limits can be used to force disconnection of clients # that are not reading data from the server fast enough for some reason (a # common reason is that a Pub/Sub client can&#39;t consume messages as fast as the # publisher can produce them). # # The limit can be set differently for the three different classes of clients: # # normal -> normal clients including MONITOR clients # replica -> replica clients # pubsub -> clients subscribed to at least one pubsub channel or pattern # # The syntax of every client-output-buffer-limit directive is the following: # # client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds> # # A client is immediately disconnected once the hard limit is reached, or if # the soft limit is reached and remains reached for the specified number of # seconds (continuously). # So for instance if the hard limit is 32 megabytes and the soft limit is # 16 megabytes / 10 seconds, the client will get disconnected immediately # if the size of the output buffers reach 32 megabytes, but will also get # disconnected if the client reaches 16 megabytes and continuously overcomes # the limit for 10 seconds. # # By default normal clients are not limited because they don&#39;t receive data # without asking (in a push way), but just after a request, so only # asynchronous clients may create a scenario where data is requested faster # than it can read. # # Instead there is a default limit for pubsub and replica clients, since # subscribers and replicas receive data in a push fashion. # # Both the hard or the soft limit can be disabled by setting them to zero. client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Client query buffers accumulate new commands. They are limited to a fixed # amount by default in order to avoid that a protocol desynchronization (for # instance due to a bug in the client) will lead to unbound memory usage in # the query buffer. However you can configure it here if you have very special # needs, such us huge multi/exec requests or alike. # # client-query-buffer-limit 1gb # In the Redis protocol, bulk requests, that are, elements representing single # strings, are normally limited to 512 mb. However you can change this limit # here, but must be 1mb or greater # # proto-max-bulk-len 512mb # Redis calls an internal function to perform many background tasks, like # closing connections of clients in timeout, purging expired keys that are # never requested, and so forth. # # Not all tasks are performed with the same frequency, but Redis checks for # tasks to perform according to the specified "hz" value. # # By default "hz" is set to 10. Raising the value will use more CPU when # Redis is idle, but at the same time will make Redis more responsive when # there are many keys expiring at the same time, and timeouts may be # handled with more precision. # # The range is between 1 and 500, however a value over 100 is usually not # a good idea. Most users should use the default of 10 and raise this up to # 100 only in environments where very low latency is required. hz 10 # Normally it is useful to have an HZ value which is proportional to the # number of clients connected. This is useful in order, for instance, to # avoid too many clients are processed for each background task invocation # in order to avoid latency spikes. # # Since the default HZ value by default is conservatively set to 10, Redis # offers, and enables by default, the ability to use an adaptive HZ value # which will temporarily raise when there are many connected clients. # # When dynamic HZ is enabled, the actual configured HZ will be used # as a baseline, but multiples of the configured HZ value will be actually # used as needed once more clients are connected. In this way an idle # instance will use very little CPU time while a busy instance will be # more responsive. dynamic-hz yes # When a child rewrites the AOF file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. aof-rewrite-incremental-fsync yes # When redis saves RDB file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. rdb-save-incremental-fsync yes # Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good # idea to start with the default settings and only change them after investigating # how to improve the performances and how the keys LFU change over time, which # is possible to inspect via the OBJECT FREQ command. # # There are two tunable parameters in the Redis LFU implementation: the # counter logarithm factor and the counter decay time. It is important to # understand what the two parameters mean before changing them. # # The LFU counter is just 8 bits per key, it&#39;s maximum value is 255, so Redis # uses a probabilistic increment with logarithmic behavior. Given the value # of the old counter, when a key is accessed, the counter is incremented in # this way: # # 1. A random number R between 0 and 1 is extracted. # 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1). # 3. The counter is incremented only if R < P. # # The default lfu-log-factor is 10. This is a table of how the frequency # counter changes with a different number of accesses with different # logarithmic factors: # # +--------+------------+------------+------------+------------+------------+ # | factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits | # +--------+------------+------------+------------+------------+------------+ # | 0 | 104 | 255 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 1 | 18 | 49 | 255 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 10 | 10 | 18 | 142 | 255 | 255 | # +--------+------------+------------+------------+------------+------------+ # | 100 | 8 | 11 | 49 | 143 | 255 | # +--------+------------+------------+------------+------------+------------+ # # NOTE: The above table was obtained by running the following commands: # # redis-benchmark -n 1000000 incr foo # redis-cli object freq foo # # NOTE 2: The counter initial value is 5 in order to give new objects a chance # to accumulate hits. # # The counter decay time is the time, in minutes, that must elapse in order # for the key counter to be divided by two (or decremented if it has a value # less <= 10). # # The default value for the lfu-decay-time is 1. A special value of 0 means to # decay the counter every time it happens to be scanned. # # lfu-log-factor 10 # lfu-decay-time 1 ########################### ACTIVE DEFRAGMENTATION ####################### # # What is active defragmentation? # ------------------------------- # # Active (online) defragmentation allows a Redis server to compact the # spaces left between small allocations and deallocations of data in memory, # thus allowing to reclaim back memory. # # Fragmentation is a natural process that happens with every allocator (but # less so with Jemalloc, fortunately) and certain workloads. Normally a server # restart is needed in order to lower the fragmentation, or at least to flush # away all the data and create it again. However thanks to this feature # implemented by Oran Agra for Redis 4.0 this process can happen at runtime # in a "hot" way, while the server is running. # # Basically when the fragmentation is over a certain level (see the # configuration options below) Redis will start to create new copies of the # values in contiguous memory regions by exploiting certain specific Jemalloc # features (in order to understand if an allocation is causing fragmentation # and to allocate it in a better place), and at the same time, will release the # old copies of the data. This process, repeated incrementally for all the keys # will cause the fragmentation to drop back to normal values. # # Important things to understand: # # 1. This feature is disabled by default, and only works if you compiled Redis # to use the copy of Jemalloc we ship with the source code of Redis. # This is the default with Linux builds. # # 2. You never need to enable this feature if you don&#39;t have fragmentation # issues. # # 3. Once you experience fragmentation, you can enable this feature when # needed with the command "CONFIG SET activedefrag yes". # # The configuration parameters are able to fine tune the behavior of the # defragmentation process. If you are not sure about what they mean it is # a good idea to leave the defaults untouched. # Enabled active defragmentation # activedefrag no # Minimum amount of fragmentation waste to start active defrag # active-defrag-ignore-bytes 100mb # Minimum percentage of fragmentation to start active defrag # active-defrag-threshold-lower 10 # Maximum percentage of fragmentation at which we use maximum effort # active-defrag-threshold-upper 100 # Minimal effort for defrag in CPU percentage, to be used when the lower # threshold is reached # active-defrag-cycle-min 1 # Maximal effort for defrag in CPU percentage, to be used when the upper # threshold is reached # active-defrag-cycle-max 25 # Maximum number of set/hash/zset/list fields that will be processed from # the main dictionary scan # active-defrag-max-scan-fields 1000 # Jemalloc background thread for purging will be enabled by default jemalloc-bg-thread yes # It is possible to pin different threads and processes of Redis to specific # CPUs in your system, in order to maximize the performances of the server. # This is useful both in order to pin different Redis threads in different # CPUs, but also in order to make sure that multiple Redis instances running # in the same host will be pinned to different CPUs. # # Normally you can do this using the "taskset" command, however it is also # possible to this via Redis configuration directly, both in Linux and FreeBSD. # # You can pin the server/IO threads, bio threads, aof rewrite child process, and # the bgsave child process. The syntax to specify the cpu list is the same as # the taskset command: # # Set redis server/io threads to cpu affinity 0,2,4,6: # server_cpulist 0-7:2 # # Set bio threads to cpu affinity 1,3: # bio_cpulist 1,3 # # Set aof rewrite child process to cpu affinity 8,9,10,11: # aof_rewrite_cpulist 8-11 # # Set bgsave child process to cpu affinity 1,10,11 # bgsave_cpulist 1,10-11 # In some cases redis will emit warnings and even refuse to start if it detects # that the system is in bad state, it is possible to suppress these warnings # by setting the following config which takes a space delimited list of warnings # to suppress # # ignore-warnings ARM64-COW-BUG'><meta itemprop=wordCount content="15835"><title>1.6 Redis配置文件详解 | CODE'NOTE</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://wangpengliang815.github.io/docs/redis/1.6redis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.16bbea805e586532aeca5e48249564b81bcbb5a9d44401ea4658ef5e6a5e812f.js integrity="sha256-FrvqgF5YZTKuyl5IJJVkuBvLtanURAHqRljvXmpegS8=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-docs"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>CODE'NOTE</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-f32afe48992fac3b3fc76dc3b27dd1d5 class=toggle>
<label for=section-f32afe48992fac3b3fc76dc3b27dd1d5 class=flex><a role=button>📚 .NET</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/dotnet/%E5%80%BC%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/>值类型和引用类型的内存分配</a></li><li><a href=/docs/dotnet/%E5%8F%8D%E5%B0%84%E6%8A%80%E6%9C%AF/>反射技术</a></li><li><a href=/docs/dotnet/%E5%9F%BA%E7%A1%80%E5%90%88%E9%9B%86/>基础合集</a></li><li><a href=/docs/dotnet/%E5%A4%9A%E7%BA%BF%E7%A8%8B/>多线程</a></li><li><a href=/docs/dotnet/%E5%A7%94%E6%89%98%E5%92%8C%E4%BA%8B%E4%BB%B6/>委托和事件</a></li><li><a href=/docs/dotnet/%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B/>并行编程</a></li><li><a href=/docs/dotnet/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/>异步编程</a></li><li><a href=/docs/dotnet/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/>数据结构</a></li><li><a href=/docs/dotnet/%E6%B3%9B%E5%9E%8B%E6%8A%80%E6%9C%AF/>泛型技术</a></li><li><a href=/docs/dotnet/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/>线程同步</a></li><li><a href=/docs/dotnet/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/>面向对象</a></li></ul></li><li><input type=checkbox id=section-17ee4616d3316ecf2ecdb7c27cfa2a63 class=toggle>
<label for=section-17ee4616d3316ecf2ecdb7c27cfa2a63 class=flex><a role=button>🎭 PMI-ACP</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/acp/pmi-acp%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/>Pmi Acp基础了解</a></li><li><a href=/docs/acp/pmi-acpdown/>Pmi Acpdown</a></li><li><a href=/docs/acp/pmi-acp%E5%A4%87%E8%80%83%E7%AC%94%E8%AE%B001/>Pmi Acp备考笔记01</a></li><li><a href=/docs/acp/pmi-acp%E5%A4%87%E8%80%83%E7%AC%94%E8%AE%B002/>Pmi Acp备考笔记02</a></li><li><a href=/docs/acp/pmi-acp%E5%A4%87%E8%80%83%E7%AC%94%E8%AE%B003/>Pmi Acp备考笔记03</a></li></ul></li><li><input type=checkbox id=section-fba10961f5d9c66eab238d766cb1a791 class=toggle>
<label for=section-fba10961f5d9c66eab238d766cb1a791 class=flex><a role=button>⌛ 软件测试</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/test/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/>单元测试</a></li><li><a href=/docs/test/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95k6/>压力测试k6</a></li><li><a href=/docs/test/%E8%87%AA%E5%8A%A8%E5%8C%96ui%E6%B5%8B%E8%AF%95/>自动化 Ui测试</a></li><li><a href=/docs/test/%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95/>集成测试</a></li></ul></li><li><input type=checkbox id=section-92cef1621a3b87cdf19787a11c3e85e0 class=toggle>
<label for=section-92cef1621a3b87cdf19787a11c3e85e0 class=flex><a role=button>⛷️ Prometheus</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/prometheus/1.1prometheus%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%AE%89%E8%A3%85/>1.1 Prometheus简介及安装</a></li><li><a href=/docs/prometheus/1.2exporter%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/>1.2 Exporter数据采集</a></li><li><a href=/docs/prometheus/1.3promql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/>1.3 Prom Ql查询语言</a></li><li><a href=/docs/prometheus/1.4alertmanager%E5%91%8A%E8%AD%A6%E5%A4%84%E7%90%86/>1.4 Alertmanager告警处理</a></li><li><a href=/docs/prometheus/1.5grafana%E7%9B%91%E6%8E%A7%E5%8F%AF%E8%A7%86%E5%8C%96/>1.5 Grafana监控可视化</a></li></ul></li><li><input type=checkbox id=section-c4b81cc06a2cdd0259ab09c2dde93fb5 class=toggle>
<label for=section-c4b81cc06a2cdd0259ab09c2dde93fb5 class=flex><a role=button>🐇 RabbitMq</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/rabbitmq/1.1rabbitmq%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%AE%89%E8%A3%85/>1.1 Rabbit Mq概念及安装</a></li><li><a href=/docs/rabbitmq/1.2%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/>1.2工作模式介绍</a></li><li><a href=/docs/rabbitmq/1.3%E6%B6%88%E6%81%AF%E7%A1%AE%E8%AE%A4%E5%8F%8A%E6%8C%81%E4%B9%85%E5%8C%96/>1.3消息确认及持久化</a></li><li><a href=/docs/rabbitmq/1.4%E4%B8%A4%E7%A7%8D%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F%E5%92%8Cqos%E7%9A%84%E5%AE%9E%E7%8E%B0/>1.4两种消费模式和 Qos的实现</a></li><li><a href=/docs/rabbitmq/1.5channel%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95/>1.5 Channel常见方法</a></li><li><a href=/docs/rabbitmq/1.6rabbitmq%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/>1.6 Rabbit Mq常用命令</a></li><li><a href=/docs/rabbitmq/1.7rabbitmq%E5%B8%B8%E8%A7%81%E7%AD%96%E7%95%A5/>1.7 Rabbit Mq常见策略</a></li><li><a href=/docs/rabbitmq/1.8rabbitmq%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/>1.8 Rabbit Mq常见问题</a></li><li><a href=/docs/rabbitmq/1.9rabbitmq%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88/>1.9 Rabbit Mq集群方案</a></li><li><a href=/docs/rabbitmq/%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5rabbitmq/>客户端连接 Rabbit Mq</a></li></ul></li><li><input type=checkbox id=section-45de5b9a6214c965d493f727c3af2aae class=toggle>
<label for=section-45de5b9a6214c965d493f727c3af2aae class=flex><a role=button>🐹 Golang</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/go/01%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/>01开发环境搭建</a></li><li><a href=/docs/go/02%E5%8F%98%E9%87%8F%E5%92%8C%E5%B8%B8%E9%87%8F/>02变量和常量</a></li><li><a href=/docs/go/03%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/>03基本数据类型</a></li><li><a href=/docs/go/04%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%92%8C%E8%BF%90%E7%AE%97%E7%AC%A6/>04流程控制和运算符</a></li><li><a href=/docs/go/05%E6%95%B0%E7%BB%84/>05数组</a></li><li><a href=/docs/go/06%E5%88%87%E7%89%87/>06切片</a></li><li><a href=/docs/go/07map/>07map</a></li><li><a href=/docs/go/08%E5%87%BD%E6%95%B0/>08函数</a></li><li><a href=/docs/go/09%E6%8C%87%E9%92%88/>09指针</a></li><li><a href=/docs/go/10%E5%8F%8D%E5%B0%84/>10反射</a></li><li><a href=/docs/go/11%E7%BB%93%E6%9E%84%E4%BD%93/>11结构体</a></li><li><a href=/docs/go/12%E6%8E%A5%E5%8F%A3/>12接口</a></li><li><a href=/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/channel/>Channel</a></li><li><a href=/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/>Csp并发模型</a></li><li><a href=/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/goroutine/>Goroutine</a></li><li><a href=/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/gpm%E5%8E%9F%E7%90%86%E4%B8%8E%E8%B0%83%E5%BA%A6/>Gpm原理与调度</a></li><li><a href=/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/>原子操作</a></li><li><a href=/docs/go/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E5%92%8C%E9%94%81/>并发安全和锁</a></li><li><a href=/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/flag/>Flag</a></li><li><a href=/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/fmt/>Fmt</a></li><li><a href=/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/log/>Log</a></li><li><a href=/docs/go/%E6%A0%87%E5%87%86%E5%BA%93/time/>Time</a></li></ul></li><li><input type=checkbox id=section-61dde4567035e1fd2b5d2aa51b82a7a0 class=toggle>
<label for=section-61dde4567035e1fd2b5d2aa51b82a7a0 class=flex><a role=button>💫 Microservice</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/microservice/1.1%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/>1.1微服务入门之项目搭建</a></li><li><a href=/docs/microservice/1.2%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/>1.2微服务入门之服务注册与发现</a></li><li><a href=/docs/microservice/1.3%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E7%BD%91%E5%85%B3/>1.3微服务入门之网关</a></li><li><a href=/docs/microservice/1.4%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8B%E4%BA%8B%E4%BB%B6%E6%80%BB%E7%BA%BF/>1.4微服务入门之事件总线</a></li><li><a href=/docs/microservice/1.5%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E4%B9%8Bdockercompose/>1.5微服务入门之 Docker Compose</a></li><li><a href=/docs/microservice/consul%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0/>Consul服务注册发现</a></li></ul></li><li><input type=checkbox id=section-e6c26370c56585ceaa14c64b7d769452 class=toggle checked>
<label for=section-e6c26370c56585ceaa14c64b7d769452 class=flex><a role=button>📦 Redis</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/redis/1.10redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/>1.10 Redis常见问题</a></li><li><a href=/docs/redis/1.1nosql%E6%A6%82%E8%BF%B0/>1.1 No Sql概述</a></li><li><a href=/docs/redis/1.2redis%E5%AE%89%E8%A3%85/>1.2 Redis安装</a></li><li><a href=/docs/redis/1.3redis%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/>1.3 Redis基本数据类型</a></li><li><a href=/docs/redis/1.4redis%E7%89%B9%E6%AE%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/>1.4 Redis特殊数据类型</a></li><li><a href=/docs/redis/1.5redis%E4%BA%8B%E5%8A%A1%E6%93%8D%E4%BD%9C/>1.5 Redis事务操作</a></li><li><a href=/docs/redis/1.6redis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/ class=active>1.6 Redis配置文件详解</a></li><li><a href=/docs/redis/1.7redis%E6%8C%81%E4%B9%85%E5%8C%96/>1.7 Redis持久化</a></li><li><a href=/docs/redis/1.8redis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/>1.8 Redis发布订阅</a></li><li><a href=/docs/redis/1.9redis%E9%9B%86%E7%BE%A4%E6%96%B9%E6%A1%88/>1.9 Redis集群方案</a></li><li><a href=/docs/redis/%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BAredis%E9%9B%86%E7%BE%A4/>使用 Docker搭建 Redis集群</a></li><li><a href=/docs/redis/%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5redis/>客户端连接 Redis</a></li></ul></li><li><input type=checkbox id=section-f781adde1ca4021db6751ec1e71e0572 class=toggle>
<label for=section-f781adde1ca4021db6751ec1e71e0572 class=flex><a role=button>🔎 ELK</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/elk/1.1elastaticsearch%E5%85%A5%E9%97%A8/>1.1 Elastatic Search入门</a></li><li><a href=/docs/elk/1.2elastaticsearch%E9%85%8D%E7%BD%AE/>1.2 Elastatic Search配置</a></li><li><a href=/docs/elk/1.3%E4%BD%BF%E7%94%A8kibana%E6%93%8D%E4%BD%9Ces/>1.3使用 Kibana操作 Es</a></li></ul></li><li><input type=checkbox id=section-17df8bdb44c678e43d193647c6ae88f1 class=toggle>
<label for=section-17df8bdb44c678e43d193647c6ae88f1 class=flex><a role=button>🚢 Docker</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/docker/1.1docker%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%AE%89%E8%A3%85/>1.1 Docker概念及安装</a></li><li><a href=/docs/docker/1.2docker%E9%95%9C%E5%83%8F/>1.2 Docker镜像</a></li><li><a href=/docs/docker/1.3docker%E5%AE%B9%E5%99%A8/>1.3 Docker容器</a></li><li><a href=/docs/docker/1.4docker%E4%BB%93%E5%BA%93/>1.4 Docker仓库</a></li><li><a href=/docs/docker/1.5docker%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/>1.5 Docker数据管理</a></li><li><a href=/docs/docker/1.6docker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/>1.6 Docker容器网络模式</a></li><li><a href=/docs/docker/1.7docker%E9%AB%98%E7%BA%A7%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/>1.7 Docker高级网络配置</a></li><li><a href=/docs/docker/1.8dockerfile/>1.8 Dockerfile</a></li><li><a href=/docs/docker/1.9dockercompose/>1.9 Docker Compose</a></li><li><a href=/docs/docker/2.0dockermachine/>2.0 Docker Machine</a></li><li><a href=/docs/docker/2.1dockerswarm/>2.1 Docker Swarm</a></li><li><a href=/docs/docker/2.2docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/>2.2 Docker常用命令</a></li><li><a href=/docs/docker/2.3portainer%E5%8F%AF%E8%A7%86%E5%8C%96%E9%9D%A2%E6%9D%BF/>2.3 Portainer可视化面板</a></li></ul></li><li><input type=checkbox id=section-566aa18ccd5b6b6934a70aded3a8361a class=toggle>
<label for=section-566aa18ccd5b6b6934a70aded3a8361a class=flex><a role=button>🕸️ K8s</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/kubernetes/kubernetes%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/>Kubernetes基础知识</a></li><li><a href=/docs/kubernetes/kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/>Kubernetes集群安装</a></li></ul></li><li><input type=checkbox id=section-04176b4c8c5f502db36c25b60db03d67 class=toggle>
<label for=section-04176b4c8c5f502db36c25b60db03d67 class=flex><a role=button>🖥️ Linux</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/linux/centos7%E5%8D%87%E7%BA%A7gcc%E7%89%88%E6%9C%AC/>Centos7升级gcc版本</a></li><li><a href=/docs/linux/centos%E5%AE%89%E8%A3%85hexo/>Centos安装 Hexo</a></li><li><a href=/docs/linux/centos%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/>Centos网络配置</a></li><li><a href=/docs/linux/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/>Linux常用命令</a></li><li><a href=/docs/linux/linux%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E/>Linux目录说明</a></li><li><a href=/docs/linux/vmware%E5%AE%89%E8%A3%85centos/>Vmware安装 Centos</a></li></ul></li><li><input type=checkbox id=section-9397a01455952fcbd887e2206a8a3054 class=toggle>
<label for=section-9397a01455952fcbd887e2206a8a3054 class=flex><a role=button>🛍️ Devops</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/docs/devops/gitlab%E5%AE%89%E8%A3%85/>Gitlab安装</a></li><li><a href=/docs/devops/jenkins%E5%AE%89%E8%A3%85/>Jenkins安装</a></li><li><a href=/docs/devops/jenkins%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/>Jenkins常见操作</a></li><li><a href=/docs/devops/nugetserver%E6%90%AD%E5%BB%BA/>Nuget Server搭建</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>1.6 Redis配置文件详解</h3><label for=toc-control></label></div></header><article class="markdown book-article"><h1 id=redisconfig-配置文件><code>Redis.Config</code> 配置文件<a class=anchor href=#redisconfig-%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6>#</a></h1><p>经常使用的配置使用“# =>”方式写了注释</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Redis configuration file example.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that in order to read the configuration file, Redis must be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># started with the file path as first argument:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ./redis-server /path/to/redis.conf</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note on units: when memory size is needed, it is possible to specify</span>
</span></span><span style=display:flex><span><span style=color:#75715e># it in the usual form of 1k 5GB 4M and so forth:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 单位设置</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1k =&gt; 1000 bytes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1kb =&gt; 1024 bytes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1m =&gt; 1000000 bytes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1mb =&gt; 1024*1024 bytes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1g =&gt; 1000000000 bytes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1gb =&gt; 1024*1024*1024 bytes</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; Redis单位对大小写不敏感</span>
</span></span><span style=display:flex><span><span style=color:#75715e># units are case insensitive so 1GB 1Gb 1gB are all the same.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 包含：可以把多个Redis.conf组合成一个conf</span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################## INCLUDES ###################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Include one or more other config files here.  This is useful if you</span>
</span></span><span style=display:flex><span><span style=color:#75715e># have a standard template that goes to all Redis servers but also need</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to customize a few per-server settings.  Include files can include</span>
</span></span><span style=display:flex><span><span style=color:#75715e># other files, so use this wisely.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that option &#34;include&#34; won&#39;t be rewritten by command &#34;CONFIG REWRITE&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># from admin or Redis Sentinel. Since Redis always uses the last processed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># line as value of a configuration directive, you&#39;d better put includes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># at the beginning of this file to avoid overwriting config change at runtime.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If instead you are interested in using includes to override configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e># options, it is better to use include as the last line.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># include /path/to/local.conf</span>
</span></span><span style=display:flex><span><span style=color:#75715e># include /path/to/other.conf</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################## MODULES #####################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load modules at startup. If the server is not able to load modules</span>
</span></span><span style=display:flex><span><span style=color:#75715e># it will abort. It is possible to use multiple loadmodule directives.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># loadmodule /path/to/my_module.so</span>
</span></span><span style=display:flex><span><span style=color:#75715e># loadmodule /path/to/other_module.so</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 网络配置</span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################## NETWORK #####################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, if no &#34;bind&#34; configuration directive is specified, Redis listens</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for connections from all available network interfaces on the host machine.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is possible to listen to just one or multiple selected interfaces using</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the &#34;bind&#34; configuration directive, followed by one or more IP addresses.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Each address can be prefixed by &#34;-&#34;, which means that redis will not fail to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># start if the address is not available. Being not available only refers to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># addresses that does not correspond to any network interfece. Addresses that</span>
</span></span><span style=display:flex><span><span style=color:#75715e># are already in use will always fail, and unsupported protocols will always BE</span>
</span></span><span style=display:flex><span><span style=color:#75715e># silently skipped.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Examples:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses</span>
</span></span><span style=display:flex><span><span style=color:#75715e># bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6</span>
</span></span><span style=display:flex><span><span style=color:#75715e># bind * -::*                     # like the default, all available interfaces</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># internet, binding to all the interfaces is dangerous and will expose the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># instance to everybody on the internet. So by default we uncomment the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># following bind directive, that will force Redis to listen only on the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># IPv4 and IPv6 (if available) loopback interface addresses (this means Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will only be able to accept client connections from the same host that it is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># running on).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES</span>
</span></span><span style=display:flex><span><span style=color:#75715e># JUST COMMENT OUT THE FOLLOWING LINE.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 绑定的IP:127.0.0.1只能是本地使用，如果需要提供给远程访问，需要设置为*统配或者指定IP</span>
</span></span><span style=display:flex><span>bind 0.0.0.0 -::1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Protected mode is a layer of security protection, in order to avoid that</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis instances left open on the internet are accessed and exploited.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When protected mode is on and if:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) The server is not binding explicitly to a set of addresses using the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    &#34;bind&#34; directive.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) No password is configured.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The server only accepts connections from clients connecting from the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain</span>
</span></span><span style=display:flex><span><span style=color:#75715e># sockets.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default protected mode is enabled. You should disable it only if</span>
</span></span><span style=display:flex><span><span style=color:#75715e># you are sure you want clients from other hosts to connect to Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># even if no authentication is configured, nor a specific set of interfaces</span>
</span></span><span style=display:flex><span><span style=color:#75715e># are explicitly listed using the &#34;bind&#34; directive.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 是否受保护模式</span>
</span></span><span style=display:flex><span>protected-mode yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Accept connections on the specified port, default is 6379 (IANA #815344).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If port 0 is specified Redis will not listen on a TCP socket.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 端口设置</span>
</span></span><span style=display:flex><span>port <span style=color:#ae81ff>6379</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># TCP listen() backlog.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In high requests-per-second environments you need a high backlog in order</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to avoid slow clients connection issues. Note that the Linux kernel</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will silently truncate it to the value of /proc/sys/net/core/somaxconn so</span>
</span></span><span style=display:flex><span><span style=color:#75715e># make sure to raise both the value of somaxconn and tcp_max_syn_backlog</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to get the desired effect.</span>
</span></span><span style=display:flex><span>tcp-backlog <span style=color:#ae81ff>511</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Unix socket.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify the path for the Unix socket that will be used to listen for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># incoming connections. There is no default, so Redis will not listen</span>
</span></span><span style=display:flex><span><span style=color:#75715e># on a unix socket when not specified.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># unixsocket /run/redis.sock</span>
</span></span><span style=display:flex><span><span style=color:#75715e># unixsocketperm 700</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Close the connection after a client is idle for N seconds (0 to disable)</span>
</span></span><span style=display:flex><span>timeout <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># TCP keepalive.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of communication. This is useful for two reasons:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) Detect dead peers.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) Force network equipment in the middle to consider the connection to be</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    alive.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># On Linux, the specified value (in seconds) is the period used to send ACKs.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that to close the connection the double of the time is needed.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># On other kernels the period depends on the kernel configuration.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># A reasonable value for this option is 300 seconds, which is the new</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis default starting with Redis 3.2.1.</span>
</span></span><span style=display:flex><span>tcp-keepalive <span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################# TLS/SSL #####################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, TLS/SSL is disabled. To enable it, the &#34;tls-port&#34; configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e># directive can be used to define TLS-listening ports. To enable TLS on the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># default port, use:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># port 0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-port 6379</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Configure a X.509 certificate and private key to use for authenticating the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># server to connected clients, masters or cluster peers.  These files should be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># PEM formatted.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-cert-file redis.crt </span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-key-file redis.key</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Normally Redis uses the same certificate for both server functions (accepting</span>
</span></span><span style=display:flex><span><span style=color:#75715e># connections) and client functions (replicating from a master, establishing</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster bus connections, etc.).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Sometimes certificates are issued with attributes that designate them as</span>
</span></span><span style=display:flex><span><span style=color:#75715e># client-only or server-only certificates. In that case it may be desired to use</span>
</span></span><span style=display:flex><span><span style=color:#75715e># different certificates for incoming (server) and outgoing (client)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># connections. To do that, use the following directives:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-client-cert-file client.crt</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-client-key-file client.key</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-dh-params-file redis.dh</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL</span>
</span></span><span style=display:flex><span><span style=color:#75715e># clients and peers.  Redis requires an explicit configuration of at least one</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of these, and will not implicitly use the system wide configuration.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-ca-cert-file ca.crt</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-ca-cert-dir /etc/ssl/certs</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, clients (including replica servers) on a TLS port are required</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to authenticate using valid client side certificates.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If &#34;no&#34; is specified, client certificates are not required and not accepted.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If &#34;optional&#34; is specified, client certificates are accepted and must be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># valid if provided, but are not required.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-auth-clients no</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-auth-clients optional</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, a Redis replica does not attempt to establish a TLS connection</span>
</span></span><span style=display:flex><span><span style=color:#75715e># with its master.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Use the following directive to enable TLS on replication links.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-replication yes</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, the Redis Cluster bus uses a plain TCP connection. To enable</span>
</span></span><span style=display:flex><span><span style=color:#75715e># TLS for the bus protocol, use the following directive:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-cluster yes</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that older formally deprecated versions are kept disabled to reduce the attack surface.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># You can explicitly specify TLS versions to support.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Allowed values are case insensitive and include &#34;TLSv1&#34;, &#34;TLSv1.1&#34;, &#34;TLSv1.2&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;TLSv1.3&#34; (OpenSSL &gt;= 1.1.1) or any combination.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># To enable only TLSv1.2 and TLSv1.3, use:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-protocols &#34;TLSv1.2 TLSv1.3&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Configure allowed ciphers.  See the ciphers(1ssl) manpage for more information</span>
</span></span><span style=display:flex><span><span style=color:#75715e># about the syntax of this string.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note: this configuration applies only to &lt;= TLSv1.2.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-ciphers DEFAULT:!MEDIUM</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Configure allowed TLSv1.3 ciphersuites.  See the ciphers(1ssl) manpage for more</span>
</span></span><span style=display:flex><span><span style=color:#75715e># information about the syntax of this string, and specifically for TLSv1.3</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ciphersuites.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When choosing a cipher, use the server&#39;s preference instead of the client</span>
</span></span><span style=display:flex><span><span style=color:#75715e># preference. By default, the server follows the client&#39;s preference.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-prefer-server-ciphers yes</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, TLS session caching is enabled to allow faster and less expensive</span>
</span></span><span style=display:flex><span><span style=color:#75715e># reconnections by clients that support it. Use the following directive to disable</span>
</span></span><span style=display:flex><span><span style=color:#75715e># caching.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-session-caching no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Change the default number of TLS sessions cached. A zero value sets the cache</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to unlimited size. The default size is 20480.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-session-cache-size 5000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Change the default timeout of cached TLS sessions. The default timeout is 300</span>
</span></span><span style=display:flex><span><span style=color:#75715e># seconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tls-session-cache-timeout 60</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################# GENERAL #####################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default Redis does not run as a daemon. Use &#39;yes&#39; if you need it.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that Redis will write a pid file in /var/run/redis.pid when daemonized.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When Redis is supervised by upstart or systemd, this parameter has no impact.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 是否以守护进程的方式运行，默认是no</span>
</span></span><span style=display:flex><span>daemonize yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you run Redis from upstart or systemd, Redis can interact with your</span>
</span></span><span style=display:flex><span><span style=color:#75715e># supervision tree. Options:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   supervised no      - no supervision interaction</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                        requires &#34;expect stop&#34; in your upstart job config</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                        on startup, and updating Redis status on a regular</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                        basis.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   supervised auto    - detect upstart or systemd method based on</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                        UPSTART_JOB or NOTIFY_SOCKET environment variables</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note: these supervision methods only signal &#34;process is ready.&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#       They do not enable continuous pings back to your supervisor.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default is &#34;no&#34;. To run under upstart/systemd, you can simply uncomment</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the line below:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># supervised auto</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># If a pid file is specified, Redis writes it where specified at startup</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and removes it at exit.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When the server runs non daemonized, no pid file is created if none is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># specified in the configuration. When the server is daemonized, the pid file</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is used even if not specified, defaulting to &#34;/var/run/redis.pid&#34;.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Creating a pid file is best effort: if Redis is not able to create it</span>
</span></span><span style=display:flex><span><span style=color:#75715e># nothing bad happens, the server will start and run normally.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that on modern Linux systems &#34;/run/redis.pid&#34; is more conforming</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and should be used instead.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 如果以守护进程方式运行，需要指定一个守护进程的文件</span>
</span></span><span style=display:flex><span>pidfile /var/run/redis_6379.pid
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify the server verbosity level.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This can be one of:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># debug (a lot of information, useful for development/testing)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># verbose (many rarely useful info, but not a mess like the debug level)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># notice (moderately verbose, what you want in production probably)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># warning (only very important / critical messages are logged)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 设置日志级别</span>
</span></span><span style=display:flex><span>loglevel notice
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify the log file name. Also the empty string can be used to force</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis to log on the standard output. Note that if you use standard</span>
</span></span><span style=display:flex><span><span style=color:#75715e># output for logging but daemonize, logs will be sent to /dev/null</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 设置日志的存储位置</span>
</span></span><span style=display:flex><span>logfile <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># To enable logging to the system logger, just set &#39;syslog-enabled&#39; to yes,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and optionally update the other syslog parameters to suit your needs.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># syslog-enabled no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify the syslog identity.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># syslog-ident redis</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># syslog-facility local0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># To disable the built in crash log, which will possibly produce cleaner core</span>
</span></span><span style=display:flex><span><span style=color:#75715e># dumps when they are needed, uncomment the following:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># crash-log-enabled no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># To disable the fast memory check that&#39;s run as part of the crash log, which</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will possibly let redis terminate sooner, uncomment the following:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># crash-memcheck-enabled no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the number of databases. The default database is DB 0, you can select</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a different one on a per-connection basis using SELECT &lt;dbid&gt; where</span>
</span></span><span style=display:flex><span><span style=color:#75715e># dbid is a number between 0 and &#39;databases&#39;-1</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 默认数据库数量</span>
</span></span><span style=display:flex><span>databases <span style=color:#ae81ff>16</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default Redis shows an ASCII art logo only when started to log to the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># standard output and if the standard output is a TTY and syslog logging is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># disabled. Basically this means that normally a logo is displayed only in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># interactive sessions.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># However it is possible to force the pre-4.0 behavior and always show a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ASCII art logo in startup logs by setting the following option to yes.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 是否总是显示Logo</span>
</span></span><span style=display:flex><span>always-show-logo no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default, Redis modifies the process title (as seen in &#39;top&#39; and &#39;ps&#39;) to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># provide some runtime information. It is possible to disable this and leave</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the process name as executed by setting the following to no.</span>
</span></span><span style=display:flex><span>set-proc-title yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When changing the process title, Redis uses the following template to construct</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the modified title.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Template variables are specified in curly brackets. The following variables are</span>
</span></span><span style=display:flex><span><span style=color:#75715e># supported:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># {title}           Name of process as executed if parent, or type of child process.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># {listen-addr}     Bind address or &#39;*&#39; followed by TCP or TLS port listening on, or</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                   Unix socket if only that&#39;s available.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># {server-mode}     Special mode, i.e. &#34;[sentinel]&#34; or &#34;[cluster]&#34;.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># {port}            TCP port listening on, or 0.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># {tls-port}        TLS port listening on, or 0.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># {unixsocket}      Unix domain socket listening on, or &#34;&#34;.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># {config-file}     Name of configuration file used.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>proc-title-template <span style=color:#e6db74>&#34;{title} {listen-addr} {server-mode}&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################ SNAPSHOTTING  ################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Save the DB to disk.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># save &lt;seconds&gt; &lt;changes&gt;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis will save the DB if both the given number of seconds and the given</span>
</span></span><span style=display:flex><span><span style=color:#75715e># number of write operations against the DB occurred.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Snapshotting can be completely disabled with a single empty string argument</span>
</span></span><span style=display:flex><span><span style=color:#75715e># as in following example:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># save &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Unless specified otherwise, by default Redis will save the DB:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   * After 3600 seconds (an hour) if at least 1 key changed</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   * After 300 seconds (5 minutes) if at least 100 keys changed</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   * After 60 seconds if at least 10000 keys changed</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># You can set these explicitly by uncommenting the three following lines.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 快照持久化规则设置</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 如果3600秒内，至少一个Key进行了修改，就会进行持久化</span>
</span></span><span style=display:flex><span><span style=color:#75715e># save 3600 1</span>
</span></span><span style=display:flex><span><span style=color:#75715e># save 300 100</span>
</span></span><span style=display:flex><span><span style=color:#75715e># save 60 10000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default Redis will stop accepting writes if RDB snapshots are enabled</span>
</span></span><span style=display:flex><span><span style=color:#75715e># (at least one save point) and the latest background save failed.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This will make the user aware (in a hard way) that data is not persisting</span>
</span></span><span style=display:flex><span><span style=color:#75715e># on disk properly, otherwise chances are that no one will notice and some</span>
</span></span><span style=display:flex><span><span style=color:#75715e># disaster will happen.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If the background saving process will start working again Redis will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># automatically allow writes again.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># However if you have setup your proper monitoring of the Redis server</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and persistence, you may want to disable this feature so that Redis will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># continue to work as usual even if there are problems with disk,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># permissions, and so forth.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 持久化出错时，是否继续工作</span>
</span></span><span style=display:flex><span>stop-writes-on-bgsave-error yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Compress string objects using LZF when dump .rdb databases?</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default compression is enabled as it&#39;s almost always a win.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you want to save some CPU in the saving child set it to &#39;no&#39; but</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the dataset will likely be bigger if you have compressible values or keys.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 是否压缩rdb文件；压缩是需要耗费一些CPU资源的</span>
</span></span><span style=display:flex><span>rdbcompression yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Since version 5 of RDB a CRC64 checksum is placed at the end of the file.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This makes the format more resistant to corruption but there is a performance</span>
</span></span><span style=display:flex><span><span style=color:#75715e># hit to pay (around 10%) when saving and loading RDB files, so you can disable it</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for maximum performances.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># RDB files created with checksum disabled have a checksum of zero that will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tell the loading code to skip the check.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 保存rdb文件时，是否校验rdb文件</span>
</span></span><span style=display:flex><span>rdbchecksum yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Enables or disables full sanitation checks for ziplist and listpack etc when</span>
</span></span><span style=display:flex><span><span style=color:#75715e># loading an RDB or RESTORE payload. This reduces the chances of a assertion or</span>
</span></span><span style=display:flex><span><span style=color:#75715e># crash later on while processing commands.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Options:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   no         - Never perform full sanitation</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   yes        - Always perform full sanitation</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   clients    - Perform full sanitation only for user connections.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                Excludes: RDB files, RESTORE commands received from the master</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                connection, and client connections which have the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                skip-sanitize-payload ACL flag.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default should be &#39;clients&#39; but since it currently affects cluster</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resharding via MIGRATE, it is temporarily set to &#39;no&#39; by default.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># sanitize-dump-payload no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The filename where to dump the DB</span>
</span></span><span style=display:flex><span>dbfilename dump.rdb
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Remove RDB files used by replication in instances without persistence</span>
</span></span><span style=display:flex><span><span style=color:#75715e># enabled. By default this option is disabled, however there are environments</span>
</span></span><span style=display:flex><span><span style=color:#75715e># where for regulations or other security concerns, RDB files persisted on</span>
</span></span><span style=display:flex><span><span style=color:#75715e># disk by masters in order to feed replicas, or stored on disk by replicas</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to load them for the initial synchronization, should be deleted</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ASAP. Note that this option ONLY WORKS in instances that have both AOF</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and RDB persistence disabled, otherwise is completely ignored.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># An alternative (and sometimes better) way to obtain the same effect is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to use diskless replication on both master and replicas instances. However</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in the case of replicas, diskless is not always an option.</span>
</span></span><span style=display:flex><span>rdb-del-sync-files no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The working directory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The DB will be written inside this directory, with the filename specified</span>
</span></span><span style=display:flex><span><span style=color:#75715e># above using the &#39;dbfilename&#39; configuration directive.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The Append Only File will also be created inside this directory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that you must specify a directory here, not a file name.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; rdb文件保存目录</span>
</span></span><span style=display:flex><span>dir ./
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################# REPLICATION #################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Master-Replica replication. Use replicaof to make a Redis instance a copy of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># another Redis server. A few things to understand ASAP about Redis replication.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   +------------------+      +---------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   |      Master      | ---&gt; |    Replica    |</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   | (receive writes) |      |  (exact copy) |</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   +------------------+      +---------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) Redis replication is asynchronous, but you can configure a master to</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    stop accepting writes if it appears to be not connected with at least</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    a given number of replicas.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) Redis replicas are able to perform a partial resynchronization with the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    master if the replication link is lost for a relatively small amount of</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    time. You may want to configure the replication backlog size (see the next</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    sections of this file) with a sensible value depending on your needs.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3) Replication is automatic and does not need user intervention. After a</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    network partition replicas automatically try to reconnect to masters</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    and resynchronize with them.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replicaof &lt;masterip&gt; &lt;masterport&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># If the master is password protected (using the &#34;requirepass&#34; configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e># directive below) it is possible to tell the replica to authenticate before</span>
</span></span><span style=display:flex><span><span style=color:#75715e># starting the replication synchronization process, otherwise the master will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># refuse the replica request.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># masterauth &lt;master-password&gt;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># However this is not enough if you are using Redis ACLs (for Redis version</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 6 or greater), and the default user is not capable of running the PSYNC</span>
</span></span><span style=display:flex><span><span style=color:#75715e># command and/or other commands needed for replication. In this case it&#39;s</span>
</span></span><span style=display:flex><span><span style=color:#75715e># better to configure a special user to use with replication, and specify the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># masteruser configuration as such:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># masteruser &lt;username&gt;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When masteruser is specified, the replica will authenticate against its</span>
</span></span><span style=display:flex><span><span style=color:#75715e># master using the new AUTH form: AUTH &lt;username&gt; &lt;password&gt;.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When a replica loses its connection with the master, or when the replication</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is still in progress, the replica can act in two different ways:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) if replica-serve-stale-data is set to &#39;yes&#39; (the default) the replica will</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    still reply to client requests, possibly with out of date data, or the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    data set may just be empty if this is the first synchronization.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) If replica-serve-stale-data is set to &#39;no&#39; the replica will reply with</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    an error &#34;SYNC with master in progress&#34; to all commands except:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    INFO, REPLICAOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    HOST and LATENCY.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>replica-serve-stale-data yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># You can configure a replica instance to accept writes or not. Writing against</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a replica instance may be useful to store some ephemeral data (because data</span>
</span></span><span style=display:flex><span><span style=color:#75715e># written on a replica will be easily deleted after resync with the master) but</span>
</span></span><span style=display:flex><span><span style=color:#75715e># may also cause problems if clients are writing to it because of a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># misconfiguration.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Since Redis 2.6 by default replicas are read-only.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note: read only replicas are not designed to be exposed to untrusted clients</span>
</span></span><span style=display:flex><span><span style=color:#75715e># on the internet. It&#39;s just a protection layer against misuse of the instance.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Still a read only replica exports by default all the administrative commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e># such as CONFIG, DEBUG, and so forth. To a limited extent you can improve</span>
</span></span><span style=display:flex><span><span style=color:#75715e># security of read only replicas using &#39;rename-command&#39; to shadow all the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># administrative / dangerous commands.</span>
</span></span><span style=display:flex><span>replica-read-only yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Replication SYNC strategy: disk or socket.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># New replicas and reconnecting replicas that are not able to continue the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replication process just receiving differences, need to do what is called a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;full synchronization&#34;. An RDB file is transmitted from the master to the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replicas.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The transmission can happen in two different ways:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) Disk-backed: The Redis master creates a new process that writes the RDB</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                 file on disk. Later the file is transferred by the parent</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                 process to the replicas incrementally.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) Diskless: The Redis master creates a new process that directly writes the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#              RDB file to replica sockets, without touching the disk at all.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># With disk-backed replication, while the RDB file is generated, more replicas</span>
</span></span><span style=display:flex><span><span style=color:#75715e># can be queued and served with the RDB file as soon as the current child</span>
</span></span><span style=display:flex><span><span style=color:#75715e># producing the RDB file finishes its work. With diskless replication instead</span>
</span></span><span style=display:flex><span><span style=color:#75715e># once the transfer starts, new replicas arriving will be queued and a new</span>
</span></span><span style=display:flex><span><span style=color:#75715e># transfer will start when the current one terminates.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When diskless replication is used, the master waits a configurable amount of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># time (in seconds) before starting the transfer in the hope that multiple</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replicas will arrive and the transfer can be parallelized.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># With slow disks and fast (large bandwidth) networks, diskless replication</span>
</span></span><span style=display:flex><span><span style=color:#75715e># works better.</span>
</span></span><span style=display:flex><span>repl-diskless-sync no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When diskless replication is enabled, it is possible to configure the delay</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the server waits in order to spawn the child that transfers the RDB via socket</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to the replicas.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This is important since once the transfer starts, it is not possible to serve</span>
</span></span><span style=display:flex><span><span style=color:#75715e># new replicas arriving, that will be queued for the next RDB transfer, so the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># server waits a delay in order to let more replicas arrive.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The delay is specified in seconds, and by default is 5 seconds. To disable</span>
</span></span><span style=display:flex><span><span style=color:#75715e># it entirely just set it to 0 seconds and the transfer will start ASAP.</span>
</span></span><span style=display:flex><span>repl-diskless-sync-delay <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># -----------------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e># WARNING: RDB diskless load is experimental. Since in this setup the replica</span>
</span></span><span style=display:flex><span><span style=color:#75715e># does not immediately store an RDB on disk, it may cause data loss during</span>
</span></span><span style=display:flex><span><span style=color:#75715e># failovers. RDB diskless load + Redis modules not handling I/O reads may also</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cause Redis to abort in case of I/O errors during the initial synchronization</span>
</span></span><span style=display:flex><span><span style=color:#75715e># stage with the master. Use only if you know what you are doing.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -----------------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Replica can load the RDB it reads from the replication link directly from the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># socket, or store the RDB to a file and read that file after it was completely</span>
</span></span><span style=display:flex><span><span style=color:#75715e># received from the master.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In many cases the disk is slower than the network, and storing and loading</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the RDB file may increase replication time (and even increase the master&#39;s</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Copy on Write memory and salve buffers).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># However, parsing the RDB file directly from the socket may mean that we have</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to flush the contents of the current database before the full rdb was</span>
</span></span><span style=display:flex><span><span style=color:#75715e># received. For this reason we have the following options:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;disabled&#34;    - Don&#39;t use diskless load (store the rdb file to the disk first)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;on-empty-db&#34; - Use diskless load only when it is completely safe.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;swapdb&#34;      - Keep a copy of the current db contents in RAM while parsing</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                 the data directly from the socket. note that this requires</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                 sufficient memory, if you don&#39;t have it, you risk an OOM kill.</span>
</span></span><span style=display:flex><span>repl-diskless-load disabled
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Replicas send PINGs to server in a predefined interval. It&#39;s possible to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># change this interval with the repl_ping_replica_period option. The default</span>
</span></span><span style=display:flex><span><span style=color:#75715e># value is 10 seconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># repl-ping-replica-period 10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The following option sets the replication timeout for:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) Bulk transfer I/O during SYNC, from the point of view of replica.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) Master timeout from the point of view of replicas (data, pings).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is important to make sure that this value is greater than the value</span>
</span></span><span style=display:flex><span><span style=color:#75715e># specified for repl-ping-replica-period otherwise a timeout will be detected</span>
</span></span><span style=display:flex><span><span style=color:#75715e># every time there is low traffic between the master and the replica. The default</span>
</span></span><span style=display:flex><span><span style=color:#75715e># value is 60 seconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># repl-timeout 60</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Disable TCP_NODELAY on the replica socket after SYNC?</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you select &#34;yes&#34; Redis will use a smaller number of TCP packets and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># less bandwidth to send data to replicas. But this can add a delay for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the data to appear on the replica side, up to 40 milliseconds with</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Linux kernels using a default configuration.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you select &#34;no&#34; the delay for data to appear on the replica side will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># be reduced but more bandwidth will be used for replication.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default we optimize for low latency, but in very high traffic conditions</span>
</span></span><span style=display:flex><span><span style=color:#75715e># or when the master and replicas are many hops away, turning this to &#34;yes&#34; may</span>
</span></span><span style=display:flex><span><span style=color:#75715e># be a good idea.</span>
</span></span><span style=display:flex><span>repl-disable-tcp-nodelay no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the replication backlog size. The backlog is a buffer that accumulates</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replica data when replicas are disconnected for some time, so that when a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replica wants to reconnect again, often a full resync is not needed, but a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># partial resync is enough, just passing the portion of data the replica</span>
</span></span><span style=display:flex><span><span style=color:#75715e># missed while disconnected.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The bigger the replication backlog, the longer the replica can endure the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># disconnect and later be able to perform a partial resynchronization.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The backlog is only allocated if there is at least one replica connected.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># repl-backlog-size 1mb</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># After a master has no connected replicas for some time, the backlog will be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># freed. The following option configures the amount of seconds that need to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># elapse, starting from the time the last replica disconnected, for the backlog</span>
</span></span><span style=display:flex><span><span style=color:#75715e># buffer to be freed.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that replicas never free the backlog for timeout, since they may be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># promoted to masters later, and should be able to correctly &#34;partially</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resynchronize&#34; with other replicas: hence they should always accumulate backlog.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># A value of 0 means to never release the backlog.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># repl-backlog-ttl 3600</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The replica priority is an integer number published by Redis in the INFO</span>
</span></span><span style=display:flex><span><span style=color:#75715e># output. It is used by Redis Sentinel in order to select a replica to promote</span>
</span></span><span style=display:flex><span><span style=color:#75715e># into a master if the master is no longer working correctly.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># A replica with a low priority number is considered better for promotion, so</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for instance if there are three replicas with priority 10, 100, 25 Sentinel</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will pick the one with priority 10, that is the lowest.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># However a special priority of 0 marks the replica as not able to perform the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># role of master, so a replica with priority of 0 will never be selected by</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis Sentinel for promotion.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default the priority is 100.</span>
</span></span><span style=display:flex><span>replica-priority <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is possible for a master to stop accepting writes if there are less than</span>
</span></span><span style=display:flex><span><span style=color:#75715e># N replicas connected, having a lag less or equal than M seconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The N replicas need to be in &#34;online&#34; state.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The lag in seconds, that must be &lt;= the specified value, is calculated from</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the last ping received from the replica, that is usually sent every second.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This option does not GUARANTEE that N replicas will accept the write, but</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will limit the window of exposure for lost writes in case not enough replicas</span>
</span></span><span style=display:flex><span><span style=color:#75715e># are available, to the specified number of seconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For example to require at least 3 replicas with a lag &lt;= 10 seconds use:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># min-replicas-to-write 3</span>
</span></span><span style=display:flex><span><span style=color:#75715e># min-replicas-max-lag 10</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Setting one or the other to 0 disables the feature.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default min-replicas-to-write is set to 0 (feature disabled) and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># min-replicas-max-lag is set to 10.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># A Redis master is able to list the address and port of the attached</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replicas in different ways. For example the &#34;INFO replication&#34; section</span>
</span></span><span style=display:flex><span><span style=color:#75715e># offers this information, which is used, among other tools, by</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis Sentinel in order to discover replica instances.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Another place where this info is available is in the output of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;ROLE&#34; command of a master.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The listed IP address and port normally reported by a replica is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># obtained in the following way:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   IP: The address is auto detected by checking the peer address</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   of the socket used by the replica to connect with the master.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   Port: The port is communicated by the replica during the replication</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   handshake, and is normally the port that the replica is using to</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   listen for connections.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># However when port forwarding or Network Address Translation (NAT) is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># used, the replica may actually be reachable via different IP and port</span>
</span></span><span style=display:flex><span><span style=color:#75715e># pairs. The following two options can be used by a replica in order to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># report to its master a specific set of IP and port, so that both INFO</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and ROLE will report those values.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># There is no need to use both the options if you need to override just</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the port or the IP address.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replica-announce-ip 5.5.5.5</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replica-announce-port 1234</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################### KEYS TRACKING #################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis implements server assisted support for client side caching of values.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This is implemented using an invalidation table that remembers, using</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a radix key indexed by key name, what clients have which keys. In turn</span>
</span></span><span style=display:flex><span><span style=color:#75715e># this is used in order to send invalidation messages to clients. Please</span>
</span></span><span style=display:flex><span><span style=color:#75715e># check this page to understand more about the feature:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   https://redis.io/topics/client-side-caching</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When tracking is enabled for a client, all the read only queries are assumed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to be cached: this will force Redis to store information in the invalidation</span>
</span></span><span style=display:flex><span><span style=color:#75715e># table. When keys are modified, such information is flushed away, and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># invalidation messages are sent to the clients. However if the workload is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># heavily dominated by reads, Redis could use more and more memory in order</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to track the keys fetched by many clients.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For this reason it is possible to configure a maximum fill value for the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># invalidation table. By default it is set to 1M of keys, and once this limit</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is reached, Redis will start to evict keys in the invalidation table</span>
</span></span><span style=display:flex><span><span style=color:#75715e># even if they were not modified, just to reclaim memory: this will in turn</span>
</span></span><span style=display:flex><span><span style=color:#75715e># force the clients to invalidate the cached values. Basically the table</span>
</span></span><span style=display:flex><span><span style=color:#75715e># maximum size is a trade off between the memory you want to spend server</span>
</span></span><span style=display:flex><span><span style=color:#75715e># side to track information about who cached what, and the ability of clients</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to retain cached objects in memory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you set the value to 0, it means there are no limits, and Redis will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># retain as many keys as needed in the invalidation table.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In the &#34;stats&#34; INFO section, you can find information about the number of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># keys in the invalidation table at every given moment.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note: when key tracking is used in broadcasting mode, no memory is used</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in the server side so this setting is useless.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tracking-table-max-keys 1000000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################## SECURITY ###################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Warning: since Redis is pretty fast, an outside user can try up to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1 million passwords per second against a modern box. This means that you</span>
</span></span><span style=display:flex><span><span style=color:#75715e># should use very strong passwords, otherwise they will be very easy to break.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that because the password is really a shared secret between the client</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and the server, and should not be memorized by any human, the password</span>
</span></span><span style=display:flex><span><span style=color:#75715e># can be easily a long string from /dev/urandom or whatever, so by using a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># long and unguessable password no brute force attack will be possible.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis ACL users are defined in the following format:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   user &lt;username&gt; ... acl rules ...</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For example:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The special username &#34;default&#34; is used for new connections. If this user</span>
</span></span><span style=display:flex><span><span style=color:#75715e># has the &#34;nopass&#34; rule, then new connections will be immediately authenticated</span>
</span></span><span style=display:flex><span><span style=color:#75715e># as the &#34;default&#34; user without the need of any password provided via the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AUTH command. Otherwise if the &#34;default&#34; user is not flagged with &#34;nopass&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the connections will start in not authenticated state, and will require</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AUTH (or the HELLO command AUTH option) in order to be authenticated and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># start to work.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The ACL rules that describe what a user can do are the following:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  on           Enable the user: it is possible to authenticate as this user.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  off          Disable the user: it&#39;s no longer possible to authenticate</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               with this user, however the already authenticated connections</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               will still work.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  skip-sanitize-payload    RESTORE dump-payload sanitation is skipped.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  sanitize-payload         RESTORE dump-payload is sanitized (default).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  +&lt;command&gt;   Allow the execution of that command</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  -&lt;command&gt;   Disallow the execution of that command</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  +@&lt;category&gt; Allow the execution of all the commands in such category</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               with valid categories are like @admin, @set, @sortedset, ...</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               and so forth, see the full list in the server.c file where</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               the Redis command table is described and defined.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               The special category @all means all the commands, but currently</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               present in the server, and that will be loaded in the future</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               via modules.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  +&lt;command&gt;|subcommand    Allow a specific subcommand of an otherwise</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                           disabled command. Note that this form is not</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                           allowed as negative like -DEBUG|SEGFAULT, but</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#                           only additive starting with &#34;+&#34;.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  allcommands  Alias for +@all. Note that it implies the ability to execute</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               all the future commands loaded via the modules system.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  nocommands   Alias for -@all.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  ~&lt;pattern&gt;   Add a pattern of keys that can be mentioned as part of</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               commands. For instance ~* allows all the keys. The pattern</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               is a glob-style pattern like the one of KEYS.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               It is possible to specify multiple patterns.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  allkeys      Alias for ~*</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  resetkeys    Flush the list of allowed keys patterns.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  &amp;&lt;pattern&gt;   Add a glob-style pattern of Pub/Sub channels that can be</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               accessed by the user. It is possible to specify multiple channel</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               patterns.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  allchannels  Alias for &amp;*</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  resetchannels            Flush the list of allowed channel patterns.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  &gt;&lt;password&gt;  Add this password to the list of valid password for the user.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               For example &gt;mypass will add &#34;mypass&#34; to the list.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               This directive clears the &#34;nopass&#34; flag (see later).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  &lt;&lt;password&gt;  Remove this password from the list of valid passwords.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  nopass       All the set passwords of the user are removed, and the user</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               is flagged as requiring no password: it means that every</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               password will work against this user. If this directive is</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               used for the default user, every new connection will be</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               immediately authenticated with the default user without</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               any explicit AUTH command required. Note that the &#34;resetpass&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               directive will clear this condition.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  resetpass    Flush the list of allowed passwords. Moreover removes the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               &#34;nopass&#34; status. After &#34;resetpass&#34; the user has no associated</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               passwords and there is no way to authenticate without adding</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               some password (or setting it as &#34;nopass&#34; later).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  reset        Performs the following actions: resetpass, resetkeys, off,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               -@all. The user returns to the same state it has immediately</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#               after its creation.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ACL rules can be specified in any order: for instance you can start with</span>
</span></span><span style=display:flex><span><span style=color:#75715e># passwords, then flags, or key patterns. However note that the additive</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and subtractive rules will CHANGE MEANING depending on the ordering.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For instance see the following example:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   user alice on +@all -DEBUG ~* &gt;somepassword</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This will allow &#34;alice&#34; to use all the commands with the exception of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># DEBUG command, since +@all added all the commands to the set of the commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e># alice can use, and later DEBUG was removed. However if we invert the order</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of two ACL rules the result will be different:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   user alice on -DEBUG +@all ~* &gt;somepassword</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Now DEBUG was removed when alice had yet no commands in the set of allowed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># commands, later all the commands are added, so the user will be able to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># execute everything.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Basically ACL rules are processed left-to-right.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For more information about ACL configuration please refer to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the Redis web site at https://redis.io/topics/acl</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ACL LOG</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The ACL Log tracks failed commands and authentication events associated</span>
</span></span><span style=display:flex><span><span style=color:#75715e># with ACLs. The ACL Log is useful to troubleshoot failed commands blocked </span>
</span></span><span style=display:flex><span><span style=color:#75715e># by ACLs. The ACL Log is stored in memory. You can reclaim memory with </span>
</span></span><span style=display:flex><span><span style=color:#75715e># ACL LOG RESET. Define the maximum entry length of the ACL Log below.</span>
</span></span><span style=display:flex><span>acllog-max-len <span style=color:#ae81ff>128</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Using an external ACL file</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Instead of configuring users here in this file, it is possible to use</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a stand-alone file just listing users. The two methods cannot be mixed:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># if you configure users here and at the same time you activate the external</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ACL file, the server will refuse to start.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The format of the external ACL user file is exactly the same as the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># format that is used inside redis.conf to describe users.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># aclfile /etc/redis/users.acl</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># IMPORTANT NOTE: starting with Redis 6 &#34;requirepass&#34; is just a compatibility</span>
</span></span><span style=display:flex><span><span style=color:#75715e># layer on top of the new ACL system. The option effect will be just setting</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the password for the default user. Clients will still authenticate using</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AUTH &lt;password&gt; as usually, or more explicitly with AUTH default &lt;password&gt;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># if they follow the new protocol: both will work.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The requirepass is not compatable with aclfile option and the ACL LOAD</span>
</span></span><span style=display:flex><span><span style=color:#75715e># command, these will cause requirepass to be ignored.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; Redis默认没有密码；可以在这里设置密码</span>
</span></span><span style=display:flex><span><span style=color:#75715e># requirepass wpl19950815</span>
</span></span><span style=display:flex><span><span style=color:#75715e># requirepass foobared</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># New users are initialized with restrictive permissions by default, via the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># equivalent of this ACL rule &#39;off resetkeys -@all&#39;. Starting with Redis 6.2, it</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is possible to manage access to Pub/Sub channels with ACL rules as well. The</span>
</span></span><span style=display:flex><span><span style=color:#75715e># default Pub/Sub channels permission if new users is controlled by the </span>
</span></span><span style=display:flex><span><span style=color:#75715e># acl-pubsub-default configuration directive, which accepts one of these values:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># allchannels: grants access to all Pub/Sub channels</span>
</span></span><span style=display:flex><span><span style=color:#75715e># resetchannels: revokes access to all Pub/Sub channels</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># To ensure backward compatibility while upgrading Redis 6.0, acl-pubsub-default</span>
</span></span><span style=display:flex><span><span style=color:#75715e># defaults to the &#39;allchannels&#39; permission.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Future compatibility note: it is very likely that in a future version of Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the directive&#39;s default of &#39;allchannels&#39; will be changed to &#39;resetchannels&#39; in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># order to provide better out-of-the-box Pub/Sub security. Therefore, it is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># recommended that you explicitly define Pub/Sub permissions for all users</span>
</span></span><span style=display:flex><span><span style=color:#75715e># rather then rely on implicit default values. Once you&#39;ve set explicit</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Pub/Sub for all exisitn users, you should uncomment the following line.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># acl-pubsub-default resetchannels</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Command renaming (DEPRECATED).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e># WARNING: avoid using this option if possible. Instead use ACLs to remove</span>
</span></span><span style=display:flex><span><span style=color:#75715e># commands from the default user, and put them only in some admin user you</span>
</span></span><span style=display:flex><span><span style=color:#75715e># create for administrative purposes.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is possible to change the name of dangerous commands in a shared</span>
</span></span><span style=display:flex><span><span style=color:#75715e># environment. For instance the CONFIG command may be renamed into something</span>
</span></span><span style=display:flex><span><span style=color:#75715e># hard to guess so that it will still be available for internal-use tools</span>
</span></span><span style=display:flex><span><span style=color:#75715e># but not available for general clients.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Example:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is also possible to completely kill a command by renaming it into</span>
</span></span><span style=display:flex><span><span style=color:#75715e># an empty string:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># rename-command CONFIG &#34;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Please note that changing the name of commands that are logged into the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AOF file or transmitted to replicas may cause problems.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################### CLIENTS ####################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the max number of connected clients at the same time. By default</span>
</span></span><span style=display:flex><span><span style=color:#75715e># this limit is set to 10000 clients, however if the Redis server is not</span>
</span></span><span style=display:flex><span><span style=color:#75715e># able to configure the process file limit to allow for the specified limit</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the max number of allowed clients is set to the current file limit</span>
</span></span><span style=display:flex><span><span style=color:#75715e># minus 32 (as Redis reserves a few file descriptors for internal uses).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Once the limit is reached Redis will close all the new connections sending</span>
</span></span><span style=display:flex><span><span style=color:#75715e># an error &#39;max number of clients reached&#39;.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># IMPORTANT: When Redis Cluster is used, the max number of connections is also</span>
</span></span><span style=display:flex><span><span style=color:#75715e># shared with the cluster bus: every node in the cluster will use two</span>
</span></span><span style=display:flex><span><span style=color:#75715e># connections, one incoming and another outgoing. It is important to size the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># limit accordingly in case of very large clusters.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 限制client最大连接数</span>
</span></span><span style=display:flex><span><span style=color:#75715e># maxclients 10000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################## MEMORY MANAGEMENT ################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set a memory usage limit to the specified amount of bytes.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When the memory limit is reached Redis will try to remove keys</span>
</span></span><span style=display:flex><span><span style=color:#75715e># according to the eviction policy selected (see maxmemory-policy).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If Redis can&#39;t remove keys according to the policy, or if the policy is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># set to &#39;noeviction&#39;, Redis will start to reply with errors to commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that would use more memory, like SET, LPUSH, and so on, and will continue</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to reply to read-only commands like GET.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This option is usually useful when using Redis as an LRU or LFU cache, or to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># set a hard memory limit for an instance (using the &#39;noeviction&#39; policy).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># WARNING: If you have replicas attached to an instance with maxmemory on,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the size of the output buffers needed to feed the replicas are subtracted</span>
</span></span><span style=display:flex><span><span style=color:#75715e># from the used memory count, so that network problems / resyncs will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># not trigger a loop where keys are evicted, and in turn the output</span>
</span></span><span style=display:flex><span><span style=color:#75715e># buffer of replicas is full with DELs of keys evicted triggering the deletion</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of more keys, and so forth until the database is completely emptied.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In short... if you have replicas attached it is suggested that you set a lower</span>
</span></span><span style=display:flex><span><span style=color:#75715e># limit for maxmemory so that there is some free RAM on the system for replica</span>
</span></span><span style=display:flex><span><span style=color:#75715e># output buffers (but this is not needed if the policy is &#39;noeviction&#39;).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 配置Redis最大内存容量;单位字节</span>
</span></span><span style=display:flex><span><span style=color:#75715e># maxmemory &lt;bytes&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># MAXMEMORY POLICY: how Redis will select what to remove when maxmemory</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is reached. You can select one from the following behaviors:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># allkeys-lru -&gt; Evict any key using approximated LRU.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># allkeys-lfu -&gt; Evict any key using approximated LFU.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># volatile-random -&gt; Remove a random key having an expire set.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># allkeys-random -&gt; Remove a random key, any key.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># noeviction -&gt; Don&#39;t evict anything, just return an error on write operations.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LRU means Least Recently Used</span>
</span></span><span style=display:flex><span><span style=color:#75715e># LFU means Least Frequently Used</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Both LRU, LFU and volatile-ttl are implemented using approximated</span>
</span></span><span style=display:flex><span><span style=color:#75715e># randomized algorithms.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note: with any of the above policies, when there are no suitable keys for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># eviction, Redis will return an error on write operations that require</span>
</span></span><span style=display:flex><span><span style=color:#75715e># more memory. These are usually commands that create new keys, add data or</span>
</span></span><span style=display:flex><span><span style=color:#75715e># modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># SORT (due to the STORE argument), and EXEC (if the transaction includes any</span>
</span></span><span style=display:flex><span><span style=color:#75715e># command that requires memory).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default is:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 内存到达上限的处理策略</span>
</span></span><span style=display:flex><span><span style=color:#75715e># maxmemory-policy noeviction</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated</span>
</span></span><span style=display:flex><span><span style=color:#75715e># algorithms (in order to save memory), so you can tune it for speed or</span>
</span></span><span style=display:flex><span><span style=color:#75715e># accuracy. By default Redis will check five keys and pick the one that was</span>
</span></span><span style=display:flex><span><span style=color:#75715e># used least recently, you can change the sample size using the following</span>
</span></span><span style=display:flex><span><span style=color:#75715e># configuration directive.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default of 5 produces good enough results. 10 Approximates very closely</span>
</span></span><span style=display:flex><span><span style=color:#75715e># true LRU but costs more CPU. 3 is faster but not very accurate.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># maxmemory-samples 5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Eviction processing is designed to function well with the default setting.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If there is an unusually large amount of write traffic, this value may need to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># be increased.  Decreasing this value may reduce latency at the risk of </span>
</span></span><span style=display:flex><span><span style=color:#75715e># eviction processing effectiveness</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   0 = minimum latency, 10 = default, 100 = process without regard to latency</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># maxmemory-eviction-tenacity 10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Starting from Redis 5, by default a replica will ignore its maxmemory setting</span>
</span></span><span style=display:flex><span><span style=color:#75715e># (unless it is promoted to master after a failover or manually). It means</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that the eviction of keys will be just handled by the master, sending the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># DEL commands to the replica as keys evict in the master side.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This behavior ensures that masters and replicas stay consistent, and is usually</span>
</span></span><span style=display:flex><span><span style=color:#75715e># what you want, however if your replica is writable, or you want the replica</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to have a different memory setting, and you are sure all the writes performed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to the replica are idempotent, then you may change this default (but be sure</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to understand what you are doing).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that since the replica by default does not evict, it may end using more</span>
</span></span><span style=display:flex><span><span style=color:#75715e># memory than the one set via maxmemory (there are certain buffers that may</span>
</span></span><span style=display:flex><span><span style=color:#75715e># be larger on the replica, or data structures may sometimes take more memory</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and so forth). So make sure you monitor your replicas and make sure they</span>
</span></span><span style=display:flex><span><span style=color:#75715e># have enough memory to never hit a real out-of-memory condition before the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># master hits the configured maxmemory setting.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replica-ignore-maxmemory yes</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis reclaims expired keys in two ways: upon access when those keys are</span>
</span></span><span style=display:flex><span><span style=color:#75715e># found to be expired, and also in background, in what is called the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;active expire key&#34;. The key space is slowly and interactively scanned</span>
</span></span><span style=display:flex><span><span style=color:#75715e># looking for expired keys to reclaim, so that it is possible to free memory</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of keys that are expired and will never be accessed again in a short time.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default effort of the expire cycle will try to avoid having more than</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ten percent of expired keys still in memory, and will try to avoid consuming</span>
</span></span><span style=display:flex><span><span style=color:#75715e># more than 25% of total memory and to add latency to the system. However</span>
</span></span><span style=display:flex><span><span style=color:#75715e># it is possible to increase the expire &#34;effort&#34; that is normally set to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;1&#34;, to a greater value, up to the value &#34;10&#34;. At its maximum value the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># system will use more CPU, longer cycles (and technically may introduce</span>
</span></span><span style=display:flex><span><span style=color:#75715e># more latency), and will tolerate less already expired keys still present</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in the system. It&#39;s a tradeoff between memory, CPU and latency.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># active-expire-effort 1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################# LAZY FREEING ####################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis has two primitives to delete keys. One is called DEL and is a blocking</span>
</span></span><span style=display:flex><span><span style=color:#75715e># deletion of the object. It means that the server stops processing new commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to reclaim all the memory associated with an object in a synchronous</span>
</span></span><span style=display:flex><span><span style=color:#75715e># way. If the key deleted is associated with a small object, the time needed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to execute the DEL command is very small and comparable to most other</span>
</span></span><span style=display:flex><span><span style=color:#75715e># O(1) or O(log_N) commands in Redis. However if the key is associated with an</span>
</span></span><span style=display:flex><span><span style=color:#75715e># aggregated value containing millions of elements, the server can block for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a long time (even seconds) in order to complete the operation.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For the above reasons Redis also offers non blocking deletion primitives</span>
</span></span><span style=display:flex><span><span style=color:#75715e># such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># FLUSHDB commands, in order to reclaim memory in background. Those commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e># are executed in constant time. Another thread will incrementally free the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># object in the background as fast as possible.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># It&#39;s up to the design of the application to understand when it is a good</span>
</span></span><span style=display:flex><span><span style=color:#75715e># idea to use one or the other. However the Redis server sometimes has to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># delete keys or flush the whole database as a side effect of other operations.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specifically Redis deletes objects independently of a user call in the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># following scenarios:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) On eviction, because of the maxmemory and maxmemory policy configurations,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    in order to make room for new data, without going over the specified</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    memory limit.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) Because of expire: when a key with an associated time to live (see the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    EXPIRE command) must be deleted from memory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3) Because of a side effect of a command that stores data on a key that may</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    already exist. For example the RENAME command may delete the old key</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    content when it is replaced with another one. Similarly SUNIONSTORE</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    or SORT with STORE option may delete existing keys. The SET command</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    itself removes any old content of the specified key in order to replace</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    it with the specified string.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 4) During replication, when a replica performs a full resynchronization with</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    its master, the content of the whole database is removed in order to</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    load the RDB file just transferred.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In all the above cases the default is to delete objects in a blocking way,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># like if DEL was called. However you can configure each case specifically</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to instead release memory in a non-blocking way like if UNLINK</span>
</span></span><span style=display:flex><span><span style=color:#75715e># was called, using the following configuration directives.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lazyfree-lazy-eviction no
</span></span><span style=display:flex><span>lazyfree-lazy-expire no
</span></span><span style=display:flex><span>lazyfree-lazy-server-del no
</span></span><span style=display:flex><span>replica-lazy-flush no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is also possible, for the case when to replace the user code DEL calls</span>
</span></span><span style=display:flex><span><span style=color:#75715e># with UNLINK calls is not easy, to modify the default behavior of the DEL</span>
</span></span><span style=display:flex><span><span style=color:#75715e># command to act exactly like UNLINK, using the following configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e># directive:</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lazyfree-lazy-user-del no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># FLUSHDB, FLUSHALL, and SCRIPT FLUSH support both asynchronous and synchronous</span>
</span></span><span style=display:flex><span><span style=color:#75715e># deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># commands. When neither flag is passed, this directive will be used to determine</span>
</span></span><span style=display:flex><span><span style=color:#75715e># if the data should be deleted asynchronously.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lazyfree-lazy-user-flush no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################ THREADED I/O #################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis is mostly single threaded, however there are certain threaded</span>
</span></span><span style=display:flex><span><span style=color:#75715e># operations such as UNLINK, slow I/O accesses and other things that are</span>
</span></span><span style=display:flex><span><span style=color:#75715e># performed on side threads.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Now it is also possible to handle Redis clients socket reads and writes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in different I/O threads. Since especially writing is so slow, normally</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis users use pipelining in order to speed up the Redis performances per</span>
</span></span><span style=display:flex><span><span style=color:#75715e># core, and spawn multiple instances in order to scale more. Using I/O</span>
</span></span><span style=display:flex><span><span style=color:#75715e># threads it is possible to easily speedup two times Redis without resorting</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to pipelining nor sharding of the instance.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default threading is disabled, we suggest enabling it only in machines</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that have at least 4 or more cores, leaving at least one spare core.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Using more than 8 threads is unlikely to help much. We also recommend using</span>
</span></span><span style=display:flex><span><span style=color:#75715e># threaded I/O only if you actually have performance problems, with Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># instances being able to use a quite big percentage of CPU time, otherwise</span>
</span></span><span style=display:flex><span><span style=color:#75715e># there is no point in using this feature.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># So for instance if you have a four cores boxes, try to use 2 or 3 I/O</span>
</span></span><span style=display:flex><span><span style=color:#75715e># threads, if you have a 8 cores, try to use 6 threads. In order to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># enable I/O threads use the following configuration directive:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># io-threads 4</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Setting io-threads to 1 will just use the main thread as usual.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When I/O threads are enabled, we only use threads for writes, that is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to thread the write(2) syscall and transfer the client buffers to the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># socket. However it is also possible to enable threading of reads and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># protocol parsing using the following configuration directive, by setting</span>
</span></span><span style=display:flex><span><span style=color:#75715e># it to yes:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># io-threads-do-reads no</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Usually threading reads doesn&#39;t help much.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NOTE 1: This configuration directive cannot be changed at runtime via</span>
</span></span><span style=display:flex><span><span style=color:#75715e># CONFIG SET. Aso this feature currently does not work when SSL is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># enabled.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NOTE 2: If you want to test the Redis speedup using redis-benchmark, make</span>
</span></span><span style=display:flex><span><span style=color:#75715e># sure you also run the benchmark itself in threaded mode, using the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># --threads option to match the number of Redis threads, otherwise you&#39;ll not</span>
</span></span><span style=display:flex><span><span style=color:#75715e># be able to notice the improvements.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################ KERNEL OOM CONTROL ##############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># On Linux, it is possible to hint the kernel OOM killer on what processes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># should be killed first when out of memory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Enabling this feature makes Redis actively control the oom_score_adj value</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for all its processes, depending on their role. The default scores will</span>
</span></span><span style=display:flex><span><span style=color:#75715e># attempt to have background child processes killed before all others, and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replicas killed before masters.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis supports three options:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># no:       Don&#39;t make changes to oom-score-adj (default).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># yes:      Alias to &#34;relative&#34; see below.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># absolute: Values in oom-score-adj-values are written as is to the kernel.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># relative: Values are used relative to the initial value of oom_score_adj when</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#           the server starts and are then clamped to a range of -1000 to 1000.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#           Because typically the initial value is 0, they will often match the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#           absolute values.</span>
</span></span><span style=display:flex><span>oom-score-adj no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When oom-score-adj is used, this directive controls the specific values used</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for master, replica and background child processes. Values range -2000 to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2000 (higher means more likely to be killed).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># can freely increase their value, but not decrease it below its initial</span>
</span></span><span style=display:flex><span><span style=color:#75715e># settings. This means that setting oom-score-adj to &#34;relative&#34; and setting the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># oom-score-adj-values to positive values will always succeed.</span>
</span></span><span style=display:flex><span>oom-score-adj-values <span style=color:#ae81ff>0</span> <span style=color:#ae81ff>200</span> <span style=color:#ae81ff>800</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#################### KERNEL transparent hugepage CONTROL ######################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Usually the kernel Transparent Huge Pages control is set to &#34;madvise&#34; or</span>
</span></span><span style=display:flex><span><span style=color:#75715e># or &#34;never&#34; by default (/sys/kernel/mm/transparent_hugepage/enabled), in which</span>
</span></span><span style=display:flex><span><span style=color:#75715e># case this config has no effect. On systems in which it is set to &#34;always&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># redis will attempt to disable it specifically for the redis process in order</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to avoid latency problems specifically with fork(2) and CoW.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If for some reason you prefer to keep it enabled, you can set this config to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;no&#34; and the kernel global to &#34;always&#34;.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>disable-thp yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################## APPEND ONLY MODE ###############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default Redis asynchronously dumps the dataset on disk. This mode is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># good enough in many applications, but an issue with the Redis process or</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a power outage may result into a few minutes of writes lost (depending on</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the configured save points).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The Append Only File is an alternative persistence mode that provides</span>
</span></span><span style=display:flex><span><span style=color:#75715e># much better durability. For instance using the default data fsync policy</span>
</span></span><span style=display:flex><span><span style=color:#75715e># (see later in the config file) Redis can lose just one second of writes in a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># dramatic event like a server power outage, or a single write if something</span>
</span></span><span style=display:flex><span><span style=color:#75715e># wrong with the Redis process itself happens, but the operating system is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># still running correctly.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AOF and RDB persistence can be enabled at the same time without problems.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If the AOF is enabled on startup Redis will load the AOF, that is the file</span>
</span></span><span style=display:flex><span><span style=color:#75715e># with the better durability guarantees.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Please check http://redis.io/topics/persistence for more information.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 是否开启aof模式；默认使用rdb方式持久化</span>
</span></span><span style=display:flex><span>appendonly no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The name of the append only file (default: &#34;appendonly.aof&#34;)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 使用aof持久化文件的名称</span>
</span></span><span style=display:flex><span>appendfilename <span style=color:#e6db74>&#34;appendonly.aof&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The fsync() call tells the Operating System to actually write data on disk</span>
</span></span><span style=display:flex><span><span style=color:#75715e># instead of waiting for more data in the output buffer. Some OS will really flush</span>
</span></span><span style=display:flex><span><span style=color:#75715e># data on disk, some other OS will just try to do it ASAP.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis supports three different modes:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># no: don&#39;t fsync, just let the OS flush the data when it wants. Faster.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># always: fsync after every write to the append only log. Slow, Safest.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># everysec: fsync only one time every second. Compromise.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default is &#34;everysec&#34;, as that&#39;s usually the right compromise between</span>
</span></span><span style=display:flex><span><span style=color:#75715e># speed and data safety. It&#39;s up to you to understand if you can relax this to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;no&#34; that will let the operating system flush the output buffer when</span>
</span></span><span style=display:flex><span><span style=color:#75715e># it wants, for better performances (but if you can live with the idea of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># some data loss consider the default persistence mode that&#39;s snapshotting),</span>
</span></span><span style=display:flex><span><span style=color:#75715e># or on the contrary, use &#34;always&#34; that&#39;s very slow but a bit safer than</span>
</span></span><span style=display:flex><span><span style=color:#75715e># everysec.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># More details please check the following article:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># http://antirez.com/post/redis-persistence-demystified.html</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If unsure, use &#34;everysec&#34;.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 每次修改都会同步；耗费性能</span>
</span></span><span style=display:flex><span><span style=color:#75715e># appendfsync always </span>
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 每秒执行一次同步；可能会丢失这一秒的数据</span>
</span></span><span style=display:flex><span>appendfsync everysec
</span></span><span style=display:flex><span><span style=color:#75715e># =&gt; 不执行同步；由操作系统自己同步</span>
</span></span><span style=display:flex><span><span style=color:#75715e># appendfsync no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When the AOF fsync policy is set to always or everysec, and a background</span>
</span></span><span style=display:flex><span><span style=color:#75715e># saving process (a background save or AOF log background rewriting) is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># performing a lot of I/O against the disk, in some Linux configurations</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis may block too long on the fsync() call. Note that there is no fix for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># this currently, as even performing fsync in a different thread will block</span>
</span></span><span style=display:flex><span><span style=color:#75715e># our synchronous write(2) call.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In order to mitigate this problem it&#39;s possible to use the following option</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that will prevent fsync() from being called in the main process while a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># BGSAVE or BGREWRITEAOF is in progress.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This means that while another child is saving, the durability of Redis is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the same as &#34;appendfsync none&#34;. In practical terms, this means that it is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># possible to lose up to 30 seconds of log in the worst scenario (with the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># default Linux settings).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you have latency problems turn this to &#34;yes&#34;. Otherwise leave it as</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;no&#34; that is the safest pick from the point of view of durability.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>no-appendfsync-on-rewrite no
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Automatic rewrite of the append only file.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis is able to automatically rewrite the log file implicitly calling</span>
</span></span><span style=display:flex><span><span style=color:#75715e># BGREWRITEAOF when the AOF log size grows by the specified percentage.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This is how it works: Redis remembers the size of the AOF file after the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># latest rewrite (if no rewrite has happened since the restart, the size of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the AOF at startup is used).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This base size is compared to the current size. If the current size is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># bigger than the specified percentage, the rewrite is triggered. Also</span>
</span></span><span style=display:flex><span><span style=color:#75715e># you need to specify a minimal size for the AOF file to be rewritten, this</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is useful to avoid rewriting the AOF file even if the percentage increase</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is reached but it is still pretty small.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify a percentage of zero in order to disable the automatic AOF</span>
</span></span><span style=display:flex><span><span style=color:#75715e># rewrite feature.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>auto-aof-rewrite-percentage <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>auto-aof-rewrite-min-size 64mb
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># An AOF file may be found to be truncated at the end during the Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># startup process, when the AOF data gets loaded back into memory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This may happen when the system where Redis is running</span>
</span></span><span style=display:flex><span><span style=color:#75715e># crashes, especially when an ext4 filesystem is mounted without the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># data=ordered option (however this can&#39;t happen when Redis itself</span>
</span></span><span style=display:flex><span><span style=color:#75715e># crashes or aborts but the operating system still works correctly).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis can either exit with an error when this happens, or load as much</span>
</span></span><span style=display:flex><span><span style=color:#75715e># data as possible (the default now) and start if the AOF file is found</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to be truncated at the end. The following option controls this behavior.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If aof-load-truncated is set to yes, a truncated AOF file is loaded and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the Redis server starts emitting a log to inform the user of the event.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Otherwise if the option is set to no, the server aborts with an error</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and refuses to start. When the option is set to no, the user requires</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to fix the AOF file using the &#34;redis-check-aof&#34; utility before to restart</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the server.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that if the AOF file will be found to be corrupted in the middle</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the server will still exit with an error. This option only applies when</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis will try to read more data from the AOF file but not enough bytes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will be found.</span>
</span></span><span style=display:flex><span>aof-load-truncated yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When rewriting the AOF file, Redis is able to use an RDB preamble in the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># AOF file for faster rewrites and recoveries. When this option is turned</span>
</span></span><span style=display:flex><span><span style=color:#75715e># on the rewritten AOF file is composed of two different stanzas:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   [RDB file][AOF tail]</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When loading, Redis recognizes that the AOF file starts with the &#34;REDIS&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># string and loads the prefixed RDB file, then continues loading the AOF</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tail.</span>
</span></span><span style=display:flex><span>aof-use-rdb-preamble yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################ LUA SCRIPTING  ###############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Max execution time of a Lua script in milliseconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If the maximum execution time is reached Redis will log that a script is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># still in execution after the maximum allowed time and will start to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># reply to queries with an error.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When a long running script exceeds the maximum execution time only the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># used to stop a script that did not yet call any write commands. The second</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is the only way to shut down the server in the case a write command was</span>
</span></span><span style=display:flex><span><span style=color:#75715e># already issued by the script but the user doesn&#39;t want to wait for the natural</span>
</span></span><span style=display:flex><span><span style=color:#75715e># termination of the script.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set it to 0 or a negative value for unlimited execution without warnings.</span>
</span></span><span style=display:flex><span>lua-time-limit <span style=color:#ae81ff>5000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################ REDIS CLUSTER  ###############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Normal Redis instances can&#39;t be part of a Redis Cluster; only nodes that are</span>
</span></span><span style=display:flex><span><span style=color:#75715e># started as cluster nodes can. In order to start a Redis instance as a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster node enable the cluster support uncommenting the following:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-enabled yes</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Every cluster node has a cluster configuration file. This file is not</span>
</span></span><span style=display:flex><span><span style=color:#75715e># intended to be edited by hand. It is created and updated by Redis nodes.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Every Redis Cluster node requires a different cluster configuration file.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Make sure that instances running in the same system do not have</span>
</span></span><span style=display:flex><span><span style=color:#75715e># overlapping cluster configuration file names.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-config-file nodes-6379.conf</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Cluster node timeout is the amount of milliseconds a node must be unreachable</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for it to be considered in failure state.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Most other internal time limits are a multiple of the node timeout.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-node-timeout 15000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># A replica of a failing master will avoid to start a failover if its data</span>
</span></span><span style=display:flex><span><span style=color:#75715e># looks too old.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># There is no simple way for a replica to actually have an exact measure of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># its &#34;data age&#34;, so the following two checks are performed:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1) If there are multiple replicas able to failover, they exchange messages</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    in order to try to give an advantage to the replica with the best</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    replication offset (more data from the master processed).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    Replicas will try to get their rank by offset, and apply to the start</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    of the failover a delay proportional to their rank.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2) Every single replica computes the time of the last interaction with</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    its master. This can be the last ping or command received (if the master</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    is still in the &#34;connected&#34; state), or the time that elapsed since the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    disconnection with the master (if the replication link is currently down).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    If the last interaction is too old, the replica will not try to failover</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    at all.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The point &#34;2&#34; can be tuned by user. Specifically a replica will not perform</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the failover if, since the last interaction with the master, the time</span>
</span></span><span style=display:flex><span><span style=color:#75715e># elapsed is greater than:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is 10, and assuming a default repl-ping-replica-period of 10 seconds, the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replica will not try to failover if it was not able to talk with the master</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for longer than 310 seconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># A large cluster-replica-validity-factor may allow replicas with too old data to failover</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a master, while a too small value may prevent the cluster from being able to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># elect a replica at all.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For maximum availability, it is possible to set the cluster-replica-validity-factor</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to a value of 0, which means, that replicas will always try to failover the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># master regardless of the last time they interacted with the master.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># (However they&#39;ll always try to apply a delay proportional to their</span>
</span></span><span style=display:flex><span><span style=color:#75715e># offset rank).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Zero is the only value able to guarantee that when all the partitions heal</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the cluster will always be able to continue.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-replica-validity-factor 10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Cluster replicas are able to migrate to orphaned masters, that are masters</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that are left without working replicas. This improves the cluster ability</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to resist to failures as otherwise an orphaned master can&#39;t be failed over</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in case of failure if it has no working replicas.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Replicas migrate to orphaned masters only if there are still at least a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># given number of other working replicas for their old master. This number</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is the &#34;migration barrier&#34;. A migration barrier of 1 means that a replica</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will migrate only if there is at least 1 other working replica for its master</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and so forth. It usually reflects the number of replicas you want for every</span>
</span></span><span style=display:flex><span><span style=color:#75715e># master in your cluster.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Default is 1 (replicas migrate only if their masters remain with at least</span>
</span></span><span style=display:flex><span><span style=color:#75715e># one replica). To disable migration just set it to a very large value.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># A value of 0 can be set but is useful only for debugging and dangerous</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in production.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-migration-barrier 1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default Redis Cluster nodes stop accepting queries if they detect there</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is at least a hash slot uncovered (no available node is serving it).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This way if the cluster is partially down (for example a range of hash slots</span>
</span></span><span style=display:flex><span><span style=color:#75715e># are no longer covered) all the cluster becomes, eventually, unavailable.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># It automatically returns available as soon as all the slots are covered again.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># However sometimes you want the subset of the cluster which is working,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to continue to accept queries for the part of the key space that is still</span>
</span></span><span style=display:flex><span><span style=color:#75715e># covered. In order to do so, just set the cluster-require-full-coverage</span>
</span></span><span style=display:flex><span><span style=color:#75715e># option to no.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-require-full-coverage yes</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># This option, when set to yes, prevents replicas from trying to failover its</span>
</span></span><span style=display:flex><span><span style=color:#75715e># master during master failures. However the replica can still perform a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># manual failover, if forced to do so.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This is useful in different scenarios, especially in the case of multiple</span>
</span></span><span style=display:flex><span><span style=color:#75715e># data center operations, where we want one side to never be promoted if not</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in the case of a total DC failure.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-replica-no-failover no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># This option, when set to yes, allows nodes to serve read traffic while the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the cluster is in a down state, as long as it believes it owns the slots. </span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This is useful for two cases.  The first case is for when an application </span>
</span></span><span style=display:flex><span><span style=color:#75715e># doesn&#39;t require consistency of data during node failures or network partitions.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># One example of this is a cache, where as long as the node has the data it</span>
</span></span><span style=display:flex><span><span style=color:#75715e># should be able to serve it. </span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The second use case is for configurations that don&#39;t meet the recommended  </span>
</span></span><span style=display:flex><span><span style=color:#75715e># three shards but want to enable cluster mode and scale later. A </span>
</span></span><span style=display:flex><span><span style=color:#75715e># master outage in a 1 or 2 shard configuration causes a read/write outage to the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># entire cluster without this option set, with it set there is only a write outage.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Without a quorum of masters, slot ownership will not change automatically. </span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-allow-reads-when-down no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># In order to setup your cluster make sure to read the documentation</span>
</span></span><span style=display:flex><span><span style=color:#75715e># available at http://redis.io web site.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>########################## CLUSTER DOCKER/NAT support  ########################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># In certain deployments, Redis Cluster nodes address discovery fails, because</span>
</span></span><span style=display:flex><span><span style=color:#75715e># addresses are NAT-ted or because ports are forwarded (the typical case is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Docker and other containers).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In order to make Redis Cluster working in such environments, a static</span>
</span></span><span style=display:flex><span><span style=color:#75715e># configuration where each node knows its public address is needed. The</span>
</span></span><span style=display:flex><span><span style=color:#75715e># following two options are used for this scope, and are:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># * cluster-announce-ip</span>
</span></span><span style=display:flex><span><span style=color:#75715e># * cluster-announce-port</span>
</span></span><span style=display:flex><span><span style=color:#75715e># * cluster-announce-bus-port</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Each instructs the node about its address, client port, and cluster message</span>
</span></span><span style=display:flex><span><span style=color:#75715e># bus port. The information is then published in the header of the bus packets</span>
</span></span><span style=display:flex><span><span style=color:#75715e># so that other nodes will be able to correctly map the address of the node</span>
</span></span><span style=display:flex><span><span style=color:#75715e># publishing the information.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If the above options are not used, the normal Redis Cluster auto-detection</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will be used instead.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that when remapped, the bus port may not be at the fixed offset of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># clients port + 10000, so you can specify any port and bus-port depending</span>
</span></span><span style=display:flex><span><span style=color:#75715e># on how they get remapped. If the bus-port is not set, a fixed offset of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 10000 will be used as usual.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Example:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-announce-ip 10.1.1.5</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-announce-port 6379</span>
</span></span><span style=display:flex><span><span style=color:#75715e># cluster-announce-bus-port 6380</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################## SLOW LOG ###################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The Redis Slow Log is a system to log queries that exceeded a specified</span>
</span></span><span style=display:flex><span><span style=color:#75715e># execution time. The execution time does not include the I/O operations</span>
</span></span><span style=display:flex><span><span style=color:#75715e># like talking with the client, sending the reply and so forth,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># but just the time needed to actually execute the command (this is the only</span>
</span></span><span style=display:flex><span><span style=color:#75715e># stage of command execution where the thread is blocked and can not serve</span>
</span></span><span style=display:flex><span><span style=color:#75715e># other requests in the meantime).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># You can configure the slow log with two parameters: one tells Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># what is the execution time, in microseconds, to exceed in order for the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># command to get logged, and the other parameter is the length of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># slow log. When a new command is logged the oldest one is removed from the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># queue of logged commands.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The following time is expressed in microseconds, so 1000000 is equivalent</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to one second. Note that a negative number disables the slow log, while</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a value of zero forces the logging of every command.</span>
</span></span><span style=display:flex><span>slowlog-log-slower-than <span style=color:#ae81ff>10000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># There is no limit to this length. Just be aware that it will consume memory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># You can reclaim memory used by the slow log with SLOWLOG RESET.</span>
</span></span><span style=display:flex><span>slowlog-max-len <span style=color:#ae81ff>128</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>################################ LATENCY MONITOR ##############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The Redis latency monitoring subsystem samples different operations</span>
</span></span><span style=display:flex><span><span style=color:#75715e># at runtime in order to collect data related to possible sources of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># latency of a Redis instance.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Via the LATENCY command this information is available to the user that can</span>
</span></span><span style=display:flex><span><span style=color:#75715e># print graphs and obtain reports.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The system only logs operations that were performed in a time equal or</span>
</span></span><span style=display:flex><span><span style=color:#75715e># greater than the amount of milliseconds specified via the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># latency-monitor-threshold configuration directive. When its value is set</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to zero, the latency monitor is turned off.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default latency monitoring is disabled since it is mostly not needed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># if you don&#39;t have latency issues, and collecting data has a performance</span>
</span></span><span style=display:flex><span><span style=color:#75715e># impact, that while very small, can be measured under big load. Latency</span>
</span></span><span style=display:flex><span><span style=color:#75715e># monitoring can easily be enabled at runtime using the command</span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#34;CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;&#34; if needed.</span>
</span></span><span style=display:flex><span>latency-monitor-threshold <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################# EVENT NOTIFICATION ##############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis can notify Pub/Sub clients about events happening in the key space.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This feature is documented at http://redis.io/topics/notifications</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For instance if keyspace events notification is enabled, and a client</span>
</span></span><span style=display:flex><span><span style=color:#75715e># performs a DEL operation on key &#34;foo&#34; stored in the Database 0, two</span>
</span></span><span style=display:flex><span><span style=color:#75715e># messages will be published via Pub/Sub:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># PUBLISH __keyspace@0__:foo del</span>
</span></span><span style=display:flex><span><span style=color:#75715e># PUBLISH __keyevent@0__:del foo</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is possible to select the events that Redis will notify among a set</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of classes. Every class is identified by a single character:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  $     String commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  l     List commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  s     Set commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  h     Hash commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  z     Sorted set commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  x     Expired events (events generated every time a key expires)</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  e     Evicted events (events generated when a key is evicted for maxmemory)</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  t     Stream commands</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  m     Key-miss events (Note: It is not included in the &#39;A&#39; class)</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  A     Alias for g$lshzxet, so that the &#34;AKE&#34; string means all the events</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#        (Except key-miss events which are excluded from &#39;A&#39; due to their</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#         unique nature).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  The &#34;notify-keyspace-events&#34; takes as argument a string that is composed</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  of zero or multiple characters. The empty string means that notifications</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  are disabled.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  Example: to enable list and generic events, from the point of view of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#           event name, use:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  notify-keyspace-events Elg</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  Example 2: to get the stream of the expired keys subscribing to channel</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#             name __keyevent@0__:expired use:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  notify-keyspace-events Ex</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  By default all notifications are disabled because most users don&#39;t need</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  this feature and the feature has some overhead. Note that if you don&#39;t</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#  specify at least one of K or E, no events will be delivered.</span>
</span></span><span style=display:flex><span>notify-keyspace-events <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################### GOPHER SERVER #################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis contains an implementation of the Gopher protocol, as specified in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the RFC 1436 (https://www.ietf.org/rfc/rfc1436.txt).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The Gopher protocol was very popular in the late &#39;90s. It is an alternative</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to the web, and the implementation both server and client side is so simple</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that the Redis server has just 100 lines of code in order to implement this</span>
</span></span><span style=display:flex><span><span style=color:#75715e># support.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># What do you do with Gopher nowadays? Well Gopher never *really* died, and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># lately there is a movement in order for the Gopher more hierarchical content</span>
</span></span><span style=display:flex><span><span style=color:#75715e># composed of just plain text documents to be resurrected. Some want a simpler</span>
</span></span><span style=display:flex><span><span style=color:#75715e># internet, others believe that the mainstream internet became too much</span>
</span></span><span style=display:flex><span><span style=color:#75715e># controlled, and it&#39;s cool to create an alternative space for people that</span>
</span></span><span style=display:flex><span><span style=color:#75715e># want a bit of fresh air.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Anyway for the 10nth birthday of the Redis, we gave it the Gopher protocol</span>
</span></span><span style=display:flex><span><span style=color:#75715e># as a gift.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># --- HOW IT WORKS? ---</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The Redis Gopher support uses the inline protocol of Redis, and specifically</span>
</span></span><span style=display:flex><span><span style=color:#75715e># two kind of inline requests that were anyway illegal: an empty request</span>
</span></span><span style=display:flex><span><span style=color:#75715e># or any request that starts with &#34;/&#34; (there are no Redis commands starting</span>
</span></span><span style=display:flex><span><span style=color:#75715e># with such a slash). Normal RESP2/RESP3 requests are completely out of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># path of the Gopher protocol implementation and are served as usual as well.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you open a connection to Redis when Gopher is enabled and send it</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a string like &#34;/foo&#34;, if there is a key named &#34;/foo&#34; it is served via the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Gopher protocol.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># In order to create a real Gopher &#34;hole&#34; (the name of a Gopher site in Gopher</span>
</span></span><span style=display:flex><span><span style=color:#75715e># talking), you likely need a script like the following:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   https://github.com/antirez/gopher2redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># --- SECURITY WARNING ---</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If you plan to put Redis on the internet in a publicly accessible address</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to server Gopher pages MAKE SURE TO SET A PASSWORD to the instance.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Once a password is set:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   1. The Gopher server (when enabled, not by default) will still serve</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#      content via Gopher.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   2. However other commands cannot be called before the client will</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#      authenticate.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># So use the &#39;requirepass&#39; option to protect your instance.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note that Gopher is not currently supported when &#39;io-threads-do-reads&#39;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is enabled.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># To enable Gopher support, uncomment the following line and set the option</span>
</span></span><span style=display:flex><span><span style=color:#75715e># from no (the default) to yes.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># gopher-enabled no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>############################### ADVANCED CONFIG ###############################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Hashes are encoded using a memory efficient data structure when they have a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># small number of entries, and the biggest entry does not exceed a given</span>
</span></span><span style=display:flex><span><span style=color:#75715e># threshold. These thresholds can be configured using the following directives.</span>
</span></span><span style=display:flex><span>hash-max-ziplist-entries <span style=color:#ae81ff>512</span>
</span></span><span style=display:flex><span>hash-max-ziplist-value <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Lists are also encoded in a special way to save a lot of space.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The number of entries allowed per internal list node can be specified</span>
</span></span><span style=display:flex><span><span style=color:#75715e># as a fixed maximum size or a maximum number of elements.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For a fixed maximum size, use -5 through -1, meaning:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -5: max size: 64 Kb  &lt;-- not recommended for normal workloads</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -4: max size: 32 Kb  &lt;-- not recommended</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -3: max size: 16 Kb  &lt;-- probably not recommended</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -2: max size: 8 Kb   &lt;-- good</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -1: max size: 4 Kb   &lt;-- good</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Positive numbers mean store up to _exactly_ that number of elements</span>
</span></span><span style=display:flex><span><span style=color:#75715e># per list node.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),</span>
</span></span><span style=display:flex><span><span style=color:#75715e># but if your use case is unique, adjust the settings as necessary.</span>
</span></span><span style=display:flex><span>list-max-ziplist-size -2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Lists may also be compressed.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Compress depth is the number of quicklist ziplist nodes from *each* side of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the list to *exclude* from compression.  The head and tail of the list</span>
</span></span><span style=display:flex><span><span style=color:#75715e># are always uncompressed for fast push/pop operations.  Settings are:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 0: disable all list compression</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1: depth 1 means &#34;don&#39;t start compressing until after 1 node into the list,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    going from either the head or tail&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    [head], [tail] will always be uncompressed; inner nodes will compress.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    2 here means: don&#39;t compress head or head-&gt;next or tail-&gt;prev or tail,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    but compress all nodes between them.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]</span>
</span></span><span style=display:flex><span><span style=color:#75715e># etc.</span>
</span></span><span style=display:flex><span>list-compress-depth <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Sets have a special encoding in just one case: when a set is composed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of just strings that happen to be integers in radix 10 in the range</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of 64 bit signed integers.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The following configuration setting sets the limit in the size of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># set in order to use this special memory saving encoding.</span>
</span></span><span style=display:flex><span>set-max-intset-entries <span style=color:#ae81ff>512</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Similarly to hashes and lists, sorted sets are also specially encoded in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># order to save a lot of space. This encoding is only used when the length and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># elements of a sorted set are below the following limits:</span>
</span></span><span style=display:flex><span>zset-max-ziplist-entries <span style=color:#ae81ff>128</span>
</span></span><span style=display:flex><span>zset-max-ziplist-value <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># HyperLogLog sparse representation bytes limit. The limit includes the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 16 bytes header. When an HyperLogLog using the sparse representation crosses</span>
</span></span><span style=display:flex><span><span style=color:#75715e># this limit, it is converted into the dense representation.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># A value greater than 16000 is totally useless, since at that point the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># dense representation is more memory efficient.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The suggested value is ~ 3000 in order to have the benefits of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the space efficient encoding without slowing down too much PFADD,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># which is O(N) with the sparse encoding. The value can be raised to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ~ 10000 when CPU is not a concern, but space is, and the data set is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># composed of many HyperLogLogs with cardinality in the 0 - 15000 range.</span>
</span></span><span style=display:flex><span>hll-sparse-max-bytes <span style=color:#ae81ff>3000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Streams macro node max size / items. The stream data structure is a radix</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tree of big nodes that encode multiple items inside. Using this configuration</span>
</span></span><span style=display:flex><span><span style=color:#75715e># it is possible to configure how big a single node can be in bytes, and the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># maximum number of items it may contain before switching to a new node when</span>
</span></span><span style=display:flex><span><span style=color:#75715e># appending new stream entries. If any of the following settings are set to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># zero, the limit is ignored, so for instance it is possible to set just a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># max entries limit by setting max-bytes to 0 and max-entries to the desired</span>
</span></span><span style=display:flex><span><span style=color:#75715e># value.</span>
</span></span><span style=display:flex><span>stream-node-max-bytes <span style=color:#ae81ff>4096</span>
</span></span><span style=display:flex><span>stream-node-max-entries <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># order to help rehashing the main Redis hash table (the one mapping top-level</span>
</span></span><span style=display:flex><span><span style=color:#75715e># keys to values). The hash table implementation Redis uses (see dict.c)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># performs a lazy rehashing: the more operation you run into a hash table</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that is rehashing, the more rehashing &#34;steps&#34; are performed, so if the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># server is idle the rehashing is never complete and some more memory is used</span>
</span></span><span style=display:flex><span><span style=color:#75715e># by the hash table.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default is to use this millisecond 10 times every second in order to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># actively rehash the main dictionaries, freeing memory when possible.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># If unsure:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># use &#34;activerehashing no&#34; if you have hard latency requirements and it is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># not a good thing in your environment that Redis can reply from time to time</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to queries with 2 milliseconds delay.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># use &#34;activerehashing yes&#34; if you don&#39;t have such hard requirements but</span>
</span></span><span style=display:flex><span><span style=color:#75715e># want to free memory asap when possible.</span>
</span></span><span style=display:flex><span>activerehashing yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The client output buffer limits can be used to force disconnection of clients</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that are not reading data from the server fast enough for some reason (a</span>
</span></span><span style=display:flex><span><span style=color:#75715e># common reason is that a Pub/Sub client can&#39;t consume messages as fast as the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># publisher can produce them).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The limit can be set differently for the three different classes of clients:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># normal -&gt; normal clients including MONITOR clients</span>
</span></span><span style=display:flex><span><span style=color:#75715e># replica  -&gt; replica clients</span>
</span></span><span style=display:flex><span><span style=color:#75715e># pubsub -&gt; clients subscribed to at least one pubsub channel or pattern</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The syntax of every client-output-buffer-limit directive is the following:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># A client is immediately disconnected once the hard limit is reached, or if</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the soft limit is reached and remains reached for the specified number of</span>
</span></span><span style=display:flex><span><span style=color:#75715e># seconds (continuously).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># So for instance if the hard limit is 32 megabytes and the soft limit is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 16 megabytes / 10 seconds, the client will get disconnected immediately</span>
</span></span><span style=display:flex><span><span style=color:#75715e># if the size of the output buffers reach 32 megabytes, but will also get</span>
</span></span><span style=display:flex><span><span style=color:#75715e># disconnected if the client reaches 16 megabytes and continuously overcomes</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the limit for 10 seconds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default normal clients are not limited because they don&#39;t receive data</span>
</span></span><span style=display:flex><span><span style=color:#75715e># without asking (in a push way), but just after a request, so only</span>
</span></span><span style=display:flex><span><span style=color:#75715e># asynchronous clients may create a scenario where data is requested faster</span>
</span></span><span style=display:flex><span><span style=color:#75715e># than it can read.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Instead there is a default limit for pubsub and replica clients, since</span>
</span></span><span style=display:flex><span><span style=color:#75715e># subscribers and replicas receive data in a push fashion.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Both the hard or the soft limit can be disabled by setting them to zero.</span>
</span></span><span style=display:flex><span>client-output-buffer-limit normal <span style=color:#ae81ff>0</span> <span style=color:#ae81ff>0</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>client-output-buffer-limit replica 256mb 64mb <span style=color:#ae81ff>60</span>
</span></span><span style=display:flex><span>client-output-buffer-limit pubsub 32mb 8mb <span style=color:#ae81ff>60</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Client query buffers accumulate new commands. They are limited to a fixed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># amount by default in order to avoid that a protocol desynchronization (for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># instance due to a bug in the client) will lead to unbound memory usage in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the query buffer. However you can configure it here if you have very special</span>
</span></span><span style=display:flex><span><span style=color:#75715e># needs, such us huge multi/exec requests or alike.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># client-query-buffer-limit 1gb</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># In the Redis protocol, bulk requests, that are, elements representing single</span>
</span></span><span style=display:flex><span><span style=color:#75715e># strings, are normally limited to 512 mb. However you can change this limit</span>
</span></span><span style=display:flex><span><span style=color:#75715e># here, but must be 1mb or greater</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># proto-max-bulk-len 512mb</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis calls an internal function to perform many background tasks, like</span>
</span></span><span style=display:flex><span><span style=color:#75715e># closing connections of clients in timeout, purging expired keys that are</span>
</span></span><span style=display:flex><span><span style=color:#75715e># never requested, and so forth.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Not all tasks are performed with the same frequency, but Redis checks for</span>
</span></span><span style=display:flex><span><span style=color:#75715e># tasks to perform according to the specified &#34;hz&#34; value.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># By default &#34;hz&#34; is set to 10. Raising the value will use more CPU when</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis is idle, but at the same time will make Redis more responsive when</span>
</span></span><span style=display:flex><span><span style=color:#75715e># there are many keys expiring at the same time, and timeouts may be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># handled with more precision.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The range is between 1 and 500, however a value over 100 is usually not</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a good idea. Most users should use the default of 10 and raise this up to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 100 only in environments where very low latency is required.</span>
</span></span><span style=display:flex><span>hz <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Normally it is useful to have an HZ value which is proportional to the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># number of clients connected. This is useful in order, for instance, to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># avoid too many clients are processed for each background task invocation</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to avoid latency spikes.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Since the default HZ value by default is conservatively set to 10, Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># offers, and enables by default, the ability to use an adaptive HZ value</span>
</span></span><span style=display:flex><span><span style=color:#75715e># which will temporarily raise when there are many connected clients.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># When dynamic HZ is enabled, the actual configured HZ will be used</span>
</span></span><span style=display:flex><span><span style=color:#75715e># as a baseline, but multiples of the configured HZ value will be actually</span>
</span></span><span style=display:flex><span><span style=color:#75715e># used as needed once more clients are connected. In this way an idle</span>
</span></span><span style=display:flex><span><span style=color:#75715e># instance will use very little CPU time while a busy instance will be</span>
</span></span><span style=display:flex><span><span style=color:#75715e># more responsive.</span>
</span></span><span style=display:flex><span>dynamic-hz yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When a child rewrites the AOF file, if the following option is enabled</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the file will be fsync-ed every 32 MB of data generated. This is useful</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to commit the file to the disk more incrementally and avoid</span>
</span></span><span style=display:flex><span><span style=color:#75715e># big latency spikes.</span>
</span></span><span style=display:flex><span>aof-rewrite-incremental-fsync yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># When redis saves RDB file, if the following option is enabled</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the file will be fsync-ed every 32 MB of data generated. This is useful</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in order to commit the file to the disk more incrementally and avoid</span>
</span></span><span style=display:flex><span><span style=color:#75715e># big latency spikes.</span>
</span></span><span style=display:flex><span>rdb-save-incremental-fsync yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good</span>
</span></span><span style=display:flex><span><span style=color:#75715e># idea to start with the default settings and only change them after investigating</span>
</span></span><span style=display:flex><span><span style=color:#75715e># how to improve the performances and how the keys LFU change over time, which</span>
</span></span><span style=display:flex><span><span style=color:#75715e># is possible to inspect via the OBJECT FREQ command.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># There are two tunable parameters in the Redis LFU implementation: the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># counter logarithm factor and the counter decay time. It is important to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># understand what the two parameters mean before changing them.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The LFU counter is just 8 bits per key, it&#39;s maximum value is 255, so Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e># uses a probabilistic increment with logarithmic behavior. Given the value</span>
</span></span><span style=display:flex><span><span style=color:#75715e># of the old counter, when a key is accessed, the counter is incremented in</span>
</span></span><span style=display:flex><span><span style=color:#75715e># this way:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1. A random number R between 0 and 1 is extracted.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. The counter is incremented only if R &lt; P.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default lfu-log-factor is 10. This is a table of how the frequency</span>
</span></span><span style=display:flex><span><span style=color:#75715e># counter changes with a different number of accesses with different</span>
</span></span><span style=display:flex><span><span style=color:#75715e># logarithmic factors:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># +--------+------------+------------+------------+------------+------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># +--------+------------+------------+------------+------------+------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | 0      | 104        | 255        | 255        | 255        | 255        |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># +--------+------------+------------+------------+------------+------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | 1      | 18         | 49         | 255        | 255        | 255        |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># +--------+------------+------------+------------+------------+------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | 10     | 10         | 18         | 142        | 255        | 255        |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># +--------+------------+------------+------------+------------+------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e># | 100    | 8          | 11         | 49         | 143        | 255        |</span>
</span></span><span style=display:flex><span><span style=color:#75715e># +--------+------------+------------+------------+------------+------------+</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NOTE: The above table was obtained by running the following commands:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   redis-benchmark -n 1000000 incr foo</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   redis-cli object freq foo</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># NOTE 2: The counter initial value is 5 in order to give new objects a chance</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to accumulate hits.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The counter decay time is the time, in minutes, that must elapse in order</span>
</span></span><span style=display:flex><span><span style=color:#75715e># for the key counter to be divided by two (or decremented if it has a value</span>
</span></span><span style=display:flex><span><span style=color:#75715e># less &lt;= 10).</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The default value for the lfu-decay-time is 1. A special value of 0 means to</span>
</span></span><span style=display:flex><span><span style=color:#75715e># decay the counter every time it happens to be scanned.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># lfu-log-factor 10</span>
</span></span><span style=display:flex><span><span style=color:#75715e># lfu-decay-time 1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>########################### ACTIVE DEFRAGMENTATION #######################</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># What is active defragmentation?</span>
</span></span><span style=display:flex><span><span style=color:#75715e># -------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Active (online) defragmentation allows a Redis server to compact the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># spaces left between small allocations and deallocations of data in memory,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># thus allowing to reclaim back memory.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fragmentation is a natural process that happens with every allocator (but</span>
</span></span><span style=display:flex><span><span style=color:#75715e># less so with Jemalloc, fortunately) and certain workloads. Normally a server</span>
</span></span><span style=display:flex><span><span style=color:#75715e># restart is needed in order to lower the fragmentation, or at least to flush</span>
</span></span><span style=display:flex><span><span style=color:#75715e># away all the data and create it again. However thanks to this feature</span>
</span></span><span style=display:flex><span><span style=color:#75715e># implemented by Oran Agra for Redis 4.0 this process can happen at runtime</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in a &#34;hot&#34; way, while the server is running.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Basically when the fragmentation is over a certain level (see the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># configuration options below) Redis will start to create new copies of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># values in contiguous memory regions by exploiting certain specific Jemalloc</span>
</span></span><span style=display:flex><span><span style=color:#75715e># features (in order to understand if an allocation is causing fragmentation</span>
</span></span><span style=display:flex><span><span style=color:#75715e># and to allocate it in a better place), and at the same time, will release the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># old copies of the data. This process, repeated incrementally for all the keys</span>
</span></span><span style=display:flex><span><span style=color:#75715e># will cause the fragmentation to drop back to normal values.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Important things to understand:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1. This feature is disabled by default, and only works if you compiled Redis</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    to use the copy of Jemalloc we ship with the source code of Redis.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    This is the default with Linux builds.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. You never need to enable this feature if you don&#39;t have fragmentation</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    issues.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. Once you experience fragmentation, you can enable this feature when</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#    needed with the command &#34;CONFIG SET activedefrag yes&#34;.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># The configuration parameters are able to fine tune the behavior of the</span>
</span></span><span style=display:flex><span><span style=color:#75715e># defragmentation process. If you are not sure about what they mean it is</span>
</span></span><span style=display:flex><span><span style=color:#75715e># a good idea to leave the defaults untouched.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Enabled active defragmentation</span>
</span></span><span style=display:flex><span><span style=color:#75715e># activedefrag no</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Minimum amount of fragmentation waste to start active defrag</span>
</span></span><span style=display:flex><span><span style=color:#75715e># active-defrag-ignore-bytes 100mb</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Minimum percentage of fragmentation to start active defrag</span>
</span></span><span style=display:flex><span><span style=color:#75715e># active-defrag-threshold-lower 10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Maximum percentage of fragmentation at which we use maximum effort</span>
</span></span><span style=display:flex><span><span style=color:#75715e># active-defrag-threshold-upper 100</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Minimal effort for defrag in CPU percentage, to be used when the lower</span>
</span></span><span style=display:flex><span><span style=color:#75715e># threshold is reached</span>
</span></span><span style=display:flex><span><span style=color:#75715e># active-defrag-cycle-min 1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Maximal effort for defrag in CPU percentage, to be used when the upper</span>
</span></span><span style=display:flex><span><span style=color:#75715e># threshold is reached</span>
</span></span><span style=display:flex><span><span style=color:#75715e># active-defrag-cycle-max 25</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Maximum number of set/hash/zset/list fields that will be processed from</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the main dictionary scan</span>
</span></span><span style=display:flex><span><span style=color:#75715e># active-defrag-max-scan-fields 1000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Jemalloc background thread for purging will be enabled by default</span>
</span></span><span style=display:flex><span>jemalloc-bg-thread yes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># It is possible to pin different threads and processes of Redis to specific</span>
</span></span><span style=display:flex><span><span style=color:#75715e># CPUs in your system, in order to maximize the performances of the server.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This is useful both in order to pin different Redis threads in different</span>
</span></span><span style=display:flex><span><span style=color:#75715e># CPUs, but also in order to make sure that multiple Redis instances running</span>
</span></span><span style=display:flex><span><span style=color:#75715e># in the same host will be pinned to different CPUs.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Normally you can do this using the &#34;taskset&#34; command, however it is also</span>
</span></span><span style=display:flex><span><span style=color:#75715e># possible to this via Redis configuration directly, both in Linux and FreeBSD.</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># You can pin the server/IO threads, bio threads, aof rewrite child process, and</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the bgsave child process. The syntax to specify the cpu list is the same as</span>
</span></span><span style=display:flex><span><span style=color:#75715e># the taskset command:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set redis server/io threads to cpu affinity 0,2,4,6:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># server_cpulist 0-7:2</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set bio threads to cpu affinity 1,3:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># bio_cpulist 1,3</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set aof rewrite child process to cpu affinity 8,9,10,11:</span>
</span></span><span style=display:flex><span><span style=color:#75715e># aof_rewrite_cpulist 8-11</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set bgsave child process to cpu affinity 1,10,11</span>
</span></span><span style=display:flex><span><span style=color:#75715e># bgsave_cpulist 1,10-11</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># In some cases redis will emit warnings and even refuse to start if it detects</span>
</span></span><span style=display:flex><span><span style=color:#75715e># that the system is in bad state, it is possible to suppress these warnings</span>
</span></span><span style=display:flex><span><span style=color:#75715e># by setting the following config which takes a space delimited list of warnings</span>
</span></span><span style=display:flex><span><span style=color:#75715e># to suppress</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ignore-warnings ARM64-COW-BUG</span></span></span></code></pre></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/docs/redis/1.5redis%E4%BA%8B%E5%8A%A1%E6%93%8D%E4%BD%9C/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>1.5 Redis事务操作</span>
</a></span><span><a href=/docs/redis/1.7redis%E6%8C%81%E4%B9%85%E5%8C%96/ class="flex align-center"><span>1.7 Redis持久化</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div></main></body></html>